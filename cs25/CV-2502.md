
## 2025-02-06 (Thu)
- [ ] [\[2502.03444\] Masked Autoencoders Are Effective Tokenizers for Diffusion Models](https://arxiv.org/abs/2502.03444) (CMU)
- [ ] [\[2502.03207\] MotionAgent: Fine-grained Controllable Video Generation via Motion Field Agent](https://arxiv.org/abs/2502.03207) (NTU)
- [ ] [\[2502.02977\] Disentangling CLIP Features for Enhanced Localized Understanding](https://arxiv.org/abs/2502.02977) (Illinois)
- [ ] [\[2502.02936\] Every Angle Is Worth A Second Glance: Mining Kinematic Skeletal Structures from Multi-view Joint Cloud](https://arxiv.org/abs/2502.02936) (BU)
- [ ] [\[2502.02867\] Domain-Invariant Per-Frame Feature Extraction for Cross-Domain Imitation Learning with Visual Observations](https://arxiv.org/abs/2502.02867) (ICML)
- [ ] [\[2502.02835\] A Survey of Sample-Efficient Deep Learning for Change Detection in Remote Sensing: Tasks, Strategies, and Challenges](https://arxiv.org/abs/2502.02835) (University of Tokyo)
- [ ] [\[2502.02763\] Rethinking Vision Transformer for Object Centric Foundation Models](https://arxiv.org/abs/2502.02763) (University of TÃ¼bingen)
- [ ] [\[2502.02741\] RFMedSAM 2: Automatic Prompt Refinement for Enhanced Volumetric Medical Image Segmentation with SAM 2](https://arxiv.org/abs/2502.02741) (Peking)
- [ ] [\[2502.02707\] Multiple Instance Learning with Coarse-to-Fine Self-Distillation](https://arxiv.org/abs/2502.02707) (University of Edinburgh)
- [ ] [\[2502.02690\] Controllable Video Generation with Provable Disentanglement](https://arxiv.org/abs/2502.02690) (CMU)
- [ ] [\[2502.02676\] Blind Visible Watermark Removal with Morphological Dilation](https://arxiv.org/abs/2502.02676) (Vanderbilt University)
- [ ] [\[2502.02607\] MIND: Microstructure INverse Design with Generative Hybrid Neural Representation](https://arxiv.org/abs/2502.02607) (ETH)
- [ ] [\[2502.03270\] When Pre-trained Visual Representations Fall Short: Limitations in Visuo-Motor Robot Learning](https://arxiv.org/abs/2502.03270) (University of Edinburgh)
- [ ] [\[2502.02922\] Elucidating the Preconditioning in Consistency Distillation](https://arxiv.org/abs/2502.02922) (ICLR)
- [ ] [\[2502.02773\] SD++: Enhancing Standard Definition Maps by Incorporating Road Knowledge using LLMs](https://arxiv.org/abs/2502.02773) (UCSD)
- [ ] [\[2502.02610\] Secure & Personalized Music-to-Video Generation via CHARCHA](https://arxiv.org/abs/2502.02610) (CMU, NIPS)

## 2025-02-05 (Wed)
- [ ] [\[2502.02525\] Diff9D: Diffusion-Based Domain-Generalized Category-Level 9-DoF Object Pose Estimation](https://arxiv.org/abs/2502.02525) (XJTU)
- [ ] [\[2502.02501\] Graph-based Document Structure Analysis](https://arxiv.org/abs/2502.02501) (ICLR)
- [ ] [\[2502.02454\] IMDPrompter: Adapting SAM to Image Manipulation Detection by Cross-View Automated Prompt Learning](https://arxiv.org/abs/2502.02454) (SJTU)
- [ ] [\[2502.02449\] TUMTraffic-VideoQA: A Benchmark for Unified Spatio-Temporal Video Understanding in Traffic Scenes](https://arxiv.org/abs/2502.02449) (TUM)
- [ ] [\[2502.02372\] MaintaAvatar: A Maintainable Avatar Based on Neural Radiance Fields by Continual Learning](https://arxiv.org/abs/2502.02372) (SYSU)
- [ ] [\[2502.02340\] Transfer Risk Map: Mitigating Pixel-level Negative Transfer in Medical Segmentation](https://arxiv.org/abs/2502.02340) (Tsinghua)
- [ ] [\[2502.02338\] Geometric Neural Process Fields](https://arxiv.org/abs/2502.02338) (UVA.NL)
- [ ] [\[2502.02334\] Event-aided Semantic Scene Completion](https://arxiv.org/abs/2502.02334) (ZJU)
- [ ] [\[2502.02257\] UNIP: Rethinking Pre-trained Attention Patterns for Infrared Semantic Segmentation](https://arxiv.org/abs/2502.02257) (ICLR)
- [ ] [\[2502.02247\] Rotation-Adaptive Point Cloud Domain Generalization via Intricate Orientation Learning](https://arxiv.org/abs/2502.02247) (TPAMI)
- [ ] [\[2502.02225\] Exploring the latent space of diffusion models directly through singular value decomposition](https://arxiv.org/abs/2502.02225) (ZJU)
- [ ] [\[2502.02215\] InterLCM: Low-Quality Images as Intermediate States of Latent Consistency Models for Effective Blind Face Restoration](https://arxiv.org/abs/2502.02215) (ICLR)
- [ ] [\[2502.02196\] Exploiting Ensemble Learning for Cross-View Isolated Sign Language Recognition](https://arxiv.org/abs/2502.02196) (USTC)
- [ ] [\[2502.02187\] ShapeShifter: 3D Variations Using Multiscale and Sparse Point-Voxel Diffusion](https://arxiv.org/abs/2502.02187) (Inria)
- [ ] [\[2502.02182\] Sequence models for continuous cell cycle stage prediction from brightfield images](https://arxiv.org/abs/2502.02182) (EPFL)
- [ ] [\[2502.02144\] DOC-Depth: A novel approach for dense depth ground truth generation](https://arxiv.org/abs/2502.02144) (PSL University)
- [ ] [\[2502.02097\] VerteNet -- A Multi-Context Hybrid CNN Transformer for Accurate Vertebral Landmark Localization in Lateral Spine DXA Images](https://arxiv.org/abs/2502.02097) (SYSU)
- [ ] [\[2502.02096\] Dual-Flow: Transferable Multi-Target, Instance-Agnostic Attacks via In-the-wild Cascading Flow Optimization](https://arxiv.org/abs/2502.02096) (Tsinghua)
- [ ] [\[2502.02091\] Efficient Dynamic Scene Editing via 4D Gaussian-based Static-Dynamic Separation](https://arxiv.org/abs/2502.02091) (KAIST)
- [ ] [\[2502.02027\] From Fog to Failure: How Dehazing Can Harm Clear Image Object Detection](https://arxiv.org/abs/2502.02027) (Rochester Institute of Technology)
- [ ] [\[2502.01969\] Mitigating Object Hallucinations in Large Vision-Language Models via Attention Calibration](https://arxiv.org/abs/2502.01969) (USyd)
- [ ] [\[2502.01962\] Memory Efficient Transformer Adapter for Dense Predictions](https://arxiv.org/abs/2502.01962) (NJU, ICLR)
- [ ] [\[2502.01959\] MATCNN: Infrared and Visible Image Fusion Method Based on Multi-scale CNN with Attention Transformer](https://arxiv.org/abs/2502.01959) (Fudan)
- [ ] [\[2502.01890\] Geometric Framework for 3D Cell Segmentation Correction](https://arxiv.org/abs/2502.01890) (Columbia University)
- [ ] [\[2502.01850\] Foundation Model-Based Apple Ripeness and Size Estimation for Selective Harvesting](https://arxiv.org/abs/2502.01850) (Michigan State University)
- [ ] [\[2502.01776\] Sparse VideoGen: Accelerating Video Diffusion Transformers with Spatial-Temporal Sparsity](https://arxiv.org/abs/2502.01776) (Berkeley)
- [ ] [\[2502.01707\] CLIP-DQA: Blindly Evaluating Dehazed Images from Global and Local Perspectives Using CLIP](https://arxiv.org/abs/2502.01707) (SYSU)
- [ ] [\[2502.02562\] Learning the RoPEs: Better 2D and 3D Position Encodings with STRING](https://arxiv.org/abs/2502.02562) (Google)
- [ ] [\[2502.02558\] Particle Trajectory Representation Learning with Masked Point Modeling](https://arxiv.org/abs/2502.02558) (Stanford)
- [ ] [\[2502.02500\] The Skin Game: Revolutionizing Standards for AI Dermatology Model Comparison](https://arxiv.org/abs/2502.02500) (MIT)
- [ ] [\[2502.02458\] SAISA: Towards Multimodal Large Language Models with Both Training and Inference Efficiency](https://arxiv.org/abs/2502.02458) (UCAS)
- [ ] [\[2502.02175\] VLA-Cache: Towards Efficient Vision-Language-Action Model via Adaptive Token Caching in Robotic Manipulation](https://arxiv.org/abs/2502.02175) (USyd)
- [ ] [\[2502.02048\] Efficient Domain Adaptation of Multimodal Embeddings using Constrastive Learning](https://arxiv.org/abs/2502.02048) (MIT)

## 2025-02-04 (Tue)
- [ ] [\[2502.01576\] Robust-LLaVA: On the Effectiveness of Large-Scale Robust Image Encoders for Multi-modal Large Language Models](https://arxiv.org/abs/2502.01576) (MBZUAI)
- [ ] [\[2502.01467\] Deep Unfolding Multi-modal Image Fusion Network via Attribution Analysis](https://arxiv.org/abs/2502.01467) (XJTU)
- [ ] [\[2502.01441\] Improved Training Technique for Latent Consistency Models](https://arxiv.org/abs/2502.01441) (ICLR)
- [ ] [\[2502.01403\] AdaSVD: Adaptive Singular Value Decomposition for Large Language Models](https://arxiv.org/abs/2502.01403) (SJTU)
- [ ] [\[2502.01357\] Bayesian Approximation-Based Trajectory Prediction and Tracking with 4D Radar](https://arxiv.org/abs/2502.01357) (KAIST)
- [ ] [\[2502.01356\] Quasi-Conformal Convolution : A Learnable Convolution for Deep Learning on Riemann Surfaces](https://arxiv.org/abs/2502.01356) (CUHK)
- [ ] [\[2502.01309\] Heterogeneous Image GNN: Graph-Conditioned Diffusion for Image Synthesis](https://arxiv.org/abs/2502.01309) (Cambridge)
- [ ] [\[2502.01303\] Partial Channel Network: Compute Fewer, Perform Better](https://arxiv.org/abs/2502.01303) (XJTU)
- [ ] [\[2502.01297\] XR-VIO: High-precision Visual Inertial Odometry with Fast Initialization for XR Applications](https://arxiv.org/abs/2502.01297) (SenseTime)
- [ ] [\[2502.01201\] One-to-Normal: Anomaly Personalization for Few-shot Anomaly Detection](https://arxiv.org/abs/2502.01201) (BUPT, NIPS)
- [ ] [\[2502.01199\] Nearly Lossless Adaptive Bit Switching](https://arxiv.org/abs/2502.01199) (XJTU)
- [ ] [\[2502.01191\] Towards Robust and Reliable Concept Representations: Reliability-Enhanced Concept Embedding Model](https://arxiv.org/abs/2502.01191) (NTU)
- [ ] [\[2502.01183\] Enhancing Environmental Robustness in Few-shot Learning via Conditional Representation Learning](https://arxiv.org/abs/2502.01183) (Fudan, TIP)
- [ ] [\[2502.01105\] LayerTracer: Cognitive-Aligned Layered SVG Synthesis via Diffusion Transformer](https://arxiv.org/abs/2502.01105) (NUS)
- [ ] [\[2502.01101\] VidSketch: Hand-drawn Sketch-Driven Video Generation with Diffusion Control](https://arxiv.org/abs/2502.01101) (ZJU)
- [ ] [\[2502.01080\] BC-GAN: A Generative Adversarial Network for Synthesizing a Batch of Collocated Clothing](https://arxiv.org/abs/2502.01080) (HIT)
- [ ] [\[2502.01051\] Diffusion Model as a Noise-Aware Latent Reward Model for Step-Level Preference Optimization](https://arxiv.org/abs/2502.01051) (IA CAS)
- [ ] [\[2502.01004\] ZeroBP: Learning Position-Aware Correspondence for Zero-shot 6D Pose Estimation in Bin-Picking](https://arxiv.org/abs/2502.01004) (HIT)
- [ ] [\[2502.01002\] Multi-Resolution SAR and Optical Remote Sensing Image Registration Methods: A Review, Datasets, and Future Perspectives](https://arxiv.org/abs/2502.01002) (WHU)
- [ ] [\[2502.01000\] Adapting Foundation Models for Few-Shot Medical Image Segmentation: Actively and Sequentially](https://arxiv.org/abs/2502.01000) (Tsinghua)
- [ ] [\[2502.00992\] FCBoost-Net: A Generative Network for Synthesizing Multiple Collocated Outfits via Fashion Compatibility Boosting](https://arxiv.org/abs/2502.00992) (HIT, ACMMM)
- [ ] [\[2502.00965\] CLIP-UP: A Simple and Efficient Mixture-of-Experts CLIP Training Recipe with Sparse Upcycling](https://arxiv.org/abs/2502.00965) (Apple)
- [ ] [\[2502.00960\] SAM-guided Pseudo Label Enhancement for Multi-modal 3D Semantic Segmentation](https://arxiv.org/abs/2502.00960) (University of Michigan)
- [ ] [\[2502.00954\] Hypo3D: Exploring Hypothetical Reasoning in 3D](https://arxiv.org/abs/2502.00954) (Imperial)
- [ ] [\[2502.00869\] STAF: Sinusoidal Trainable Activation Functions for Implicit Neural Representation](https://arxiv.org/abs/2502.00869) (University of Toronto)
- [ ] [\[2502.00730\] Spatio-Temporal Progressive Attention Model for EEG Classification in Rapid Serial Visual Presentation Task](https://arxiv.org/abs/2502.00730) (Xidian)
- [ ] [\[2502.00688\] High-Order Matching for One-Step Shortcut Diffusion Models](https://arxiv.org/abs/2502.00688) (UT Austin)
- [ ] [\[2502.00639\] Zeroth-order Informed Fine-Tuning for Diffusion Model: A Recursive Likelihood Ratio Optimizer](https://arxiv.org/abs/2502.00639) (Peking)
- [ ] [\[2502.00630\] Self-Prompt SAM: Medical Image Segmentation via Automatic Prompt SAM Adaptation](https://arxiv.org/abs/2502.00630) (Peking)
- [ ] [\[2502.00618\] DesCLIP: Robust Continual Adaptation via General Attribute Descriptions for Pretrained Vision-Language Models](https://arxiv.org/abs/2502.00618) (UESTC)
- [ ] [\[2502.00568\] Generating crossmodal gene expression from cancer histopathology improves multimodal AI predictions](https://arxiv.org/abs/2502.00568) (Alan Turing Institute)
- [ ] [\[2502.00433\] CAT Pruning: Cluster-Aware Token Pruning For Text-to-Image Diffusion Models](https://arxiv.org/abs/2502.00433) (Peking)
- [ ] [\[2502.00426\] TeST-V: TEst-time Support-set Tuning for Zero-shot Video Classification](https://arxiv.org/abs/2502.00426) (NJU)
- [ ] [\[2502.00418\] Parameter Efficient Fine-Tuning of Segment Anything Model](https://arxiv.org/abs/2502.00418) (University of GÃ¶ttingen)
- [ ] [\[2502.00392\] RefDrone: A Challenging Benchmark for Referring Expression Comprehension in Drone Scenes](https://arxiv.org/abs/2502.00392) (WHU)
- [ ] [\[2502.00382\] Masked Generative Nested Transformers with Decode Time Scaling](https://arxiv.org/abs/2502.00382) (Google)
- [ ] [\[2502.00360\] Shape from Semantics: 3D Shape Generation from Multi-View Semantics](https://arxiv.org/abs/2502.00360) (USTC)
- [ ] [\[2502.00342\] Embodied Intelligence for 3D Understanding: A Survey on 3D Scene Question Answering](https://arxiv.org/abs/2502.00342) (USyd)
- [ ] [\[2502.00333\] BiMaCoSR: Binary One-Step Diffusion Model Leveraging Flexible Matrix Compression for Real Super-Resolution](https://arxiv.org/abs/2502.00333) (SJTU)
- [ ] [\[2502.00307\] A Diffusion Model Translator for Efficient Image-to-Image Translation](https://arxiv.org/abs/2502.00307) (SJTU)
- [ ] [\[2502.00156\] ALBAR: Adversarial Learning approach to mitigate Biases in Action Recognition](https://arxiv.org/abs/2502.00156) (ICLR)
- [ ] [\[2502.00129\] ProtoSnap: Prototype Alignment for Cuneiform Signs](https://arxiv.org/abs/2502.00129) (ICLR)
- [ ] [\[2502.01427\] Structural features of the fly olfactory circuit mitigate the stability-plasticity dilemma in continual learning](https://arxiv.org/abs/2502.01427) (Tsinghua)
- [ ] [\[2502.01385\] Detecting Backdoor Samples in Contrastive Language Image Pretraining](https://arxiv.org/abs/2502.01385) (ICLR)
- [ ] [\[2502.01218\] Provable Ordering and Continuity in Vision-Language Pretraining for Generalizable Embodied Agents](https://arxiv.org/abs/2502.01218) (Queensland)
- [ ] [\[2502.01158\] MIND: Modality-Informed Knowledge Distillation Framework for Multimodal Clinical Prediction Tasks](https://arxiv.org/abs/2502.01158) (NYU)
- [ ] [\[2502.01117\] Learning to Learn Weight Generation via Trajectory Diffusion](https://arxiv.org/abs/2502.01117) (NTU)
- [ ] [\[2502.01046\] Emotional Face-to-Speech](https://arxiv.org/abs/2502.01046) (Fudan)
- [ ] [\[2502.00987\] RandLoRA: Full-rank parameter-efficient fine-tuning of large models](https://arxiv.org/abs/2502.00987) (ICLR)
- [ ] [\[2502.00754\] Continuity-Preserving Convolutional Autoencoders for Learning Continuous Latent Dynamical Models from Images](https://arxiv.org/abs/2502.00754) (NUS)
- [ ] [\[2502.00745\] BEEM: Boosting Performance of Early Exit DNNs using Multi-Exit Classifiers as Experts](https://arxiv.org/abs/2502.00745) (ICLR)
- [ ] [\[2502.00712\] Registration-Enhanced Segmentation Method for Prostate Cancer in Ultrasound Images](https://arxiv.org/abs/2502.00712) (Stanford)
- [ ] [\[2502.00698\] MM-IQ: Benchmarking Human-Like Abstraction and Reasoning in Multimodal Models](https://arxiv.org/abs/2502.00698) (UCAS)
- [ ] [\[2502.00619\] Distribution-aware Fairness Learning in Medical Image Segmentation From A Control-Theoretic Perspective](https://arxiv.org/abs/2502.00619) (Harvard)
- [ ] [\[2502.00545\] Integrating Frequency Guidance into Multi-source Domain Generalization for Bearing Fault Diagnosis](https://arxiv.org/abs/2502.00545) (Xiamen)
- [ ] [\[2502.00473\] Weak-to-Strong Diffusion with Reflection](https://arxiv.org/abs/2502.00473) (HKUST(GZ))
- [ ] [\[2502.00408\] Segment Anything for Histopathology](https://arxiv.org/abs/2502.00408) (University of GÃ¶ttingen)
- [ ] [\[2502.00395\] FlexCloud: Direct, Modular Georeferencing and Drift-Correction of Point Cloud Maps](https://arxiv.org/abs/2502.00395) (TUM)
- [ ] [\[2502.00374\] A Unit-based System and Dataset for Expressive Direct Speech-to-Speech Translation](https://arxiv.org/abs/2502.00374) (Tsinghua)
- [ ] [\[2502.00366\] Prostate-Specific Foundation Models for Enhanced Detection of Clinically Significant Cancer](https://arxiv.org/abs/2502.00366) (Stanford)
- [ ] [\[2502.00253\] Patch Triplet Similarity Purification for Guided Real-World Low-Dose CT Image Denoising](https://arxiv.org/abs/2502.00253) (Nankai)
- [ ] [\[2502.00241\] Mordal: Automated Pretrained Model Selection for Vision Language Models](https://arxiv.org/abs/2502.00241) (University of Michigan)
- [ ] [\[2502.00234\] Fast Solvers for Discrete Diffusion Models: Theory and Applications of High-Order Algorithms](https://arxiv.org/abs/2502.00234) (Stanford)
- [ ] [\[2502.00114\] Mobile Robot Navigation Using Hand-Drawn Maps: A Vision Language Model Approach](https://arxiv.org/abs/2502.00114) (University of Toronto)

## 2025-02-03 (Mon)
- [ ] [\[2501.19252\] Inference-Time Text-to-Video Alignment with Diffusion Latent Beam Search](https://arxiv.org/abs/2501.19252) (University of Tokyo)
- [ ] [\[2501.19160\] RMDM: Radio Map Diffusion Model with Physics Informed](https://arxiv.org/abs/2501.19160) (HKUST(GZ))
- [ ] [\[2501.19159\] GDO: Gradual Domain Osmosis](https://arxiv.org/abs/2501.19159) (ICML)
- [ ] [\[2501.19155\] SWAT: Sliding Window Adversarial Training for Gradual Domain Adaptation](https://arxiv.org/abs/2501.19155) (UESTC, ICML)
- [ ] [\[2501.19129\] RGB-Event ISP: The Dataset and Benchmark](https://arxiv.org/abs/2501.19129) (HKUST(GZ), ICLR)
- [ ] [\[2501.19111\] A Benchmark for Incremental Micro-expression Recognition](https://arxiv.org/abs/2501.19111) (HIT)
- [ ] [\[2501.19086\] Fairness Analysis of CLIP-Based Foundation Models for X-Ray Image Classification](https://arxiv.org/abs/2501.19086) (UESTC)
- [ ] [\[2501.19084\] Laser: Efficient Language-Guided Segmentation in Neural Radiance Fields](https://arxiv.org/abs/2501.19084) (A*STAR,, TPAMI)
- [ ] [\[2501.19083\] MotionPCM: Real-Time Motion Synthesis with Phased Consistency Model](https://arxiv.org/abs/2501.19083) (UCL)
- [ ] [\[2501.19069\] Improving vision-language alignment with graph spiking hybrid Networks](https://arxiv.org/abs/2501.19069) (Tongji)
- [ ] [\[2501.19066\] Concept Steerers: Leveraging K-Sparse Autoencoders for Controllable Generations](https://arxiv.org/abs/2501.19066) (BU)
- [ ] [\[2501.19061\] EgoMe: Follow Me via Egocentric View in Real World](https://arxiv.org/abs/2501.19061) (UESTC)
- [ ] [\[2501.19060\] Contrast-Aware Calibration for Fine-Tuned CLIP: Leveraging Image-Text Alignment](https://arxiv.org/abs/2501.19060) (NJU)
- [ ] [\[2501.19054\] Text-to-CAD Generation Through Infusing Visual Feedback in Large Language Models](https://arxiv.org/abs/2501.19054) (Microsoft)
- [ ] [\[2501.19034\] XRF V2: A Dataset for Action Summarization with Wi-Fi Signals, and IMUs in Phones, Watches, Earbuds, and Glasses](https://arxiv.org/abs/2501.19034) (XJTU)
- [ ] [\[2501.18984\] Context Matters: Query-aware Dynamic Long Sequence Modeling of Gigapixel Images](https://arxiv.org/abs/2501.18984) (HKUST)
- [ ] [\[2501.18982\] OmniPhysGS: 3D Constitutive Gaussians for General Physics-Based Dynamics Generation](https://arxiv.org/abs/2501.18982) (ICLR)
- [ ] [\[2501.18954\] LLMDet: Learning Strong Open-Vocabulary Object Detectors under the Supervision of Large Language Models](https://arxiv.org/abs/2501.18954) (SYSU)
- [ ] [\[2501.18940\] TV-Dialogue: Crafting Theme-Aware Video Dialogues with Immersive Interaction](https://arxiv.org/abs/2501.18940) (WHU)
- [ ] [\[2501.18913\] Rethinking Diffusion Posterior Sampling: From Conditional Score Estimator to Maximizing a Posterior](https://arxiv.org/abs/2501.18913) (NYU, ICLR)
- [ ] [\[2501.18880\] RLS3: RL-Based Synthetic Sample Selection to Enhance Spatial Reasoning in Vision-Language Models for Indoor Autonomous Perception](https://arxiv.org/abs/2501.18880) (NYU)
- [ ] [\[2501.18867\] UP-VLA: A Unified Understanding and Prediction Model for Embodied Agent](https://arxiv.org/abs/2501.18867) (Tsinghua)
- [ ] [\[2501.18865\] REG: Rectified Gradient Guidance for Conditional Diffusion Models](https://arxiv.org/abs/2501.18865) (MIT)
- [ ] [\[2501.18864\] Test-time Loss Landscape Adaptation for Zero-Shot Generalization in Vision-Language Models](https://arxiv.org/abs/2501.18864) (USTC)
- [ ] [\[2501.18855\] FlexiCrackNet: A Flexible Pipeline for Enhanced Crack Segmentation with General Features Transfered from SAM](https://arxiv.org/abs/2501.18855) (UW)
- [ ] [\[2501.18716\] Full-Head Segmentation of MRI with Abnormal Brain Anatomy: Model and Data Release](https://arxiv.org/abs/2501.18716) (NYU)
- [ ] [\[2501.18648\] Image, Text, and Speech Data Augmentation using Multimodal LLMs for Deep Learning: A Survey](https://arxiv.org/abs/2501.18648) (Cornell)
- [ ] [\[2501.18616\] STAMP: Scalable Task And Model-agnostic Collaborative Perception](https://arxiv.org/abs/2501.18616) (ICLR)
- [ ] [\[2501.19203\] Single cell resolution 3D imaging and segmentation within intact live tissues](https://arxiv.org/abs/2501.19203) (UCL)
- [ ] [\[2501.19047\] Understanding Model Calibration -- A gentle introduction and visual exploration of calibration and the expected calibration error (ECE)](https://arxiv.org/abs/2501.19047) (QMUL)
- [ ] [\[2501.18834\] Pitfalls of defacing whole-head MRI: re-identification risk with diffusion models and compromised research potential](https://arxiv.org/abs/2501.18834) (Vanderbilt University)
- [ ] [\[2501.18736\] Distillation-Driven Diffusion Model for Multi-Scale MRI Super-Resolution: Make 1.5T MRI Great Again](https://arxiv.org/abs/2501.18736) (Harvard)
- [ ] [\[2501.18614\] Review and Recommendations for using Artificial Intelligence in Intracoronary Optical Coherence Tomography Analysis](https://arxiv.org/abs/2501.18614) (Cambridge)

## 2025-01-31 (Fri)
- [ ] [\[2501.18593\] Diffusion Autoencoders are Scalable Image Tokenizers](https://arxiv.org/abs/2501.18593) (UCSD)
- [ ] [\[2501.18533\] Rethinking Bottlenecks in Safety Fine-Tuning of Vision Language Models](https://arxiv.org/abs/2501.18533) (Tianjin)
- [ ] [\[2501.18504\] CLEAR: Cue Learning using Evolution for Accurate Recognition Applied to Sustainability Data Extraction](https://arxiv.org/abs/2501.18504) (UCL)
- [ ] [\[2501.18500\] HSRMamba: Contextual Spatial-Spectral State Space Model for Single Hyperspectral Super-Resolution](https://arxiv.org/abs/2501.18500) (WHU)
- [ ] [\[2501.18494\] Runway vs. Taxiway: Challenges in Automated Line Identification and Notation Approaches](https://arxiv.org/abs/2501.18494) (NASA)
- [ ] [\[2501.18487\] Track-On: Transformer-based Online Point Tracking with Memory](https://arxiv.org/abs/2501.18487) (ICLR)
- [ ] [\[2501.18232\] Free-T2M: Frequency Enhanced Text-to-Motion Diffusion Model With Consistency Loss](https://arxiv.org/abs/2501.18232) (HKUST(GZ))
- [ ] [\[2501.18124\] REMOTE: Real-time Ego-motion Tracking for Various Endoscopes via Multimodal Visual Feature Learning](https://arxiv.org/abs/2501.18124) (Fudan)
- [ ] [\[2501.18116\] DeepFRC: An End-to-End Deep Learning Model for Functional Registration and Classification](https://arxiv.org/abs/2501.18116) (ShanghaiTech)
- [ ] [\[2501.18098\] Disentangling Safe and Unsafe Corruptions via Anisotropy and Locality](https://arxiv.org/abs/2501.18098) (JHU)
- [ ] [\[2501.18096\] LLMs can see and hear without any training](https://arxiv.org/abs/2501.18096) (UT Austin)
- [ ] [\[2501.17906\] Unsupervised Patch-GAN with Targeted Patch Ranking for Fine-Grained Novelty Detection in Medical Imaging](https://arxiv.org/abs/2501.17906) (SUSTech)
- [ ] [\[2501.18588\] Inkspire: Supporting Design Exploration with Generative AI through Analogical Sketching](https://arxiv.org/abs/2501.18588) (CMU)
- [ ] [\[2501.18362\] MedXpertQA: Benchmarking Expert-Level Medical Reasoning and Understanding](https://arxiv.org/abs/2501.18362) (Tsinghua)
- [ ] [\[2501.18314\] AGAV-Rater: Adapting Large Multimodal Model for AI-Generated Audio-Visual Quality Assessment](https://arxiv.org/abs/2501.18314) (SJTU)

