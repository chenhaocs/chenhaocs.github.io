
## 2025-02-21 (Fri)
- [ ] [\[2502.14786\] SigLIP 2: Multilingual Vision-Language Encoders with Improved Semantic Understanding, Localization, and Dense Features](https://arxiv.org/abs/2502.14786) (Google)
- [ ] [\[2502.14676\] BP-SGCN: Behavioral Pseudo-Label Informed Sparse Graph Convolution Network for Pedestrian and Heterogeneous Trajectory Prediction](https://arxiv.org/abs/2502.14676) (KAIST)
- [ ] [\[2502.14616\] Monocular Depth Estimation and Segmentation for Transparent Object with Iterative Semantic and Geometric Fusion](https://arxiv.org/abs/2502.14616) (IA CAS)
- [ ] [\[2502.14573\] Self-supervised Monocular Depth Estimation Robust to Reflective Surface Leveraged by Triplet Mining](https://arxiv.org/abs/2502.14573) (Stanford, ICLR)
- [ ] [\[2502.14495\] Nearshore Underwater Target Detection Meets UAV-borne Hyperspectral Remote Sensing: A Novel Hybrid-level Contrastive Learning Framework and Benchmark Dataset](https://arxiv.org/abs/2502.14495) (NUDT)
- [ ] [\[2502.14471\] Integrating Extra Modality Helps Segmentor Find Camouflaged Objects Well](https://arxiv.org/abs/2502.14471) (Tsinghua)
- [ ] [\[2502.14412\] Evaluating Precise Geolocation Inference Capabilities of Vision Language Models](https://arxiv.org/abs/2502.14412) (UMD)
- [ ] [\[2502.14373\] CrossVTON: Mimicking the Logic Reasoning on Cross-category Virtual Try-on guided by Tri-zone Priors](https://arxiv.org/abs/2502.14373) (Fudan)
- [ ] [\[2502.14355\] Triply Laplacian Scale Mixture Modeling for Seismic Data Noise Suppression](https://arxiv.org/abs/2502.14355) (NTU)
- [ ] [\[2502.14344\] Towards Accurate Binary Spiking Neural Networks: Learning with Adaptive Gradient Modulation Mechanism](https://arxiv.org/abs/2502.14344) (UESTC)
- [ ] [\[2502.14316\] Textured 3D Regenerative Morphing with 3D Diffusion Prior](https://arxiv.org/abs/2502.14316) (NTU)
- [ ] [\[2502.14282\] PC-Agent: A Hierarchical Multi-Agent Collaboration Framework for Complex Task Automation on PC](https://arxiv.org/abs/2502.14282) (IA CAS)
- [ ] [\[2502.14273\] LLM-EvRep: Learning an LLM-Compatible Event Representation Using a Self-Supervised Framework](https://arxiv.org/abs/2502.14273) (BU)
- [ ] [\[2502.14235\] OG-Gaussian: Occupancy Based Street Gaussians for Autonomous Driving](https://arxiv.org/abs/2502.14235) (USTC)
- [ ] [\[2502.14226\] Designing Parameter and Compute Efficient Diffusion Transformers using Distillation](https://arxiv.org/abs/2502.14226) (Illinois)
- [ ] [\[2502.14195\] Bridging Text and Vision: A Multi-View Text-Vision Registration Approach for Cross-Modal Place Recognition](https://arxiv.org/abs/2502.14195) (SJTU)
- [ ] [\[2502.14190\] Stereo Image Coding for Machines with Joint Visual Feature Compression](https://arxiv.org/abs/2502.14190) (Tianjin)
- [ ] [\[2502.14156\] Mixed Signals: A Diverse Point Cloud Dataset for Heterogeneous LiDAR V2X Collaboration](https://arxiv.org/abs/2502.14156) (Inria)
- [ ] [\[2502.14149\] PitVQA++: Vector Matrix-Low-Rank Adaptation for Open-Ended Visual Question Answering in Pituitary Surgery](https://arxiv.org/abs/2502.14149) (UCL)
- [ ] [\[2502.14088\] Regression in EO: Are VLMs Up to the Challenge?](https://arxiv.org/abs/2502.14088) (TUM)
- [ ] [\[2502.14070\] DiffExp: Efficient Exploration in Reward Fine-tuning for Text-to-Image Diffusion Models](https://arxiv.org/abs/2502.14070) (KAIST)
- [ ] [\[2502.14044\] Enhancing Cognition and Explainability of Multimodal Foundation Models with Self-Synthesized Data](https://arxiv.org/abs/2502.14044) (ICLR)
- [ ] [\[2502.14864\] Benchmarking Multimodal RAG through a Chart-based Document Question-Answering Generation Framework](https://arxiv.org/abs/2502.14864) (Chongqing)
- [ ] [\[2502.14807\] FetalCLIP: A Visual-Language Foundation Model for Fetal Ultrasound Image Analysis](https://arxiv.org/abs/2502.14807) (MBZUAI)
- [ ] [\[2502.14780\] ReVision: A Dataset and Baseline VLM for Privacy-Preserving Task-Oriented Visual Instruction Rewriting](https://arxiv.org/abs/2502.14780) (Yale)
- [ ] [\[2502.14778\] Harnessing PDF Data for Improving Japanese Large Multimodal Models](https://arxiv.org/abs/2502.14778) (University of Tokyo)
- [ ] [\[2502.14638\] NAVIG: Natural Language-guided Analysis with Vision Language Models for Image Geo-localization](https://arxiv.org/abs/2502.14638) (Tsinghua)
- [ ] [\[2502.14584\] Vision Foundation Models in Medical Image Analysis: Advances and Challenges](https://arxiv.org/abs/2502.14584) (HKUST)
- [ ] [\[2502.14487\] Temporal Misalignment and Probabilistic Neurons](https://arxiv.org/abs/2502.14487) (MBZUAI)
- [ ] [\[2502.14376\] A Similarity Paradigm Through Textual Regularization Without Forgetting](https://arxiv.org/abs/2502.14376) (SJTU)
- [ ] [\[2502.14370\] PPO-MI: Efficient Black-Box Model Inversion via Proximal Policy Optimization](https://arxiv.org/abs/2502.14370) (ICML)
- [ ] [\[2502.14178\] NeRF-3DTalker: Neural Radiance Field with 3D Prior Aided Audio Disentanglement for Talking Head Synthesis](https://arxiv.org/abs/2502.14178) (Tianjin)

## 2025-02-20 (Thu)
- [ ] [\[2502.13967\] FlexTok: Resampling Images into 1D Token Sequences of Flexible Length](https://arxiv.org/abs/2502.13967) (EPFL)
- [ ] [\[2502.13935\] Continually Learning Structured Visual Representations via Network Refinement with Rerelation](https://arxiv.org/abs/2502.13935) (EPFL)
- [ ] [\[2502.13716\] Event-Based Video Frame Interpolation With Cross-Modal Asymmetric Bidirectional Motion Fields](https://arxiv.org/abs/2502.13716) (CVPR)
- [ ] [\[2502.13637\] Exploring Mutual Cross-Modal Attention for Context-Aware Human Affordance Generation](https://arxiv.org/abs/2502.13637) (UTS)
- [ ] [\[2502.13524\] MobileViM: A Light-weight and Dimension-independent Vision Mamba for 3D Medical Image Analysis](https://arxiv.org/abs/2502.13524) (HKU)
- [ ] [\[2502.13407\] JL1-CD: A New Benchmark for Remote Sensing Change Detection and a Robust Multi-Teacher Knowledge Distillation Framework](https://arxiv.org/abs/2502.13407) (Tsinghua)
- [ ] [\[2502.13385\] SNN-Driven Multimodal Human Action Recognition via Event Camera and Skeleton Data Fusion](https://arxiv.org/abs/2502.13385) (BUPT)
- [ ] [\[2502.13234\] MotionMatcher: Motion Customization of Text-to-Video Diffusion Models via Motion Feature Matching](https://arxiv.org/abs/2502.13234) (NVIDIA)
- [ ] [\[2502.13838\] Generative Video Semantic Communication via Multimodal Semantic Fusion with Large Model](https://arxiv.org/abs/2502.13838) (NTU)
- [ ] [\[2502.13593\] Toward Robust Non-Transferable Learning: A Survey and Benchmark](https://arxiv.org/abs/2502.13593) (USyd)
- [ ] [\[2502.13498\] Improving Collision-Free Success Rate For Object Goal Visual Navigation Via Two-Stage Training With Collision Prediction](https://arxiv.org/abs/2502.13498) (Peking)
- [ ] [\[2502.13440\] Semi-supervised classification of bird vocalizations](https://arxiv.org/abs/2502.13440) (NUS)
- [ ] [\[2502.13383\] MM-Verify: Enhancing Multimodal Reasoning with Chain-of-Thought Verification](https://arxiv.org/abs/2502.13383) (UCAS)
- [ ] [\[2502.13372\] MoVer: Motion Verification for Motion Graphics Animations](https://arxiv.org/abs/2502.13372) (Stanford)

## 2025-02-19 (Wed)
- [ ] [\[2502.13145\] Multimodal Mamba: Decoder-only Multimodal State Space Model via Quadratic to Linear Distillation](https://arxiv.org/abs/2502.13145) (HUST)
- [ ] [\[2502.13133\] AV-Flow: Transforming Text to Audio-Visual Human-like Interactions](https://arxiv.org/abs/2502.13133) (Meta)
- [ ] [\[2502.13129\] Is Noise Conditioning Necessary for Denoising Generative Models?](https://arxiv.org/abs/2502.13129) (MIT)
- [ ] [\[2502.13081\] Personalized Image Generation with Deep Generative Models: A Decade Survey](https://arxiv.org/abs/2502.13081) (HIT)
- [ ] [\[2502.13071\] RobuRCDet: Enhancing Robustness of Radar-Camera Fusion in Bird's Eye View for 3D Object Detection](https://arxiv.org/abs/2502.13071) (ICLR)
- [ ] [\[2502.13017\] Mean of Means: Human Localization with Calibration-free and Unconstrained Camera Settings (extended version)](https://arxiv.org/abs/2502.13017) (PolyU)
- [ ] [\[2502.12994\] SHADeS: Self-supervised Monocular Depth Estimation Through Non-Lambertian Image Decomposition](https://arxiv.org/abs/2502.12994) (UCL)
- [ ] [\[2502.12985\] PartSDF: Part-Based Implicit Neural Representation for Composite 3D Shape Parametrization and Optimization](https://arxiv.org/abs/2502.12985) (EPFL)
- [ ] [\[2502.12975\] Instance-Level Moving Object Segmentation from a Single Image with Events](https://arxiv.org/abs/2502.12975) (NWPU)
- [ ] [\[2502.12894\] CAST: Component-Aligned 3D Scene Reconstruction from an RGB Image](https://arxiv.org/abs/2502.12894) (HUST)
- [ ] [\[2502.12752\] High-Fidelity Novel View Synthesis via Splatting-Guided Diffusion](https://arxiv.org/abs/2502.12752) (ETH)
- [ ] [\[2502.12677\] Spiking Vision Transformer with Saccadic Attention](https://arxiv.org/abs/2502.12677) (UESTC, ICLR)
- [ ] [\[2502.12627\] DAMamba: Vision State Space Model with Dynamic Adaptive Scan](https://arxiv.org/abs/2502.12627) (Xiamen)
- [ ] [\[2502.12600\] Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining](https://arxiv.org/abs/2502.12600) (SJTU)
- [ ] [\[2502.12579\] CHATS: Combining Human-Aligned Optimization and Test-Time Sampling for Text-to-Image Generation](https://arxiv.org/abs/2502.12579) (Alibaba)
- [ ] [\[2502.12524\] YOLOv12: Attention-Centric Real-Time Object Detectors](https://arxiv.org/abs/2502.12524) (UCAS)
- [ ] [\[2502.12520\] SAFEERASER: Enhancing Safety in Multimodal Large Language Models through Multimodal Machine Unlearning](https://arxiv.org/abs/2502.12520) (HKUST(GZ))
- [ ] [\[2502.12513\] RealSyn: An Effective and Scalable Multimodal Interleaved Document Transformation Paradigm](https://arxiv.org/abs/2502.12513) (USyd)
- [ ] [\[2502.12488\] Enhancing Audio-Visual Spiking Neural Networks through Semantic-Alignment and Cross-Modal Residual Learning](https://arxiv.org/abs/2502.12488) (IA CAS)
- [ ] [\[2502.12481\] Predicate Hierarchies Improve Few-Shot State Classification](https://arxiv.org/abs/2502.12481) (ICLR)
- [ ] [\[2502.12454\] Benchmarking Zero-Shot Facial Emotion Annotation with Large Language Models: A Multi-Class and Multi-Frame Approach in DailyLife](https://arxiv.org/abs/2502.12454) (Tsinghua)
- [ ] [\[2502.12425\] Robust Disentangled Counterfactual Learning for Physical Audiovisual Commonsense Reasoning](https://arxiv.org/abs/2502.12425) (BUPT)
- [ ] [\[2502.12415\] Gaseous Object Detection](https://arxiv.org/abs/2502.12415) (TPAMI)
- [ ] [\[2502.12297\] Duo Streamers: A Streaming Gesture Recognition Framework](https://arxiv.org/abs/2502.12297) (HKUST(GZ))
- [ ] [\[2502.12231\] PUGS: Zero-shot Physical Understanding with Gaussian Splatting](https://arxiv.org/abs/2502.12231) (Tsinghua)
- [ ] [\[2502.12794\] RAPID: Retrieval Augmented Training of Differentially Private Diffusion Models](https://arxiv.org/abs/2502.12794) (ICLR)
- [ ] [\[2502.12191\] AnyTouch: Learning Unified Static-Dynamic Representation across Multiple Visuo-tactile Sensors](https://arxiv.org/abs/2502.12191) (ICLR)
- [ ] [\[2502.12181\] 3D ReX: Causal Explanations in 3D Neuroimaging Classification](https://arxiv.org/abs/2502.12181) (UCL)

## 2025-02-18 (Tue)
- [ ] [\[2502.12081\] Unhackable Temporal Rewarding for Scalable Video MLLMs](https://arxiv.org/abs/2502.12081) (ICLR)
- [ ] [\[2502.11974\] Image Inversion: A Survey from GANs to Diffusion and Beyond](https://arxiv.org/abs/2502.11974) (ZJU)
- [ ] [\[2502.11971\] Robust 6DoF Pose Tracking Considering Contour and Interior Correspondence Uncertainty for AR Assembly Guidance](https://arxiv.org/abs/2502.11971) (BIT)
- [ ] [\[2502.11831\] Intuitive physics understanding emerges from self-supervised pretraining on natural videos](https://arxiv.org/abs/2502.11831) (Meta)
- [ ] [\[2502.11809\] Revealing Bias Formation in Deep Neural Networks Through the Geometric Mechanisms of Human Visual Decoupling](https://arxiv.org/abs/2502.11809) (Xidian)
- [ ] [\[2502.11801\] 3D Gaussian Inpainting with Depth-Guided Cross-View Consistency](https://arxiv.org/abs/2502.11801) (NVIDIA)
- [ ] [\[2502.11775\] video-SALMONN-o1: Reasoning-enhanced Audio-visual Large Language Model](https://arxiv.org/abs/2502.11775) (Tsinghua)
- [ ] [\[2502.11749\] JotlasNet: Joint Tensor Low-Rank and Attention-based Sparse Unrolling Network for Accelerating Dynamic MRI](https://arxiv.org/abs/2502.11749) (HIT)
- [ ] [\[2502.11742\] Range and Bird's Eye View Fused Cross-Modal Visual Place Recognition](https://arxiv.org/abs/2502.11742) (Tongji)
- [ ] [\[2502.11731\] GraphMorph: Tubular Structure Extraction by Morphing Predicted Graphs](https://arxiv.org/abs/2502.11731) (Peking, NIPS)
- [ ] [\[2502.11712\] Component-aware Unsupervised Logical Anomaly Generation for Industrial Anomaly Detection](https://arxiv.org/abs/2502.11712) (Fudan)
- [ ] [\[2502.11697\] MVTokenFlow: High-quality 4D Content Generation using Multiview Token Flow](https://arxiv.org/abs/2502.11697) (HKUST, ICLR)
- [ ] [\[2502.11651\] MMXU: A Multi-Modal and Multi-X-ray Understanding Dataset for Disease Progression](https://arxiv.org/abs/2502.11651) (SJTU)
- [ ] [\[2502.11642\] GaussianMotion: End-to-End Learning of Animatable Gaussian Avatars with Pose Guidance from Text](https://arxiv.org/abs/2502.11642) (KAIST)
- [ ] [\[2502.11638\] Enhancing Out-of-Distribution Detection in Medical Imaging with Normalizing Flows](https://arxiv.org/abs/2502.11638) (HKU)
- [ ] [\[2502.11586\] Syllables to Scenes: Literary-Guided Free-Viewpoint 3D Scene Synthesis from Japanese Haiku](https://arxiv.org/abs/2502.11586) (JHU)
- [ ] [\[2502.11515\] SayAnything: Audio-Driven Lip Synchronization with Conditional Video Diffusion](https://arxiv.org/abs/2502.11515) (UCAS)
- [ ] [\[2502.11481\] Variable-frame CNNLSTM for Breast Nodule Classification using Ultrasound Videos](https://arxiv.org/abs/2502.11481) (XJTU)
- [ ] [\[2502.11440\] Medical Image Registration Meets Vision Foundation Model: Prototype Learning and Contour Awareness](https://arxiv.org/abs/2502.11440) (USyd)
- [ ] [\[2502.11408\] Precise GPS-Denied UAV Self-Positioning via Context-Enhanced Cross-View Geo-Localization](https://arxiv.org/abs/2502.11408) (Stanford)
- [ ] [\[2502.11381\] Without Paired Labeled Data: An End-to-End Self-Supervised Paradigm for UAV-View Geo-Localization](https://arxiv.org/abs/2502.11381) (XJTU)
- [ ] [\[2502.11360\] GeoDANO: Geometric VLM with Domain Agnostic Vision Encoder](https://arxiv.org/abs/2502.11360) (POSTECH)
- [ ] [\[2502.11307\] Exploiting Point-Language Models with Dual-Prompts for 3D Anomaly Detection](https://arxiv.org/abs/2502.11307) (Xiamen)
- [ ] [\[2502.11195\] From Deception to Perception: The Surprising Benefits of Deepfakes for Detecting, Measuring, and Mitigating Bias](https://arxiv.org/abs/2502.11195) (UMD)
- [ ] [\[2502.11168\] Knowing Your Target: Target-Aware Transformer Makes Better Spatio-Temporal Video Grounding](https://arxiv.org/abs/2502.11168) (IS CAS)
- [ ] [\[2502.11158\] AnyRefill: A Unified, Data-Efficient Framework for Left-Prompt-Guided Vision Tasks](https://arxiv.org/abs/2502.11158) (Alibaba, TPAMI)
- [ ] [\[2502.11003\] FeaKM: Robust Collaborative Perception under Noisy Pose Conditions](https://arxiv.org/abs/2502.11003) (IA CAS)
- [ ] [\[2502.10988\] OMG: Opacity Matters in Material Modeling with Gaussian Splatting](https://arxiv.org/abs/2502.10988) (ICLR)
- [ ] [\[2502.10982\] TEASER: Token Enhanced Spatial Modeling for Expressions Reconstruction](https://arxiv.org/abs/2502.10982) (ICLR)
- [ ] [\[2502.10957\] Skillful Nowcasting of Convective Clouds With a Cascade Diffusion Model](https://arxiv.org/abs/2502.10957) (Fudan)
- [ ] [\[2502.10920\] Do Deepfake Detectors Work in Reality?](https://arxiv.org/abs/2502.10920) (GIT)
- [ ] [\[2502.10908\] Automatic Quality Assessment of First Trimester Crown-Rump-Length Ultrasound Images](https://arxiv.org/abs/2502.10908) (MBZUAI)
- [ ] [\[2502.10842\] Mobile Robotic Multi-View Photometric Stereo](https://arxiv.org/abs/2502.10842) (ISPRS)
- [ ] [\[2502.10810\] SVBench: A Benchmark with Temporal Multi-Turn Dialogues for Streaming Video Understanding](https://arxiv.org/abs/2502.10810) (IA CAS, ICLR)
- [ ] [\[2502.10785\] REGNav: Room Expert Guided Image-Goal Navigation](https://arxiv.org/abs/2502.10785) (XJTU)
- [ ] [\[2502.10724\] Semantics-aware Test-time Adaptation for 3D Human Pose Estimation](https://arxiv.org/abs/2502.10724) (NUS)
- [ ] [\[2502.10714\] Disentangle Nighttime Lens Flares: Self-supervised Generation-based Lens Flare Removal](https://arxiv.org/abs/2502.10714) (HIT)
- [ ] [\[2502.10704\] Occlusion-aware Non-Rigid Point Cloud Registration via Unsupervised Neural Deformation Correntropy](https://arxiv.org/abs/2502.10704) (ICLR)
- [ ] [\[2502.10669\] Is Self-Supervised Pre-training on Satellite Imagery Better than ImageNet? A Systematic Study with Sentinel-2](https://arxiv.org/abs/2502.10669) (Stanford)
- [ ] [\[2502.10614\] Optimizing CNN Architectures for Advanced Thoracic Disease Classification](https://arxiv.org/abs/2502.10614) (GIT)
- [ ] [\[2502.10606\] HIPPo: Harnessing Image-to-3D Priors for Model-free Zero-shot 6D Pose Estimation](https://arxiv.org/abs/2502.10606) (University of Toronto)
- [ ] [\[2502.10562\] Detecting and Monitoring Bias for Subgroups in Breast Cancer Detection AI](https://arxiv.org/abs/2502.10562) (UMD)
- [ ] [\[2502.10435\] RAMer: Reconstruction-based Adversarial Model for Multi-party Multi-modal Multi-label Emotion Recognition](https://arxiv.org/abs/2502.10435) (HKUST(GZ))
- [ ] [\[2502.12096\] Token Communications: A Unified Framework for Cross-modal Context-aware Semantic Communications](https://arxiv.org/abs/2502.12096) (NTU)
- [ ] [\[2502.11925\] GRAPHGPT-O: Synergistic Multimodal Comprehension and Generation on Graphs](https://arxiv.org/abs/2502.11925) (NYU)
- [ ] [\[2502.11858\] Rethinking Audio-Visual Adversarial Vulnerability from Temporal and Modality Perspectives](https://arxiv.org/abs/2502.11858) (ICLR)
- [ ] [\[2502.11850\] Steering the LoCoMotif: Using Domain Knowledge in Time Series Motif Discovery](https://arxiv.org/abs/2502.11850) (KU Leuven)
- [ ] [\[2502.11756\] On the Computation of the Fisher Information in Continual Learning](https://arxiv.org/abs/2502.11756) (KU Leuven, ICLR)
- [ ] [\[2502.11740\] Mitigating Visual Knowledge Forgetting in MLLM Instruction-tuning via Modality-decoupled Gradient Descent](https://arxiv.org/abs/2502.11740) (UCSD)
- [ ] [\[2502.11501\] Token Pruning in Multimodal Large Language Models: Are We Solving the Right Problem?](https://arxiv.org/abs/2502.11501) (Shanghai AI Lab)
- [ ] [\[2502.11494\] Stop Looking for Important Tokens in Multimodal Language Models: Duplication Matters More](https://arxiv.org/abs/2502.11494) (Shanghai AI Lab)
- [ ] [\[2502.11271\] OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning](https://arxiv.org/abs/2502.11271) (Stanford)
- [ ] [\[2502.11037\] Deep Incomplete Multi-view Learning via Cyclic Permutation of VAEs](https://arxiv.org/abs/2502.11037) (Fudan, ICLR)
- [ ] [\[2502.10652\] Deep Learning for Wound Tissue Segmentation: A Comprehensive Evaluation using A Novel Dataset](https://arxiv.org/abs/2502.10652) (USyd)
- [ ] [\[2502.10570\] Quantifying the Impact of Motion on 2D Gaze Estimation in Real-World Mobile Interactions](https://arxiv.org/abs/2502.10570) (University of Tokyo)

## 2025-02-17 (Mon)
- [ ] [\[2502.10392\] Text-guided Sparse Voxel Pruning for Efficient 3D Visual Grounding](https://arxiv.org/abs/2502.10392) (NTU)
- [ ] [\[2502.10385\] Simplifying DINO via Coding Rate Regularization](https://arxiv.org/abs/2502.10385) (Berkeley)
- [ ] [\[2502.10273\] Probing Perceptual Constancy in Large Vision Language Models](https://arxiv.org/abs/2502.10273) (University of Michigan)
- [ ] [\[2502.10214\] Mapping bathymetry of inland water bodies on the North Slope of Alaska with Landsat using Random Forest](https://arxiv.org/abs/2502.10214) (NASA)
- [ ] [\[2502.10195\] Exploring the Camera Bias of Person Re-identification](https://arxiv.org/abs/2502.10195) (ICLR)
- [ ] [\[2502.10118\] Image Embedding Sampling Method for Diverse Captioning](https://arxiv.org/abs/2502.10118) (KAIST)
- [ ] [\[2502.10060\] DiSciPLE: Learning Interpretable Programs for Scientific Visual Discovery](https://arxiv.org/abs/2502.10060) (Columbia University)
- [ ] [\[2502.10028\] ManiTrend: Bridging Future Generation and Action Prediction with 3D Flow for Robotic Manipulation](https://arxiv.org/abs/2502.10028) (HIT)
- [ ] [\[2502.09971\] Conditional Latent Coding with Learnable Synthesized Reference for Deep Image Compression](https://arxiv.org/abs/2502.09971) (SUSTech)
- [ ] [\[2502.09935\] Precise Parameter Localization for Textual Generation in Diffusion Models](https://arxiv.org/abs/2502.09935) (ICLR)
- [ ] [\[2502.09923\] Self-Consistent Model-based Adaptation for Visual Reinforcement Learning](https://arxiv.org/abs/2502.09923) (Tsinghua)
- [ ] [\[2502.09874\] FrGNet: A fourier-guided weakly-supervised framework for nuclear instance segmentation](https://arxiv.org/abs/2502.09874) (SYSU)
- [ ] [\[2502.09872\] Learning to Calibrate for Reliable Visual Fire Detection](https://arxiv.org/abs/2502.09872) (BUPT)
- [ ] [\[2502.09819\] A Solver-Aided Hierarchical Language for LLM-Driven CAD Design](https://arxiv.org/abs/2502.09819) (MIT)
- [ ] [\[2502.09818\] On the robustness of multimodal language model towards distractions](https://arxiv.org/abs/2502.09818) (CMU)
- [ ] [\[2502.09793\] Noise Controlled CT Super-Resolution with Conditional Diffusion Model](https://arxiv.org/abs/2502.09793) (Harvard)
- [ ] [\[2502.09696\] ZeroBench: An Impossible Visual Benchmark for Contemporary Large Multimodal Models](https://arxiv.org/abs/2502.09696) (Cambridge)
- [ ] [\[2502.09688\] Towards Virtual Clinical Trials of Radiology AI with Conditional Generative Modeling](https://arxiv.org/abs/2502.09688) (JHU)
- [ ] [\[2502.09665\] Revealing Subtle Phenotypes in Small Microscopy Datasets Using Latent Diffusion Models](https://arxiv.org/abs/2502.09665) (PSL University)
- [ ] [\[2502.09663\] DiffEx: Explaining a Classifier with Diffusion Models to Identify Microscopic Cellular Variations](https://arxiv.org/abs/2502.09663) (PSL University)
- [ ] [\[2502.10307\] SPIRIT: Short-term Prediction of solar IRradIance for zero-shot Transfer learning using Foundation Models](https://arxiv.org/abs/2502.10307) (Microsoft)
- [ ] [\[2502.10162\] Revisiting Generalization Power of a DNN in Terms of Symbolic Interactions](https://arxiv.org/abs/2502.10162) (SJTU)
- [ ] [\[2502.09990\] X-Boundary: Establishing Exact Safety Boundary to Shield LLMs from Multi-Turn Jailbreaks without Compromising Usability](https://arxiv.org/abs/2502.09990) (Shanghai AI Lab)
- [ ] [\[2502.09893\] Dynamic-Computed Tomography Angiography for Cerebral Vessel Templates and Segmentation](https://arxiv.org/abs/2502.09893) (Harvard)
- [ ] [\[2502.09824\] PUGS: Perceptual Uncertainty for Grasp Selection in Underwater Environments](https://arxiv.org/abs/2502.09824) (University of Michigan)
- [ ] [\[2502.09775\] CellFlow: Simulating Cellular Morphology Changes via Flow Matching](https://arxiv.org/abs/2502.09775) (Stanford)
- [ ] [\[2502.09689\] Large Language Models and Provenance Metadata for Determining the Relevance of Images and Videos in News Stories](https://arxiv.org/abs/2502.09689) (Stanford)
- [ ] [\[2502.09656\] Multi-Omics Fusion with Soft Labeling for Enhanced Prediction of Distant Metastasis in Nasopharyngeal Carcinoma Patients after Radiotherapy](https://arxiv.org/abs/2502.09656) (PolyU)

## 2025-02-14 (Fri)
- [ ] [\[2502.09617\] LIFe-GoM: Generalizable Human Rendering with Learned Iterative Feedback Over Multi-Resolution Gaussians-on-Mesh](https://arxiv.org/abs/2502.09617) (ICLR)
- [ ] [\[2502.09613\] Latent Radiance Fields with 3D-aware 2D Representations](https://arxiv.org/abs/2502.09613) (ICLR)
- [ ] [\[2502.09608\] Instance Segmentation of Scene Sketches Using Natural Image Priors](https://arxiv.org/abs/2502.09608) (MIT)
- [ ] [\[2502.09598\] GAIA: A Global, Multi-modal, Multi-scale Vision-Language Dataset for Remote Sensing Image Analysis](https://arxiv.org/abs/2502.09598) (TUM)
- [ ] [\[2502.09528\] SteROI-D: System Design and Mapping for Stereo Depth Inference on Regions of Interest](https://arxiv.org/abs/2502.09528) (University of Michigan)
- [ ] [\[2502.09501\] Prior-Constrained Association Learning for Fine-Grained Generalized Category Discovery](https://arxiv.org/abs/2502.09501) (ZJU)
- [ ] [\[2502.09482\] Standardisation of Convex Ultrasound Data Through Geometric Analysis and Augmentation](https://arxiv.org/abs/2502.09482) (Imperial)
- [ ] [\[2502.09471\] Wholly-WOOD: Wholly Leveraging Diversified-quality Labels for Weakly-supervised Oriented Object Detection](https://arxiv.org/abs/2502.09471) (SJTU, TPAMI)
- [ ] [\[2502.09434\] Redistribute Ensemble Training for Mitigating Memorization in Diffusion Models](https://arxiv.org/abs/2502.09434) (WHU)
- [ ] [\[2502.09311\] Mitigating the Impact of Prominent Position Shift in Drone-based RGBT Object Detection](https://arxiv.org/abs/2502.09311) (WHU)
- [ ] [\[2502.09278\] ConsistentDreamer: View-Consistent Meshes Through Balanced Multi-View Gaussian Optimization](https://arxiv.org/abs/2502.09278) (TUM)
- [ ] [\[2502.09164\] E-MD3C: Taming Masked Diffusion Transformers for Efficient Zero-Shot Object Customization](https://arxiv.org/abs/2502.09164) (KAIST)
- [ ] [\[2502.09125\] Automatic Pruning via Structured Lasso with Class-wise Information](https://arxiv.org/abs/2502.09125) (ETH)
- [ ] [\[2502.09080\] BevSplat: Resolving Height Ambiguity via Feature-Based Gaussian Primitives for Weakly-Supervised Cross-View Localization](https://arxiv.org/abs/2502.09080) (ShanghaiTech)
- [ ] [\[2502.09075\] PTZ-Calib: Robust Pan-Tilt-Zoom Camera Calibration](https://arxiv.org/abs/2502.09075) (Alibaba)
- [ ] [\[2502.09039\] Large Images are Gaussians: High-Quality Large Image Representation with Levels of 2D Gaussian Splatting](https://arxiv.org/abs/2502.09039) (HKU)
- [ ] [\[2502.09020\] EventSTR: A Benchmark Dataset and Baselines for Event Stream based Scene Text Recognition](https://arxiv.org/abs/2502.09020) (Peking)
- [ ] [\[2502.08905\] DiffoRA: Enabling Parameter-Efficient LLM Fine-Tuning via Differential Low-Rank Matrix Adaptation](https://arxiv.org/abs/2502.08905) (Tsinghua)
- [ ] [\[2502.08884\] ShapeLib: designing a library of procedural 3D shape abstractions with Large Language Models](https://arxiv.org/abs/2502.08884) (UCL)
- [ ] [\[2502.08769\] Cluster and Predict Latents Patches for Improved Masked Image Modeling](https://arxiv.org/abs/2502.08769) (Meta)
- [ ] [\[2502.08674\] COutfitGAN: Learning to Synthesize Compatible Outfits Supervised by Silhouette Masks and Fashion Styles](https://arxiv.org/abs/2502.08674) (HIT)
- [ ] [\[2502.09616\] Variational Rectified Flow Matching](https://arxiv.org/abs/2502.09616) (Apple)
- [ ] [\[2502.09614\] DexTrack: Towards Generalizable Neural Tracking Control for Dexterous Manipulation from Human References](https://arxiv.org/abs/2502.09614) (ICLR)
- [ ] [\[2502.09560\] EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language Models for Vision-Driven Embodied Agents](https://arxiv.org/abs/2502.09560) (Illinois)
- [ ] [\[2502.09352\] Wasserstein distributional adversarial training for deep neural networks](https://arxiv.org/abs/2502.09352) (MIT)
- [ ] [\[2502.09211\] Visual Graph Question Answering with ASP and LLMs for Language Parsing](https://arxiv.org/abs/2502.09211) (ETH)
- [ ] [\[2502.09122\] Improving Deep Regression with Tightness](https://arxiv.org/abs/2502.09122) (NUS, ICLR)
- [ ] [\[2502.08946\] The Stochastic Parrot on LLM's Shoulder: A Summative Assessment of Physical Concept Understanding](https://arxiv.org/abs/2502.08946) (JHU)
- [ ] [\[2502.08921\] Detecting Malicious Concepts Without Image Generation in AIGC](https://arxiv.org/abs/2502.08921) (CUHK)
- [ ] [\[2502.08869\] Harnessing Vision Models for Time Series Analysis: A Survey](https://arxiv.org/abs/2502.08869) (Illinois)
- [ ] [\[2502.08786\] MRUCT: Mixed Reality Assistance for Acupuncture Guided by Ultrasonic Computed Tomography](https://arxiv.org/abs/2502.08786) (Stanford)

## 2025-02-13 (Thu)
- [ ] [\[2502.08642\] SwiftSketch: A Diffusion Model for Image-to-Vector Sketch Generation](https://arxiv.org/abs/2502.08642) (MIT)
- [ ] [\[2502.08438\] Composite Sketch+Text Queries for Retrieving Objects with Elusive Names and Complex Interactions](https://arxiv.org/abs/2502.08438) (Microsoft)
- [ ] [\[2502.08391\] ViLa-MIL: Dual-scale Vision-Language Multiple Instance Learning for Whole Slide Image Classification](https://arxiv.org/abs/2502.08391) (XJTU, CVPR)
- [ ] [\[2502.08352\] Sat-DN: Implicit Surface Reconstruction from Multi-View Satellite Images with Depth and Normal Supervision](https://arxiv.org/abs/2502.08352) (WHU)
- [ ] [\[2502.08347\] Hi-End-MAE: Hierarchical encoder-driven masked autoencoders are stronger vision learners for medical image segmentation](https://arxiv.org/abs/2502.08347) (USTC)
- [ ] [\[2502.08285\] Fully-Geometric Cross-Attention for Point Cloud Registration](https://arxiv.org/abs/2502.08285) (UTS)
- [ ] [\[2502.08234\] Learning Human Skill Generators at Key-Step Levels](https://arxiv.org/abs/2502.08234) (NJU)
- [ ] [\[2502.08226\] TRISHUL: Towards Region Identification and Screen Hierarchy Understanding for Large VLM based GUI Agents](https://arxiv.org/abs/2502.08226) (ICML)
- [ ] [\[2502.08221\] Take What You Need: Flexible Multi-Task Semantic Communications with Channel Adaptation](https://arxiv.org/abs/2502.08221) (SYSU)
- [ ] [\[2502.08189\] AnyCharV: Bootstrap Controllable Character Video Generation with Fine-to-Coarse Guidance](https://arxiv.org/abs/2502.08189) (Tsinghua)
- [ ] [\[2502.08134\] A Survey on Data Curation for Visual Contrastive Learning: Why Crafting Effective Positive and Negative Pairs Matters](https://arxiv.org/abs/2502.08134) (Yale)
- [ ] [\[2502.08097\] ID-Cloak: Crafting Identity-Specific Cloaks Against Personalized Text-to-Image Generation](https://arxiv.org/abs/2502.08097) (BUPT)
- [ ] [\[2502.08079\] MAA: Meticulous Adversarial Attack against Vision-Language Pre-trained Models](https://arxiv.org/abs/2502.08079) (Queensland)
- [ ] [\[2502.07979\] Joint Modelling Histology and Molecular Markers for Cancer Classification](https://arxiv.org/abs/2502.07979) (Cambridge)
- [ ] [\[2502.07951\] Federated Self-supervised Domain Generalization for Label-efficient Polyp Segmentation](https://arxiv.org/abs/2502.07951) (Xiamen)
- [ ] [\[2502.07869\] EventEgo3D++: 3D Human Motion Capture from a Head-Mounted Event Camera](https://arxiv.org/abs/2502.07869) (MPI)
- [ ] [\[2502.07856\] MRS: A Fast Sampler for Mean Reverting Diffusion based on ODE and SDE Solvers](https://arxiv.org/abs/2502.07856) (Alibaba, ICLR)
- [ ] [\[2502.07855\] Vision-Language Models for Edge Networks: A Comprehensive Survey](https://arxiv.org/abs/2502.07855) (MBZUAI)
- [ ] [\[2502.07830\] Captured by Captions: On Memorization and its Mitigation in CLIP Models](https://arxiv.org/abs/2502.07830) (ICLR)
- [ ] [\[2502.07829\] Preference Alignment on Diffusion Model: A Comprehensive Survey for Image Generation and Editing](https://arxiv.org/abs/2502.07829) (University of Edinburgh)
- [ ] [\[2502.07825\] Pre-Trained Video Generative Models as World Simulators](https://arxiv.org/abs/2502.07825) (HKUST)
- [ ] [\[2502.07821\] Amnesia as a Catalyst for Enhancing Black Box Pixel Attacks in Image Classification and Object Detection](https://arxiv.org/abs/2502.07821) (NIPS)
- [ ] [\[2502.08634\] Rapid Whole Brain Mesoscale In-vivo MR Imaging using Multi-scale Implicit Neural Representation](https://arxiv.org/abs/2502.08634) (Harvard)
- [ ] [\[2502.08317\] Mitigating Hallucinations in Multimodal Spatial Relations through Constraint-Aware Prompting](https://arxiv.org/abs/2502.08317) (University of Rochester)
- [ ] [\[2502.08279\] What Is That Talk About? A Video-to-Text Summarization Dataset for Scientific Presentations](https://arxiv.org/abs/2502.08279) (Cambridge)
- [ ] [\[2502.08150\] Force Matching with Relativistic Constraints: A Physics-Inspired Approach to Stable and Efficient Generative Modeling](https://arxiv.org/abs/2502.08150) (HKU)
- [ ] [\[2502.08005\] Towards Training One-Step Diffusion Models Without Distillation](https://arxiv.org/abs/2502.08005) (UCL)
- [ ] [\[2502.07862\] ADMN: A Layer-Wise Adaptive Multimodal Network for Dynamic Input Noise and Compute Resources](https://arxiv.org/abs/2502.07862) (UCLA)
- [ ] [\[2502.07844\] The establishment of static digital humans and the integration with spinal models](https://arxiv.org/abs/2502.07844) (BUPT)
- [ ] [\[2502.06823\] CTR-Driven Advertising Image Generation with Multimodal Large Language Models](https://arxiv.org/abs/2502.06823) (HUST)

## 2025-02-12 (Wed)
- [ ] [\[2502.07784\] MatSwap: Light-aware material transfers in images](https://arxiv.org/abs/2502.07784) (Inria)
- [ ] [\[2502.07737\] Next Block Prediction: Video Generation via Semi-Auto-Regressive Modeling](https://arxiv.org/abs/2502.07737) (Peking)
- [ ] [\[2502.07685\] Matrix3D: Large Photogrammetry Model All-in-One](https://arxiv.org/abs/2502.07685) (NJU)
- [ ] [\[2502.07615\] Flow Distillation Sampling: Regularizing 3D Gaussians with Pre-trained Matching Priors](https://arxiv.org/abs/2502.07615) (ICLR)
- [ ] [\[2502.07602\] An Improved Optimal Proximal Gradient Algorithm for Non-Blind Image Deblurring](https://arxiv.org/abs/2502.07602) (CUHK)
- [ ] [\[2502.07466\] Less is More: Masking Elements in Image Condition Features Avoids Content Leakages in Style Transfer Diffusion Models](https://arxiv.org/abs/2502.07466) (Shanghai AI Lab)
- [ ] [\[2502.07403\] Extended monocular 3D imaging](https://arxiv.org/abs/2502.07403) (Tsinghua)
- [ ] [\[2502.07389\] FADE: Forecasting for Anomaly Detection on ECG](https://arxiv.org/abs/2502.07389) (EPFL)
- [ ] [\[2502.07381\] Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution](https://arxiv.org/abs/2502.07381) (UCAS)
- [ ] [\[2502.07351\] Multi-Task-oriented Nighttime Haze Imaging Enhancer for Vision-driven Measurement Systems](https://arxiv.org/abs/2502.07351) (UESTC)
- [ ] [\[2502.07331\] ERANet: Edge Replacement Augmentation for Semi-Supervised Meniscus Segmentation with Prototype Consistency Alignment and Conditional Self-Training](https://arxiv.org/abs/2502.07331) (CUHK)
- [ ] [\[2502.07309\] Semi-Supervised Vision-Centric 3D Occupancy World Model for Autonomous Driving](https://arxiv.org/abs/2502.07309) (Tsinghua, ICLR)
- [ ] [\[2502.07302\] CASC-AI: Consensus-aware Self-corrective AI Agents for Noise Cell Segmentation](https://arxiv.org/abs/2502.07302) (Vanderbilt University)
- [ ] [\[2502.07238\] Diffusion Suction Grasping with Large-Scale Parcel Dataset](https://arxiv.org/abs/2502.07238) (Tsinghua)
- [ ] [\[2502.07216\] SparseFormer: Detecting Objects in HRW Shots via Sparse Vision Transformer](https://arxiv.org/abs/2502.07216) (ACMMM)
- [ ] [\[2502.07192\] OscNet: Machine Learning on CMOS Oscillator Networks](https://arxiv.org/abs/2502.07192) (Stanford)
- [ ] [\[2502.07007\] Grounding Creativity in Physics: A Brief Survey of Physical Priors in AIGC](https://arxiv.org/abs/2502.07007) (ZJU)
- [ ] [\[2502.07001\] From Image to Video: An Empirical Study of Diffusion Representations](https://arxiv.org/abs/2502.07001) (Google)
- [ ] [\[2502.06973\] Indoor Light and Heat Estimation from a Single Panorama](https://arxiv.org/abs/2502.06973) (CMU)
- [ ] [\[2502.06875\] Beyond Vision: How Large Language Models Interpret Facial Expressions from Valence-Arousal Values](https://arxiv.org/abs/2502.06875) (Cambridge)
- [ ] [\[2502.06863\] BF-GAN: Development of an AI-driven Bubbly Flow Image Generation Model Using Generative Adversarial Networks](https://arxiv.org/abs/2502.06863) (University of Tokyo)
- [ ] [\[2502.07556\] SketchFlex: Facilitating Spatial-Semantic Coherence in Text-to-Image Generation with Region-Based Sketches](https://arxiv.org/abs/2502.07556) (HKUST(GZ))
- [ ] [\[2502.07516\] The Devil is in the Prompts: De-Identification Traces Enhance Memorization Risks in Synthetic Chest X-Ray Generation](https://arxiv.org/abs/2502.07516) (University of Edinburgh)
- [ ] [\[2502.07492\] RoMA: Robust Malware Attribution via Byte-level Adversarial Training with Global Perturbations and Adversarial Consistency Regularization](https://arxiv.org/abs/2502.07492) (PolyU)
- [ ] [\[2502.07456\] FedAPA: Server-side Gradient-Based Adaptive Personalized Aggregation for Federated Learning on Heterogeneous Data](https://arxiv.org/abs/2502.07456) (University of Toronto)
- [ ] [\[2502.07422\] MoENAS: Mixture-of-Expert based Neural Architecture Search for jointly Accurate, Fair, and Robust Edge Deep Neural Networks](https://arxiv.org/abs/2502.07422) (NYU)
- [ ] [\[2502.07408\] No Data, No Optimization: A Lightweight Method To Disrupt Neural Networks With Sign-Flips](https://arxiv.org/abs/2502.07408) (NVIDIA)
- [ ] [\[2502.07360\] Supervised contrastive learning for cell stage classification of animal embryos](https://arxiv.org/abs/2502.07360) (Inria)
- [ ] [\[2502.07327\] Generative Ghost: Investigating Ranking Bias Hidden in AI-Generated Videos](https://arxiv.org/abs/2502.07327) (ICT CAS)
- [ ] [\[2502.07276\] Dataset Ownership Verification in Contrastive Pre-trained Models](https://arxiv.org/abs/2502.07276) (ICLR)
- [ ] [\[2502.07181\] Tab2Visual: Overcoming Limited Data in Tabular Data Classification Using Deep Learning with Visual Representations](https://arxiv.org/abs/2502.07181) (Harvard)
- [ ] [\[2502.07096\] Lotus: Creating Short Videos From Long Videos With Abstractive and Extractive Summarization](https://arxiv.org/abs/2502.07096) (UT Austin)

## 2025-02-11 (Tue)
- [ ] [\[2502.06782\] Lumina-Video: Efficient and Flexible Video Generation with Multi-scale Next-DiT](https://arxiv.org/abs/2502.06782) (Shanghai AI Lab)
- [ ] [\[2502.06779\] KARST: Multi-Kernel Kronecker Adaptation with Re-Scaling Transmission for Visual Classification](https://arxiv.org/abs/2502.06779) (HKUST)
- [ ] [\[2502.06756\] SAMRefiner: Taming Segment Anything Model for Universal Mask Refinement](https://arxiv.org/abs/2502.06756) (ICLR)
- [ ] [\[2502.06750\] Accelerating Data Processing and Benchmarking of AI Models for Pathology](https://arxiv.org/abs/2502.06750) (Harvard)
- [ ] [\[2502.06619\] Unleashing the Potential of Pre-Trained Diffusion Models for Generalizable Person Re-Identification](https://arxiv.org/abs/2502.06619) (ZJU)
- [ ] [\[2502.06615\] Multi-Scale Feature Fusion with Image-Driven Spatial Integration for Left Atrium Segmentation from Cardiac MRI Images](https://arxiv.org/abs/2502.06615) (Rochester Institute of Technology)
- [ ] [\[2502.06552\] Diffusion Models for Computational Neuroimaging: A Survey](https://arxiv.org/abs/2502.06552) (Stanford)
- [ ] [\[2502.06527\] CustomVideoX: 3D Reference Attention Driven Dynamic Adaptation for Zero-Shot Customized Video Diffusion Transformers](https://arxiv.org/abs/2502.06527) (ZJU)
- [ ] [\[2502.06501\] Learning Clustering-based Prototypes for Compositional Zero-shot Learning](https://arxiv.org/abs/2502.06501) (ICLR)
- [ ] [\[2502.06460\] Group-CLIP Uncertainty Modeling for Group Re-Identification](https://arxiv.org/abs/2502.06460) (UESTC)
- [ ] [\[2502.06452\] SparseFocus: Learning-based One-shot Autofocus for Microscopy with Sparse Content](https://arxiv.org/abs/2502.06452) (NUDT)
- [ ] [\[2502.06434\] Rethinking Large-scale Dataset Compression: Shifting Focus From Labels to Images](https://arxiv.org/abs/2502.06434) (A*STAR,)
- [ ] [\[2502.06432\] Prompt-SID: Learning Structural Representation Prompt via Latent Diffusion for Single-Image Denoising](https://arxiv.org/abs/2502.06432) (Tsinghua)
- [ ] [\[2502.06431\] FCVSR: A Frequency-aware Method for Compressed Video Super-Resolution](https://arxiv.org/abs/2502.06431) (UESTC)
- [ ] [\[2502.06428\] CoS: Chain-of-Shot Prompting for Long Video Understanding](https://arxiv.org/abs/2502.06428) (QMUL)
- [ ] [\[2502.06392\] TANGLED: Generating 3D Hair Strands from Images with Arbitrary Styles and Viewpoints](https://arxiv.org/abs/2502.06392) (HUST)
- [ ] [\[2502.06390\] When Data Manipulation Meets Attack Goals: An In-depth Survey of Attacks for VLMs](https://arxiv.org/abs/2502.06390) (HKUST(GZ))
- [ ] [\[2502.06352\] LANTERN++: Enhanced Relaxed Speculative Decoding with Static Tree Drafting for Visual Auto-regressive Models](https://arxiv.org/abs/2502.06352) (KAIST)
- [ ] [\[2502.06338\] Zero-shot Depth Completion via Test-time Alignment with Affine-invariant Depth Prior](https://arxiv.org/abs/2502.06338) (POSTECH)
- [ ] [\[2502.06337\] Accelerating Outlier-robust Rotation Estimation by Stereographic Projection](https://arxiv.org/abs/2502.06337) (ZJU)
- [ ] [\[2502.06220\] FunduSAM: A Specialized Deep Learning Model for Enhanced Optic Disc and Cup Segmentation in Fundus Images](https://arxiv.org/abs/2502.06220) (USTC)
- [ ] [\[2502.06189\] Multi-Level Decoupled Relational Distillation for Heterogeneous Architectures](https://arxiv.org/abs/2502.06189) (Fudan)
- [ ] [\[2502.06181\] CANeRV: Content Adaptive Neural Representation for Video Compression](https://arxiv.org/abs/2502.06181) (UCAS)
- [ ] [\[2502.06155\] Efficient-vDiT: Efficient Video Diffusion Transformers With Attention Tile](https://arxiv.org/abs/2502.06155) (UCSD)
- [ ] [\[2502.06134\] Integrating Sequence and Image Modeling in Irregular Medical Time Series Through Self-Supervised Learning](https://arxiv.org/abs/2502.06134) (ZJU)
- [ ] [\[2502.06130\] Self-Correcting Decoding with Generative Feedback for Mitigating Hallucinations in Large Vision-Language Models](https://arxiv.org/abs/2502.06130) (ICLR)
- [ ] [\[2502.06114\] A Novel Multi-Teacher Knowledge Distillation for Real-Time Object Detection using 4D Radar](https://arxiv.org/abs/2502.06114) (KAIST)
- [ ] [\[2502.06100\] Col-OLHTR: A Novel Framework for Multimodal Online Handwritten Text Recognition](https://arxiv.org/abs/2502.06100) (USTC)
- [ ] [\[2502.06029\] DiTASK: Multi-Task Fine-Tuning with Diffeomorphic Transformations](https://arxiv.org/abs/2502.06029) (Cambridge, CVPR)
- [ ] [\[2502.05979\] VFX Creator: Animated Visual Effect Generation with Controllable Diffusion Transformer](https://arxiv.org/abs/2502.05979) (HKUST)
- [ ] [\[2502.05964\] Revisiting Gradient-based Uncertainty for Monocular Depth Estimation](https://arxiv.org/abs/2502.05964) (TPAMI)
- [ ] [\[2502.05905\] QP-SNN: Quantized and Pruned Spiking Neural Networks](https://arxiv.org/abs/2502.05905) (UESTC, ICLR)
- [ ] [\[2502.05874\] MMGDreamer: Mixed-Modality Graph for Geometry-Controllable 3D Indoor Scene Generation](https://arxiv.org/abs/2502.05874) (Peking)
- [ ] [\[2502.05869\] HyLiFormer: Hyperbolic Linear Attention for Skeleton-based Human Action Recognition](https://arxiv.org/abs/2502.05869) (SYSU)
- [ ] [\[2502.05859\] SphereFusion: Efficient Panorama Depth Estimation via Gated Fusion](https://arxiv.org/abs/2502.05859) (WHU)
- [ ] [\[2502.05835\] Contrastive Representation Distillation via Multi-Scale Feature Decoupling](https://arxiv.org/abs/2502.05835) (Fudan)
- [ ] [\[2502.05806\] Divide-and-Conquer: Tree-structured Strategy with Answer Distribution Estimator for Goal-Oriented Visual Dialogue](https://arxiv.org/abs/2502.05806) (ICT CAS)
- [ ] [\[2502.05772\] Effective Black-Box Multi-Faceted Attacks Breach Vision Large Language Model Guardrails](https://arxiv.org/abs/2502.05772) (CUHK)
- [ ] [\[2502.05749\] UniDB: A Unified Diffusion Bridge Framework via Stochastic Optimal Control](https://arxiv.org/abs/2502.05749) (ShanghaiTech)
- [ ] [\[2502.05741\] Linear Attention Modeling for Learned Image Compression](https://arxiv.org/abs/2502.05741) (SJTU)
- [ ] [\[2502.05738\] Performance Analysis of Traditional VQA Models Under Limited Computational Resources](https://arxiv.org/abs/2502.05738) (UCL)
- [ ] [\[2502.05710\] SSDD-GAN: Single-Step Denoising Diffusion GAN for Cochlear Implant Surgical Scene Completion](https://arxiv.org/abs/2502.05710) (Vanderbilt University)
- [ ] [\[2502.05673\] The Evolution of Dataset Distillation: Toward Scalable and Generalizable Solutions](https://arxiv.org/abs/2502.05673) (A*STAR,)
- [ ] [\[2502.05669\] Rigid Body Adversarial Attacks](https://arxiv.org/abs/2502.05669) (University of Toronto)
- [ ] [\[2502.05574\] Event Stream-based Visual Object Tracking: HDETrack V2 and A High-Definition Benchmark](https://arxiv.org/abs/2502.05574) (Peking, CVPR)
- [ ] [\[2502.05540\] Demystifying Catastrophic Forgetting in Two-Stage Incremental Object Detector](https://arxiv.org/abs/2502.05540) (NWPU)
- [ ] [\[2502.05482\] Robustifying Fourier Features Embeddings for Implicit Neural Representations](https://arxiv.org/abs/2502.05482) (University of Tokyo)
- [ ] [\[2502.05433\] AdaFlow: Efficient Long Video Editing via Adaptive Attention Slimming And Keyframe Selection](https://arxiv.org/abs/2502.05433) (Xiamen)
- [ ] [\[2502.05423\] LRA-GNN: Latent Relation-Aware Graph Neural Network with Initial and Dynamic Residual for Facial Age Estimation](https://arxiv.org/abs/2502.05423) (XJTU)
- [ ] [\[2502.05378\] NextBestPath: Efficient 3D Mapping of Unseen Environments](https://arxiv.org/abs/2502.05378) (ICLR)
- [ ] [\[2502.05320\] Towards Fine-grained Renal Vasculature Segmentation: Full-Scale Hierarchical Learning with FH-Seg](https://arxiv.org/abs/2502.05320) (Vanderbilt University)
- [ ] [\[2502.05240\] Survey on AI-Generated Media Detection: From Non-MLLM to MLLM](https://arxiv.org/abs/2502.05240) (BUPT)
- [ ] [\[2502.06764\] History-Guided Video Diffusion](https://arxiv.org/abs/2502.06764) (MIT)
- [ ] [\[2502.06581\] A Survey on Video Analytics in Cloud-Edge-Terminal Collaborative Systems](https://arxiv.org/abs/2502.06581) (Imperial)
- [ ] [\[2502.06516\] Boost-and-Skip: A Simple Guidance-Free Diffusion for Minority Generation](https://arxiv.org/abs/2502.06516) (KAIST)
- [ ] [\[2502.06314\] From Pixels to Components: Eigenvector Masking for Visual Representation Learning](https://arxiv.org/abs/2502.06314) (ETH)
- [ ] [\[2502.06209\] Enhancing Cost Efficiency in Active Learning with Candidate Set Query](https://arxiv.org/abs/2502.06209) (POSTECH)
- [ ] [\[2502.06167\] Universal Approximation of Visual Autoregressive Transformers](https://arxiv.org/abs/2502.06167) (HKU)
- [ ] [\[2502.06116\] Event Vision Sensor: A Review](https://arxiv.org/abs/2502.06116) (UCAS)
- [ ] [\[2502.05832\] Compressing Model with Few Class-Imbalance Samples: An Out-of-Distribution Expedition](https://arxiv.org/abs/2502.05832) (NJU)
- [ ] [\[2502.05713\] 4D VQ-GAN: Synthesising Medical Scans at Any Time Point for Personalised Disease Progression Modelling of Idiopathic Pulmonary Fibrosis](https://arxiv.org/abs/2502.05713) (UCL)
- [ ] [\[2502.05505\] Differentially Private Synthetic Data via APIs 3: Using Simulators Instead of Foundation Model](https://arxiv.org/abs/2502.05505) (Microsoft)
- [ ] [\[2502.05445\] Unsupervised Self-Prior Embedding Neural Representation for Iterative Sparse-View CT Reconstruction](https://arxiv.org/abs/2502.05445) (ShanghaiTech)
- [ ] [\[2502.05242\] SEER: Self-Explainability Enhancement of Large Language Models' Representations](https://arxiv.org/abs/2502.05242) (Shanghai AI Lab)
- [ ] [\[2502.05214\] CoRPA: Adversarial Image Generation for Chest X-rays Using Concept Vector Perturbations and Generative Models](https://arxiv.org/abs/2502.05214) (University of Edinburgh)
- [ ] [\[2502.05206\] Safety at Scale: A Comprehensive Survey of Large Model Safety](https://arxiv.org/abs/2502.05206) (Fudan)

## 2025-02-10 (Mon)
- [ ] [\[2502.05153\] Hummingbird: High Fidelity Image Generation via Multimodal Context Alignment](https://arxiv.org/abs/2502.05153) (ICLR)
- [ ] [\[2502.05147\] LP-DETR: Layer-wise Progressive Relations for Object Detection](https://arxiv.org/abs/2502.05147) (NYU)
- [ ] [\[2502.05129\] Counting Fish with Temporal Representations of Sonar Video](https://arxiv.org/abs/2502.05129) (MIT, ECCV)
- [ ] [\[2502.05066\] Beautiful Images, Toxic Words: Understanding and Addressing Offensive Text in Generated Images](https://arxiv.org/abs/2502.05066) (University of Toronto)
- [ ] [\[2502.05034\] MindAligner: Explicit Brain Functional Alignment for Cross-Subject Visual Decoding from Limited fMRI Data](https://arxiv.org/abs/2502.05034) (CUHK)
- [ ] [\[2502.04923\] Cached Multi-Lora Composition for Multi-Concept Image Generation](https://arxiv.org/abs/2502.04923) (ICLR)
- [ ] [\[2502.04734\] SC-OmniGS: Self-Calibrating Omnidirectional Gaussian Splatting](https://arxiv.org/abs/2502.04734) (HKUST, ICLR)
- [ ] [\[2502.04725\] Can Diffusion Models Learn Hidden Inter-Feature Rules Behind Images?](https://arxiv.org/abs/2502.04725) (HKU)
- [ ] [\[2502.04719\] Tolerance-Aware Deep Optics](https://arxiv.org/abs/2502.04719) (Shanghai AI Lab)
- [ ] [\[2502.04638\] Learning Street View Representations with Spatiotemporal Contrast](https://arxiv.org/abs/2502.04638) (Peking)
- [ ] [\[2502.04628\] AIQViT: Architecture-Informed Post-Training Quantization for Vision Transformers](https://arxiv.org/abs/2502.04628) (SYSU)
- [ ] [\[2502.04623\] HetSSNet: Spatial-Spectral Heterogeneous Graph Learning Network for Panchromatic and Multispectral Images Fusion](https://arxiv.org/abs/2502.04623) (ZJU)
- [ ] [\[2502.04541\] The Phantom of the Elytra -- Phylogenetic Trait Extraction from Images of Rove Beetles Using Deep Learning -- Is the Mask Enough?](https://arxiv.org/abs/2502.04541) (University of Copenhagen)
- [ ] [\[2502.04507\] Fast Video Generation with Sliding Tile Attention](https://arxiv.org/abs/2502.04507) (UCSD)
- [ ] [\[2502.04483\] Measuring Physical Plausibility of 3D Human Poses Using Physics Simulation](https://arxiv.org/abs/2502.04483) (University of Michigan)
- [ ] [\[2502.04475\] Augmented Conditioning Is Enough For Effective Training Image Generation](https://arxiv.org/abs/2502.04475) (UT Austin)
- [ ] [\[2502.04469\] No Images, No Problem: Retaining Knowledge in Continual VQA with Questions-Only Memory](https://arxiv.org/abs/2502.04469) (Inria)
- [ ] [\[2502.04412\] Decoder-Only LLMs are Better Controllers for Diffusion Models](https://arxiv.org/abs/2502.04412) (SYSU)
- [ ] [\[2502.04386\] Towards Fair Medical AI: Adversarial Debiasing of 3D CT Foundation Embeddings](https://arxiv.org/abs/2502.04386) (JHU)
- [ ] [\[2502.04385\] TexLiDAR: Automated Text Understanding for Panoramic LiDAR Data](https://arxiv.org/abs/2502.04385) (Tel Aviv)
- [ ] [\[2502.05151\] Transforming Science with Large Language Models: A Survey on AI-assisted Scientific Discovery, Experimentation, Content Generation, and Evaluation](https://arxiv.org/abs/2502.05151) (University of Tübingen)
- [ ] [\[2502.05119\] Investigating the impact of kernel harmonization and deformable registration on inspiratory and expiratory chest CT images for people with COPD](https://arxiv.org/abs/2502.05119) (Vanderbilt University)
- [ ] [\[2502.04988\] CMamba: Learned Image Compression with State Space Models](https://arxiv.org/abs/2502.04988) (Queensland)
- [ ] [\[2502.04903\] Wavelet-Assisted Multi-Frequency Attention Network for Pansharpening](https://arxiv.org/abs/2502.04903) (IA CAS)
- [ ] [\[2502.04794\] MedMimic: Physician-Inspired Multimodal Fusion for Early Diagnosis of Fever of Unknown Origin](https://arxiv.org/abs/2502.04794) (University of Tokyo)
- [ ] [\[2502.04359\] Exploring Spatial Language Grounding Through Referring Expressions](https://arxiv.org/abs/2502.04359) (UCSD)

## 2025-02-07 (Fri)
- [ ] [\[2502.04326\] WorldSense: Evaluating Real-world Omnimodal Understanding for Multimodal LLMs](https://arxiv.org/abs/2502.04326) (SJTU)
- [ ] [\[2502.04320\] ConceptAttention: Diffusion Transformers Learn Highly Interpretable Features](https://arxiv.org/abs/2502.04320) (GIT)
- [ ] [\[2502.04318\] sshELF: Single-Shot Hierarchical Extrapolation of Latent Features for 3D Reconstruction from Sparse-Views](https://arxiv.org/abs/2502.04318) (University of Tübingen)
- [ ] [\[2502.04293\] GCE-Pose: Global Context Enhancement for Category-level Object Pose Estimation](https://arxiv.org/abs/2502.04293) (TUM)
- [ ] [\[2502.04268\] Point2RBox-v2: Rethinking Point-supervised Oriented Object Detection with Spatial Layout Among Instances](https://arxiv.org/abs/2502.04268) (Tsinghua)
- [ ] [\[2502.04263\] Cross the Gap: Exposing the Intra-modal Misalignment in CLIP via Modality Inversion](https://arxiv.org/abs/2502.04263) (ICLR)
- [ ] [\[2502.04207\] Enhanced Feature-based Image Stitching for Endoscopic Videos in Pediatric Eosinophilic Esophagitis](https://arxiv.org/abs/2502.04207) (Vanderbilt University)
- [ ] [\[2502.04139\] Beyond the Final Layer: Hierarchical Query Fusion Transformer with Agent-Interpolation Initialization for 3D Instance Segmentation](https://arxiv.org/abs/2502.04139) (USTC)
- [ ] [\[2502.04111\] Adaptive Margin Contrastive Learning for Ambiguity-aware 3D Semantic Segmentation](https://arxiv.org/abs/2502.04111) (Tsinghua)
- [ ] [\[2502.04098\] Efficient Few-Shot Continual Learning in Vision-Language Models](https://arxiv.org/abs/2502.04098) (Cambridge)
- [ ] [\[2502.04076\] Content-Rich AIGC Video Quality Assessment via Intricate Text Alignment and Motion-Aware Consistency](https://arxiv.org/abs/2502.04076) (Peking)
- [ ] [\[2502.03997\] CAD-Editor: A Locate-then-Infill Framework with Automated Training Data Synthesis for Text-Based CAD Editing](https://arxiv.org/abs/2502.03997) (Microsoft)
- [ ] [\[2502.03971\] RWKV-UI: UI Understanding with Enhanced Perception and Reasoning](https://arxiv.org/abs/2502.03971) (SYSU)
- [ ] [\[2502.03950\] LR0.FM: Low-Resolution Zero-shot Classification Benchmark For Foundation Models](https://arxiv.org/abs/2502.03950) (ICLR)
- [ ] [\[2502.03877\] Advanced Object Detection and Pose Estimation with Hybrid Task Cascade and High-Resolution Networks](https://arxiv.org/abs/2502.03877) (University of Michigan)
- [ ] [\[2502.03856\] Taking A Closer Look at Interacting Objects: Interaction-Aware Open Vocabulary Scene Graph Generation](https://arxiv.org/abs/2502.03856) (HKUST)
- [ ] [\[2502.03852\] Pursuing Better Decision Boundaries for Long-Tailed Object Detection via Category Information Amount](https://arxiv.org/abs/2502.03852) (Xidian, ICLR)
- [ ] [\[2502.03829\] FE-UNet: Frequency Domain Enhanced U-Net with Segment Anything Capability for Versatile Image Segmentation](https://arxiv.org/abs/2502.03829) (UESTC)
- [ ] [\[2502.03826\] FairT2I: Mitigating Social Bias in Text-to-Image Generation via Large Language Model-Assisted Detection and Attribute Rebalancing](https://arxiv.org/abs/2502.03826) (University of Tokyo)
- [ ] [\[2502.03777\] Multi-Label Test-Time Adaptation with Bound Entropy Minimization](https://arxiv.org/abs/2502.03777) (ICLR)
- [ ] [\[2502.03758\] Improving Adversarial Robustness via Phase and Amplitude-aware Prompting](https://arxiv.org/abs/2502.03758) (Xidian)
- [ ] [\[2502.03649\] All-in-One Image Compression and Restoration](https://arxiv.org/abs/2502.03649) (USTC)
- [ ] [\[2502.03549\] Kronecker Mask and Interpretive Prompts are Language-Action Video Learners](https://arxiv.org/abs/2502.03549) (USTC, ICLR)
- [ ] [\[2502.04199\] Expanding Training Data for Endoscopic Phenotyping of Eosinophilic Esophagitis](https://arxiv.org/abs/2502.04199) (Vanderbilt University)
- [ ] [\[2502.04116\] Generative Adversarial Networks Bridging Art and Machine Intelligence](https://arxiv.org/abs/2502.04116) (Imperial)
- [ ] [\[2502.04079\] DEALing with Image Reconstruction: Deep Attentive Least Squares](https://arxiv.org/abs/2502.04079) (EPFL)
- [ ] [\[2502.03897\] UniForm: A Unified Diffusion Transformer for Audio-Video Generation](https://arxiv.org/abs/2502.03897) (NWPU)
- [ ] [\[2502.03482\] Can Domain Experts Rely on AI Appropriately? A Case Study on AI-Assisted Prostate Cancer MRI Diagnosis](https://arxiv.org/abs/2502.03482) (University of Michigan)

## 2025-02-06 (Thu)
- [ ] [\[2502.03444\] Masked Autoencoders Are Effective Tokenizers for Diffusion Models](https://arxiv.org/abs/2502.03444) (CMU)
- [ ] [\[2502.03207\] MotionAgent: Fine-grained Controllable Video Generation via Motion Field Agent](https://arxiv.org/abs/2502.03207) (NTU)
- [ ] [\[2502.02977\] Disentangling CLIP Features for Enhanced Localized Understanding](https://arxiv.org/abs/2502.02977) (Illinois)
- [ ] [\[2502.02936\] Every Angle Is Worth A Second Glance: Mining Kinematic Skeletal Structures from Multi-view Joint Cloud](https://arxiv.org/abs/2502.02936) (BU)
- [ ] [\[2502.02867\] Domain-Invariant Per-Frame Feature Extraction for Cross-Domain Imitation Learning with Visual Observations](https://arxiv.org/abs/2502.02867) (ICML)
- [ ] [\[2502.02835\] A Survey of Sample-Efficient Deep Learning for Change Detection in Remote Sensing: Tasks, Strategies, and Challenges](https://arxiv.org/abs/2502.02835) (University of Tokyo)
- [ ] [\[2502.02763\] Rethinking Vision Transformer for Object Centric Foundation Models](https://arxiv.org/abs/2502.02763) (University of Tübingen)
- [ ] [\[2502.02741\] RFMedSAM 2: Automatic Prompt Refinement for Enhanced Volumetric Medical Image Segmentation with SAM 2](https://arxiv.org/abs/2502.02741) (Peking)
- [ ] [\[2502.02707\] Multiple Instance Learning with Coarse-to-Fine Self-Distillation](https://arxiv.org/abs/2502.02707) (University of Edinburgh)
- [ ] [\[2502.02690\] Controllable Video Generation with Provable Disentanglement](https://arxiv.org/abs/2502.02690) (CMU)
- [ ] [\[2502.02676\] Blind Visible Watermark Removal with Morphological Dilation](https://arxiv.org/abs/2502.02676) (Vanderbilt University)
- [ ] [\[2502.02607\] MIND: Microstructure INverse Design with Generative Hybrid Neural Representation](https://arxiv.org/abs/2502.02607) (ETH)
- [ ] [\[2502.03270\] When Pre-trained Visual Representations Fall Short: Limitations in Visuo-Motor Robot Learning](https://arxiv.org/abs/2502.03270) (University of Edinburgh)
- [ ] [\[2502.02922\] Elucidating the Preconditioning in Consistency Distillation](https://arxiv.org/abs/2502.02922) (ICLR)
- [ ] [\[2502.02773\] SD++: Enhancing Standard Definition Maps by Incorporating Road Knowledge using LLMs](https://arxiv.org/abs/2502.02773) (UCSD)
- [ ] [\[2502.02610\] Secure & Personalized Music-to-Video Generation via CHARCHA](https://arxiv.org/abs/2502.02610) (CMU, NIPS)

## 2025-02-05 (Wed)
- [ ] [\[2502.02525\] Diff9D: Diffusion-Based Domain-Generalized Category-Level 9-DoF Object Pose Estimation](https://arxiv.org/abs/2502.02525) (XJTU)
- [ ] [\[2502.02501\] Graph-based Document Structure Analysis](https://arxiv.org/abs/2502.02501) (ICLR)
- [ ] [\[2502.02454\] IMDPrompter: Adapting SAM to Image Manipulation Detection by Cross-View Automated Prompt Learning](https://arxiv.org/abs/2502.02454) (SJTU)
- [ ] [\[2502.02449\] TUMTraffic-VideoQA: A Benchmark for Unified Spatio-Temporal Video Understanding in Traffic Scenes](https://arxiv.org/abs/2502.02449) (TUM)
- [ ] [\[2502.02372\] MaintaAvatar: A Maintainable Avatar Based on Neural Radiance Fields by Continual Learning](https://arxiv.org/abs/2502.02372) (SYSU)
- [ ] [\[2502.02340\] Transfer Risk Map: Mitigating Pixel-level Negative Transfer in Medical Segmentation](https://arxiv.org/abs/2502.02340) (Tsinghua)
- [ ] [\[2502.02338\] Geometric Neural Process Fields](https://arxiv.org/abs/2502.02338) (UVA.NL)
- [ ] [\[2502.02334\] Event-aided Semantic Scene Completion](https://arxiv.org/abs/2502.02334) (ZJU)
- [ ] [\[2502.02257\] UNIP: Rethinking Pre-trained Attention Patterns for Infrared Semantic Segmentation](https://arxiv.org/abs/2502.02257) (ICLR)
- [ ] [\[2502.02247\] Rotation-Adaptive Point Cloud Domain Generalization via Intricate Orientation Learning](https://arxiv.org/abs/2502.02247) (TPAMI)
- [ ] [\[2502.02225\] Exploring the latent space of diffusion models directly through singular value decomposition](https://arxiv.org/abs/2502.02225) (ZJU)
- [ ] [\[2502.02215\] InterLCM: Low-Quality Images as Intermediate States of Latent Consistency Models for Effective Blind Face Restoration](https://arxiv.org/abs/2502.02215) (ICLR)
- [ ] [\[2502.02196\] Exploiting Ensemble Learning for Cross-View Isolated Sign Language Recognition](https://arxiv.org/abs/2502.02196) (USTC)
- [ ] [\[2502.02187\] ShapeShifter: 3D Variations Using Multiscale and Sparse Point-Voxel Diffusion](https://arxiv.org/abs/2502.02187) (Inria)
- [ ] [\[2502.02182\] Sequence models for continuous cell cycle stage prediction from brightfield images](https://arxiv.org/abs/2502.02182) (EPFL)
- [ ] [\[2502.02144\] DOC-Depth: A novel approach for dense depth ground truth generation](https://arxiv.org/abs/2502.02144) (PSL University)
- [ ] [\[2502.02097\] VerteNet -- A Multi-Context Hybrid CNN Transformer for Accurate Vertebral Landmark Localization in Lateral Spine DXA Images](https://arxiv.org/abs/2502.02097) (SYSU)
- [ ] [\[2502.02096\] Dual-Flow: Transferable Multi-Target, Instance-Agnostic Attacks via In-the-wild Cascading Flow Optimization](https://arxiv.org/abs/2502.02096) (Tsinghua)
- [ ] [\[2502.02091\] Efficient Dynamic Scene Editing via 4D Gaussian-based Static-Dynamic Separation](https://arxiv.org/abs/2502.02091) (KAIST)
- [ ] [\[2502.02027\] From Fog to Failure: How Dehazing Can Harm Clear Image Object Detection](https://arxiv.org/abs/2502.02027) (Rochester Institute of Technology)
- [ ] [\[2502.01969\] Mitigating Object Hallucinations in Large Vision-Language Models via Attention Calibration](https://arxiv.org/abs/2502.01969) (USyd)
- [ ] [\[2502.01962\] Memory Efficient Transformer Adapter for Dense Predictions](https://arxiv.org/abs/2502.01962) (NJU, ICLR)
- [ ] [\[2502.01959\] MATCNN: Infrared and Visible Image Fusion Method Based on Multi-scale CNN with Attention Transformer](https://arxiv.org/abs/2502.01959) (Fudan)
- [ ] [\[2502.01890\] Geometric Framework for 3D Cell Segmentation Correction](https://arxiv.org/abs/2502.01890) (Columbia University)
- [ ] [\[2502.01850\] Foundation Model-Based Apple Ripeness and Size Estimation for Selective Harvesting](https://arxiv.org/abs/2502.01850) (Michigan State University)
- [ ] [\[2502.01776\] Sparse VideoGen: Accelerating Video Diffusion Transformers with Spatial-Temporal Sparsity](https://arxiv.org/abs/2502.01776) (Berkeley)
- [ ] [\[2502.01707\] CLIP-DQA: Blindly Evaluating Dehazed Images from Global and Local Perspectives Using CLIP](https://arxiv.org/abs/2502.01707) (SYSU)
- [ ] [\[2502.02562\] Learning the RoPEs: Better 2D and 3D Position Encodings with STRING](https://arxiv.org/abs/2502.02562) (Google)
- [ ] [\[2502.02558\] Particle Trajectory Representation Learning with Masked Point Modeling](https://arxiv.org/abs/2502.02558) (Stanford)
- [ ] [\[2502.02500\] The Skin Game: Revolutionizing Standards for AI Dermatology Model Comparison](https://arxiv.org/abs/2502.02500) (MIT)
- [ ] [\[2502.02458\] SAISA: Towards Multimodal Large Language Models with Both Training and Inference Efficiency](https://arxiv.org/abs/2502.02458) (UCAS)
- [ ] [\[2502.02175\] VLA-Cache: Towards Efficient Vision-Language-Action Model via Adaptive Token Caching in Robotic Manipulation](https://arxiv.org/abs/2502.02175) (USyd)
- [ ] [\[2502.02048\] Efficient Domain Adaptation of Multimodal Embeddings using Constrastive Learning](https://arxiv.org/abs/2502.02048) (MIT)

## 2025-02-04 (Tue)
- [ ] [\[2502.01576\] Robust-LLaVA: On the Effectiveness of Large-Scale Robust Image Encoders for Multi-modal Large Language Models](https://arxiv.org/abs/2502.01576) (MBZUAI)
- [ ] [\[2502.01467\] Deep Unfolding Multi-modal Image Fusion Network via Attribution Analysis](https://arxiv.org/abs/2502.01467) (XJTU)
- [ ] [\[2502.01441\] Improved Training Technique for Latent Consistency Models](https://arxiv.org/abs/2502.01441) (ICLR)
- [ ] [\[2502.01403\] AdaSVD: Adaptive Singular Value Decomposition for Large Language Models](https://arxiv.org/abs/2502.01403) (SJTU)
- [ ] [\[2502.01357\] Bayesian Approximation-Based Trajectory Prediction and Tracking with 4D Radar](https://arxiv.org/abs/2502.01357) (KAIST)
- [ ] [\[2502.01356\] Quasi-Conformal Convolution : A Learnable Convolution for Deep Learning on Riemann Surfaces](https://arxiv.org/abs/2502.01356) (CUHK)
- [ ] [\[2502.01309\] Heterogeneous Image GNN: Graph-Conditioned Diffusion for Image Synthesis](https://arxiv.org/abs/2502.01309) (Cambridge)
- [ ] [\[2502.01303\] Partial Channel Network: Compute Fewer, Perform Better](https://arxiv.org/abs/2502.01303) (XJTU)
- [ ] [\[2502.01297\] XR-VIO: High-precision Visual Inertial Odometry with Fast Initialization for XR Applications](https://arxiv.org/abs/2502.01297) (SenseTime)
- [ ] [\[2502.01201\] One-to-Normal: Anomaly Personalization for Few-shot Anomaly Detection](https://arxiv.org/abs/2502.01201) (BUPT, NIPS)
- [ ] [\[2502.01199\] Nearly Lossless Adaptive Bit Switching](https://arxiv.org/abs/2502.01199) (XJTU)
- [ ] [\[2502.01191\] Towards Robust and Reliable Concept Representations: Reliability-Enhanced Concept Embedding Model](https://arxiv.org/abs/2502.01191) (NTU)
- [ ] [\[2502.01183\] Enhancing Environmental Robustness in Few-shot Learning via Conditional Representation Learning](https://arxiv.org/abs/2502.01183) (Fudan, TIP)
- [ ] [\[2502.01105\] LayerTracer: Cognitive-Aligned Layered SVG Synthesis via Diffusion Transformer](https://arxiv.org/abs/2502.01105) (NUS)
- [ ] [\[2502.01101\] VidSketch: Hand-drawn Sketch-Driven Video Generation with Diffusion Control](https://arxiv.org/abs/2502.01101) (ZJU)
- [ ] [\[2502.01080\] BC-GAN: A Generative Adversarial Network for Synthesizing a Batch of Collocated Clothing](https://arxiv.org/abs/2502.01080) (HIT)
- [ ] [\[2502.01051\] Diffusion Model as a Noise-Aware Latent Reward Model for Step-Level Preference Optimization](https://arxiv.org/abs/2502.01051) (IA CAS)
- [ ] [\[2502.01004\] ZeroBP: Learning Position-Aware Correspondence for Zero-shot 6D Pose Estimation in Bin-Picking](https://arxiv.org/abs/2502.01004) (HIT)
- [ ] [\[2502.01002\] Multi-Resolution SAR and Optical Remote Sensing Image Registration Methods: A Review, Datasets, and Future Perspectives](https://arxiv.org/abs/2502.01002) (WHU)
- [ ] [\[2502.01000\] Adapting Foundation Models for Few-Shot Medical Image Segmentation: Actively and Sequentially](https://arxiv.org/abs/2502.01000) (Tsinghua)
- [ ] [\[2502.00992\] FCBoost-Net: A Generative Network for Synthesizing Multiple Collocated Outfits via Fashion Compatibility Boosting](https://arxiv.org/abs/2502.00992) (HIT, ACMMM)
- [ ] [\[2502.00965\] CLIP-UP: A Simple and Efficient Mixture-of-Experts CLIP Training Recipe with Sparse Upcycling](https://arxiv.org/abs/2502.00965) (Apple)
- [ ] [\[2502.00960\] SAM-guided Pseudo Label Enhancement for Multi-modal 3D Semantic Segmentation](https://arxiv.org/abs/2502.00960) (University of Michigan)
- [ ] [\[2502.00954\] Hypo3D: Exploring Hypothetical Reasoning in 3D](https://arxiv.org/abs/2502.00954) (Imperial)
- [ ] [\[2502.00869\] STAF: Sinusoidal Trainable Activation Functions for Implicit Neural Representation](https://arxiv.org/abs/2502.00869) (University of Toronto)
- [ ] [\[2502.00730\] Spatio-Temporal Progressive Attention Model for EEG Classification in Rapid Serial Visual Presentation Task](https://arxiv.org/abs/2502.00730) (Xidian)
- [ ] [\[2502.00688\] High-Order Matching for One-Step Shortcut Diffusion Models](https://arxiv.org/abs/2502.00688) (UT Austin)
- [ ] [\[2502.00639\] Zeroth-order Informed Fine-Tuning for Diffusion Model: A Recursive Likelihood Ratio Optimizer](https://arxiv.org/abs/2502.00639) (Peking)
- [ ] [\[2502.00630\] Self-Prompt SAM: Medical Image Segmentation via Automatic Prompt SAM Adaptation](https://arxiv.org/abs/2502.00630) (Peking)
- [ ] [\[2502.00618\] DesCLIP: Robust Continual Adaptation via General Attribute Descriptions for Pretrained Vision-Language Models](https://arxiv.org/abs/2502.00618) (UESTC)
- [ ] [\[2502.00568\] Generating crossmodal gene expression from cancer histopathology improves multimodal AI predictions](https://arxiv.org/abs/2502.00568) (Alan Turing Institute)
- [ ] [\[2502.00433\] CAT Pruning: Cluster-Aware Token Pruning For Text-to-Image Diffusion Models](https://arxiv.org/abs/2502.00433) (Peking)
- [ ] [\[2502.00426\] TeST-V: TEst-time Support-set Tuning for Zero-shot Video Classification](https://arxiv.org/abs/2502.00426) (NJU)
- [ ] [\[2502.00418\] Parameter Efficient Fine-Tuning of Segment Anything Model](https://arxiv.org/abs/2502.00418) (University of Göttingen)
- [ ] [\[2502.00392\] RefDrone: A Challenging Benchmark for Referring Expression Comprehension in Drone Scenes](https://arxiv.org/abs/2502.00392) (WHU)
- [ ] [\[2502.00382\] Masked Generative Nested Transformers with Decode Time Scaling](https://arxiv.org/abs/2502.00382) (Google)
- [ ] [\[2502.00360\] Shape from Semantics: 3D Shape Generation from Multi-View Semantics](https://arxiv.org/abs/2502.00360) (USTC)
- [ ] [\[2502.00342\] Embodied Intelligence for 3D Understanding: A Survey on 3D Scene Question Answering](https://arxiv.org/abs/2502.00342) (USyd)
- [ ] [\[2502.00333\] BiMaCoSR: Binary One-Step Diffusion Model Leveraging Flexible Matrix Compression for Real Super-Resolution](https://arxiv.org/abs/2502.00333) (SJTU)
- [ ] [\[2502.00307\] A Diffusion Model Translator for Efficient Image-to-Image Translation](https://arxiv.org/abs/2502.00307) (SJTU)
- [ ] [\[2502.00156\] ALBAR: Adversarial Learning approach to mitigate Biases in Action Recognition](https://arxiv.org/abs/2502.00156) (ICLR)
- [ ] [\[2502.00129\] ProtoSnap: Prototype Alignment for Cuneiform Signs](https://arxiv.org/abs/2502.00129) (ICLR)
- [ ] [\[2502.01427\] Structural features of the fly olfactory circuit mitigate the stability-plasticity dilemma in continual learning](https://arxiv.org/abs/2502.01427) (Tsinghua)
- [ ] [\[2502.01385\] Detecting Backdoor Samples in Contrastive Language Image Pretraining](https://arxiv.org/abs/2502.01385) (ICLR)
- [ ] [\[2502.01218\] Provable Ordering and Continuity in Vision-Language Pretraining for Generalizable Embodied Agents](https://arxiv.org/abs/2502.01218) (Queensland)
- [ ] [\[2502.01158\] MIND: Modality-Informed Knowledge Distillation Framework for Multimodal Clinical Prediction Tasks](https://arxiv.org/abs/2502.01158) (NYU)
- [ ] [\[2502.01117\] Learning to Learn Weight Generation via Trajectory Diffusion](https://arxiv.org/abs/2502.01117) (NTU)
- [ ] [\[2502.01046\] Emotional Face-to-Speech](https://arxiv.org/abs/2502.01046) (Fudan)
- [ ] [\[2502.00987\] RandLoRA: Full-rank parameter-efficient fine-tuning of large models](https://arxiv.org/abs/2502.00987) (ICLR)
- [ ] [\[2502.00754\] Continuity-Preserving Convolutional Autoencoders for Learning Continuous Latent Dynamical Models from Images](https://arxiv.org/abs/2502.00754) (NUS)
- [ ] [\[2502.00745\] BEEM: Boosting Performance of Early Exit DNNs using Multi-Exit Classifiers as Experts](https://arxiv.org/abs/2502.00745) (ICLR)
- [ ] [\[2502.00712\] Registration-Enhanced Segmentation Method for Prostate Cancer in Ultrasound Images](https://arxiv.org/abs/2502.00712) (Stanford)
- [ ] [\[2502.00698\] MM-IQ: Benchmarking Human-Like Abstraction and Reasoning in Multimodal Models](https://arxiv.org/abs/2502.00698) (UCAS)
- [ ] [\[2502.00619\] Distribution-aware Fairness Learning in Medical Image Segmentation From A Control-Theoretic Perspective](https://arxiv.org/abs/2502.00619) (Harvard)
- [ ] [\[2502.00545\] Integrating Frequency Guidance into Multi-source Domain Generalization for Bearing Fault Diagnosis](https://arxiv.org/abs/2502.00545) (Xiamen)
- [ ] [\[2502.00473\] Weak-to-Strong Diffusion with Reflection](https://arxiv.org/abs/2502.00473) (HKUST(GZ))
- [ ] [\[2502.00408\] Segment Anything for Histopathology](https://arxiv.org/abs/2502.00408) (University of Göttingen)
- [ ] [\[2502.00395\] FlexCloud: Direct, Modular Georeferencing and Drift-Correction of Point Cloud Maps](https://arxiv.org/abs/2502.00395) (TUM)
- [ ] [\[2502.00374\] A Unit-based System and Dataset for Expressive Direct Speech-to-Speech Translation](https://arxiv.org/abs/2502.00374) (Tsinghua)
- [ ] [\[2502.00366\] Prostate-Specific Foundation Models for Enhanced Detection of Clinically Significant Cancer](https://arxiv.org/abs/2502.00366) (Stanford)
- [ ] [\[2502.00253\] Patch Triplet Similarity Purification for Guided Real-World Low-Dose CT Image Denoising](https://arxiv.org/abs/2502.00253) (Nankai)
- [ ] [\[2502.00241\] Mordal: Automated Pretrained Model Selection for Vision Language Models](https://arxiv.org/abs/2502.00241) (University of Michigan)
- [ ] [\[2502.00234\] Fast Solvers for Discrete Diffusion Models: Theory and Applications of High-Order Algorithms](https://arxiv.org/abs/2502.00234) (Stanford)
- [ ] [\[2502.00114\] Mobile Robot Navigation Using Hand-Drawn Maps: A Vision Language Model Approach](https://arxiv.org/abs/2502.00114) (University of Toronto)

## 2025-02-03 (Mon)
- [ ] [\[2501.19252\] Inference-Time Text-to-Video Alignment with Diffusion Latent Beam Search](https://arxiv.org/abs/2501.19252) (University of Tokyo)
- [ ] [\[2501.19160\] RMDM: Radio Map Diffusion Model with Physics Informed](https://arxiv.org/abs/2501.19160) (HKUST(GZ))
- [ ] [\[2501.19159\] GDO: Gradual Domain Osmosis](https://arxiv.org/abs/2501.19159) (ICML)
- [ ] [\[2501.19155\] SWAT: Sliding Window Adversarial Training for Gradual Domain Adaptation](https://arxiv.org/abs/2501.19155) (UESTC, ICML)
- [ ] [\[2501.19129\] RGB-Event ISP: The Dataset and Benchmark](https://arxiv.org/abs/2501.19129) (HKUST(GZ), ICLR)
- [ ] [\[2501.19111\] A Benchmark for Incremental Micro-expression Recognition](https://arxiv.org/abs/2501.19111) (HIT)
- [ ] [\[2501.19086\] Fairness Analysis of CLIP-Based Foundation Models for X-Ray Image Classification](https://arxiv.org/abs/2501.19086) (UESTC)
- [ ] [\[2501.19084\] Laser: Efficient Language-Guided Segmentation in Neural Radiance Fields](https://arxiv.org/abs/2501.19084) (A*STAR,, TPAMI)
- [ ] [\[2501.19083\] MotionPCM: Real-Time Motion Synthesis with Phased Consistency Model](https://arxiv.org/abs/2501.19083) (UCL)
- [ ] [\[2501.19069\] Improving vision-language alignment with graph spiking hybrid Networks](https://arxiv.org/abs/2501.19069) (Tongji)
- [ ] [\[2501.19066\] Concept Steerers: Leveraging K-Sparse Autoencoders for Controllable Generations](https://arxiv.org/abs/2501.19066) (BU)
- [ ] [\[2501.19061\] EgoMe: Follow Me via Egocentric View in Real World](https://arxiv.org/abs/2501.19061) (UESTC)
- [ ] [\[2501.19060\] Contrast-Aware Calibration for Fine-Tuned CLIP: Leveraging Image-Text Alignment](https://arxiv.org/abs/2501.19060) (NJU)
- [ ] [\[2501.19054\] Text-to-CAD Generation Through Infusing Visual Feedback in Large Language Models](https://arxiv.org/abs/2501.19054) (Microsoft)
- [ ] [\[2501.19034\] XRF V2: A Dataset for Action Summarization with Wi-Fi Signals, and IMUs in Phones, Watches, Earbuds, and Glasses](https://arxiv.org/abs/2501.19034) (XJTU)
- [ ] [\[2501.18984\] Context Matters: Query-aware Dynamic Long Sequence Modeling of Gigapixel Images](https://arxiv.org/abs/2501.18984) (HKUST)
- [ ] [\[2501.18982\] OmniPhysGS: 3D Constitutive Gaussians for General Physics-Based Dynamics Generation](https://arxiv.org/abs/2501.18982) (ICLR)
- [ ] [\[2501.18954\] LLMDet: Learning Strong Open-Vocabulary Object Detectors under the Supervision of Large Language Models](https://arxiv.org/abs/2501.18954) (SYSU)
- [ ] [\[2501.18940\] TV-Dialogue: Crafting Theme-Aware Video Dialogues with Immersive Interaction](https://arxiv.org/abs/2501.18940) (WHU)
- [ ] [\[2501.18913\] Rethinking Diffusion Posterior Sampling: From Conditional Score Estimator to Maximizing a Posterior](https://arxiv.org/abs/2501.18913) (NYU, ICLR)
- [ ] [\[2501.18880\] RLS3: RL-Based Synthetic Sample Selection to Enhance Spatial Reasoning in Vision-Language Models for Indoor Autonomous Perception](https://arxiv.org/abs/2501.18880) (NYU)
- [ ] [\[2501.18867\] UP-VLA: A Unified Understanding and Prediction Model for Embodied Agent](https://arxiv.org/abs/2501.18867) (Tsinghua)
- [ ] [\[2501.18865\] REG: Rectified Gradient Guidance for Conditional Diffusion Models](https://arxiv.org/abs/2501.18865) (MIT)
- [ ] [\[2501.18864\] Test-time Loss Landscape Adaptation for Zero-Shot Generalization in Vision-Language Models](https://arxiv.org/abs/2501.18864) (USTC)
- [ ] [\[2501.18855\] FlexiCrackNet: A Flexible Pipeline for Enhanced Crack Segmentation with General Features Transfered from SAM](https://arxiv.org/abs/2501.18855) (UW)
- [ ] [\[2501.18716\] Full-Head Segmentation of MRI with Abnormal Brain Anatomy: Model and Data Release](https://arxiv.org/abs/2501.18716) (NYU)
- [ ] [\[2501.18648\] Image, Text, and Speech Data Augmentation using Multimodal LLMs for Deep Learning: A Survey](https://arxiv.org/abs/2501.18648) (Cornell)
- [ ] [\[2501.18616\] STAMP: Scalable Task And Model-agnostic Collaborative Perception](https://arxiv.org/abs/2501.18616) (ICLR)
- [ ] [\[2501.19203\] Single cell resolution 3D imaging and segmentation within intact live tissues](https://arxiv.org/abs/2501.19203) (UCL)
- [ ] [\[2501.19047\] Understanding Model Calibration -- A gentle introduction and visual exploration of calibration and the expected calibration error (ECE)](https://arxiv.org/abs/2501.19047) (QMUL)
- [ ] [\[2501.18834\] Pitfalls of defacing whole-head MRI: re-identification risk with diffusion models and compromised research potential](https://arxiv.org/abs/2501.18834) (Vanderbilt University)
- [ ] [\[2501.18736\] Distillation-Driven Diffusion Model for Multi-Scale MRI Super-Resolution: Make 1.5T MRI Great Again](https://arxiv.org/abs/2501.18736) (Harvard)
- [ ] [\[2501.18614\] Review and Recommendations for using Artificial Intelligence in Intracoronary Optical Coherence Tomography Analysis](https://arxiv.org/abs/2501.18614) (Cambridge)

## 2025-01-31 (Fri)
- [ ] [\[2501.18593\] Diffusion Autoencoders are Scalable Image Tokenizers](https://arxiv.org/abs/2501.18593) (UCSD)
- [ ] [\[2501.18533\] Rethinking Bottlenecks in Safety Fine-Tuning of Vision Language Models](https://arxiv.org/abs/2501.18533) (Tianjin)
- [ ] [\[2501.18504\] CLEAR: Cue Learning using Evolution for Accurate Recognition Applied to Sustainability Data Extraction](https://arxiv.org/abs/2501.18504) (UCL)
- [ ] [\[2501.18500\] HSRMamba: Contextual Spatial-Spectral State Space Model for Single Hyperspectral Super-Resolution](https://arxiv.org/abs/2501.18500) (WHU)
- [ ] [\[2501.18494\] Runway vs. Taxiway: Challenges in Automated Line Identification and Notation Approaches](https://arxiv.org/abs/2501.18494) (NASA)
- [ ] [\[2501.18487\] Track-On: Transformer-based Online Point Tracking with Memory](https://arxiv.org/abs/2501.18487) (ICLR)
- [ ] [\[2501.18232\] Free-T2M: Frequency Enhanced Text-to-Motion Diffusion Model With Consistency Loss](https://arxiv.org/abs/2501.18232) (HKUST(GZ))
- [ ] [\[2501.18124\] REMOTE: Real-time Ego-motion Tracking for Various Endoscopes via Multimodal Visual Feature Learning](https://arxiv.org/abs/2501.18124) (Fudan)
- [ ] [\[2501.18116\] DeepFRC: An End-to-End Deep Learning Model for Functional Registration and Classification](https://arxiv.org/abs/2501.18116) (ShanghaiTech)
- [ ] [\[2501.18098\] Disentangling Safe and Unsafe Corruptions via Anisotropy and Locality](https://arxiv.org/abs/2501.18098) (JHU)
- [ ] [\[2501.18096\] LLMs can see and hear without any training](https://arxiv.org/abs/2501.18096) (UT Austin)
- [ ] [\[2501.17906\] Unsupervised Patch-GAN with Targeted Patch Ranking for Fine-Grained Novelty Detection in Medical Imaging](https://arxiv.org/abs/2501.17906) (SUSTech)
- [ ] [\[2501.18588\] Inkspire: Supporting Design Exploration with Generative AI through Analogical Sketching](https://arxiv.org/abs/2501.18588) (CMU)
- [ ] [\[2501.18362\] MedXpertQA: Benchmarking Expert-Level Medical Reasoning and Understanding](https://arxiv.org/abs/2501.18362) (Tsinghua)
- [ ] [\[2501.18314\] AGAV-Rater: Adapting Large Multimodal Model for AI-Generated Audio-Visual Quality Assessment](https://arxiv.org/abs/2501.18314) (SJTU)