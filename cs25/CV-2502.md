
## 2025-02-12 (Wed)
- [ ] [\[2502.07784\] MatSwap: Light-aware material transfers in images](https://arxiv.org/abs/2502.07784) (Inria)
- [ ] [\[2502.07737\] Next Block Prediction: Video Generation via Semi-Auto-Regressive Modeling](https://arxiv.org/abs/2502.07737) (Peking)
- [ ] [\[2502.07685\] Matrix3D: Large Photogrammetry Model All-in-One](https://arxiv.org/abs/2502.07685) (NJU)
- [ ] [\[2502.07615\] Flow Distillation Sampling: Regularizing 3D Gaussians with Pre-trained Matching Priors](https://arxiv.org/abs/2502.07615) (ICLR)
- [ ] [\[2502.07602\] An Improved Optimal Proximal Gradient Algorithm for Non-Blind Image Deblurring](https://arxiv.org/abs/2502.07602) (CUHK)
- [ ] [\[2502.07466\] Less is More: Masking Elements in Image Condition Features Avoids Content Leakages in Style Transfer Diffusion Models](https://arxiv.org/abs/2502.07466) (Shanghai AI Lab)
- [ ] [\[2502.07403\] Extended monocular 3D imaging](https://arxiv.org/abs/2502.07403) (Tsinghua)
- [ ] [\[2502.07389\] FADE: Forecasting for Anomaly Detection on ECG](https://arxiv.org/abs/2502.07389) (EPFL)
- [ ] [\[2502.07381\] Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution](https://arxiv.org/abs/2502.07381) (UCAS)
- [ ] [\[2502.07351\] Multi-Task-oriented Nighttime Haze Imaging Enhancer for Vision-driven Measurement Systems](https://arxiv.org/abs/2502.07351) (UESTC)
- [ ] [\[2502.07331\] ERANet: Edge Replacement Augmentation for Semi-Supervised Meniscus Segmentation with Prototype Consistency Alignment and Conditional Self-Training](https://arxiv.org/abs/2502.07331) (CUHK)
- [ ] [\[2502.07309\] Semi-Supervised Vision-Centric 3D Occupancy World Model for Autonomous Driving](https://arxiv.org/abs/2502.07309) (Tsinghua, ICLR)
- [ ] [\[2502.07302\] CASC-AI: Consensus-aware Self-corrective AI Agents for Noise Cell Segmentation](https://arxiv.org/abs/2502.07302) (Vanderbilt University)
- [ ] [\[2502.07238\] Diffusion Suction Grasping with Large-Scale Parcel Dataset](https://arxiv.org/abs/2502.07238) (Tsinghua)
- [ ] [\[2502.07216\] SparseFormer: Detecting Objects in HRW Shots via Sparse Vision Transformer](https://arxiv.org/abs/2502.07216) (ACMMM)
- [ ] [\[2502.07192\] OscNet: Machine Learning on CMOS Oscillator Networks](https://arxiv.org/abs/2502.07192) (Stanford)
- [ ] [\[2502.07007\] Grounding Creativity in Physics: A Brief Survey of Physical Priors in AIGC](https://arxiv.org/abs/2502.07007) (ZJU)
- [ ] [\[2502.07001\] From Image to Video: An Empirical Study of Diffusion Representations](https://arxiv.org/abs/2502.07001) (Google)
- [ ] [\[2502.06973\] Indoor Light and Heat Estimation from a Single Panorama](https://arxiv.org/abs/2502.06973) (CMU)
- [ ] [\[2502.06875\] Beyond Vision: How Large Language Models Interpret Facial Expressions from Valence-Arousal Values](https://arxiv.org/abs/2502.06875) (Cambridge)
- [ ] [\[2502.06863\] BF-GAN: Development of an AI-driven Bubbly Flow Image Generation Model Using Generative Adversarial Networks](https://arxiv.org/abs/2502.06863) (University of Tokyo)
- [ ] [\[2502.07556\] SketchFlex: Facilitating Spatial-Semantic Coherence in Text-to-Image Generation with Region-Based Sketches](https://arxiv.org/abs/2502.07556) (HKUST(GZ))
- [ ] [\[2502.07516\] The Devil is in the Prompts: De-Identification Traces Enhance Memorization Risks in Synthetic Chest X-Ray Generation](https://arxiv.org/abs/2502.07516) (University of Edinburgh)
- [ ] [\[2502.07492\] RoMA: Robust Malware Attribution via Byte-level Adversarial Training with Global Perturbations and Adversarial Consistency Regularization](https://arxiv.org/abs/2502.07492) (PolyU)
- [ ] [\[2502.07456\] FedAPA: Server-side Gradient-Based Adaptive Personalized Aggregation for Federated Learning on Heterogeneous Data](https://arxiv.org/abs/2502.07456) (University of Toronto)
- [ ] [\[2502.07422\] MoENAS: Mixture-of-Expert based Neural Architecture Search for jointly Accurate, Fair, and Robust Edge Deep Neural Networks](https://arxiv.org/abs/2502.07422) (NYU)
- [ ] [\[2502.07408\] No Data, No Optimization: A Lightweight Method To Disrupt Neural Networks With Sign-Flips](https://arxiv.org/abs/2502.07408) (NVIDIA)
- [ ] [\[2502.07360\] Supervised contrastive learning for cell stage classification of animal embryos](https://arxiv.org/abs/2502.07360) (Inria)
- [ ] [\[2502.07327\] Generative Ghost: Investigating Ranking Bias Hidden in AI-Generated Videos](https://arxiv.org/abs/2502.07327) (ICT CAS)
- [ ] [\[2502.07276\] Dataset Ownership Verification in Contrastive Pre-trained Models](https://arxiv.org/abs/2502.07276) (ICLR)
- [ ] [\[2502.07181\] Tab2Visual: Overcoming Limited Data in Tabular Data Classification Using Deep Learning with Visual Representations](https://arxiv.org/abs/2502.07181) (Harvard)
- [ ] [\[2502.07096\] Lotus: Creating Short Videos From Long Videos With Abstractive and Extractive Summarization](https://arxiv.org/abs/2502.07096) (UT Austin)

## 2025-02-11 (Tue)
- [ ] [\[2502.06782\] Lumina-Video: Efficient and Flexible Video Generation with Multi-scale Next-DiT](https://arxiv.org/abs/2502.06782) (Shanghai AI Lab)
- [ ] [\[2502.06779\] KARST: Multi-Kernel Kronecker Adaptation with Re-Scaling Transmission for Visual Classification](https://arxiv.org/abs/2502.06779) (HKUST)
- [ ] [\[2502.06756\] SAMRefiner: Taming Segment Anything Model for Universal Mask Refinement](https://arxiv.org/abs/2502.06756) (ICLR)
- [ ] [\[2502.06750\] Accelerating Data Processing and Benchmarking of AI Models for Pathology](https://arxiv.org/abs/2502.06750) (Harvard)
- [ ] [\[2502.06619\] Unleashing the Potential of Pre-Trained Diffusion Models for Generalizable Person Re-Identification](https://arxiv.org/abs/2502.06619) (ZJU)
- [ ] [\[2502.06615\] Multi-Scale Feature Fusion with Image-Driven Spatial Integration for Left Atrium Segmentation from Cardiac MRI Images](https://arxiv.org/abs/2502.06615) (Rochester Institute of Technology)
- [ ] [\[2502.06552\] Diffusion Models for Computational Neuroimaging: A Survey](https://arxiv.org/abs/2502.06552) (Stanford)
- [ ] [\[2502.06527\] CustomVideoX: 3D Reference Attention Driven Dynamic Adaptation for Zero-Shot Customized Video Diffusion Transformers](https://arxiv.org/abs/2502.06527) (ZJU)
- [ ] [\[2502.06501\] Learning Clustering-based Prototypes for Compositional Zero-shot Learning](https://arxiv.org/abs/2502.06501) (ICLR)
- [ ] [\[2502.06460\] Group-CLIP Uncertainty Modeling for Group Re-Identification](https://arxiv.org/abs/2502.06460) (UESTC)
- [ ] [\[2502.06452\] SparseFocus: Learning-based One-shot Autofocus for Microscopy with Sparse Content](https://arxiv.org/abs/2502.06452) (NUDT)
- [ ] [\[2502.06434\] Rethinking Large-scale Dataset Compression: Shifting Focus From Labels to Images](https://arxiv.org/abs/2502.06434) (A*STAR,)
- [ ] [\[2502.06432\] Prompt-SID: Learning Structural Representation Prompt via Latent Diffusion for Single-Image Denoising](https://arxiv.org/abs/2502.06432) (Tsinghua)
- [ ] [\[2502.06431\] FCVSR: A Frequency-aware Method for Compressed Video Super-Resolution](https://arxiv.org/abs/2502.06431) (UESTC)
- [ ] [\[2502.06428\] CoS: Chain-of-Shot Prompting for Long Video Understanding](https://arxiv.org/abs/2502.06428) (QMUL)
- [ ] [\[2502.06392\] TANGLED: Generating 3D Hair Strands from Images with Arbitrary Styles and Viewpoints](https://arxiv.org/abs/2502.06392) (HUST)
- [ ] [\[2502.06390\] When Data Manipulation Meets Attack Goals: An In-depth Survey of Attacks for VLMs](https://arxiv.org/abs/2502.06390) (HKUST(GZ))
- [ ] [\[2502.06352\] LANTERN++: Enhanced Relaxed Speculative Decoding with Static Tree Drafting for Visual Auto-regressive Models](https://arxiv.org/abs/2502.06352) (KAIST)
- [ ] [\[2502.06338\] Zero-shot Depth Completion via Test-time Alignment with Affine-invariant Depth Prior](https://arxiv.org/abs/2502.06338) (POSTECH)
- [ ] [\[2502.06337\] Accelerating Outlier-robust Rotation Estimation by Stereographic Projection](https://arxiv.org/abs/2502.06337) (ZJU)
- [ ] [\[2502.06220\] FunduSAM: A Specialized Deep Learning Model for Enhanced Optic Disc and Cup Segmentation in Fundus Images](https://arxiv.org/abs/2502.06220) (USTC)
- [ ] [\[2502.06189\] Multi-Level Decoupled Relational Distillation for Heterogeneous Architectures](https://arxiv.org/abs/2502.06189) (Fudan)
- [ ] [\[2502.06181\] CANeRV: Content Adaptive Neural Representation for Video Compression](https://arxiv.org/abs/2502.06181) (UCAS)
- [ ] [\[2502.06155\] Efficient-vDiT: Efficient Video Diffusion Transformers With Attention Tile](https://arxiv.org/abs/2502.06155) (UCSD)
- [ ] [\[2502.06134\] Integrating Sequence and Image Modeling in Irregular Medical Time Series Through Self-Supervised Learning](https://arxiv.org/abs/2502.06134) (ZJU)
- [ ] [\[2502.06130\] Self-Correcting Decoding with Generative Feedback for Mitigating Hallucinations in Large Vision-Language Models](https://arxiv.org/abs/2502.06130) (ICLR)
- [ ] [\[2502.06114\] A Novel Multi-Teacher Knowledge Distillation for Real-Time Object Detection using 4D Radar](https://arxiv.org/abs/2502.06114) (KAIST)
- [ ] [\[2502.06100\] Col-OLHTR: A Novel Framework for Multimodal Online Handwritten Text Recognition](https://arxiv.org/abs/2502.06100) (USTC)
- [ ] [\[2502.06029\] DiTASK: Multi-Task Fine-Tuning with Diffeomorphic Transformations](https://arxiv.org/abs/2502.06029) (Cambridge, CVPR)
- [ ] [\[2502.05979\] VFX Creator: Animated Visual Effect Generation with Controllable Diffusion Transformer](https://arxiv.org/abs/2502.05979) (HKUST)
- [ ] [\[2502.05964\] Revisiting Gradient-based Uncertainty for Monocular Depth Estimation](https://arxiv.org/abs/2502.05964) (TPAMI)
- [ ] [\[2502.05905\] QP-SNN: Quantized and Pruned Spiking Neural Networks](https://arxiv.org/abs/2502.05905) (UESTC, ICLR)
- [ ] [\[2502.05874\] MMGDreamer: Mixed-Modality Graph for Geometry-Controllable 3D Indoor Scene Generation](https://arxiv.org/abs/2502.05874) (Peking)
- [ ] [\[2502.05869\] HyLiFormer: Hyperbolic Linear Attention for Skeleton-based Human Action Recognition](https://arxiv.org/abs/2502.05869) (SYSU)
- [ ] [\[2502.05859\] SphereFusion: Efficient Panorama Depth Estimation via Gated Fusion](https://arxiv.org/abs/2502.05859) (WHU)
- [ ] [\[2502.05835\] Contrastive Representation Distillation via Multi-Scale Feature Decoupling](https://arxiv.org/abs/2502.05835) (Fudan)
- [ ] [\[2502.05806\] Divide-and-Conquer: Tree-structured Strategy with Answer Distribution Estimator for Goal-Oriented Visual Dialogue](https://arxiv.org/abs/2502.05806) (ICT CAS)
- [ ] [\[2502.05772\] Effective Black-Box Multi-Faceted Attacks Breach Vision Large Language Model Guardrails](https://arxiv.org/abs/2502.05772) (CUHK)
- [ ] [\[2502.05749\] UniDB: A Unified Diffusion Bridge Framework via Stochastic Optimal Control](https://arxiv.org/abs/2502.05749) (ShanghaiTech)
- [ ] [\[2502.05741\] Linear Attention Modeling for Learned Image Compression](https://arxiv.org/abs/2502.05741) (SJTU)
- [ ] [\[2502.05738\] Performance Analysis of Traditional VQA Models Under Limited Computational Resources](https://arxiv.org/abs/2502.05738) (UCL)
- [ ] [\[2502.05710\] SSDD-GAN: Single-Step Denoising Diffusion GAN for Cochlear Implant Surgical Scene Completion](https://arxiv.org/abs/2502.05710) (Vanderbilt University)
- [ ] [\[2502.05673\] The Evolution of Dataset Distillation: Toward Scalable and Generalizable Solutions](https://arxiv.org/abs/2502.05673) (A*STAR,)
- [ ] [\[2502.05669\] Rigid Body Adversarial Attacks](https://arxiv.org/abs/2502.05669) (University of Toronto)
- [ ] [\[2502.05574\] Event Stream-based Visual Object Tracking: HDETrack V2 and A High-Definition Benchmark](https://arxiv.org/abs/2502.05574) (Peking, CVPR)
- [ ] [\[2502.05540\] Demystifying Catastrophic Forgetting in Two-Stage Incremental Object Detector](https://arxiv.org/abs/2502.05540) (NWPU)
- [ ] [\[2502.05482\] Robustifying Fourier Features Embeddings for Implicit Neural Representations](https://arxiv.org/abs/2502.05482) (University of Tokyo)
- [ ] [\[2502.05433\] AdaFlow: Efficient Long Video Editing via Adaptive Attention Slimming And Keyframe Selection](https://arxiv.org/abs/2502.05433) (Xiamen)
- [ ] [\[2502.05423\] LRA-GNN: Latent Relation-Aware Graph Neural Network with Initial and Dynamic Residual for Facial Age Estimation](https://arxiv.org/abs/2502.05423) (XJTU)
- [ ] [\[2502.05378\] NextBestPath: Efficient 3D Mapping of Unseen Environments](https://arxiv.org/abs/2502.05378) (ICLR)
- [ ] [\[2502.05320\] Towards Fine-grained Renal Vasculature Segmentation: Full-Scale Hierarchical Learning with FH-Seg](https://arxiv.org/abs/2502.05320) (Vanderbilt University)
- [ ] [\[2502.05240\] Survey on AI-Generated Media Detection: From Non-MLLM to MLLM](https://arxiv.org/abs/2502.05240) (BUPT)
- [ ] [\[2502.06764\] History-Guided Video Diffusion](https://arxiv.org/abs/2502.06764) (MIT)
- [ ] [\[2502.06581\] A Survey on Video Analytics in Cloud-Edge-Terminal Collaborative Systems](https://arxiv.org/abs/2502.06581) (Imperial)
- [ ] [\[2502.06516\] Boost-and-Skip: A Simple Guidance-Free Diffusion for Minority Generation](https://arxiv.org/abs/2502.06516) (KAIST)
- [ ] [\[2502.06314\] From Pixels to Components: Eigenvector Masking for Visual Representation Learning](https://arxiv.org/abs/2502.06314) (ETH)
- [ ] [\[2502.06209\] Enhancing Cost Efficiency in Active Learning with Candidate Set Query](https://arxiv.org/abs/2502.06209) (POSTECH)
- [ ] [\[2502.06167\] Universal Approximation of Visual Autoregressive Transformers](https://arxiv.org/abs/2502.06167) (HKU)
- [ ] [\[2502.06116\] Event Vision Sensor: A Review](https://arxiv.org/abs/2502.06116) (UCAS)
- [ ] [\[2502.05832\] Compressing Model with Few Class-Imbalance Samples: An Out-of-Distribution Expedition](https://arxiv.org/abs/2502.05832) (NJU)
- [ ] [\[2502.05713\] 4D VQ-GAN: Synthesising Medical Scans at Any Time Point for Personalised Disease Progression Modelling of Idiopathic Pulmonary Fibrosis](https://arxiv.org/abs/2502.05713) (UCL)
- [ ] [\[2502.05505\] Differentially Private Synthetic Data via APIs 3: Using Simulators Instead of Foundation Model](https://arxiv.org/abs/2502.05505) (Microsoft)
- [ ] [\[2502.05445\] Unsupervised Self-Prior Embedding Neural Representation for Iterative Sparse-View CT Reconstruction](https://arxiv.org/abs/2502.05445) (ShanghaiTech)
- [ ] [\[2502.05242\] SEER: Self-Explainability Enhancement of Large Language Models' Representations](https://arxiv.org/abs/2502.05242) (Shanghai AI Lab)
- [ ] [\[2502.05214\] CoRPA: Adversarial Image Generation for Chest X-rays Using Concept Vector Perturbations and Generative Models](https://arxiv.org/abs/2502.05214) (University of Edinburgh)
- [ ] [\[2502.05206\] Safety at Scale: A Comprehensive Survey of Large Model Safety](https://arxiv.org/abs/2502.05206) (Fudan)

## 2025-02-10 (Mon)
- [ ] [\[2502.05153\] Hummingbird: High Fidelity Image Generation via Multimodal Context Alignment](https://arxiv.org/abs/2502.05153) (ICLR)
- [ ] [\[2502.05147\] LP-DETR: Layer-wise Progressive Relations for Object Detection](https://arxiv.org/abs/2502.05147) (NYU)
- [ ] [\[2502.05129\] Counting Fish with Temporal Representations of Sonar Video](https://arxiv.org/abs/2502.05129) (MIT, ECCV)
- [ ] [\[2502.05066\] Beautiful Images, Toxic Words: Understanding and Addressing Offensive Text in Generated Images](https://arxiv.org/abs/2502.05066) (University of Toronto)
- [ ] [\[2502.05034\] MindAligner: Explicit Brain Functional Alignment for Cross-Subject Visual Decoding from Limited fMRI Data](https://arxiv.org/abs/2502.05034) (CUHK)
- [ ] [\[2502.04923\] Cached Multi-Lora Composition for Multi-Concept Image Generation](https://arxiv.org/abs/2502.04923) (ICLR)
- [ ] [\[2502.04734\] SC-OmniGS: Self-Calibrating Omnidirectional Gaussian Splatting](https://arxiv.org/abs/2502.04734) (HKUST, ICLR)
- [ ] [\[2502.04725\] Can Diffusion Models Learn Hidden Inter-Feature Rules Behind Images?](https://arxiv.org/abs/2502.04725) (HKU)
- [ ] [\[2502.04719\] Tolerance-Aware Deep Optics](https://arxiv.org/abs/2502.04719) (Shanghai AI Lab)
- [ ] [\[2502.04638\] Learning Street View Representations with Spatiotemporal Contrast](https://arxiv.org/abs/2502.04638) (Peking)
- [ ] [\[2502.04628\] AIQViT: Architecture-Informed Post-Training Quantization for Vision Transformers](https://arxiv.org/abs/2502.04628) (SYSU)
- [ ] [\[2502.04623\] HetSSNet: Spatial-Spectral Heterogeneous Graph Learning Network for Panchromatic and Multispectral Images Fusion](https://arxiv.org/abs/2502.04623) (ZJU)
- [ ] [\[2502.04541\] The Phantom of the Elytra -- Phylogenetic Trait Extraction from Images of Rove Beetles Using Deep Learning -- Is the Mask Enough?](https://arxiv.org/abs/2502.04541) (University of Copenhagen)
- [ ] [\[2502.04507\] Fast Video Generation with Sliding Tile Attention](https://arxiv.org/abs/2502.04507) (UCSD)
- [ ] [\[2502.04483\] Measuring Physical Plausibility of 3D Human Poses Using Physics Simulation](https://arxiv.org/abs/2502.04483) (University of Michigan)
- [ ] [\[2502.04475\] Augmented Conditioning Is Enough For Effective Training Image Generation](https://arxiv.org/abs/2502.04475) (UT Austin)
- [ ] [\[2502.04469\] No Images, No Problem: Retaining Knowledge in Continual VQA with Questions-Only Memory](https://arxiv.org/abs/2502.04469) (Inria)
- [ ] [\[2502.04412\] Decoder-Only LLMs are Better Controllers for Diffusion Models](https://arxiv.org/abs/2502.04412) (SYSU)
- [ ] [\[2502.04386\] Towards Fair Medical AI: Adversarial Debiasing of 3D CT Foundation Embeddings](https://arxiv.org/abs/2502.04386) (JHU)
- [ ] [\[2502.04385\] TexLiDAR: Automated Text Understanding for Panoramic LiDAR Data](https://arxiv.org/abs/2502.04385) (Tel Aviv)
- [ ] [\[2502.05151\] Transforming Science with Large Language Models: A Survey on AI-assisted Scientific Discovery, Experimentation, Content Generation, and Evaluation](https://arxiv.org/abs/2502.05151) (University of Tübingen)
- [ ] [\[2502.05119\] Investigating the impact of kernel harmonization and deformable registration on inspiratory and expiratory chest CT images for people with COPD](https://arxiv.org/abs/2502.05119) (Vanderbilt University)
- [ ] [\[2502.04988\] CMamba: Learned Image Compression with State Space Models](https://arxiv.org/abs/2502.04988) (Queensland)
- [ ] [\[2502.04903\] Wavelet-Assisted Multi-Frequency Attention Network for Pansharpening](https://arxiv.org/abs/2502.04903) (IA CAS)
- [ ] [\[2502.04794\] MedMimic: Physician-Inspired Multimodal Fusion for Early Diagnosis of Fever of Unknown Origin](https://arxiv.org/abs/2502.04794) (University of Tokyo)
- [ ] [\[2502.04359\] Exploring Spatial Language Grounding Through Referring Expressions](https://arxiv.org/abs/2502.04359) (UCSD)

## 2025-02-07 (Fri)
- [ ] [\[2502.04326\] WorldSense: Evaluating Real-world Omnimodal Understanding for Multimodal LLMs](https://arxiv.org/abs/2502.04326) (SJTU)
- [ ] [\[2502.04320\] ConceptAttention: Diffusion Transformers Learn Highly Interpretable Features](https://arxiv.org/abs/2502.04320) (GIT)
- [ ] [\[2502.04318\] sshELF: Single-Shot Hierarchical Extrapolation of Latent Features for 3D Reconstruction from Sparse-Views](https://arxiv.org/abs/2502.04318) (University of Tübingen)
- [ ] [\[2502.04293\] GCE-Pose: Global Context Enhancement for Category-level Object Pose Estimation](https://arxiv.org/abs/2502.04293) (TUM)
- [ ] [\[2502.04268\] Point2RBox-v2: Rethinking Point-supervised Oriented Object Detection with Spatial Layout Among Instances](https://arxiv.org/abs/2502.04268) (Tsinghua)
- [ ] [\[2502.04263\] Cross the Gap: Exposing the Intra-modal Misalignment in CLIP via Modality Inversion](https://arxiv.org/abs/2502.04263) (ICLR)
- [ ] [\[2502.04207\] Enhanced Feature-based Image Stitching for Endoscopic Videos in Pediatric Eosinophilic Esophagitis](https://arxiv.org/abs/2502.04207) (Vanderbilt University)
- [ ] [\[2502.04139\] Beyond the Final Layer: Hierarchical Query Fusion Transformer with Agent-Interpolation Initialization for 3D Instance Segmentation](https://arxiv.org/abs/2502.04139) (USTC)
- [ ] [\[2502.04111\] Adaptive Margin Contrastive Learning for Ambiguity-aware 3D Semantic Segmentation](https://arxiv.org/abs/2502.04111) (Tsinghua)
- [ ] [\[2502.04098\] Efficient Few-Shot Continual Learning in Vision-Language Models](https://arxiv.org/abs/2502.04098) (Cambridge)
- [ ] [\[2502.04076\] Content-Rich AIGC Video Quality Assessment via Intricate Text Alignment and Motion-Aware Consistency](https://arxiv.org/abs/2502.04076) (Peking)
- [ ] [\[2502.03997\] CAD-Editor: A Locate-then-Infill Framework with Automated Training Data Synthesis for Text-Based CAD Editing](https://arxiv.org/abs/2502.03997) (Microsoft)
- [ ] [\[2502.03971\] RWKV-UI: UI Understanding with Enhanced Perception and Reasoning](https://arxiv.org/abs/2502.03971) (SYSU)
- [ ] [\[2502.03950\] LR0.FM: Low-Resolution Zero-shot Classification Benchmark For Foundation Models](https://arxiv.org/abs/2502.03950) (ICLR)
- [ ] [\[2502.03877\] Advanced Object Detection and Pose Estimation with Hybrid Task Cascade and High-Resolution Networks](https://arxiv.org/abs/2502.03877) (University of Michigan)
- [ ] [\[2502.03856\] Taking A Closer Look at Interacting Objects: Interaction-Aware Open Vocabulary Scene Graph Generation](https://arxiv.org/abs/2502.03856) (HKUST)
- [ ] [\[2502.03852\] Pursuing Better Decision Boundaries for Long-Tailed Object Detection via Category Information Amount](https://arxiv.org/abs/2502.03852) (Xidian, ICLR)
- [ ] [\[2502.03829\] FE-UNet: Frequency Domain Enhanced U-Net with Segment Anything Capability for Versatile Image Segmentation](https://arxiv.org/abs/2502.03829) (UESTC)
- [ ] [\[2502.03826\] FairT2I: Mitigating Social Bias in Text-to-Image Generation via Large Language Model-Assisted Detection and Attribute Rebalancing](https://arxiv.org/abs/2502.03826) (University of Tokyo)
- [ ] [\[2502.03777\] Multi-Label Test-Time Adaptation with Bound Entropy Minimization](https://arxiv.org/abs/2502.03777) (ICLR)
- [ ] [\[2502.03758\] Improving Adversarial Robustness via Phase and Amplitude-aware Prompting](https://arxiv.org/abs/2502.03758) (Xidian)
- [ ] [\[2502.03649\] All-in-One Image Compression and Restoration](https://arxiv.org/abs/2502.03649) (USTC)
- [ ] [\[2502.03549\] Kronecker Mask and Interpretive Prompts are Language-Action Video Learners](https://arxiv.org/abs/2502.03549) (USTC, ICLR)
- [ ] [\[2502.04199\] Expanding Training Data for Endoscopic Phenotyping of Eosinophilic Esophagitis](https://arxiv.org/abs/2502.04199) (Vanderbilt University)
- [ ] [\[2502.04116\] Generative Adversarial Networks Bridging Art and Machine Intelligence](https://arxiv.org/abs/2502.04116) (Imperial)
- [ ] [\[2502.04079\] DEALing with Image Reconstruction: Deep Attentive Least Squares](https://arxiv.org/abs/2502.04079) (EPFL)
- [ ] [\[2502.03897\] UniForm: A Unified Diffusion Transformer for Audio-Video Generation](https://arxiv.org/abs/2502.03897) (NWPU)
- [ ] [\[2502.03482\] Can Domain Experts Rely on AI Appropriately? A Case Study on AI-Assisted Prostate Cancer MRI Diagnosis](https://arxiv.org/abs/2502.03482) (University of Michigan)

## 2025-02-06 (Thu)
- [ ] [\[2502.03444\] Masked Autoencoders Are Effective Tokenizers for Diffusion Models](https://arxiv.org/abs/2502.03444) (CMU)
- [ ] [\[2502.03207\] MotionAgent: Fine-grained Controllable Video Generation via Motion Field Agent](https://arxiv.org/abs/2502.03207) (NTU)
- [ ] [\[2502.02977\] Disentangling CLIP Features for Enhanced Localized Understanding](https://arxiv.org/abs/2502.02977) (Illinois)
- [ ] [\[2502.02936\] Every Angle Is Worth A Second Glance: Mining Kinematic Skeletal Structures from Multi-view Joint Cloud](https://arxiv.org/abs/2502.02936) (BU)
- [ ] [\[2502.02867\] Domain-Invariant Per-Frame Feature Extraction for Cross-Domain Imitation Learning with Visual Observations](https://arxiv.org/abs/2502.02867) (ICML)
- [ ] [\[2502.02835\] A Survey of Sample-Efficient Deep Learning for Change Detection in Remote Sensing: Tasks, Strategies, and Challenges](https://arxiv.org/abs/2502.02835) (University of Tokyo)
- [ ] [\[2502.02763\] Rethinking Vision Transformer for Object Centric Foundation Models](https://arxiv.org/abs/2502.02763) (University of Tübingen)
- [ ] [\[2502.02741\] RFMedSAM 2: Automatic Prompt Refinement for Enhanced Volumetric Medical Image Segmentation with SAM 2](https://arxiv.org/abs/2502.02741) (Peking)
- [ ] [\[2502.02707\] Multiple Instance Learning with Coarse-to-Fine Self-Distillation](https://arxiv.org/abs/2502.02707) (University of Edinburgh)
- [ ] [\[2502.02690\] Controllable Video Generation with Provable Disentanglement](https://arxiv.org/abs/2502.02690) (CMU)
- [ ] [\[2502.02676\] Blind Visible Watermark Removal with Morphological Dilation](https://arxiv.org/abs/2502.02676) (Vanderbilt University)
- [ ] [\[2502.02607\] MIND: Microstructure INverse Design with Generative Hybrid Neural Representation](https://arxiv.org/abs/2502.02607) (ETH)
- [ ] [\[2502.03270\] When Pre-trained Visual Representations Fall Short: Limitations in Visuo-Motor Robot Learning](https://arxiv.org/abs/2502.03270) (University of Edinburgh)
- [ ] [\[2502.02922\] Elucidating the Preconditioning in Consistency Distillation](https://arxiv.org/abs/2502.02922) (ICLR)
- [ ] [\[2502.02773\] SD++: Enhancing Standard Definition Maps by Incorporating Road Knowledge using LLMs](https://arxiv.org/abs/2502.02773) (UCSD)
- [ ] [\[2502.02610\] Secure & Personalized Music-to-Video Generation via CHARCHA](https://arxiv.org/abs/2502.02610) (CMU, NIPS)

## 2025-02-05 (Wed)
- [ ] [\[2502.02525\] Diff9D: Diffusion-Based Domain-Generalized Category-Level 9-DoF Object Pose Estimation](https://arxiv.org/abs/2502.02525) (XJTU)
- [ ] [\[2502.02501\] Graph-based Document Structure Analysis](https://arxiv.org/abs/2502.02501) (ICLR)
- [ ] [\[2502.02454\] IMDPrompter: Adapting SAM to Image Manipulation Detection by Cross-View Automated Prompt Learning](https://arxiv.org/abs/2502.02454) (SJTU)
- [ ] [\[2502.02449\] TUMTraffic-VideoQA: A Benchmark for Unified Spatio-Temporal Video Understanding in Traffic Scenes](https://arxiv.org/abs/2502.02449) (TUM)
- [ ] [\[2502.02372\] MaintaAvatar: A Maintainable Avatar Based on Neural Radiance Fields by Continual Learning](https://arxiv.org/abs/2502.02372) (SYSU)
- [ ] [\[2502.02340\] Transfer Risk Map: Mitigating Pixel-level Negative Transfer in Medical Segmentation](https://arxiv.org/abs/2502.02340) (Tsinghua)
- [ ] [\[2502.02338\] Geometric Neural Process Fields](https://arxiv.org/abs/2502.02338) (UVA.NL)
- [ ] [\[2502.02334\] Event-aided Semantic Scene Completion](https://arxiv.org/abs/2502.02334) (ZJU)
- [ ] [\[2502.02257\] UNIP: Rethinking Pre-trained Attention Patterns for Infrared Semantic Segmentation](https://arxiv.org/abs/2502.02257) (ICLR)
- [ ] [\[2502.02247\] Rotation-Adaptive Point Cloud Domain Generalization via Intricate Orientation Learning](https://arxiv.org/abs/2502.02247) (TPAMI)
- [ ] [\[2502.02225\] Exploring the latent space of diffusion models directly through singular value decomposition](https://arxiv.org/abs/2502.02225) (ZJU)
- [ ] [\[2502.02215\] InterLCM: Low-Quality Images as Intermediate States of Latent Consistency Models for Effective Blind Face Restoration](https://arxiv.org/abs/2502.02215) (ICLR)
- [ ] [\[2502.02196\] Exploiting Ensemble Learning for Cross-View Isolated Sign Language Recognition](https://arxiv.org/abs/2502.02196) (USTC)
- [ ] [\[2502.02187\] ShapeShifter: 3D Variations Using Multiscale and Sparse Point-Voxel Diffusion](https://arxiv.org/abs/2502.02187) (Inria)
- [ ] [\[2502.02182\] Sequence models for continuous cell cycle stage prediction from brightfield images](https://arxiv.org/abs/2502.02182) (EPFL)
- [ ] [\[2502.02144\] DOC-Depth: A novel approach for dense depth ground truth generation](https://arxiv.org/abs/2502.02144) (PSL University)
- [ ] [\[2502.02097\] VerteNet -- A Multi-Context Hybrid CNN Transformer for Accurate Vertebral Landmark Localization in Lateral Spine DXA Images](https://arxiv.org/abs/2502.02097) (SYSU)
- [ ] [\[2502.02096\] Dual-Flow: Transferable Multi-Target, Instance-Agnostic Attacks via In-the-wild Cascading Flow Optimization](https://arxiv.org/abs/2502.02096) (Tsinghua)
- [ ] [\[2502.02091\] Efficient Dynamic Scene Editing via 4D Gaussian-based Static-Dynamic Separation](https://arxiv.org/abs/2502.02091) (KAIST)
- [ ] [\[2502.02027\] From Fog to Failure: How Dehazing Can Harm Clear Image Object Detection](https://arxiv.org/abs/2502.02027) (Rochester Institute of Technology)
- [ ] [\[2502.01969\] Mitigating Object Hallucinations in Large Vision-Language Models via Attention Calibration](https://arxiv.org/abs/2502.01969) (USyd)
- [ ] [\[2502.01962\] Memory Efficient Transformer Adapter for Dense Predictions](https://arxiv.org/abs/2502.01962) (NJU, ICLR)
- [ ] [\[2502.01959\] MATCNN: Infrared and Visible Image Fusion Method Based on Multi-scale CNN with Attention Transformer](https://arxiv.org/abs/2502.01959) (Fudan)
- [ ] [\[2502.01890\] Geometric Framework for 3D Cell Segmentation Correction](https://arxiv.org/abs/2502.01890) (Columbia University)
- [ ] [\[2502.01850\] Foundation Model-Based Apple Ripeness and Size Estimation for Selective Harvesting](https://arxiv.org/abs/2502.01850) (Michigan State University)
- [ ] [\[2502.01776\] Sparse VideoGen: Accelerating Video Diffusion Transformers with Spatial-Temporal Sparsity](https://arxiv.org/abs/2502.01776) (Berkeley)
- [ ] [\[2502.01707\] CLIP-DQA: Blindly Evaluating Dehazed Images from Global and Local Perspectives Using CLIP](https://arxiv.org/abs/2502.01707) (SYSU)
- [ ] [\[2502.02562\] Learning the RoPEs: Better 2D and 3D Position Encodings with STRING](https://arxiv.org/abs/2502.02562) (Google)
- [ ] [\[2502.02558\] Particle Trajectory Representation Learning with Masked Point Modeling](https://arxiv.org/abs/2502.02558) (Stanford)
- [ ] [\[2502.02500\] The Skin Game: Revolutionizing Standards for AI Dermatology Model Comparison](https://arxiv.org/abs/2502.02500) (MIT)
- [ ] [\[2502.02458\] SAISA: Towards Multimodal Large Language Models with Both Training and Inference Efficiency](https://arxiv.org/abs/2502.02458) (UCAS)
- [ ] [\[2502.02175\] VLA-Cache: Towards Efficient Vision-Language-Action Model via Adaptive Token Caching in Robotic Manipulation](https://arxiv.org/abs/2502.02175) (USyd)
- [ ] [\[2502.02048\] Efficient Domain Adaptation of Multimodal Embeddings using Constrastive Learning](https://arxiv.org/abs/2502.02048) (MIT)

## 2025-02-04 (Tue)
- [ ] [\[2502.01576\] Robust-LLaVA: On the Effectiveness of Large-Scale Robust Image Encoders for Multi-modal Large Language Models](https://arxiv.org/abs/2502.01576) (MBZUAI)
- [ ] [\[2502.01467\] Deep Unfolding Multi-modal Image Fusion Network via Attribution Analysis](https://arxiv.org/abs/2502.01467) (XJTU)
- [ ] [\[2502.01441\] Improved Training Technique for Latent Consistency Models](https://arxiv.org/abs/2502.01441) (ICLR)
- [ ] [\[2502.01403\] AdaSVD: Adaptive Singular Value Decomposition for Large Language Models](https://arxiv.org/abs/2502.01403) (SJTU)
- [ ] [\[2502.01357\] Bayesian Approximation-Based Trajectory Prediction and Tracking with 4D Radar](https://arxiv.org/abs/2502.01357) (KAIST)
- [ ] [\[2502.01356\] Quasi-Conformal Convolution : A Learnable Convolution for Deep Learning on Riemann Surfaces](https://arxiv.org/abs/2502.01356) (CUHK)
- [ ] [\[2502.01309\] Heterogeneous Image GNN: Graph-Conditioned Diffusion for Image Synthesis](https://arxiv.org/abs/2502.01309) (Cambridge)
- [ ] [\[2502.01303\] Partial Channel Network: Compute Fewer, Perform Better](https://arxiv.org/abs/2502.01303) (XJTU)
- [ ] [\[2502.01297\] XR-VIO: High-precision Visual Inertial Odometry with Fast Initialization for XR Applications](https://arxiv.org/abs/2502.01297) (SenseTime)
- [ ] [\[2502.01201\] One-to-Normal: Anomaly Personalization for Few-shot Anomaly Detection](https://arxiv.org/abs/2502.01201) (BUPT, NIPS)
- [ ] [\[2502.01199\] Nearly Lossless Adaptive Bit Switching](https://arxiv.org/abs/2502.01199) (XJTU)
- [ ] [\[2502.01191\] Towards Robust and Reliable Concept Representations: Reliability-Enhanced Concept Embedding Model](https://arxiv.org/abs/2502.01191) (NTU)
- [ ] [\[2502.01183\] Enhancing Environmental Robustness in Few-shot Learning via Conditional Representation Learning](https://arxiv.org/abs/2502.01183) (Fudan, TIP)
- [ ] [\[2502.01105\] LayerTracer: Cognitive-Aligned Layered SVG Synthesis via Diffusion Transformer](https://arxiv.org/abs/2502.01105) (NUS)
- [ ] [\[2502.01101\] VidSketch: Hand-drawn Sketch-Driven Video Generation with Diffusion Control](https://arxiv.org/abs/2502.01101) (ZJU)
- [ ] [\[2502.01080\] BC-GAN: A Generative Adversarial Network for Synthesizing a Batch of Collocated Clothing](https://arxiv.org/abs/2502.01080) (HIT)
- [ ] [\[2502.01051\] Diffusion Model as a Noise-Aware Latent Reward Model for Step-Level Preference Optimization](https://arxiv.org/abs/2502.01051) (IA CAS)
- [ ] [\[2502.01004\] ZeroBP: Learning Position-Aware Correspondence for Zero-shot 6D Pose Estimation in Bin-Picking](https://arxiv.org/abs/2502.01004) (HIT)
- [ ] [\[2502.01002\] Multi-Resolution SAR and Optical Remote Sensing Image Registration Methods: A Review, Datasets, and Future Perspectives](https://arxiv.org/abs/2502.01002) (WHU)
- [ ] [\[2502.01000\] Adapting Foundation Models for Few-Shot Medical Image Segmentation: Actively and Sequentially](https://arxiv.org/abs/2502.01000) (Tsinghua)
- [ ] [\[2502.00992\] FCBoost-Net: A Generative Network for Synthesizing Multiple Collocated Outfits via Fashion Compatibility Boosting](https://arxiv.org/abs/2502.00992) (HIT, ACMMM)
- [ ] [\[2502.00965\] CLIP-UP: A Simple and Efficient Mixture-of-Experts CLIP Training Recipe with Sparse Upcycling](https://arxiv.org/abs/2502.00965) (Apple)
- [ ] [\[2502.00960\] SAM-guided Pseudo Label Enhancement for Multi-modal 3D Semantic Segmentation](https://arxiv.org/abs/2502.00960) (University of Michigan)
- [ ] [\[2502.00954\] Hypo3D: Exploring Hypothetical Reasoning in 3D](https://arxiv.org/abs/2502.00954) (Imperial)
- [ ] [\[2502.00869\] STAF: Sinusoidal Trainable Activation Functions for Implicit Neural Representation](https://arxiv.org/abs/2502.00869) (University of Toronto)
- [ ] [\[2502.00730\] Spatio-Temporal Progressive Attention Model for EEG Classification in Rapid Serial Visual Presentation Task](https://arxiv.org/abs/2502.00730) (Xidian)
- [ ] [\[2502.00688\] High-Order Matching for One-Step Shortcut Diffusion Models](https://arxiv.org/abs/2502.00688) (UT Austin)
- [ ] [\[2502.00639\] Zeroth-order Informed Fine-Tuning for Diffusion Model: A Recursive Likelihood Ratio Optimizer](https://arxiv.org/abs/2502.00639) (Peking)
- [ ] [\[2502.00630\] Self-Prompt SAM: Medical Image Segmentation via Automatic Prompt SAM Adaptation](https://arxiv.org/abs/2502.00630) (Peking)
- [ ] [\[2502.00618\] DesCLIP: Robust Continual Adaptation via General Attribute Descriptions for Pretrained Vision-Language Models](https://arxiv.org/abs/2502.00618) (UESTC)
- [ ] [\[2502.00568\] Generating crossmodal gene expression from cancer histopathology improves multimodal AI predictions](https://arxiv.org/abs/2502.00568) (Alan Turing Institute)
- [ ] [\[2502.00433\] CAT Pruning: Cluster-Aware Token Pruning For Text-to-Image Diffusion Models](https://arxiv.org/abs/2502.00433) (Peking)
- [ ] [\[2502.00426\] TeST-V: TEst-time Support-set Tuning for Zero-shot Video Classification](https://arxiv.org/abs/2502.00426) (NJU)
- [ ] [\[2502.00418\] Parameter Efficient Fine-Tuning of Segment Anything Model](https://arxiv.org/abs/2502.00418) (University of Göttingen)
- [ ] [\[2502.00392\] RefDrone: A Challenging Benchmark for Referring Expression Comprehension in Drone Scenes](https://arxiv.org/abs/2502.00392) (WHU)
- [ ] [\[2502.00382\] Masked Generative Nested Transformers with Decode Time Scaling](https://arxiv.org/abs/2502.00382) (Google)
- [ ] [\[2502.00360\] Shape from Semantics: 3D Shape Generation from Multi-View Semantics](https://arxiv.org/abs/2502.00360) (USTC)
- [ ] [\[2502.00342\] Embodied Intelligence for 3D Understanding: A Survey on 3D Scene Question Answering](https://arxiv.org/abs/2502.00342) (USyd)
- [ ] [\[2502.00333\] BiMaCoSR: Binary One-Step Diffusion Model Leveraging Flexible Matrix Compression for Real Super-Resolution](https://arxiv.org/abs/2502.00333) (SJTU)
- [ ] [\[2502.00307\] A Diffusion Model Translator for Efficient Image-to-Image Translation](https://arxiv.org/abs/2502.00307) (SJTU)
- [ ] [\[2502.00156\] ALBAR: Adversarial Learning approach to mitigate Biases in Action Recognition](https://arxiv.org/abs/2502.00156) (ICLR)
- [ ] [\[2502.00129\] ProtoSnap: Prototype Alignment for Cuneiform Signs](https://arxiv.org/abs/2502.00129) (ICLR)
- [ ] [\[2502.01427\] Structural features of the fly olfactory circuit mitigate the stability-plasticity dilemma in continual learning](https://arxiv.org/abs/2502.01427) (Tsinghua)
- [ ] [\[2502.01385\] Detecting Backdoor Samples in Contrastive Language Image Pretraining](https://arxiv.org/abs/2502.01385) (ICLR)
- [ ] [\[2502.01218\] Provable Ordering and Continuity in Vision-Language Pretraining for Generalizable Embodied Agents](https://arxiv.org/abs/2502.01218) (Queensland)
- [ ] [\[2502.01158\] MIND: Modality-Informed Knowledge Distillation Framework for Multimodal Clinical Prediction Tasks](https://arxiv.org/abs/2502.01158) (NYU)
- [ ] [\[2502.01117\] Learning to Learn Weight Generation via Trajectory Diffusion](https://arxiv.org/abs/2502.01117) (NTU)
- [ ] [\[2502.01046\] Emotional Face-to-Speech](https://arxiv.org/abs/2502.01046) (Fudan)
- [ ] [\[2502.00987\] RandLoRA: Full-rank parameter-efficient fine-tuning of large models](https://arxiv.org/abs/2502.00987) (ICLR)
- [ ] [\[2502.00754\] Continuity-Preserving Convolutional Autoencoders for Learning Continuous Latent Dynamical Models from Images](https://arxiv.org/abs/2502.00754) (NUS)
- [ ] [\[2502.00745\] BEEM: Boosting Performance of Early Exit DNNs using Multi-Exit Classifiers as Experts](https://arxiv.org/abs/2502.00745) (ICLR)
- [ ] [\[2502.00712\] Registration-Enhanced Segmentation Method for Prostate Cancer in Ultrasound Images](https://arxiv.org/abs/2502.00712) (Stanford)
- [ ] [\[2502.00698\] MM-IQ: Benchmarking Human-Like Abstraction and Reasoning in Multimodal Models](https://arxiv.org/abs/2502.00698) (UCAS)
- [ ] [\[2502.00619\] Distribution-aware Fairness Learning in Medical Image Segmentation From A Control-Theoretic Perspective](https://arxiv.org/abs/2502.00619) (Harvard)
- [ ] [\[2502.00545\] Integrating Frequency Guidance into Multi-source Domain Generalization for Bearing Fault Diagnosis](https://arxiv.org/abs/2502.00545) (Xiamen)
- [ ] [\[2502.00473\] Weak-to-Strong Diffusion with Reflection](https://arxiv.org/abs/2502.00473) (HKUST(GZ))
- [ ] [\[2502.00408\] Segment Anything for Histopathology](https://arxiv.org/abs/2502.00408) (University of Göttingen)
- [ ] [\[2502.00395\] FlexCloud: Direct, Modular Georeferencing and Drift-Correction of Point Cloud Maps](https://arxiv.org/abs/2502.00395) (TUM)
- [ ] [\[2502.00374\] A Unit-based System and Dataset for Expressive Direct Speech-to-Speech Translation](https://arxiv.org/abs/2502.00374) (Tsinghua)
- [ ] [\[2502.00366\] Prostate-Specific Foundation Models for Enhanced Detection of Clinically Significant Cancer](https://arxiv.org/abs/2502.00366) (Stanford)
- [ ] [\[2502.00253\] Patch Triplet Similarity Purification for Guided Real-World Low-Dose CT Image Denoising](https://arxiv.org/abs/2502.00253) (Nankai)
- [ ] [\[2502.00241\] Mordal: Automated Pretrained Model Selection for Vision Language Models](https://arxiv.org/abs/2502.00241) (University of Michigan)
- [ ] [\[2502.00234\] Fast Solvers for Discrete Diffusion Models: Theory and Applications of High-Order Algorithms](https://arxiv.org/abs/2502.00234) (Stanford)
- [ ] [\[2502.00114\] Mobile Robot Navigation Using Hand-Drawn Maps: A Vision Language Model Approach](https://arxiv.org/abs/2502.00114) (University of Toronto)

## 2025-02-03 (Mon)
- [ ] [\[2501.19252\] Inference-Time Text-to-Video Alignment with Diffusion Latent Beam Search](https://arxiv.org/abs/2501.19252) (University of Tokyo)
- [ ] [\[2501.19160\] RMDM: Radio Map Diffusion Model with Physics Informed](https://arxiv.org/abs/2501.19160) (HKUST(GZ))
- [ ] [\[2501.19159\] GDO: Gradual Domain Osmosis](https://arxiv.org/abs/2501.19159) (ICML)
- [ ] [\[2501.19155\] SWAT: Sliding Window Adversarial Training for Gradual Domain Adaptation](https://arxiv.org/abs/2501.19155) (UESTC, ICML)
- [ ] [\[2501.19129\] RGB-Event ISP: The Dataset and Benchmark](https://arxiv.org/abs/2501.19129) (HKUST(GZ), ICLR)
- [ ] [\[2501.19111\] A Benchmark for Incremental Micro-expression Recognition](https://arxiv.org/abs/2501.19111) (HIT)
- [ ] [\[2501.19086\] Fairness Analysis of CLIP-Based Foundation Models for X-Ray Image Classification](https://arxiv.org/abs/2501.19086) (UESTC)
- [ ] [\[2501.19084\] Laser: Efficient Language-Guided Segmentation in Neural Radiance Fields](https://arxiv.org/abs/2501.19084) (A*STAR,, TPAMI)
- [ ] [\[2501.19083\] MotionPCM: Real-Time Motion Synthesis with Phased Consistency Model](https://arxiv.org/abs/2501.19083) (UCL)
- [ ] [\[2501.19069\] Improving vision-language alignment with graph spiking hybrid Networks](https://arxiv.org/abs/2501.19069) (Tongji)
- [ ] [\[2501.19066\] Concept Steerers: Leveraging K-Sparse Autoencoders for Controllable Generations](https://arxiv.org/abs/2501.19066) (BU)
- [ ] [\[2501.19061\] EgoMe: Follow Me via Egocentric View in Real World](https://arxiv.org/abs/2501.19061) (UESTC)
- [ ] [\[2501.19060\] Contrast-Aware Calibration for Fine-Tuned CLIP: Leveraging Image-Text Alignment](https://arxiv.org/abs/2501.19060) (NJU)
- [ ] [\[2501.19054\] Text-to-CAD Generation Through Infusing Visual Feedback in Large Language Models](https://arxiv.org/abs/2501.19054) (Microsoft)
- [ ] [\[2501.19034\] XRF V2: A Dataset for Action Summarization with Wi-Fi Signals, and IMUs in Phones, Watches, Earbuds, and Glasses](https://arxiv.org/abs/2501.19034) (XJTU)
- [ ] [\[2501.18984\] Context Matters: Query-aware Dynamic Long Sequence Modeling of Gigapixel Images](https://arxiv.org/abs/2501.18984) (HKUST)
- [ ] [\[2501.18982\] OmniPhysGS: 3D Constitutive Gaussians for General Physics-Based Dynamics Generation](https://arxiv.org/abs/2501.18982) (ICLR)
- [ ] [\[2501.18954\] LLMDet: Learning Strong Open-Vocabulary Object Detectors under the Supervision of Large Language Models](https://arxiv.org/abs/2501.18954) (SYSU)
- [ ] [\[2501.18940\] TV-Dialogue: Crafting Theme-Aware Video Dialogues with Immersive Interaction](https://arxiv.org/abs/2501.18940) (WHU)
- [ ] [\[2501.18913\] Rethinking Diffusion Posterior Sampling: From Conditional Score Estimator to Maximizing a Posterior](https://arxiv.org/abs/2501.18913) (NYU, ICLR)
- [ ] [\[2501.18880\] RLS3: RL-Based Synthetic Sample Selection to Enhance Spatial Reasoning in Vision-Language Models for Indoor Autonomous Perception](https://arxiv.org/abs/2501.18880) (NYU)
- [ ] [\[2501.18867\] UP-VLA: A Unified Understanding and Prediction Model for Embodied Agent](https://arxiv.org/abs/2501.18867) (Tsinghua)
- [ ] [\[2501.18865\] REG: Rectified Gradient Guidance for Conditional Diffusion Models](https://arxiv.org/abs/2501.18865) (MIT)
- [ ] [\[2501.18864\] Test-time Loss Landscape Adaptation for Zero-Shot Generalization in Vision-Language Models](https://arxiv.org/abs/2501.18864) (USTC)
- [ ] [\[2501.18855\] FlexiCrackNet: A Flexible Pipeline for Enhanced Crack Segmentation with General Features Transfered from SAM](https://arxiv.org/abs/2501.18855) (UW)
- [ ] [\[2501.18716\] Full-Head Segmentation of MRI with Abnormal Brain Anatomy: Model and Data Release](https://arxiv.org/abs/2501.18716) (NYU)
- [ ] [\[2501.18648\] Image, Text, and Speech Data Augmentation using Multimodal LLMs for Deep Learning: A Survey](https://arxiv.org/abs/2501.18648) (Cornell)
- [ ] [\[2501.18616\] STAMP: Scalable Task And Model-agnostic Collaborative Perception](https://arxiv.org/abs/2501.18616) (ICLR)
- [ ] [\[2501.19203\] Single cell resolution 3D imaging and segmentation within intact live tissues](https://arxiv.org/abs/2501.19203) (UCL)
- [ ] [\[2501.19047\] Understanding Model Calibration -- A gentle introduction and visual exploration of calibration and the expected calibration error (ECE)](https://arxiv.org/abs/2501.19047) (QMUL)
- [ ] [\[2501.18834\] Pitfalls of defacing whole-head MRI: re-identification risk with diffusion models and compromised research potential](https://arxiv.org/abs/2501.18834) (Vanderbilt University)
- [ ] [\[2501.18736\] Distillation-Driven Diffusion Model for Multi-Scale MRI Super-Resolution: Make 1.5T MRI Great Again](https://arxiv.org/abs/2501.18736) (Harvard)
- [ ] [\[2501.18614\] Review and Recommendations for using Artificial Intelligence in Intracoronary Optical Coherence Tomography Analysis](https://arxiv.org/abs/2501.18614) (Cambridge)

## 2025-01-31 (Fri)
- [ ] [\[2501.18593\] Diffusion Autoencoders are Scalable Image Tokenizers](https://arxiv.org/abs/2501.18593) (UCSD)
- [ ] [\[2501.18533\] Rethinking Bottlenecks in Safety Fine-Tuning of Vision Language Models](https://arxiv.org/abs/2501.18533) (Tianjin)
- [ ] [\[2501.18504\] CLEAR: Cue Learning using Evolution for Accurate Recognition Applied to Sustainability Data Extraction](https://arxiv.org/abs/2501.18504) (UCL)
- [ ] [\[2501.18500\] HSRMamba: Contextual Spatial-Spectral State Space Model for Single Hyperspectral Super-Resolution](https://arxiv.org/abs/2501.18500) (WHU)
- [ ] [\[2501.18494\] Runway vs. Taxiway: Challenges in Automated Line Identification and Notation Approaches](https://arxiv.org/abs/2501.18494) (NASA)
- [ ] [\[2501.18487\] Track-On: Transformer-based Online Point Tracking with Memory](https://arxiv.org/abs/2501.18487) (ICLR)
- [ ] [\[2501.18232\] Free-T2M: Frequency Enhanced Text-to-Motion Diffusion Model With Consistency Loss](https://arxiv.org/abs/2501.18232) (HKUST(GZ))
- [ ] [\[2501.18124\] REMOTE: Real-time Ego-motion Tracking for Various Endoscopes via Multimodal Visual Feature Learning](https://arxiv.org/abs/2501.18124) (Fudan)
- [ ] [\[2501.18116\] DeepFRC: An End-to-End Deep Learning Model for Functional Registration and Classification](https://arxiv.org/abs/2501.18116) (ShanghaiTech)
- [ ] [\[2501.18098\] Disentangling Safe and Unsafe Corruptions via Anisotropy and Locality](https://arxiv.org/abs/2501.18098) (JHU)
- [ ] [\[2501.18096\] LLMs can see and hear without any training](https://arxiv.org/abs/2501.18096) (UT Austin)
- [ ] [\[2501.17906\] Unsupervised Patch-GAN with Targeted Patch Ranking for Fine-Grained Novelty Detection in Medical Imaging](https://arxiv.org/abs/2501.17906) (SUSTech)
- [ ] [\[2501.18588\] Inkspire: Supporting Design Exploration with Generative AI through Analogical Sketching](https://arxiv.org/abs/2501.18588) (CMU)
- [ ] [\[2501.18362\] MedXpertQA: Benchmarking Expert-Level Medical Reasoning and Understanding](https://arxiv.org/abs/2501.18362) (Tsinghua)
- [ ] [\[2501.18314\] AGAV-Rater: Adapting Large Multimodal Model for AI-Generated Audio-Visual Quality Assessment](https://arxiv.org/abs/2501.18314) (SJTU)