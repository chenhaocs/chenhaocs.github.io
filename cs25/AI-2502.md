
## 2025-02-21 (Fri)
- [ ] [\[2502.14864\] Benchmarking Multimodal RAG through a Chart-based Document Question-Answering Generation Framework](https://arxiv.org/abs/2502.14864) (Chongqing)
- [ ] [\[2502.14777\] Making Universal Policies Universal](https://arxiv.org/abs/2502.14777) (UVA.NL)
- [ ] [\[2502.14760\] EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations](https://arxiv.org/abs/2502.14760) (UT Austin)
- [ ] [\[2502.14706\] Building reliable sim driving agents by scaling self-play](https://arxiv.org/abs/2502.14706) (NYU)
- [ ] [\[2502.14563\] Plan-over-Graph: Towards Parallelable LLM Agent Schedule](https://arxiv.org/abs/2502.14563) (SJTU)
- [ ] [\[2502.14361\] Retrieval-Augmented Process Reward Model for Generalizable Mathematical Reasoning](https://arxiv.org/abs/2502.14361) (SJTU)
- [ ] [\[2502.14074\] Investigating Non-Transitivity in LLM-as-a-Judge](https://arxiv.org/abs/2502.14074) (UCL)
- [ ] [\[2502.14807\] FetalCLIP: A Visual-Language Foundation Model for Fetal Ultrasound Image Analysis](https://arxiv.org/abs/2502.14807) (MBZUAI)
- [ ] [\[2502.14791\] Rapid Word Learning Through Meta In-Context Learning](https://arxiv.org/abs/2502.14791) (Peking)
- [ ] [\[2502.14786\] SigLIP 2: Multilingual Vision-Language Encoders with Improved Semantic Understanding, Localization, and Dense Features](https://arxiv.org/abs/2502.14786) (Google)
- [ ] [\[2502.14780\] ReVision: A Dataset and Baseline VLM for Privacy-Preserving Task-Oriented Visual Instruction Rewriting](https://arxiv.org/abs/2502.14780) (Yale)
- [ ] [\[2502.14778\] Harnessing PDF Data for Improving Japanese Large Multimodal Models](https://arxiv.org/abs/2502.14778) (University of Tokyo)
- [ ] [\[2502.14735\] EAGER-LLM: Enhancing Large Language Models as Recommenders through Exogenous Behavior-Semantic Integration](https://arxiv.org/abs/2502.14735) (ZJU)
- [ ] [\[2502.14727\] WavRAG: Audio-Integrated Retrieval Augmented Generation for Spoken Dialogue Models](https://arxiv.org/abs/2502.14727) (ZJU)
- [ ] [\[2502.14704\] Not All Data are Good Labels: On the Self-supervised Labeling for Time Series Forecasting](https://arxiv.org/abs/2502.14704) (ZJU)
- [ ] [\[2502.14698\] General Uncertainty Estimation with Delta Variances](https://arxiv.org/abs/2502.14698) (Google)
- [ ] [\[2502.14676\] BP-SGCN: Behavioral Pseudo-Label Informed Sparse Graph Convolution Network for Pedestrian and Heterogeneous Trajectory Prediction](https://arxiv.org/abs/2502.14676) (KAIST)
- [ ] [\[2502.14627\] ATRI: Mitigating Multilingual Audio Text Retrieval Inconsistencies by Reducing Data Distribution Errors](https://arxiv.org/abs/2502.14627) (SYSU)
- [ ] [\[2502.14572\] Factor Graph-based Interpretable Neural Networks](https://arxiv.org/abs/2502.14572) (ICLR)
- [ ] [\[2502.14560\] Less is More: Improving LLM Alignment via Preference Data Selection](https://arxiv.org/abs/2502.14560) (USTC)
- [ ] [\[2502.14546\] Position: Graph Learning Will Lose Relevance Due To Poor Benchmarks](https://arxiv.org/abs/2502.14546) (Tel Aviv)
- [ ] [\[2502.14529\] CORBA: Contagious Recursive Blocking Attacks on Multi-Agent Systems Based on Large Language Models](https://arxiv.org/abs/2502.14529) (USTC)
- [ ] [\[2502.14499\] MLGym: A New Framework and Benchmark for Advancing AI Research Agents](https://arxiv.org/abs/2502.14499) (Meta)
- [ ] [\[2502.14487\] Temporal Misalignment and Probabilistic Neurons](https://arxiv.org/abs/2502.14487) (MBZUAI)
- [ ] [\[2502.14486\] How Jailbreak Defenses Work and Ensemble? A Mechanistic Investigation](https://arxiv.org/abs/2502.14486) (Fudan)
- [ ] [\[2502.14458\] Llamba: Scaling Distilled Recurrent Models for Efficient Language Processing](https://arxiv.org/abs/2502.14458) (CMU)
- [ ] [\[2502.14457\] Watch Less, Feel More: Sim-to-Real RL for Generalizable Articulated Object Manipulation via Motion Adaptation and Impedance Control](https://arxiv.org/abs/2502.14457) (Peking)
- [ ] [\[2502.14445\] PredictaBoard: Benchmarking LLM Score Predictability](https://arxiv.org/abs/2502.14445) (Cambridge)
- [ ] [\[2502.14424\] Distribution Matching for Self-Supervised Transfer Learning](https://arxiv.org/abs/2502.14424) (WHU)
- [ ] [\[2502.14372\] Discovering highly efficient low-weight quantum error-correcting codes with reinforcement learning](https://arxiv.org/abs/2502.14372) (UT Austin)
- [ ] [\[2502.14334\] Purest Quantum State Identification](https://arxiv.org/abs/2502.14334) (USTC)
- [ ] [\[2502.14316\] Textured 3D Regenerative Morphing with 3D Diffusion Prior](https://arxiv.org/abs/2502.14316) (NTU)
- [ ] [\[2502.14302\] MedHallu: A Comprehensive Benchmark for Detecting Medical Hallucinations in Large Language Models](https://arxiv.org/abs/2502.14302) (UT Austin)
- [ ] [\[2502.14297\] An Evaluation of Sakana's AI Scientist for Autonomous Research: Wishful Thinking or an Emerging Reality Towards 'Artificial General Research Intelligence' (AGRI)?](https://arxiv.org/abs/2502.14297) (NUS)
- [ ] [\[2502.14281\] Correcting Noisy Multilabel Predictions: Modeling Label Noise through Latent Space Shifts](https://arxiv.org/abs/2502.14281) (Xidian)
- [ ] [\[2502.14276\] STeCa: Step-level Trajectory Calibration for LLM Agent Learning](https://arxiv.org/abs/2502.14276) (PolyU)
- [ ] [\[2502.14273\] LLM-EvRep: Learning an LLM-Compatible Event Representation Using a Self-Supervised Framework](https://arxiv.org/abs/2502.14273) (BU)
- [ ] [\[2502.14272\] Capturing Nuanced Preferences: Preference-Aligned Distillation for Small Language Models](https://arxiv.org/abs/2502.14272) (HKUST(GZ))
- [ ] [\[2502.14255\] Effects of Prompt Length on Domain-specific Tasks for Large Language Models](https://arxiv.org/abs/2502.14255) (GIT)
- [ ] [\[2502.14235\] OG-Gaussian: Occupancy Based Street Gaussians for Autonomous Driving](https://arxiv.org/abs/2502.14235) (USTC)
- [ ] [\[2502.14218\] Rethinking Spiking Neural Networks from an Ensemble Learning Perspective](https://arxiv.org/abs/2502.14218) (UESTC, ICLR)
- [ ] [\[2502.14205\] Accurate Forgetting for Heterogeneous Federated Continual Learning](https://arxiv.org/abs/2502.14205) (ICLR)
- [ ] [\[2502.14204\] On-the-fly Preference Alignment via Principle-Guided Decoding](https://arxiv.org/abs/2502.14204) (USTC, ICLR)
- [ ] [\[2502.14160\] Efficient Inverse Multiagent Learning](https://arxiv.org/abs/2502.14160) (ICLR)
- [ ] [\[2502.14149\] PitVQA++: Vector Matrix-Low-Rank Adaptation for Open-Ended Visual Question Answering in Pituitary Surgery](https://arxiv.org/abs/2502.14149) (UCL)
- [ ] [\[2502.14132\] Can Community Notes Replace Professional Fact-Checkers?](https://arxiv.org/abs/2502.14132) (University of Copenhagen)
- [ ] [\[2502.14070\] DiffExp: Efficient Exploration in Reward Fine-tuning for Text-to-Image Diffusion Models](https://arxiv.org/abs/2502.14070) (KAIST)
- [ ] [\[2502.14050\] Diversity-driven Data Selection for Language Model Tuning through Sparse Autoencoder](https://arxiv.org/abs/2502.14050) (Meta)
- [ ] [\[2502.14047\] Towards a Learning Theory of Representation Alignment](https://arxiv.org/abs/2502.14047) (Stanford)
- [ ] [\[2502.14043\] Asking for Help Enables Safety Guarantees Without Sacrificing Effectiveness](https://arxiv.org/abs/2502.14043) (Berkeley)
- [ ] [\[2502.14037\] DiffSampling: Enhancing Diversity and Accuracy in Neural Text Generation](https://arxiv.org/abs/2502.14037) (UCL)
- [ ] [\[2502.14010\] Which Attention Heads Matter for In-Context Learning?](https://arxiv.org/abs/2502.14010) (Berkeley)
- [ ] [\[2502.14008\] MaskPrune: Mask-based LLM Pruning for Layer-wise Uniform Structures](https://arxiv.org/abs/2502.14008) (NJU)
- [ ] [\[2502.13994\] Generative Detail Enhancement for Physically Based Materials](https://arxiv.org/abs/2502.13994) (UMD)
- [ ] [\[2502.13983\] Gesture-Aware Zero-Shot Speech Recognition for Patients with Language Disorders](https://arxiv.org/abs/2502.13983) (Yale)

## 2025-02-20 (Thu)
- [ ] [\[2502.13943\] AdaptiveStep: Automatically Dividing Reasoning Step through Model Confidence](https://arxiv.org/abs/2502.13943) (SJTU)
- [ ] [\[2502.13834\] Proving Olympiad Inequalities by Synergizing LLMs and Symbolic Reasoning](https://arxiv.org/abs/2502.13834) (NJU, ICLR)
- [ ] [\[2502.13569\] Model Evolution Framework with Genetic Algorithm for Multi-Task Reinforcement Learning](https://arxiv.org/abs/2502.13569) (USTC)
- [ ] [\[2502.13430\] Vision-Based Generic Potential Function for Policy Alignment in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2502.13430) (IA CAS)
- [ ] [\[2502.13392\] Atomic Proximal Policy Optimization for Electric Robo-Taxi Dispatch and Charger Allocation](https://arxiv.org/abs/2502.13392) (Cornell)
- [ ] [\[2502.13389\] Reasoning with Reinforced Functional Token Tuning](https://arxiv.org/abs/2502.13389) (NTU)
- [ ] [\[2502.13170\] Unveiling the Magic of Code Reasoning through Hypothesis Decomposition and Amendment](https://arxiv.org/abs/2502.13170) (USTC, ICLR)
- [ ] [\[2502.13149\] Bi-Fact: A Bidirectional Factorization-based Evaluation of Intent Extraction from UI Trajectories](https://arxiv.org/abs/2502.13149) (Google)
- [ ] [\[2502.13946\] Why Safeguarded Ships Run Aground? Aligned Large Language Models' Safety Mechanisms Tend to Be Anchored in The Template Region](https://arxiv.org/abs/2502.13946) (ZJU)
- [ ] [\[2502.13935\] Continually Learning Structured Visual Representations via Network Refinement with Rerelation](https://arxiv.org/abs/2502.13935) (EPFL)
- [ ] [\[2502.13913\] How Do LLMs Perform Two-Hop Reasoning in Context?](https://arxiv.org/abs/2502.13913) (Berkeley)
- [ ] [\[2502.13909\] Lost in Sequence: Do Large Language Models Understand Sequential Recommendation?](https://arxiv.org/abs/2502.13909) (KAIST)
- [ ] [\[2502.13881\] PSCon: Toward Conversational Product Search](https://arxiv.org/abs/2502.13881) (UVA.NL)
- [ ] [\[2502.13873\] NVR: Vector Runahead on NPUs for Sparse Memory Access](https://arxiv.org/abs/2502.13873) (HUST)
- [ ] [\[2502.13870\] SPEX: Scaling Feature Interaction Explanations for LLMs](https://arxiv.org/abs/2502.13870) (Berkeley)
- [ ] [\[2502.13845\] Enhancing LLM-Based Recommendations Through Personalized Reasoning](https://arxiv.org/abs/2502.13845) (Fudan)
- [ ] [\[2502.13843\] Enhancing Cross-Domain Recommendations with Memory-Optimized LLM-Based User Agents](https://arxiv.org/abs/2502.13843) (Fudan)
- [ ] [\[2502.13840\] Mitigating Popularity Bias in Collaborative Filtering through Fair Sampling](https://arxiv.org/abs/2502.13840) (Fudan)
- [ ] [\[2502.13836\] Quantifying Memorization and Retriever Performance in Retrieval-Augmented Vision-Language Models](https://arxiv.org/abs/2502.13836) (CMU)
- [ ] [\[2502.13805\] AnDB: Breaking Boundaries with an AI-Native Database for Universal Semantic Analysis](https://arxiv.org/abs/2502.13805) (Tsinghua)
- [ ] [\[2502.13794\] LESA: Learnable LLM Layer Scaling-Up](https://arxiv.org/abs/2502.13794) (SJTU)
- [ ] [\[2502.13767\] AI Software Engineer: Programming with Trust](https://arxiv.org/abs/2502.13767) (NUS)
- [ ] [\[2502.13723\] Direct Value Optimization: Improving Chain-of-Thought Reasoning in LLMs with Refined Values](https://arxiv.org/abs/2502.13723) (UCL)
- [ ] [\[2502.13685\] MoM: Linear Sequence Modeling with Mixture-of-Memories](https://arxiv.org/abs/2502.13685) (CUHK)
- [ ] [\[2502.13681\] An LLM-based Agent for Reliable Docker Environment Configuration](https://arxiv.org/abs/2502.13681) (HIT)
- [ ] [\[2502.13652\] C2T: A Classifier-Based Tree Construction Method in Speculative Decoding](https://arxiv.org/abs/2502.13652) (Peking)
- [ ] [\[2502.13595\] MMTEB: Massive Multilingual Text Embedding Benchmark](https://arxiv.org/abs/2502.13595) (ICLR)
- [ ] [\[2502.13562\] Are Large Language Models In-Context Graph Learners?](https://arxiv.org/abs/2502.13562) (SYSU)
- [ ] [\[2502.13555\] Democratizing Large Language Model-Based Graph Data Augmentation via Latent Knowledge Graphs](https://arxiv.org/abs/2502.13555) (HKU)
- [ ] [\[2502.13534\] Solving the Encoding Bottleneck: Of the HHL Algorithm, By the HHL Algorithm](https://arxiv.org/abs/2502.13534) (SYSU)
- [ ] [\[2502.13533\] Train Small, Infer Large: Memory-Efficient LoRA Training for Large Language Models](https://arxiv.org/abs/2502.13533) (NUS, ICLR)
- [ ] [\[2502.13524\] MobileViM: A Light-weight and Dimension-independent Vision Mamba for 3D Medical Image Analysis](https://arxiv.org/abs/2502.13524) (HKU)
- [ ] [\[2502.13509\] Unlocking Multimodal Integration in EHRs: A Prompt Learning Framework for Language and Time Series Fusion](https://arxiv.org/abs/2502.13509) (ZJU)
- [ ] [\[2502.13499\] Hidden Darkness in LLM-Generated Designs: Exploring Dark Patterns in Ecommerce Web Components Generated by LLMs](https://arxiv.org/abs/2502.13499) (University of Michigan)
- [ ] [\[2502.13450\] Interleaved Gibbs Diffusion for Constrained Generation](https://arxiv.org/abs/2502.13450) (Google)
- [ ] [\[2502.13442\] TreeCut: A Synthetic Unanswerable Math Word Problem Dataset for LLM Hallucination Evaluation](https://arxiv.org/abs/2502.13442) (Columbia University)
- [ ] [\[2502.13441\] The Self-Improvement Paradox: Can Language Models Bootstrap Reasoning Capabilities without External Scaffolding?](https://arxiv.org/abs/2502.13441) (ZJU)
- [ ] [\[2502.13440\] Semi-supervised classification of bird vocalizations](https://arxiv.org/abs/2502.13440) (NUS)
- [ ] [\[2502.13428\] MCTS-KBQA: Monte Carlo Tree Search for Knowledge Base Question Answering](https://arxiv.org/abs/2502.13428) (Peking)
- [ ] [\[2502.13407\] JL1-CD: A New Benchmark for Remote Sensing Change Detection and a Robust Multi-Teacher Knowledge Distillation Framework](https://arxiv.org/abs/2502.13407) (Tsinghua)
- [ ] [\[2502.13376\] Learning Symbolic Task Decompositions for Multi-Agent Teams](https://arxiv.org/abs/2502.13376) (Berkeley)
- [ ] [\[2502.13345\] Secure and Efficient Watermarking for Latent Diffusion Models in Model Distribution Scenarios](https://arxiv.org/abs/2502.13345) (BIT)
- [ ] [\[2502.13311\] Training Turn-by-Turn Verifiers for Dialogue Tutoring Agents: The Curious Case of LLMs as Your Coding Tutors](https://arxiv.org/abs/2502.13311) (PolyU)
- [ ] [\[2502.13259\] HumT DumT: Measuring and controlling human-like language in LLMs](https://arxiv.org/abs/2502.13259) (Stanford)
- [ ] [\[2502.13248\] Communication Strategy on Macro-and-Micro Traffic State in Cooperative Deep Reinforcement Learning for Regional Traffic Signal Control](https://arxiv.org/abs/2502.13248) (Xidian)
- [ ] [\[2502.13234\] MotionMatcher: Motion Customization of Text-to-Video Diffusion Models via Motion Feature Matching](https://arxiv.org/abs/2502.13234) (NVIDIA)
- [ ] [\[2502.13228\] Conformal Prediction as Bayesian Quadrature](https://arxiv.org/abs/2502.13228) (Princeton)
- [ ] [\[2502.13221\] Two Tickets are Better than One: Fair and Accurate Hiring Under Strategic LLM Manipulations](https://arxiv.org/abs/2502.13221) (Stanford)
- [ ] [\[2502.13207\] Thinking Outside the (Gray) Box: A Context-Based Score for Assessing Value and Originality in Neural Text Generation](https://arxiv.org/abs/2502.13207) (UCL)
- [ ] [\[2502.13189\] MoBA: Mixture of Block Attention for Long-Context LLMs](https://arxiv.org/abs/2502.13189) (Tsinghua)
- [ ] [\[2502.13185\] CondensNet: Enabling stable long-term climate simulations via hybrid deep learning models with adaptive physical constraints](https://arxiv.org/abs/2502.13185) (NUS)
- [ ] [\[2502.13180\] Uncertain Multi-Objective Recommendation via Orthogonal Meta-Learning Enhanced Bayesian Optimization](https://arxiv.org/abs/2502.13180) (Peking)
- [ ] [\[2502.13179\] PTQ1.61: Push the Real Limit of Extremely Low-Bit Post-Training Quantization Methods for Large Language Models](https://arxiv.org/abs/2502.13179) (HIT)
- [ ] [\[2502.13178\] Benchmarking Post-Training Quantization in LLMs: Comprehensive Taxonomy, Unified Evaluation, and Comparative Analysis](https://arxiv.org/abs/2502.13178) (HIT)
- [ ] [\[2502.13175\] Towards Robust and Secure Embodied AI: A Survey on Vulnerabilities and Attacks](https://arxiv.org/abs/2502.13175) (ZJU)
- [ ] [\[2502.09720\] NestQuant: Nested Lattice Quantization for Matrix Products and LLMs](https://arxiv.org/abs/2502.09720) (MIT)

## 2025-02-19 (Wed)
- [ ] [\[2502.13131\] Rethinking Diverse Human Preference Learning through Principal Component Analysis](https://arxiv.org/abs/2502.13131) (Illinois)
- [ ] [\[2502.13069\] Interactive Agents to Overcome Ambiguity in Software Engineering](https://arxiv.org/abs/2502.13069) (CMU)
- [ ] [\[2502.12995\] Free Argumentative Exchanges for Explaining Image Classifiers](https://arxiv.org/abs/2502.12995) (Imperial)
- [ ] [\[2502.12842\] Towards Adaptive Feedback with AI: Comparing the Feedback Quality of LLMs and Teachers on Experimentation Protocols](https://arxiv.org/abs/2502.12842) (TUM)
- [ ] [\[2502.12782\] VidCapBench: A Comprehensive Benchmark of Video Captioning for Controllable Text-to-Video Generation](https://arxiv.org/abs/2502.12782) (IA CAS)
- [ ] [\[2502.12566\] Exploring the Impact of Personality Traits on LLM Bias and Toxicity](https://arxiv.org/abs/2502.12566) (NTU)
- [ ] [\[2502.12224\] Accurate Expert Predictions in MoE Inference via Cross-Layer Gate](https://arxiv.org/abs/2502.12224) (SYSU)
- [ ] [\[2502.13128\] SongGen: A Single Stage Auto-regressive Transformer for Text-to-Song Generation](https://arxiv.org/abs/2502.13128) (Shanghai AI Lab)
- [ ] [\[2502.13115\] Near-Optimal Private Learning in Linear Contextual Bandits](https://arxiv.org/abs/2502.13115) (MIT)
- [ ] [\[2502.13092\] Text2World: Benchmarking Large Language Models for Symbolic World Model Generation](https://arxiv.org/abs/2502.13092) (HKU)
- [ ] [\[2502.12992\] B-cos LM: Efficiently Transforming Pre-trained Language Models for Improved Explainability](https://arxiv.org/abs/2502.12992) (MPI)
- [ ] [\[2502.12985\] PartSDF: Part-Based Implicit Neural Representation for Composite 3D Shape Parametrization and Optimization](https://arxiv.org/abs/2502.12985) (EPFL)
- [ ] [\[2502.12977\] Time-series attribution maps with regularized contrastive learning](https://arxiv.org/abs/2502.12977) (EPFL)
- [ ] [\[2502.12908\] Graph Neural Networks for Databases: A Survey](https://arxiv.org/abs/2502.12908) (HKUST(GZ))
- [ ] [\[2502.12859\] PAFT: Prompt-Agnostic Fine-Tuning](https://arxiv.org/abs/2502.12859) (Tsinghua)
- [ ] [\[2502.12825\] Reasoning and the Trusting Behavior of DeepSeek and GPT: An Experiment Revealing Hidden Fault Lines in Large Language Models](https://arxiv.org/abs/2502.12825) (NYU)
- [ ] [\[2502.12678\] Multi-Step Alignment as Markov Games: An Optimistic Online Gradient Descent Approach with Convergence Guarantees](https://arxiv.org/abs/2502.12678) (EPFL)
- [ ] [\[2502.12677\] Spiking Vision Transformer with Saccadic Attention](https://arxiv.org/abs/2502.12677) (UESTC, ICLR)
- [ ] [\[2502.12633\] One Size doesn't Fit All: A Personalized Conversational Tutoring Agent for Mathematics Instruction](https://arxiv.org/abs/2502.12633) (WHU)
- [ ] [\[2502.12608\] Unveiling Mode Connectivity in Graph Neural Networks](https://arxiv.org/abs/2502.12608) (Michigan State University)
- [ ] [\[2502.12584\] Enhancing Semi-supervised Learning with Noisy Zero-shot Pseudolabels](https://arxiv.org/abs/2502.12584) (ICML)
- [ ] [\[2502.12575\] DemonAgent: Dynamically Encrypted Multi-Backdoor Implantation Attack on LLM-based Agent](https://arxiv.org/abs/2502.12575) (USTC)
- [ ] [\[2502.12574\] HeadInfer: Memory-Efficient LLM Inference by Head-wise Offloading](https://arxiv.org/abs/2502.12574) (Caltech)
- [ ] [\[2502.12524\] YOLOv12: Attention-Centric Real-Time Object Detectors](https://arxiv.org/abs/2502.12524) (UCAS)
- [ ] [\[2502.12494\] EDGE: Efficient Data Selection for LLM Agents via Guideline Effectiveness](https://arxiv.org/abs/2502.12494) (Peking)
- [ ] [\[2502.12489\] A Comprehensive Survey on Generative AI for Video-to-Music Generation](https://arxiv.org/abs/2502.12489) (ZJU)
- [ ] [\[2502.12484\] LocalEscaper: A Weakly-supervised Framework with Regional Reconstruction for Scalable Neural TSP Solvers](https://arxiv.org/abs/2502.12484) (HUST)
- [ ] [\[2502.12481\] Predicate Hierarchies Improve Few-Shot State Classification](https://arxiv.org/abs/2502.12481) (ICLR)
- [ ] [\[2502.12468\] MCTS-Judge: Test-Time Scaling in LLM-as-a-Judge for Code Correctness Evaluation](https://arxiv.org/abs/2502.12468) (NUS)
- [ ] [\[2502.12454\] Benchmarking Zero-Shot Facial Emotion Annotation with Large Language Models: A Multi-Class and Multi-Frame Approach in DailyLife](https://arxiv.org/abs/2502.12454) (Tsinghua)
- [ ] [\[2502.12453\] UniMatch: Universal Matching from Atom to Task for Few-Shot Drug Discovery](https://arxiv.org/abs/2502.12453) (ICLR)
- [ ] [\[2502.12444\] SparAMX: Accelerating Compressed LLMs Token Generation on AMX-powered CPUs](https://arxiv.org/abs/2502.12444) (Cornell)
- [ ] [\[2502.12430\] Bridge the Gaps between Machine Unlearning and AI Regulation](https://arxiv.org/abs/2502.12430) (Cambridge)
- [ ] [\[2502.12411\] Gradient Co-occurrence Analysis for Detecting Unsafe Prompts in Large Language Models](https://arxiv.org/abs/2502.12411) (BUPT)
- [ ] [\[2502.12352\] Towards Mechanistic Interpretability of Graph Transformers via Attention Graphs](https://arxiv.org/abs/2502.12352) (Stanford)
- [ ] [\[2502.12327\] Learning Plasma Dynamics and Robust Rampdown Trajectories with Predict-First Experiments at TCV](https://arxiv.org/abs/2502.12327) (MIT)
- [ ] [\[2502.12267\] NeuroStrata: Harnessing Neurosymbolic Paradigms for Improved Design, Testability, and Verifiability of Autonomous CPS](https://arxiv.org/abs/2502.12267) (Yale)
- [ ] [\[2502.12217\] Optimal Brain Iterative Merging: Mitigating Interference in LLM Merging](https://arxiv.org/abs/2502.12217) (Peking)
- [ ] [\[2502.12215\] Revisiting the Test-Time Scaling of o1-like Models: Do they Truly Possess Test-Time Scaling Capabilities?](https://arxiv.org/abs/2502.12215) (Fudan)
- [ ] [\[2502.12214\] Zero Token-Driven Deep Thinking in LLMs: Unlocking the Full Potential of Existing Parameters via Cyclic Refinement](https://arxiv.org/abs/2502.12214) (Tsinghua)
- [ ] [\[2502.12207\] PAR-AdvGAN: Improving Adversarial Attack Capability with Progressive Auto-Regression AdvGAN](https://arxiv.org/abs/2502.12207) (USyd)
- [ ] [\[2502.12189\] Self-supervised Attribute-aware Dynamic Preference Ranking Alignment](https://arxiv.org/abs/2502.12189) (USTC)
- [ ] [\[2502.12188\] Boosting Generalization in Diffusion-Based Neural Combinatorial Solver via Energy-guided Sampling](https://arxiv.org/abs/2502.12188) (CUHK)
- [ ] [\[2502.12182\] Towards Transparent and Accurate Plasma State Monitoring at JET](https://arxiv.org/abs/2502.12182) (EPFL)
- [ ] [\[2502.12181\] 3D ReX: Causal Explanations in 3D Neuroimaging Classification](https://arxiv.org/abs/2502.12181) (UCL)
- [ ] [\[2502.12176\] Ten Challenging Problems in Federated Foundation Models](https://arxiv.org/abs/2502.12176) (HKUST)
- [ ] [\[2502.12173\] nanoML for Human Activity Recognition](https://arxiv.org/abs/2502.12173) (UT Austin)
- [ ] [\[2502.12170\] MUDDFormer: Breaking Residual Bottlenecks in Transformers via Multiway Dynamic Dense Connections](https://arxiv.org/abs/2502.12170) (BUPT)
- [ ] [\[2502.12161\] Integrating Artificial Intelligence and Geophysical Insights for Earthquake Forecasting: A Cross-Disciplinary Review](https://arxiv.org/abs/2502.12161) (ETH)

## 2025-02-18 (Tue)
- [ ] [\[2502.12143\] Small Models Struggle to Learn from Strong Reasoners](https://arxiv.org/abs/2502.12143) (CMU)
- [ ] [\[2502.12131\] Transformer Dynamics: A neuroscientific approach to interpretability of large language models](https://arxiv.org/abs/2502.12131) (Harvard)
- [ ] [\[2502.12130\] Scaling Autonomous Agents via Automatic Reward Modeling And Planning](https://arxiv.org/abs/2502.12130) (ICLR)
- [ ] [\[2502.12102\] Relational Norms for Human-AI Cooperation](https://arxiv.org/abs/2502.12102) (NUS)
- [ ] [\[2502.11959\] STRIVE: Structured Reasoning for Self-Improvement in Claim Verification](https://arxiv.org/abs/2502.11959) (IA CAS)
- [ ] [\[2502.11925\] GRAPHGPT-O: Synergistic Multimodal Comprehension and Generation on Graphs](https://arxiv.org/abs/2502.11925) (NYU)
- [ ] [\[2502.11882\] Leveraging Dual Process Theory in Language Agent Framework for Real-time Simultaneous Human-AI Collaboration](https://arxiv.org/abs/2502.11882) (SJTU)
- [ ] [\[2502.11799\] Table-Critic: A Multi-Agent Framework for Collaborative Criticism and Refinement in Table Reasoning](https://arxiv.org/abs/2502.11799) (UCAS)
- [ ] [\[2502.11664\] VRoPE: Rotary Position Embedding for Video Large Language Models](https://arxiv.org/abs/2502.11664) (IA CAS)
- [ ] [\[2502.11588\] A Unified Modeling Framework for Automated Penetration Testing](https://arxiv.org/abs/2502.11588) (NUDT)
- [ ] [\[2502.11560\] A Survey of Automatic Prompt Engineering: An Optimization Perspective](https://arxiv.org/abs/2502.11560) (Tongji)
- [ ] [\[2502.11358\] Mimicking the Familiar: Dynamic Command Generation for Information Theft Attacks in LLM Tool-Learning System](https://arxiv.org/abs/2502.11358) (Queensland)
- [ ] [\[2502.11357\] Explorer: Scaling Exploration-driven Web Trajectory Synthesis for Multimodal Web Agents](https://arxiv.org/abs/2502.11357) (Microsoft)
- [ ] [\[2502.11251\] Explaining Necessary Truths](https://arxiv.org/abs/2502.11251) (CMU)
- [ ] [\[2502.11134\] Solving Online Resource-Constrained Scheduling for Follow-Up Observation in Astronomy: a Reinforcement Learning Approach](https://arxiv.org/abs/2502.11134) (Tianjin)
- [ ] [\[2502.11102\] OptMATH: A Scalable Bidirectional Data Synthesis Framework for Optimization Modeling](https://arxiv.org/abs/2502.11102) (Peking)
- [ ] [\[2502.10978\] Agentic LLM Framework for Adaptive Decision Discourse](https://arxiv.org/abs/2502.10978) (Illinois)
- [ ] [\[2502.10938\] PEA: Enhancing LLM Performance on Computational-Reasoning Tasks](https://arxiv.org/abs/2502.10938) (JHU)
- [ ] [\[2502.10867\] A Tutorial on LLM Reasoning: Relevant Methods behind ChatGPT o1](https://arxiv.org/abs/2502.10867) (UCL)
- [ ] [\[2502.10742\] The Philosophical Foundations of Growing AI Like A Child](https://arxiv.org/abs/2502.10742) (University of Michigan)
- [ ] [\[2502.12145\] Fast or Better? Balancing Accuracy and Cost in Retrieval-Augmented Generation with Flexible User Control](https://arxiv.org/abs/2502.12145) (MBZUAI)
- [ ] [\[2502.12022\] Teaching LLMs According to Their Aptitude: Adaptive Reasoning for Mathematical Problem Solving](https://arxiv.org/abs/2502.12022) (HKUST)
- [ ] [\[2502.11995\] Presumed Cultural Identity: How Names Shape LLM Responses](https://arxiv.org/abs/2502.11995) (University of Copenhagen)
- [ ] [\[2502.11965\] A MIMO Wireless Channel Foundation Model via CIR-CSI Consistency](https://arxiv.org/abs/2502.11965) (ICML)
- [ ] [\[2502.11962\] Navigating the Helpfulness-Truthfulness Trade-Off with Uncertainty-Aware Instruction Fine-Tuning](https://arxiv.org/abs/2502.11962) (ETH)
- [ ] [\[2502.11916\] EssayJudge: A Multi-Granular Benchmark for Assessing Automated Essay Scoring Capabilities of Multimodal Large Language Models](https://arxiv.org/abs/2502.11916) (HKUST(GZ))
- [ ] [\[2502.11863\] FedEAT: A Robustness Optimization Framework for Federated LLMs](https://arxiv.org/abs/2502.11863) (HUST)
- [ ] [\[2502.11850\] Steering the LoCoMotif: Using Domain Knowledge in Time Series Motif Discovery](https://arxiv.org/abs/2502.11850) (KU Leuven)
- [ ] [\[2502.11831\] Intuitive physics understanding emerges from self-supervised pretraining on natural videos](https://arxiv.org/abs/2502.11831) (Meta)
- [ ] [\[2502.11809\] Revealing Bias Formation in Deep Neural Networks Through the Geometric Mechanisms of Human Visual Decoupling](https://arxiv.org/abs/2502.11809) (Xidian)
- [ ] [\[2502.11756\] On the Computation of the Fisher Information in Continual Learning](https://arxiv.org/abs/2502.11756) (KU Leuven, ICLR)
- [ ] [\[2502.11749\] JotlasNet: Joint Tensor Low-Rank and Attention-based Sparse Unrolling Network for Accelerating Dynamic MRI](https://arxiv.org/abs/2502.11749) (HIT)
- [ ] [\[2502.11715\] Proactive Depot Discovery: A Generative Framework for Flexible Location-Routing](https://arxiv.org/abs/2502.11715) (NTU)
- [ ] [\[2502.11711\] Knowledge-aware contrastive heterogeneous molecular graph learning](https://arxiv.org/abs/2502.11711) (WHU)
- [ ] [\[2502.11681\] RIDE: Enhancing Large Language Model Alignment through Restyled In-Context Learning Demonstration Exemplars](https://arxiv.org/abs/2502.11681) (MIT)
- [ ] [\[2502.11671\] Diversity-Oriented Data Augmentation with Large Language Models](https://arxiv.org/abs/2502.11671) (UCAS)
- [ ] [\[2502.11651\] MMXU: A Multi-Modal and Multi-X-ray Understanding Dataset for Disease Progression](https://arxiv.org/abs/2502.11651) (SJTU)
- [ ] [\[2502.11647\] DELMAN: Dynamic Defense Against Large Language Model Jailbreaking with Model Editing](https://arxiv.org/abs/2502.11647) (ZJU)
- [ ] [\[2502.11612\] Maximum Entropy Reinforcement Learning with Diffusion Policy](https://arxiv.org/abs/2502.11612) (IA CAS)
- [ ] [\[2502.11573\] InfiR : Crafting Effective Small Language Models and Multimodal Small Language Models in Reasoning](https://arxiv.org/abs/2502.11573) (PolyU)
- [ ] [\[2502.11554\] Toward Metaphor-Fluid Conversation Design for Voice User Interfaces](https://arxiv.org/abs/2502.11554) (Illinois)
- [ ] [\[2502.11541\] MuSC: Improving Complex Instruction Following with Multi-granularity Self-Contrastive Training](https://arxiv.org/abs/2502.11541) (HIT)
- [ ] [\[2502.11519\] UniGO: A Unified Graph Neural Network for Modeling Opinion Dynamics on Graphs](https://arxiv.org/abs/2502.11519) (WHU)
- [ ] [\[2502.11518\] Generative Multi-Agent Collaboration in Embodied AI: A Systematic Review](https://arxiv.org/abs/2502.11518) (Tongji)
- [ ] [\[2502.11491\] Ontology-Guided Reverse Thinking Makes Large Language Models Stronger on Knowledge Graph Question Answering](https://arxiv.org/abs/2502.11491) (BUPT)
- [ ] [\[2502.11481\] Variable-frame CNNLSTM for Breast Nodule Classification using Ultrasound Videos](https://arxiv.org/abs/2502.11481) (XJTU)
- [ ] [\[2502.11450\] Fishing For Cheap And Efficient Pruners At Initialization](https://arxiv.org/abs/2502.11450) (MBZUAI)
- [ ] [\[2502.11442\] Multi-Turn Multi-Modal Question Clarification for Enhanced Conversational Understanding](https://arxiv.org/abs/2502.11442) (University of Copenhagen)
- [ ] [\[2502.11381\] Without Paired Labeled Data: An End-to-End Self-Supervised Paradigm for UAV-View Geo-Localization](https://arxiv.org/abs/2502.11381) (XJTU)
- [ ] [\[2502.11367\] Sparse Autoencoder Features for Classifications and Transferability](https://arxiv.org/abs/2502.11367) (Harvard)
- [ ] [\[2502.11355\] "Nuclear Deployed!": Analyzing Catastrophic Risks in Decision-making of Autonomous LLM Agents](https://arxiv.org/abs/2502.11355) (Berkeley)
- [ ] [\[2502.11307\] Exploiting Point-Language Models with Dual-Prompts for 3D Anomaly Detection](https://arxiv.org/abs/2502.11307) (Xiamen)
- [ ] [\[2502.11273\] FairFare: A Tool for Crowdsourcing Rideshare Data to Empower Labor Organizers](https://arxiv.org/abs/2502.11273) (Princeton)
- [ ] [\[2502.11195\] From Deception to Perception: The Surprising Benefits of Deepfakes for Detecting, Measuring, and Mitigating Bias](https://arxiv.org/abs/2502.11195) (UMD)
- [ ] [\[2502.11181\] Improving Scientific Document Retrieval with Concept Coverage-based Query Set Generation](https://arxiv.org/abs/2502.11181) (Illinois)
- [ ] [\[2502.11168\] Knowing Your Target: Target-Aware Transformer Makes Better Spatio-Temporal Video Grounding](https://arxiv.org/abs/2502.11168) (IS CAS)
- [ ] [\[2502.11140\] VisPath: Automated Visualization Code Synthesis via Multi-Path Reasoning and Feedback-Driven Optimization](https://arxiv.org/abs/2502.11140) (Tsinghua)
- [ ] [\[2502.11124\] AdaManip: Adaptive Articulated Object Manipulation Environments and Policy Learning](https://arxiv.org/abs/2502.11124) (ICLR)
- [ ] [\[2502.11107\] Revisiting Weak-to-Strong Generalization in Theory and Practice: Reverse KL vs. Forward KL](https://arxiv.org/abs/2502.11107) (Tongji)
- [ ] [\[2502.11094\] SyncSpeech: Low-Latency and Efficient Dual-Stream Text-to-Speech based on Temporal Masked Transformer](https://arxiv.org/abs/2502.11094) (USTC)
- [ ] [\[2502.11075\] Exposing Numeracy Gaps: A Benchmark to Evaluate Fundamental Numerical Abilities in Large Language Models](https://arxiv.org/abs/2502.11075) (PolyU)
- [ ] [\[2502.11070\] A Survey on Vulnerability Prioritization: Taxonomy, Metrics, and Research Challenges](https://arxiv.org/abs/2502.11070) (NUS)
- [ ] [\[2502.11068\] Accelerating Anchors via Specialization and Feature Transformation](https://arxiv.org/abs/2502.11068) (Peking)
- [ ] [\[2502.11057\] A Physics-Informed Machine Learning Framework for Safe and Optimal Control of Autonomous Systems](https://arxiv.org/abs/2502.11057) (Stanford)
- [ ] [\[2502.11037\] Deep Incomplete Multi-view Learning via Cyclic Permutation of VAEs](https://arxiv.org/abs/2502.11037) (Fudan, ICLR)
- [ ] [\[2502.11019\] Unlocking the Power of Function Vectors for Characterizing and Mitigating Catastrophic Forgetting in Continual Instruction Tuning](https://arxiv.org/abs/2502.11019) (USTC)
- [ ] [\[2502.11018\] GRIFFIN: Effective Token Alignment for Faster Speculative Decoding](https://arxiv.org/abs/2502.11018) (Fudan)
- [ ] [\[2502.11013\] Collaborative Deterministic-Diffusion Model for Probabilistic Urban Spatiotemporal Prediction](https://arxiv.org/abs/2502.11013) (Tsinghua)
- [ ] [\[2502.11001\] CL-MFAP: A Contrastive Learning-Based Multimodal Foundation Model for Molecular Property Prediction and Antibiotic Screening](https://arxiv.org/abs/2502.11001) (ICLR)
- [ ] [\[2502.10985\] Is Elo Rating Reliable? A Study Under Model Misspecification](https://arxiv.org/abs/2502.10985) (Princeton)
- [ ] [\[2502.10961\] Graders should cheat: privileged information enables expert-level automated evaluations](https://arxiv.org/abs/2502.10961) (Google)
- [ ] [\[2502.10920\] Do Deepfake Detectors Work in Reality?](https://arxiv.org/abs/2502.10920) (GIT)
- [ ] [\[2502.10908\] Automatic Quality Assessment of First Trimester Crown-Rump-Length Ultrasound Images](https://arxiv.org/abs/2502.10908) (MBZUAI)
- [ ] [\[2502.10894\] Bridging the Sim-to-Real Gap for Athletic Loco-Manipulation](https://arxiv.org/abs/2502.10894) (MIT)
- [ ] [\[2502.10883\] Learning Identifiable Structures Helps Avoid Bias in DNN-based Supervised Causal Learning](https://arxiv.org/abs/2502.10883) (SJTU)
- [ ] [\[2502.10871\] The Representation and Recall of Interwoven Structured Knowledge in LLMs: A Geometric and Layered Analysis](https://arxiv.org/abs/2502.10871) (Imperial)
- [ ] [\[2502.10852\] Multilingual Encoder Knows more than You Realize: Shared Weights Pretraining for Extremely Low-Resource Languages](https://arxiv.org/abs/2502.10852) (SJTU)
- [ ] [\[2502.10825\] MITRE ATT&CK Applications in Cybersecurity and The Way Forward](https://arxiv.org/abs/2502.10825) (NUS)
- [ ] [\[2502.10818\] On Vanishing Gradients, Over-Smoothing, and Over-Squashing in GNNs: Bridging Recurrent and Graph Learning](https://arxiv.org/abs/2502.10818) (Oxford)
- [ ] [\[2502.10816\] BalanceBenchmark: A Survey for Imbalanced Learning](https://arxiv.org/abs/2502.10816) (BUPT)
- [ ] [\[2502.10807\] HybriDNA: A Hybrid Transformer-Mamba2 Long-Range DNA Language Model](https://arxiv.org/abs/2502.10807) (Microsoft)
- [ ] [\[2502.10776\] A Distillation-based Future-aware Graph Neural Network for Stock Trend Prediction](https://arxiv.org/abs/2502.10776) (NUDT)
- [ ] [\[2502.10749\] LoRE-Merging: Exploring Low-Rank Estimation For Large Language Model Merging](https://arxiv.org/abs/2502.10749) (HKU)
- [ ] [\[2502.10732\] Rule-Bottleneck Reinforcement Learning: Joint Explanation and Decision Optimization for Resource Allocation with Language Agents](https://arxiv.org/abs/2502.10732) (Harvard)
- [ ] [\[2502.10712\] FuncGenFoil: Airfoil Generation and Editing Model in Function Space](https://arxiv.org/abs/2502.10712) (Shanghai AI Lab)
- [ ] [\[2502.10709\] An Empirical Analysis of Uncertainty in Large Language Model Evaluations](https://arxiv.org/abs/2502.10709) (ICLR)
- [ ] [\[2502.10707\] Reading Your Heart: Learning ECG Words and Sentences via Pre-training ECG Language Model](https://arxiv.org/abs/2502.10707) (Peking, ICLR)
- [ ] [\[2502.10704\] Occlusion-aware Non-Rigid Point Cloud Registration via Unsupervised Neural Deformation Correntropy](https://arxiv.org/abs/2502.10704) (ICLR)
- [ ] [\[2502.10678\] GenComUI: Exploring Generative Visual Aids as Medium to Support Task-Oriented Human-Robot Communication](https://arxiv.org/abs/2502.10678) (Tongji)
- [ ] [\[2502.10614\] Optimizing CNN Architectures for Advanced Thoracic Disease Classification](https://arxiv.org/abs/2502.10614) (GIT)
- [ ] [\[2502.10596\] Post-training an LLM for RAG? Train on Self-Generated Demonstrations](https://arxiv.org/abs/2502.10596) (Meta)
- [ ] [\[2502.10587\] Towards Self-Supervised Covariance Estimation in Deep Heteroscedastic Regression](https://arxiv.org/abs/2502.10587) (EPFL, ICLR)
- [ ] [\[2502.10581\] Do We Need to Verify Step by Step? Rethinking Process Supervision from a Theoretical Perspective](https://arxiv.org/abs/2502.10581) (MIT)
- [ ] [\[2502.10546\] Learning to be Smooth: An End-to-End Differentiable Particle Smoother](https://arxiv.org/abs/2502.10546) (NIPS)
- [ ] [\[2502.10517\] KernelBench: Can LLMs Write Efficient GPU Kernels?](https://arxiv.org/abs/2502.10517) (Stanford)
- [ ] [\[2502.10459\] LLM4GNAS: A Large Language Model Based Toolkit for Graph Neural Architecture Search](https://arxiv.org/abs/2502.10459) (ZJU)
- [ ] [\[2502.10458\] I Think, Therefore I Diffuse: Enabling Multimodal In-Context Reasoning in Diffusion Models](https://arxiv.org/abs/2502.10458) (HKUST)
- [ ] [\[2502.10454\] One Example Shown, Many Concepts Known! Counterexample-Driven Conceptual Reasoning in Mathematical LLMs](https://arxiv.org/abs/2502.10454) (Tsinghua)
- [ ] [\[2502.10453\] Linking Cryptoasset Attribution Tags to Knowledge Graph Entities: An LLM-based Approach](https://arxiv.org/abs/2502.10453) (UTS)
- [ ] [\[2502.10438\] Injecting Universal Jailbreak Backdoors into LLMs in Minutes](https://arxiv.org/abs/2502.10438) (Cornell, ICLR)
- [ ] [\[2502.10436\] MERGE$^3$: Efficient Evolutionary Merging on Consumer-grade GPUs](https://arxiv.org/abs/2502.10436) (EPFL)
- [ ] [\[2502.10435\] RAMer: Reconstruction-based Adversarial Model for Multi-party Multi-modal Multi-label Emotion Recognition](https://arxiv.org/abs/2502.10435) (HKUST(GZ))
- [ ] [\[2502.10425\] Neuron Platonic Intrinsic Representation From Dynamics Using Contrastive Learning](https://arxiv.org/abs/2502.10425) (Peking, ICLR)
- [ ] [\[2502.10424\] QuantSpec: Self-Speculative Decoding with Hierarchical Quantized KV Cache](https://arxiv.org/abs/2502.10424) (Berkeley)
- [ ] [\[2502.10407\] Addressing Bias in Generative AI: Challenges and Research Opportunities in Information Management](https://arxiv.org/abs/2502.10407) (UW)
- [ ] [\[2502.10406\] FishBargain: An LLM-Empowered Bargaining Agent for Online Fleamarket Platform Sellers](https://arxiv.org/abs/2502.10406) (Alibaba)

## 2025-02-17 (Mon)
- [ ] [\[2502.10308\] LLM-Powered Preference Elicitation in Combinatorial Assignment](https://arxiv.org/abs/2502.10308) (Harvard)
- [ ] [\[2502.10215\] Do Large Language Models Reason Causally Like Us? Even Better?](https://arxiv.org/abs/2502.10215) (NYU)
- [ ] [\[2502.10197\] MathConstruct: Challenging LLM Reasoning with Constructive Proofs](https://arxiv.org/abs/2502.10197) (ETH)
- [ ] [\[2502.10097\] Causal Information Prioritization for Efficient Reinforcement Learning](https://arxiv.org/abs/2502.10097) (NJU)
- [ ] [\[2502.10077\] Towards Empowerment Gain through Causal Structure Learning in Model-Based RL](https://arxiv.org/abs/2502.10077) (NJU)
- [ ] [\[2502.10044\] Unsupervised Entity Alignment Based on Personalized Discriminative Rooted Tree](https://arxiv.org/abs/2502.10044) (Xidian)
- [ ] [\[2502.09974\] Has My System Prompt Been Used? Large Language Model Prompt Membership Inference](https://arxiv.org/abs/2502.09974) (AWS)
- [ ] [\[2502.09955\] Diverse Inference and Verification for Advanced Reasoning](https://arxiv.org/abs/2502.09955) (BU)
- [ ] [\[2502.09933\] MIR-Bench: Benchmarking LLM's Long-Context Intelligence via Many-Shot In-Context Inductive Reasoning](https://arxiv.org/abs/2502.09933) (Illinois)
- [ ] [\[2502.09913\] AutoS$^2$earch: Unlocking the Reasoning Potential of Large Models for Web-based Source Search](https://arxiv.org/abs/2502.09913) (NUDT)
- [ ] [\[2502.09861\] A Scoresheet for Explainable AI](https://arxiv.org/abs/2502.09861) (MIT)
- [ ] [\[2502.09624\] Efficient and Trustworthy Block Propagation for Blockchain-enabled Mobile Embodied AI Networks: A Graph Resfusion Approach](https://arxiv.org/abs/2502.09624) (SYSU)
- [ ] [\[2502.10385\] Simplifying DINO via Coding Rate Regularization](https://arxiv.org/abs/2502.10385) (Berkeley)
- [ ] [\[2502.10373\] OWLS: Scaling Laws for Multilingual Speech Recognition and Translation Models](https://arxiv.org/abs/2502.10373) (CMU)
- [ ] [\[2502.10338\] Evaluating the Meta- and Object-Level Reasoning of Large Language Models for Question Answering](https://arxiv.org/abs/2502.10338) (University of Edinburgh)
- [ ] [\[2502.10325\] Process Reward Models for LLM Agents: Practical Framework and Directions](https://arxiv.org/abs/2502.10325) (Cornell)
- [ ] [\[2502.10273\] Probing Perceptual Constancy in Large Vision Language Models](https://arxiv.org/abs/2502.10273) (University of Michigan)
- [ ] [\[2502.10226\] A Multiagent Path Search Algorithm for Large-Scale Coalition Structure Generation](https://arxiv.org/abs/2502.10226) (CMU)
- [ ] [\[2502.10216\] Forget the Data and Fine-Tuning! Just Fold the Network to Compress](https://arxiv.org/abs/2502.10216) (ETH, ICLR)
- [ ] [\[2502.10195\] Exploring the Camera Bias of Person Re-identification](https://arxiv.org/abs/2502.10195) (ICLR)
- [ ] [\[2502.10178\] From Markov to Laplace: How Mamba In-Context Learns Markov Chains](https://arxiv.org/abs/2502.10178) (EPFL)
- [ ] [\[2502.10162\] Revisiting Generalization Power of a DNN in Terms of Symbolic Interactions](https://arxiv.org/abs/2502.10162) (SJTU)
- [ ] [\[2502.10125\] Learning Relational Tabular Data without Shared Features](https://arxiv.org/abs/2502.10125) (NUS)
- [ ] [\[2502.10118\] Image Embedding Sampling Method for Diverse Captioning](https://arxiv.org/abs/2502.10118) (KAIST)
- [ ] [\[2502.10062\] Adaptive Bi-Level Multi-Robot Task Allocation and Learning under Uncertainty with Temporal Logic Constraints](https://arxiv.org/abs/2502.10062) (BU)
- [ ] [\[2502.10047\] Janus: Collaborative Vision Transformer Under Dynamic Network Environment](https://arxiv.org/abs/2502.10047) (SJTU)
- [ ] [\[2502.09990\] X-Boundary: Establishing Exact Safety Boundary to Shield LLMs from Multi-Turn Jailbreaks without Compromising Usability](https://arxiv.org/abs/2502.09990) (Shanghai AI Lab)
- [ ] [\[2502.09971\] Conditional Latent Coding with Learnable Synthesized Reference for Deep Image Compression](https://arxiv.org/abs/2502.09971) (SUSTech)
- [ ] [\[2502.09969\] Data Valuation using Neural Networks for Efficient Instruction Fine-Tuning](https://arxiv.org/abs/2502.09969) (Illinois)
- [ ] [\[2502.09889\] Evaluating and Improving Graph-based Explanation Methods for Multi-Agent Coordination](https://arxiv.org/abs/2502.09889) (GIT)
- [ ] [\[2502.09885\] Comprehensive Review of Neural Differential Equations for Time Series Analysis](https://arxiv.org/abs/2502.09885) (UCLA)
- [ ] [\[2502.09874\] FrGNet: A fourier-guided weakly-supervised framework for nuclear instance segmentation](https://arxiv.org/abs/2502.09874) (SYSU)
- [ ] [\[2502.09870\] A Taxonomy of Linguistic Expressions That Contribute To Anthropomorphism of Language Technologies](https://arxiv.org/abs/2502.09870) (CMU)
- [ ] [\[2502.09866\] How Users Who are Blind or Low Vision Play Mobile Games: Perceptions, Challenges, and Strategies](https://arxiv.org/abs/2502.09866) (CMU)
- [ ] [\[2502.09858\] Automated Hypothesis Validation with Agentic Sequential Falsifications](https://arxiv.org/abs/2502.09858) (Stanford)
- [ ] [\[2502.09819\] A Solver-Aided Hierarchical Language for LLM-Driven CAD Design](https://arxiv.org/abs/2502.09819) (MIT)
- [ ] [\[2502.09799\] Co-designing Large Language Model Tools for Project-Based Learning with K12 Educators](https://arxiv.org/abs/2502.09799) (MIT)
- [ ] [\[2502.09787\] TableTalk: Scaffolding Spreadsheet Development with a Language Agent](https://arxiv.org/abs/2502.09787) (CMU)
- [ ] [\[2502.09780\] Incentivize without Bonus: Provably Efficient Model-based Online Multi-agent RL for Markov Games](https://arxiv.org/abs/2502.09780) (GIT)
- [ ] [\[2502.09767\] Non-Markovian Discrete Diffusion with Causal Language Models](https://arxiv.org/abs/2502.09767) (Yale)
- [ ] [\[2502.09762\] Adaptive Teaming in Multi-Drone Pursuit: Simulation, Training, and Deployment](https://arxiv.org/abs/2502.09762) (SJTU)
- [ ] [\[2502.09715\] Evaluating GPT's Capability in Identifying Stages of Cognitive Impairment from Electronic Health Data](https://arxiv.org/abs/2502.09715) (Harvard)
- [ ] [\[2502.09688\] Towards Virtual Clinical Trials of Radiology AI with Conditional Generative Modeling](https://arxiv.org/abs/2502.09688) (JHU)
- [ ] [\[2502.09663\] DiffEx: Explaining a Classifier with Diffusion Models to Identify Microscopic Cellular Variations](https://arxiv.org/abs/2502.09663) (PSL University)

## 2025-02-14 (Fri)
- [ ] [\[2502.09601\] CoT-Valve: Length-Compressible Chain-of-Thought Tuning](https://arxiv.org/abs/2502.09601) (NUS)
- [ ] [\[2502.09565\] MDCrow: Automating Molecular Dynamics Workflows with Large Language Models](https://arxiv.org/abs/2502.09565) (University of Rochester)
- [ ] [\[2502.09560\] EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language Models for Vision-Driven Embodied Agents](https://arxiv.org/abs/2502.09560) (Illinois)
- [ ] [\[2502.09378\] A Deep Inverse-Mapping Model for a Flapping Robotic Wing](https://arxiv.org/abs/2502.09378) (ICLR)
- [ ] [\[2502.09224\] Order-Sorted Intensional Logic: Expressing Subtyping Polymorphism with Typing Assertions and Quantification over Concepts](https://arxiv.org/abs/2502.09224) (KU Leuven)
- [ ] [\[2502.09212\] LP-LM: No Hallucinations in Question Answering with Logic Programming](https://arxiv.org/abs/2502.09212) (Cornell)
- [ ] [\[2502.09211\] Visual Graph Question Answering with ASP and LLMs for Language Parsing](https://arxiv.org/abs/2502.09211) (ETH)
- [ ] [\[2502.09205\] Counterfactual Explanations as Plans](https://arxiv.org/abs/2502.09205) (University of Edinburgh)
- [ ] [\[2502.09053\] Game Theory Meets Large Language Models: A Systematic Survey](https://arxiv.org/abs/2502.09053) (Peking)
- [ ] [\[2502.09022\] Mechanistic Unveiling of Transformer Circuits: Self-Influence as a Key to Model Reasoning](https://arxiv.org/abs/2502.09022) (HIT)
- [ ] [\[2502.08922\] Self-Consistency of the Internal Reward Models Improves Self-Rewarding Language Models](https://arxiv.org/abs/2502.08922) (Fudan)
- [ ] [\[2502.08908\] Reinforced Large Language Model is a formal theorem prover](https://arxiv.org/abs/2502.08908) (Alibaba)
- [ ] [\[2502.08904\] MIH-TCCT: Mitigating Inconsistent Hallucinations in LLMs via Event-Driven Text-Code Cyclic Training](https://arxiv.org/abs/2502.08904) (Tsinghua)
- [ ] [\[2502.08673\] High-Throughput SAT Sampling](https://arxiv.org/abs/2502.08673) (Berkeley)
- [ ] [\[2502.09614\] DexTrack: Towards Generalizable Neural Tracking Control for Dexterous Manipulation from Human References](https://arxiv.org/abs/2502.09614) (ICLR)
- [ ] [\[2502.09604\] SelfCite: Self-Supervised Alignment for Context Attribution in Large Language Models](https://arxiv.org/abs/2502.09604) (MIT)
- [ ] [\[2502.09511\] Diffusion Models for Molecules: A Survey of Methods and Tasks](https://arxiv.org/abs/2502.09511) (IA CAS)
- [ ] [\[2502.09487\] Objective quantification of mood states using large language models](https://arxiv.org/abs/2502.09487) (UCL)
- [ ] [\[2502.09471\] Wholly-WOOD: Wholly Leveraging Diversified-quality Labels for Weakly-supervised Oriented Object Detection](https://arxiv.org/abs/2502.09471) (SJTU, TPAMI)
- [ ] [\[2502.09341\] Neural Spatiotemporal Point Processes: Trends and Challenges](https://arxiv.org/abs/2502.09341) (GIT)
- [ ] [\[2502.09307\] When the LM misunderstood the human chuckled: Analyzing garden path effects in humans and language models](https://arxiv.org/abs/2502.09307) (Tel Aviv)
- [ ] [\[2502.09271\] LiSA: Leveraging Link Recommender to Attack Graph Neural Networks via Subgraph Injection](https://arxiv.org/abs/2502.09271) (HKUST(GZ))
- [ ] [\[2502.09254\] AnomalyGFM: Graph Foundation Model for Zero/Few-shot Anomaly Detection](https://arxiv.org/abs/2502.09254) (UTS)
- [ ] [\[2502.09220\] Graphical Conditions for the Existence, Unicity and Number of Regular Models](https://arxiv.org/abs/2502.09220) (Inria)
- [ ] [\[2502.09218\] Data2Concept2Text: An Explainable Multilingual Framework for Data Analysis Narration](https://arxiv.org/abs/2502.09218) (Michigan State University)
- [ ] [\[2502.09125\] Automatic Pruning via Structured Lasso with Class-wise Information](https://arxiv.org/abs/2502.09125) (ETH)
- [ ] [\[2502.09122\] Improving Deep Regression with Tightness](https://arxiv.org/abs/2502.09122) (NUS, ICLR)
- [ ] [\[2502.09104\] One-shot Federated Learning Methods: A Practical Guide](https://arxiv.org/abs/2502.09104) (HKUST)
- [ ] [\[2502.09083\] Show Me the Work: Fact-Checkers' Requirements for Explainable Automated Fact-Checking](https://arxiv.org/abs/2502.09083) (University of Copenhagen)
- [ ] [\[2502.09082\] CoSER: Coordinating LLM-Based Persona Simulation of Established Roles](https://arxiv.org/abs/2502.09082) (Fudan)
- [ ] [\[2502.09046\] Criteria-Aware Graph Filtering: Extremely Fast Yet Accurate Multi-Criteria Recommendation](https://arxiv.org/abs/2502.09046) (KAIST)
- [ ] [\[2502.09039\] Large Images are Gaussians: High-Quality Large Image Representation with Levels of 2D Gaussian Splatting](https://arxiv.org/abs/2502.09039) (HKU)
- [ ] [\[2502.09020\] EventSTR: A Benchmark Dataset and Baselines for Event Stream based Scene Text Recognition](https://arxiv.org/abs/2502.09020) (Peking)
- [ ] [\[2502.08987\] Neural Force Field: Learning Generalized Physical Representation from a Few Examples](https://arxiv.org/abs/2502.08987) (Peking)
- [ ] [\[2502.08969\] SkyRover: A Modular Simulator for Cross-Domain Pathfinding](https://arxiv.org/abs/2502.08969) (Tongji)
- [ ] [\[2502.08958\] Biologically Plausible Brain Graph Transformer](https://arxiv.org/abs/2502.08958) (ICLR)
- [ ] [\[2502.08946\] The Stochastic Parrot on LLM's Shoulder: A Summative Assessment of Physical Concept Understanding](https://arxiv.org/abs/2502.08946) (JHU)
- [ ] [\[2502.08943\] Beyond the Singular: The Essential Role of Multiple Generations in Effective Benchmark Evaluation and Analysis](https://arxiv.org/abs/2502.08943) (Meta)
- [ ] [\[2502.08942\] Language in the Flow of Time: Time-Series-Paired Texts Weaved into a Unified Temporal Narrative](https://arxiv.org/abs/2502.08942) (Illinois)
- [ ] [\[2502.08941\] Analysis of Off-Policy $n$-Step TD-Learning with Linear Function Approximation](https://arxiv.org/abs/2502.08941) (KAIST)
- [ ] [\[2502.08898\] Learning in Strategic Queuing Systems with Small Buffers](https://arxiv.org/abs/2502.08898) (Berkeley)
- [ ] [\[2502.08896\] Communication is All You Need: Persuasion Dataset Construction via Multi-LLM Communication](https://arxiv.org/abs/2502.08896) (GIT)
- [ ] [\[2502.08884\] ShapeLib: designing a library of procedural 3D shape abstractions with Large Language Models](https://arxiv.org/abs/2502.08884) (UCL)
- [ ] [\[2502.08869\] Harnessing Vision Models for Time Series Analysis: A Survey](https://arxiv.org/abs/2502.08869) (Illinois)
- [ ] [\[2502.08792\] Auction Design using Value Prediction with Hallucinations](https://arxiv.org/abs/2502.08792) (NYU)
- [ ] [\[2502.08769\] Cluster and Predict Latents Patches for Improved Masked Image Modeling](https://arxiv.org/abs/2502.08769) (Meta)
- [ ] [\[2502.08696\] Scalable Discrete Diffusion Samplers: Combinatorial Optimization and Statistical Physics](https://arxiv.org/abs/2502.08696) (ICLR)
- [ ] [\[2502.08691\] AgentSociety: Large-Scale Simulation of LLM-Driven Generative Agents Advances Understanding of Human Behaviors and Society](https://arxiv.org/abs/2502.08691) (Tsinghua)
- [ ] [\[2502.08680\] Mathematical Reasoning in Large Language Models: Assessing Logical and Arithmetic Errors across Wide Numerical Ranges](https://arxiv.org/abs/2502.08680) (NYU)
- [ ] [\[2502.08661\] Few-shot_LLM_Synthetic_Data_with_Distribution_Matching](https://arxiv.org/abs/2502.08661) (Tsinghua)
- [ ] [\[2502.08658\] Analyzable Parameters Dominated Vehicle Platoon Dynamics Modeling and Analysis: A Physics-Encoded Deep Learning Approach](https://arxiv.org/abs/2502.08658) (Tsinghua)
- [ ] [\[2502.08657\] Refining Positive and Toxic Samples for Dual Safety Self-Alignment of LLMs with Minimal Human Interventions](https://arxiv.org/abs/2502.08657) (BUPT)
- [ ] [\[2502.06772\] ReasonFlux: Hierarchical LLM Reasoning via Scaling Thought Templates](https://arxiv.org/abs/2502.06772) (Princeton)

## 2025-02-13 (Thu)
- [ ] [\[2502.08547\] Representation Learning to Advance Multi-institutional Studies with Electronic Health Record Data](https://arxiv.org/abs/2502.08547) (Harvard)
- [ ] [\[2502.08336\] Salience-Invariant Consistent Policy Learning for Generalization in Visual Reinforcement Learning](https://arxiv.org/abs/2502.08336) (IA CAS)
- [ ] [\[2502.08235\] The Danger of Overthinking: Examining the Reasoning-Action Dilemma in Agentic Tasks](https://arxiv.org/abs/2502.08235) (Berkeley)
- [ ] [\[2502.07982\] Deep Semantic Graph Learning via LLM based Node Enhancement](https://arxiv.org/abs/2502.07982) (UCSD)
- [ ] [\[2502.07957\] Intrinsic Bias is Predicted by Pretraining Data and Correlates with Downstream Performance in Vision-Language Encoders](https://arxiv.org/abs/2502.07957) (CMU)
- [ ] [\[2502.08644\] Rhythmic sharing: A bio-inspired paradigm for zero-shot adaptation and learning in neural networks](https://arxiv.org/abs/2502.08644) (UMD)
- [ ] [\[2502.08606\] Distillation Scaling Laws](https://arxiv.org/abs/2502.08606) (Apple)
- [ ] [\[2502.08605\] CurvGAD: Leveraging Curvature for Enhanced Graph Anomaly Detection](https://arxiv.org/abs/2502.08605) (CMU)
- [ ] [\[2502.08597\] Learning in Markets with Heterogeneous Agents: Dynamics and Survival of Bayesian vs. No-Regret Learners](https://arxiv.org/abs/2502.08597) (Cornell)
- [ ] [\[2502.08586\] Commercial LLM Agents Are Already Vulnerable to Simple Yet Dangerous Attacks](https://arxiv.org/abs/2502.08586) (Columbia University)
- [ ] [\[2502.08574\] COAST: Intelligent Time-Adaptive Neural Operators](https://arxiv.org/abs/2502.08574) (Yale)
- [ ] [\[2502.08554\] Fostering Appropriate Reliance on Large Language Models: The Role of Explanations, Sources, and Inconsistencies](https://arxiv.org/abs/2502.08554) (Princeton)
- [ ] [\[2502.08550\] LLMs can implicitly learn from mistakes in-context](https://arxiv.org/abs/2502.08550) (Imperial)
- [ ] [\[2502.08518\] FedMHO: Heterogeneous One-Shot Federated Learning Towards Resource-Constrained Edge Devices](https://arxiv.org/abs/2502.08518) (MBZUAI)
- [ ] [\[2502.08512\] Measuring Diversity in Synthetic Datasets](https://arxiv.org/abs/2502.08512) (SYSU)
- [ ] [\[2502.08438\] Composite Sketch+Text Queries for Retrieving Objects with Elusive Names and Complex Interactions](https://arxiv.org/abs/2502.08438) (Microsoft)
- [ ] [\[2502.08436\] From Haystack to Needle: Label Space Reduction for Zero-shot Classification](https://arxiv.org/abs/2502.08436) (ICML)
- [ ] [\[2502.08340\] Hierarchical Learning-based Graph Partition for Large-scale Vehicle Routing Problems](https://arxiv.org/abs/2502.08340) (HKUST)
- [ ] [\[2502.08317\] Mitigating Hallucinations in Multimodal Spatial Relations through Constraint-Aware Prompting](https://arxiv.org/abs/2502.08317) (University of Rochester)
- [ ] [\[2502.08282\] Individualised Treatment Effects Estimation with Composite Treatments and Composite Outcomes](https://arxiv.org/abs/2502.08282) (Oxford)
- [ ] [\[2502.08279\] What Is That Talk About? A Video-to-Text Summarization Dataset for Scientific Presentations](https://arxiv.org/abs/2502.08279) (Cambridge)
- [ ] [\[2502.08226\] TRISHUL: Towards Region Identification and Screen Hierarchy Understanding for Large VLM based GUI Agents](https://arxiv.org/abs/2502.08226) (ICML)
- [ ] [\[2502.08211\] Quality over Quantity: Boosting Data Efficiency Through Ensembled Multimodal Data Curation](https://arxiv.org/abs/2502.08211) (SJTU)
- [ ] [\[2502.08161\] MixDec Sampling: A Soft Link-based Sampling Method of Graph Neural Network for Recommendation](https://arxiv.org/abs/2502.08161) (Tsinghua)
- [ ] [\[2502.08160\] Vertical Federated Learning in Practice: The Good, the Bad, and the Ugly](https://arxiv.org/abs/2502.08160) (NUS)
- [ ] [\[2502.08150\] Force Matching with Relativistic Constraints: A Physics-Inspired Approach to Stable and Efficient Generative Modeling](https://arxiv.org/abs/2502.08150) (HKU)
- [ ] [\[2502.08145\] Democratizing AI: Open-source Scalable LLM Training on GPU-based Supercomputers](https://arxiv.org/abs/2502.08145) (UMD)
- [ ] [\[2502.08101\] Rethinking Tokenized Graph Transformers for Node Classification](https://arxiv.org/abs/2502.08101) (HUST)
- [ ] [\[2502.08092\] GCoT: Chain-of-Thought Prompt Learning for Graphs](https://arxiv.org/abs/2502.08092) (USTC)
- [ ] [\[2502.08056\] Cognify: Supercharging Gen-AI Workflows With Hierarchical Autotuning](https://arxiv.org/abs/2502.08056) (UCSD)
- [ ] [\[2502.08021\] Model Selection for Off-policy Evaluation: New Algorithms and Experimental Protocol](https://arxiv.org/abs/2502.08021) (Illinois)
- [ ] [\[2502.08020\] Speculate, then Collaborate: Fusing Knowledge of Language Models during Decoding](https://arxiv.org/abs/2502.08020) (UMD)
- [ ] [\[2502.07980\] CIRCUIT: A Benchmark for Circuit Interpretation and Reasoning Capabilities of LLMs](https://arxiv.org/abs/2502.07980) (MIT)
- [ ] [\[2502.07963\] Caught in the Web of Words: Do LLMs Fall for Spin in Medical Literature?](https://arxiv.org/abs/2502.07963) (UT Austin)
- [ ] [\[2502.07864\] TransMLA: Multi-Head Latent Attention Is All You Need](https://arxiv.org/abs/2502.07864) (Peking)
- [ ] [\[2502.07862\] ADMN: A Layer-Wise Adaptive Multimodal Network for Dynamic Input Noise and Compute Resources](https://arxiv.org/abs/2502.07862) (UCLA)
- [ ] [\[2502.07861\] BalanceKV: KV Cache Compression through Discrepancy Theory](https://arxiv.org/abs/2502.07861) (KAIST)
- [ ] [\[2502.07856\] MRS: A Fast Sampler for Mean Reverting Diffusion based on ODE and SDE Solvers](https://arxiv.org/abs/2502.07856) (Alibaba, ICLR)
- [ ] [\[2502.07855\] Vision-Language Models for Edge Networks: A Comprehensive Survey](https://arxiv.org/abs/2502.07855) (MBZUAI)
- [ ] [\[2502.07849\] Understanding Classifier-Free Guidance: High-Dimensional Theory and Non-Linear Generalizations](https://arxiv.org/abs/2502.07849) (Meta)
- [ ] [\[2502.07832\] SHARP: Accelerating Language Model Inference by SHaring Adjacent layers with Recovery Parameters](https://arxiv.org/abs/2502.07832) (UCSD)
- [ ] [\[2502.07830\] Captured by Captions: On Memorization and its Mitigation in CLIP Models](https://arxiv.org/abs/2502.07830) (ICLR)
- [ ] [\[2502.07827\] Implicit Language Models are RNNs: Balancing Parallelization and Expressivity](https://arxiv.org/abs/2502.07827) (Microsoft)
- [ ] [\[2502.07825\] Pre-Trained Video Generative Models as World Simulators](https://arxiv.org/abs/2502.07825) (HKUST)
- [ ] [\[2502.07821\] Amnesia as a Catalyst for Enhancing Black Box Pixel Attacks in Image Classification and Object Detection](https://arxiv.org/abs/2502.07821) (NIPS)
- [ ] [\[2502.07814\] Satellite Observations Guided Diffusion Model for Accurate Meteorological States at Arbitrary Resolution](https://arxiv.org/abs/2502.07814) (CUHK)
- [ ] [\[2502.07794\] Regulatory Science Innovation for Generative AI and Large Language Models in Health and Medicine: A Global Call for Action](https://arxiv.org/abs/2502.07794) (NUS)

## 2025-02-12 (Wed)
- [ ] [\[2502.07709\] MAGELLAN: Metacognitive predictions of learning progress guide autotelic LLM agents in large goal spaces](https://arxiv.org/abs/2502.07709) (Inria)
- [ ] [\[2502.07663\] Human Decision-making is Susceptible to AI-driven Manipulation](https://arxiv.org/abs/2502.07663) (HKU)
- [ ] [\[2502.07503\] Harnessing Language's Fractal Geometry with Recursive Inference Scaling](https://arxiv.org/abs/2502.07503) (Google)
- [ ] [\[2502.07423\] Towards a Formal Theory of the Need for Competence via Computational Intrinsic Motivation](https://arxiv.org/abs/2502.07423) (Imperial)
- [ ] [\[2502.07374\] LLMs Can Easily Learn to Reason from Demonstrations Structure, not content, is what matters!](https://arxiv.org/abs/2502.07374) (Berkeley)
- [ ] [\[2502.07202\] Monte Carlo Tree Diffusion for System 2 Planning](https://arxiv.org/abs/2502.07202) (KAIST)
- [ ] [\[2502.07191\] Bag of Tricks for Inference-time Computation of LLM Reasoning](https://arxiv.org/abs/2502.07191) (HKUST)
- [ ] [\[2502.07190\] Understanding LLMs' Fluid Intelligence Deficiency: An Analysis of the ARC Task](https://arxiv.org/abs/2502.07190) (HKUST)
- [ ] [\[2502.07132\] Interactive Data Harmonization with LLM Agents](https://arxiv.org/abs/2502.07132) (NYU)
- [ ] [\[2502.07752\] Towards Efficient Optimizer Design for LLM via Structured Fisher Approximation with a Low-Rank Extension](https://arxiv.org/abs/2502.07752) (Microsoft)
- [ ] [\[2502.07737\] Next Block Prediction: Video Generation via Semi-Auto-Regressive Modeling](https://arxiv.org/abs/2502.07737) (Peking)
- [ ] [\[2502.07586\] We Can't Understand AI Using our Existing Vocabulary](https://arxiv.org/abs/2502.07586) (Google)
- [ ] [\[2502.07563\] LASP-2: Rethinking Sequence Parallelism for Linear Attention and Its Hybrid](https://arxiv.org/abs/2502.07563) (CUHK)
- [ ] [\[2502.07549\] HGTUL: A Hypergraph-based Model For Trajectory User Linking](https://arxiv.org/abs/2502.07549) (BUPT)
- [ ] [\[2502.07516\] The Devil is in the Prompts: De-Identification Traces Enhance Memorization Risks in Synthetic Chest X-Ray Generation](https://arxiv.org/abs/2502.07516) (University of Edinburgh)
- [ ] [\[2502.07408\] No Data, No Optimization: A Lightweight Method To Disrupt Neural Networks With Sign-Flips](https://arxiv.org/abs/2502.07408) (NVIDIA)
- [ ] [\[2502.07351\] Multi-Task-oriented Nighttime Haze Imaging Enhancer for Vision-driven Measurement Systems](https://arxiv.org/abs/2502.07351) (UESTC)
- [ ] [\[2502.07316\] CodeI/O: Condensing Reasoning Patterns via Code Input-Output Prediction](https://arxiv.org/abs/2502.07316) (HKUST)
- [ ] [\[2502.07279\] Exploratory Diffusion Policy for Unsupervised Reinforcement Learning](https://arxiv.org/abs/2502.07279) (Tsinghua)
- [ ] [\[2502.07276\] Dataset Ownership Verification in Contrastive Pre-trained Models](https://arxiv.org/abs/2502.07276) (ICLR)
- [ ] [\[2502.07274\] Cost-Efficient Continual Learning with Sufficient Exemplar Memory](https://arxiv.org/abs/2502.07274) (NYU)
- [ ] [\[2502.07250\] NARCE: A Mamba-Based Neural Algorithmic Reasoner Framework for Online Complex Event Detection](https://arxiv.org/abs/2502.07250) (UCLA)
- [ ] [\[2502.07244\] Linear Transformers as VAR Models: Aligning Autoregressive Attention Mechanisms with Autoregressive Forecasting](https://arxiv.org/abs/2502.07244) (GIT)
- [ ] [\[2502.07243\] Vevo: Controllable Zero-Shot Voice Imitation with Self-Supervised Disentanglement](https://arxiv.org/abs/2502.07243) (ICLR)
- [ ] [\[2502.07238\] Diffusion Suction Grasping with Large-Scale Parcel Dataset](https://arxiv.org/abs/2502.07238) (Tsinghua)
- [ ] [\[2502.07218\] LUNAR: LLM Unlearning via Neural Activation Redirection](https://arxiv.org/abs/2502.07218) (Cambridge)
- [ ] [\[2502.07216\] SparseFormer: Detecting Objects in HRW Shots via Sparse Vision Transformer](https://arxiv.org/abs/2502.07216) (ACMMM)
- [ ] [\[2502.07184\] Refine Knowledge of Large Language Models via Adaptive Contrastive Learning](https://arxiv.org/abs/2502.07184) (Tsinghua, ICLR)
- [ ] [\[2502.07154\] Rethinking Fine-Tuning when Scaling Test-Time Compute: Limiting Confidence Improves Mathematical Reasoning](https://arxiv.org/abs/2502.07154) (University of Michigan)
- [ ] [\[2502.07153\] Feature Importance Depends on Properties of the Data: Towards Choosing the Correct Explanations for Your Data and Decision Trees based Models](https://arxiv.org/abs/2502.07153) (Imperial)
- [ ] [\[2502.07115\] Online Scheduling for LLM Inference with KV Cache Constraints](https://arxiv.org/abs/2502.07115) (MIT)
- [ ] [\[2502.07088\] Kernels of Selfhood: GPT-4o shows humanlike patterns of cognitive consistency moderated by free choice](https://arxiv.org/abs/2502.07088) (BU)
- [ ] [\[2502.07071\] TRADES: Generating Realistic Market Simulations with Diffusion Models](https://arxiv.org/abs/2502.07071) (TUM)
- [ ] [\[2502.07064\] Contextual Thompson Sampling via Generation of Missing Data](https://arxiv.org/abs/2502.07064) (Imperial)
- [ ] [\[2502.07022\] AIMS.au: A Dataset for the Analysis of Modern Slavery Countermeasures in Corporate Statements](https://arxiv.org/abs/2502.07022) (ICLR)
- [ ] [\[2502.07001\] From Image to Video: An Empirical Study of Diffusion Representations](https://arxiv.org/abs/2502.07001) (Google)
- [ ] [\[2502.06994\] SyncMind: Measuring Agent Out-of-Sync Recovery in Collaborative Software Engineering](https://arxiv.org/abs/2502.06994) (Illinois)
- [ ] [\[2502.06919\] Select before Act: Spatially Decoupled Action Repetition for Continuous Control](https://arxiv.org/abs/2502.06919) (ICLR)
- [ ] [\[2502.06914\] UniZyme: A Unified Protein Cleavage Site Predictor Enhanced with Enzyme Active-Site Knowledge](https://arxiv.org/abs/2502.06914) (HKUST(GZ))
- [ ] [\[2502.06911\] Foundation Models for Anomaly Detection: Vision and Challenges](https://arxiv.org/abs/2502.06911) (MIT)
- [ ] [\[2502.06910\] TimeKAN: KAN-based Frequency Decomposition Learning Architecture for Long-term Time Series Forecasting](https://arxiv.org/abs/2502.06910) (Shanghai AI Lab)
- [ ] [\[2502.06909\] Satisfaction-Aware Incentive Scheme for Federated Learning in Industrial Metaverse: DRL-Based Stackbelberg Game Approach](https://arxiv.org/abs/2502.06909) (NTU)
- [ ] [\[2502.06905\] Lightweight Dataset Pruning without Full Training via Example Difficulty and Prediction Uncertainty](https://arxiv.org/abs/2502.06905) (KAIST)
- [ ] [\[2502.06901\] Enabling Autoregressive Models to Fill In Masked Tokens](https://arxiv.org/abs/2502.06901) (UCLA)
- [ ] [\[2502.06898\] Large Language Models for In-File Vulnerability Localization Can Be "Lost in the End"](https://arxiv.org/abs/2502.06898) (ETH)
- [ ] [\[2502.06892\] Certifying Language Model Robustness with Fuzzed Randomized Smoothing: An Efficient Defense Against Backdoor Attacks](https://arxiv.org/abs/2502.06892) (ICLR)
- [ ] [\[2502.06888\] Klotski: Efficient Mixture-of-Expert Inference via Expert-Aware Multi-Batch Pipeline](https://arxiv.org/abs/2502.06888) (SYSU)
- [ ] [\[2502.06887\] Gradient Based Method for the Fusion of Lattice Quantizers](https://arxiv.org/abs/2502.06887) (Peking)
- [ ] [\[2502.06885\] Topological derivative approach for deep neural network architecture adaptation](https://arxiv.org/abs/2502.06885) (UT Austin)
- [ ] [\[2502.06882\] Multi-Agent Simulator Drives Language Models for Legal Intensive Interaction](https://arxiv.org/abs/2502.06882) (Fudan)
- [ ] [\[2502.06875\] Beyond Vision: How Large Language Models Interpret Facial Expressions from Valence-Arousal Values](https://arxiv.org/abs/2502.06875) (Cambridge)
- [ ] [\[2502.06874\] Group Reasoning Emission Estimation Networks](https://arxiv.org/abs/2502.06874) (USyd)
- [ ] [\[2502.06872\] Towards Trustworthy Retrieval Augmented Generation for Large Language Models: A Survey](https://arxiv.org/abs/2502.06872) (PolyU)
- [ ] [\[2502.06864\] Knowledge Graph-Guided Retrieval Augmented Generation](https://arxiv.org/abs/2502.06864) (NJU)
- [ ] [\[2502.06863\] BF-GAN: Development of an AI-driven Bubbly Flow Image Generation Model Using Generative Adversarial Networks](https://arxiv.org/abs/2502.06863) (University of Tokyo)
- [ ] [\[2502.06861\] Design Considerations in Offline Preference-based RL](https://arxiv.org/abs/2502.06861) (Google)
- [ ] [\[2502.06857\] Gemstones: A Model Suite for Multi-Faceted Scaling Laws](https://arxiv.org/abs/2502.06857) (UMD)
- [ ] [\[2502.06848\] Transfer learning in Scalable Graph Neural Network for Improved Physical Simulation](https://arxiv.org/abs/2502.06848) (Peking)
- [ ] [\[2502.06846\] Prot2Chat: Protein LLM with Early Fusion of Sequence and Structure](https://arxiv.org/abs/2502.06846) (Peking)
- [ ] [\[2502.06834\] A Unified Knowledge-Distillation and Semi-Supervised Learning Framework to Improve Industrial Ads Delivery Systems](https://arxiv.org/abs/2502.06834) (Meta)
- [ ] [\[2502.06832\] Optimizing Robustness and Accuracy in Mixture of Experts: A Dual-Model Approach](https://arxiv.org/abs/2502.06832) (ICML)
- [ ] [\[2502.06827\] Learning to Synthesize Compatible Fashion Items Using Semantic Alignment and Collocation Classification: An Outfit Generation Framework](https://arxiv.org/abs/2502.06827) (HIT)
- [ ] [\[2502.06808\] On the Benefits of Attribute-Driven Graph Domain Adaptation](https://arxiv.org/abs/2502.06808) (Michigan State University, ICLR)
- [ ] [\[2502.06802\] Solving the Content Gap in Roblox Game Recommendations: LLM-Based Profile Generation and Reranking](https://arxiv.org/abs/2502.06802) (Columbia University)

## 2025-02-11 (Tue)
- [ ] [\[2502.06060\] Training Language Models for Social Deduction with Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2502.06060) (Stanford)
- [ ] [\[2502.05934\] Barriers and Pathways to Human-AI Alignment: A Game-Theoretic Approach](https://arxiv.org/abs/2502.05934) (CMU)
- [ ] [\[2502.05632\] Amorphous Fortress Online: Collaboratively Designing Open-Ended Multi-Agent AI and Game Environments](https://arxiv.org/abs/2502.05632) (NYU)
- [ ] [\[2502.05537\] Sequential Stochastic Combinatorial Optimization Using Hierarchal Reinforcement Learning](https://arxiv.org/abs/2502.05537) (UCLA)
- [ ] [\[2502.05442\] The Odyssey of the Fittest: Can Agents Survive and Still Be Good?](https://arxiv.org/abs/2502.05442) (UT Austin)
- [ ] [\[2502.06784\] RelGNN: Composite Message Passing for Relational Deep Learning](https://arxiv.org/abs/2502.06784) (Stanford)
- [ ] [\[2502.06779\] KARST: Multi-Kernel Kronecker Adaptation with Re-Scaling Transmission for Visual Classification](https://arxiv.org/abs/2502.06779) (HKUST)
- [ ] [\[2502.06776\] Towards Internet-Scale Training For Agents](https://arxiv.org/abs/2502.06776) (CMU)
- [ ] [\[2502.06751\] What makes a good feedforward computational graph?](https://arxiv.org/abs/2502.06751) (Google)
- [ ] [\[2502.06742\] Gradient Multi-Normalization for Stateless and Scalable LLM Training](https://arxiv.org/abs/2502.06742) (Microsoft)
- [ ] [\[2502.06733\] Dynamic Loss-Based Sample Reweighting for Improved Large Language Model Pretraining](https://arxiv.org/abs/2502.06733) (TUM, ICLR)
- [ ] [\[2502.06693\] Recent Advances, Applications and Open Challenges in Machine Learning for Health: Reflections from Research Roundtables at ML4H 2024 Symposium](https://arxiv.org/abs/2502.06693) (Illinois)
- [ ] [\[2502.06669\] Boosting Self-Efficacy and Performance of Large Language Models via Verbal Efficacy Stimulations](https://arxiv.org/abs/2502.06669) (UCAS)
- [ ] [\[2502.06635\] Steel-LLM:From Scratch to Open Source -- A Personal Journey in Building a Chinese-Centric LLM](https://arxiv.org/abs/2502.06635) (BUPT)
- [ ] [\[2502.06633\] Combining Large Language Models with Static Analyzers for Code Review Generation](https://arxiv.org/abs/2502.06633) (University of Montreal)
- [ ] [\[2502.06589\] Hephaestus: Improving Fundamental Agent Capabilities of Large Language Models through Continual Pre-Training](https://arxiv.org/abs/2502.06589) (GIT)
- [ ] [\[2502.06577\] The Minimal Search Space for Conditional Causal Bandits](https://arxiv.org/abs/2502.06577) (ICML)
- [ ] [\[2502.06516\] Boost-and-Skip: A Simple Guidance-Free Diffusion for Minority Generation](https://arxiv.org/abs/2502.06516) (KAIST)
- [ ] [\[2502.06490\] Recent Advances in Discrete Speech Tokens: A Review](https://arxiv.org/abs/2502.06490) (SJTU)
- [ ] [\[2502.06472\] KARMA: Leveraging Multi-Agent LLMs for Automated Knowledge Graph Enrichment](https://arxiv.org/abs/2502.06472) (Peking)
- [ ] [\[2502.06453\] MATH-Perturb: Benchmarking LLMs' Math Reasoning Abilities against Hard Perturbations](https://arxiv.org/abs/2502.06453) (Princeton)
- [ ] [\[2502.06432\] Prompt-SID: Learning Structural Representation Prompt via Latent Diffusion for Single-Image Denoising](https://arxiv.org/abs/2502.06432) (Tsinghua)
- [ ] [\[2502.06424\] CS-SHAP: Extending SHAP to Cyclic-Spectral Domain for Better Interpretability of Intelligent Fault Diagnosis](https://arxiv.org/abs/2502.06424) (SJTU)
- [ ] [\[2502.06415\] Systematic Outliers in Large Language Models](https://arxiv.org/abs/2502.06415) (IA CAS, ICLR)
- [ ] [\[2502.06348\] AiRacleX: Automated Detection of Price Oracle Manipulations via LLM-Driven Knowledge Mining and Prompt Generation](https://arxiv.org/abs/2502.06348) (A*STAR,)
- [ ] [\[2502.06327\] Prompt-Driven Continual Graph Learning](https://arxiv.org/abs/2502.06327) (BIT)
- [ ] [\[2502.06314\] From Pixels to Components: Eigenvector Masking for Visual Representation Learning](https://arxiv.org/abs/2502.06314) (ETH)
- [ ] [\[2502.06282\] Jakiro: Boosting Speculative Decoding with Decoupled Multi-Head via MoE](https://arxiv.org/abs/2502.06282) (XJTU)
- [ ] [\[2502.06274\] HODDI: A Dataset of High-Order Drug-Drug Interactions for Computational Pharmacovigilance](https://arxiv.org/abs/2502.06274) (Harvard)
- [ ] [\[2502.06215\] LessLeak-Bench: A First Investigation of Data Leakage in LLMs Across 83 Software Engineering Benchmarks](https://arxiv.org/abs/2502.06215) (WHU)
- [ ] [\[2502.06192\] Right Time to Learn:Promoting Generalization via Bio-inspired Spacing Effect in Knowledge Distillation](https://arxiv.org/abs/2502.06192) (Tsinghua)
- [ ] [\[2502.06167\] Universal Approximation of Visual Autoregressive Transformers](https://arxiv.org/abs/2502.06167) (HKU)
- [ ] [\[2502.06146\] Guided Exploration for Efficient Relational Model Learning](https://arxiv.org/abs/2502.06146) (MIT)
- [ ] [\[2502.06136\] Graph Neural Networks at a Fraction](https://arxiv.org/abs/2502.06136) (Microsoft)
- [ ] [\[2502.06134\] Integrating Sequence and Image Modeling in Irregular Medical Time Series Through Self-Supervised Learning](https://arxiv.org/abs/2502.06134) (ZJU)
- [ ] [\[2502.06117\] Revisiting Dynamic Graph Clustering via Matrix Factorization](https://arxiv.org/abs/2502.06117) (University of Tokyo)
- [ ] [\[2502.06106\] Circuit-tuning: A Mechanistic Approach for Identifying Parameter Redundancy and Fine-tuning Neural Networks](https://arxiv.org/abs/2502.06106) (BUPT)
- [ ] [\[2502.06096\] Post-detection inference for sequential changepoint localization](https://arxiv.org/abs/2502.06096) (CMU)
- [ ] [\[2502.06084\] Physics-Guided Foundation Model for Scientific Discovery: An Application to Aquatic Science](https://arxiv.org/abs/2502.06084) (UMD)
- [ ] [\[2502.06065\] Benchmarking Prompt Sensitivity in Large Language Models](https://arxiv.org/abs/2502.06065) (University of Toronto)
- [ ] [\[2502.06051\] Nearly Optimal Sample Complexity of Offline KL-Regularized Contextual Bandits under Single-Policy Concentrability](https://arxiv.org/abs/2502.06051) (UCLA)
- [ ] [\[2502.06038\] Provably Overwhelming Transformer Models with Designed Inputs](https://arxiv.org/abs/2502.06038) (UMD)
- [ ] [\[2502.05949\] Verifying Proportionality in Temporal Voting](https://arxiv.org/abs/2502.05949) (NUS)
- [ ] [\[2502.05932\] Skill Expansion and Composition in Parameter Space](https://arxiv.org/abs/2502.05932) (NUDT, ICLR)
- [ ] [\[2502.05892\] A Distributional Perspective on Word Learning in Neural Language Models](https://arxiv.org/abs/2502.05892) (UCSD)
- [ ] [\[2502.05887\] MTPChat: A Multimodal Time-Aware Persona Dataset for Conversational Agents](https://arxiv.org/abs/2502.05887) (UTS)
- [ ] [\[2502.05874\] MMGDreamer: Mixed-Modality Graph for Geometry-Controllable 3D Indoor Scene Generation](https://arxiv.org/abs/2502.05874) (Peking)
- [ ] [\[2502.05835\] Contrastive Representation Distillation via Multi-Scale Feature Decoupling](https://arxiv.org/abs/2502.05835) (Fudan)
- [ ] [\[2502.05832\] Compressing Model with Few Class-Imbalance Samples: An Out-of-Distribution Expedition](https://arxiv.org/abs/2502.05832) (NJU)
- [ ] [\[2502.05795\] The Curse of Depth in Large Language Models](https://arxiv.org/abs/2502.05795) (Oxford)
- [ ] [\[2502.05783\] WatchGuardian: Enabling User-Defined Personalized Just-in-Time Intervention on Smartwatch](https://arxiv.org/abs/2502.05783) (Columbia University)
- [ ] [\[2502.05777\] Predictive Crash Analytics for Traffic Safety using Deep Learning](https://arxiv.org/abs/2502.05777) (UT Austin)
- [ ] [\[2502.05772\] Effective Black-Box Multi-Faceted Attacks Breach Vision Large Language Model Guardrails](https://arxiv.org/abs/2502.05772) (CUHK)
- [ ] [\[2502.05749\] UniDB: A Unified Diffusion Bridge Framework via Stochastic Optimal Control](https://arxiv.org/abs/2502.05749) (ShanghaiTech)
- [ ] [\[2502.05740\] RECOVER: Designing a Large Language Model-based Remote Patient Monitoring System for Postoperative Gastrointestinal Cancer Care](https://arxiv.org/abs/2502.05740) (JHU)
- [ ] [\[2502.05739\] Mitigating Sensitive Information Leakage in LLMs4Code through Machine Unlearning](https://arxiv.org/abs/2502.05739) (BUPT)
- [ ] [\[2502.05713\] 4D VQ-GAN: Synthesising Medical Scans at Any Time Point for Personalised Disease Progression Modelling of Idiopathic Pulmonary Fibrosis](https://arxiv.org/abs/2502.05713) (UCL)
- [ ] [\[2502.05694\] Zero-Shot End-to-End Relation Extraction in Chinese: A Comparative Study of Gemini, LLaMA and ChatGPT](https://arxiv.org/abs/2502.05694) (UVA.NL)
- [ ] [\[2502.05574\] Event Stream-based Visual Object Tracking: HDETrack V2 and A High-Definition Benchmark](https://arxiv.org/abs/2502.05574) (Peking, CVPR)
- [ ] [\[2502.05567\] ATLAS: Autoformalizing Theorems through Lifting, Augmentation, and Synthesis of Data](https://arxiv.org/abs/2502.05567) (SJTU)
- [ ] [\[2502.05564\] TabICL: A Tabular Foundation Model for In-Context Learning on Large Data](https://arxiv.org/abs/2502.05564) (Inria)
- [ ] [\[2502.05547\] Dual Defense: Enhancing Privacy and Mitigating Poisoning Attacks in Federated Learning](https://arxiv.org/abs/2502.05547) (NIPS)
- [ ] [\[2502.05500\] Vision-Ultrasound Robotic System based on Deep Learning for Gas and Arc Hazard Detection in Manufacturing](https://arxiv.org/abs/2502.05500) (University of Michigan)
- [ ] [\[2502.05498\] Riemannian Manifold Learning for Stackelberg Games with Neural Flow Representations](https://arxiv.org/abs/2502.05498) (TUM)
- [ ] [\[2502.05467\] Position: LLMs Can be Good Tutors in Foreign Language Education](https://arxiv.org/abs/2502.05467) (Tsinghua)
- [ ] [\[2502.05431\] APE: Faster and Longer Context-Augmented Generation via Adaptive Parallel Encoding](https://arxiv.org/abs/2502.05431) (ICLR)
- [ ] [\[2502.05424\] SAMGPT: Text-free Graph Foundation Model for Multi-domain Pre-training and Cross-domain Adaptation](https://arxiv.org/abs/2502.05424) (USTC)
- [ ] [\[2502.05407\] The Complexity of Learning Sparse Superposed Features with Feedback](https://arxiv.org/abs/2502.05407) (UCSD)
- [ ] [\[2502.05344\] RAG-Verus: Repository-Level Program Verification with LLMs using Retrieval Augmented Generation](https://arxiv.org/abs/2502.05344) (University of Toronto)
- [ ] [\[2502.05310\] Oracular Programming: A Modular Foundation for Building LLM-Enabled Software](https://arxiv.org/abs/2502.05310) (CMU)
- [ ] [\[2502.05252\] GSM-Infinite: How Do Your LLMs Behave over Infinitely Increasing Context Length and Reasoning Complexity?](https://arxiv.org/abs/2502.05252) (Meta)
- [ ] [\[2502.05242\] SEER: Self-Explainability Enhancement of Large Language Models' Representations](https://arxiv.org/abs/2502.05242) (Shanghai AI Lab)
- [ ] [\[2502.05236\] Koel-TTS: Enhancing LLM based Speech Generation with Preference Alignment and Classifier Free Guidance](https://arxiv.org/abs/2502.05236) (NVIDIA)
- [ ] [\[2502.05234\] Optimizing Temperature for Language Models with Multi-Sample Inference](https://arxiv.org/abs/2502.05234) (CMU)
- [ ] [\[2502.05232\] Aligner-Encoders: Self-Attention Transformers Can Be Self-Transducers](https://arxiv.org/abs/2502.05232) (Google)
- [ ] [\[2502.05228\] Multi-Objective Mobile Damped Wave Algorithm (MOMDWA): A Novel Approach For Quantum System Control](https://arxiv.org/abs/2502.05228) (Columbia University)
- [ ] [\[2502.05227\] Robotouille: An Asynchronous Planning Benchmark for LLM Agents](https://arxiv.org/abs/2502.05227) (Cornell)
- [ ] [\[2502.05218\] FactorGCL: A Hypergraph-Based Factor Model with Temporal Residual Contrastive Learning for Stock Returns Prediction](https://arxiv.org/abs/2502.05218) (Tsinghua)
- [ ] [\[2502.05214\] CoRPA: Adversarial Image Generation for Chest X-rays Using Concept Vector Perturbations and Generative Models](https://arxiv.org/abs/2502.05214) (University of Edinburgh)
- [ ] [\[2502.05213\] DERMARK: A Dynamic, Efficient and Robust Multi-bit Watermark for Large Language Models](https://arxiv.org/abs/2502.05213) (USTC)
- [ ] [\[2502.05209\] Model Tampering Attacks Enable More Rigorous Evaluations of LLM Capabilities](https://arxiv.org/abs/2502.05209) (MIT)
- [ ] [\[2502.05206\] Safety at Scale: A Comprehensive Survey of Large Model Safety](https://arxiv.org/abs/2502.05206) (Fudan)
- [ ] [\[2410.13772\] Is Prior-Free Black-Box Non-Stationary Reinforcement Learning Feasible?](https://arxiv.org/abs/2410.13772) (Illinois)
- [ ] [\[2301.06943\] Self-supervised Domain Adaptation for Breaking the Limits of Low-quality Fundus Image Quality Enhancement](https://arxiv.org/abs/2301.06943) (Alibaba)

## 2025-02-10 (Mon)
- [ ] [\[2502.05007\] Analyzing Advanced AI Systems Against Definitions of Life and Consciousness](https://arxiv.org/abs/2502.05007) (MIT)
- [ ] [\[2502.04780\] SiriuS: Self-improving Multi-agent Systems via Bootstrapped Reasoning](https://arxiv.org/abs/2502.04780) (Stanford)
- [ ] [\[2502.04671\] ${\rm P{\small ROOF}W{\small ALA}}$: Multilingual Proof Data Synthesis and Theorem-Proving](https://arxiv.org/abs/2502.04671) (UT Austin)
- [ ] [\[2502.04567\] Preference Optimization via Contrastive Divergence: Your Reward Model is Secretly an NLL Estimator](https://arxiv.org/abs/2502.04567) (AWS)
- [ ] [\[2502.04512\] Safety is Essential for Responsible Open-Ended Systems](https://arxiv.org/abs/2502.04512) (Microsoft)
- [ ] [\[2502.04371\] PerPO: Perceptual Preference Optimization via Discriminative Rewarding](https://arxiv.org/abs/2502.04371) (UCAS)
- [ ] [\[2502.05172\] Joint MoE Scaling Laws: Mixture of Experts Can Be Memory Efficient](https://arxiv.org/abs/2502.05172) (UW)
- [ ] [\[2502.05151\] Transforming Science with Large Language Models: A Survey on AI-assisted Scientific Discovery, Experimentation, Content Generation, and Evaluation](https://arxiv.org/abs/2502.05151) (University of Tbingen)
- [ ] [\[2502.05147\] LP-DETR: Layer-wise Progressive Relations for Object Detection](https://arxiv.org/abs/2502.05147) (NYU)
- [ ] [\[2502.05111\] Flexible and Efficient Grammar-Constrained Decoding](https://arxiv.org/abs/2502.05111) (UCSD)
- [ ] [\[2502.05087\] Mitigating Unintended Memorization with LoRA in Federated Learning for LLMs](https://arxiv.org/abs/2502.05087) (EPFL)
- [ ] [\[2502.05085\] Causality can systematically address the monsters under the bench(marks)](https://arxiv.org/abs/2502.05085) (MPI)
- [ ] [\[2502.05084\] ChallengeMe: An Adversarial Learning-enabled Text Summarization Framework](https://arxiv.org/abs/2502.05084) (NYU)
- [ ] [\[2502.05060\] Preference-aware compensation policies for crowdsourced on-demand services](https://arxiv.org/abs/2502.05060) (TUM)
- [ ] [\[2502.05017\] Bridging Voting and Deliberation with Algorithms: Field Insights from vTaiwan and Kultur Komitee](https://arxiv.org/abs/2502.05017) (ETH)
- [ ] [\[2502.05001\] A New Paradigm in Tuning Learned Indexes: A Reinforcement Learning Enhanced Approach](https://arxiv.org/abs/2502.05001) (Cambridge)
- [ ] [\[2502.04951\] The Rising Threat to Emerging AI-Powered Search Engines](https://arxiv.org/abs/2502.04951) (HKUST(GZ))
- [ ] [\[2502.04935\] Conformal Prediction for Electricity Price Forecasting in the Day-Ahead and Real-Time Balancing Market](https://arxiv.org/abs/2502.04935) (University of Edinburgh)
- [ ] [\[2502.04923\] Cached Multi-Lora Composition for Multi-Concept Image Generation](https://arxiv.org/abs/2502.04923) (ICLR)
- [ ] [\[2502.04903\] Wavelet-Assisted Multi-Frequency Attention Network for Pansharpening](https://arxiv.org/abs/2502.04903) (IA CAS)
- [ ] [\[2502.04899\] Unified Approaches in Self-Supervised Event Stream Modeling: Progress and Prospects](https://arxiv.org/abs/2502.04899) (Microsoft)
- [ ] [\[2502.04878\] Sparse Autoencoders Do Not Find Canonical Units of Analysis](https://arxiv.org/abs/2502.04878) (ICLR)
- [ ] [\[2502.04794\] MedMimic: Physician-Inspired Multimodal Fusion for Early Diagnosis of Fever of Unknown Origin](https://arxiv.org/abs/2502.04794) (University of Tokyo)
- [ ] [\[2502.04790\] S$^2$-MAD: Breaking the Token Barrier to Enhance Multi-Agent Debate Efficiency](https://arxiv.org/abs/2502.04790) (HIT)
- [ ] [\[2502.04778\] Behavior-Regularized Diffusion Policy Optimization for Offline Reinforcement Learning](https://arxiv.org/abs/2502.04778) (NJU)
- [ ] [\[2502.04759\] Enhancing Phishing Email Identification with Large Language Models](https://arxiv.org/abs/2502.04759) (GIT)
- [ ] [\[2502.04747\] Every Software as an Agent: Blueprint and Case Study](https://arxiv.org/abs/2502.04747) (BUPT)
- [ ] [\[2502.04725\] Can Diffusion Models Learn Hidden Inter-Feature Rules Behind Images?](https://arxiv.org/abs/2502.04725) (HKU)
- [ ] [\[2502.04670\] CCS: Controllable and Constrained Sampling with Diffusion Models via Initial Noise Perturbation](https://arxiv.org/abs/2502.04670) (University of Michigan)
- [ ] [\[2502.04669\] A Comprehensive Review on Noise Control of Diffusion Model](https://arxiv.org/abs/2502.04669) (Columbia University)
- [ ] [\[2502.04658\] Shifting Attention to You: Personalized Brain-Inspired AI Models](https://arxiv.org/abs/2502.04658) (Vanderbilt University)
- [ ] [\[2502.04646\] Importance Sampling via Score-based Generative Models](https://arxiv.org/abs/2502.04646) (UT Austin)
- [ ] [\[2502.04645\] Cross-Encoder Rediscovers a Semantic Variant of BM25](https://arxiv.org/abs/2502.04645) (University of Tbingen)
- [ ] [\[2502.04638\] Learning Street View Representations with Spatiotemporal Contrast](https://arxiv.org/abs/2502.04638) (Peking)
- [ ] [\[2502.04636\] An Empirical Study of Code Obfuscation Practices in the Google Play Store](https://arxiv.org/abs/2502.04636) (USyd)
- [ ] [\[2502.04602\] Extracting and Understanding the Superficial Knowledge in Alignment](https://arxiv.org/abs/2502.04602) (UT Austin)
- [ ] [\[2502.04573\] Zero-shot Meta-learning for Tabular Prediction Tasks with Adversarially Pre-trained Transformer](https://arxiv.org/abs/2502.04573) (Berkeley)
- [ ] [\[2502.04515\] MedGNN: Towards Multi-resolution Spatiotemporal Graph Learning for Medical Time Series Classification](https://arxiv.org/abs/2502.04515) (BIT)
- [ ] [\[2502.04488\] Building A Unified AI-centric Language System: analysis, framework and future work](https://arxiv.org/abs/2502.04488) (Harvard)
- [ ] [\[2502.04476\] ADIFF: Explaining audio difference using natural language](https://arxiv.org/abs/2502.04476) (ICLR)
- [ ] [\[2502.04475\] Augmented Conditioning Is Enough For Effective Training Image Generation](https://arxiv.org/abs/2502.04475) (UT Austin)
- [ ] [\[2502.04469\] No Images, No Problem: Retaining Knowledge in Continual VQA with Questions-Only Memory](https://arxiv.org/abs/2502.04469) (Inria)
- [ ] [\[2502.04420\] KVTuner: Sensitivity-Aware Layer-wise Mixed Precision KV Cache Quantization for Efficient and Nearly Lossless LLM Inference](https://arxiv.org/abs/2502.04420) (CUHK)
- [ ] [\[2502.04419\] Understanding and Mitigating the Bias Inheritance in LLM-based Data Augmentation on Downstream Tasks](https://arxiv.org/abs/2502.04419) (CMU)
- [ ] [\[2502.04417\] NeuralMOVES: A lightweight and microscopic vehicle emission estimation model based on reverse engineering and surrogate learning](https://arxiv.org/abs/2502.04417) (MIT)
- [ ] [\[2502.04413\] MedRAG: Enhancing Retrieval-augmented Generation with Knowledge Graph-Elicited Reasoning for Healthcare Copilot](https://arxiv.org/abs/2502.04413) (NTU)
- [ ] [\[2502.04412\] Decoder-Only LLMs are Better Controllers for Diffusion Models](https://arxiv.org/abs/2502.04412) (SYSU)
- [ ] [\[2502.04407\] Illuminating Spaces: Deep Reinforcement Learning and Laser-Wall Partitioning for Architectural Layout Generation](https://arxiv.org/abs/2502.04407) (ETH)
- [ ] [\[2502.04406\] Calibrated Physics-Informed Uncertainty Quantification](https://arxiv.org/abs/2502.04406) (UCL)
- [ ] [\[2502.04399\] Online Location Planning for AI-Defined Vehicles: Optimizing Joint Tasks of Order Serving and Spatio-Temporal Heterogeneous Model Fine-Tuning](https://arxiv.org/abs/2502.04399) (NTU)
- [ ] [\[2502.04394\] DECT: Harnessing LLM-assisted Fine-Grained Linguistic Knowledge and Label-Switched and Label-Preserved Data Generation for Diagnosis of Alzheimer's Disease](https://arxiv.org/abs/2502.04394) (CUHK)
- [ ] [\[2502.04392\] Division-of-Thoughts: Harnessing Hybrid Language Model Synergy for Efficient On-Device Agents](https://arxiv.org/abs/2502.04392) (Tsinghua)
- [ ] [\[2502.04386\] Towards Fair Medical AI: Adversarial Debiasing of 3D CT Foundation Embeddings](https://arxiv.org/abs/2502.04386) (JHU)
- [ ] [\[2502.04385\] TexLiDAR: Automated Text Understanding for Panoramic LiDAR Data](https://arxiv.org/abs/2502.04385) (Tel Aviv)
- [ ] [\[2502.04382\] Sparse Autoencoders for Hypothesis Generation](https://arxiv.org/abs/2502.04382) (Berkeley)
- [ ] [\[2502.04380\] Diversity as a Reward: Fine-Tuning LLMs on a Mixture of Domain-Undetermined Data](https://arxiv.org/abs/2502.04380) (SYSU)
- [ ] [\[2502.04359\] Exploring Spatial Language Grounding Through Referring Expressions](https://arxiv.org/abs/2502.04359) (UCSD)
- [ ] [\[2502.04357\] Reusing Embeddings: Reproducible Reward Model Research in Large Language Model Alignment without GPUs](https://arxiv.org/abs/2502.04357) (Cambridge)
- [ ] [\[2502.04354\] Reviving The Classics: Active Reward Modeling in Large Language Model Alignment](https://arxiv.org/abs/2502.04354) (MIT)
- [ ] [\[2502.04352\] Investigating the Robustness of Deductive Reasoning with Large Language Models](https://arxiv.org/abs/2502.04352) (UVA.NL)
- [ ] [\[2502.04350\] CodeSteer: Symbolic-Augmented Language Models via Code/Text Guidance](https://arxiv.org/abs/2502.04350) (Harvard)
- [ ] [\[2502.04345\] JingFang: A Traditional Chinese Medicine Large Language Model of Expert-Level Medical Diagnosis and Syndrome Differentiation-Based Treatment](https://arxiv.org/abs/2502.04345) (BUPT)

## 2025-02-07 (Fri)
- [ ] [\[2502.03948\] Enhancing Online Learning Efficiency Through Heterogeneous Resource Integration with a Multi-Agent RAG System](https://arxiv.org/abs/2502.03948) (TUM)
- [ ] [\[2502.03544\] Gold-medalist Performance in Solving Olympiad Geometry with AlphaGeometry2](https://arxiv.org/abs/2502.03544) (Google)
- [ ] [\[2502.04326\] WorldSense: Evaluating Real-world Omnimodal Understanding for Multimodal LLMs](https://arxiv.org/abs/2502.04326) (SJTU)
- [ ] [\[2502.04308\] HOG-Diff: Higher-Order Guided Diffusion for Graph Generation](https://arxiv.org/abs/2502.04308) (Imperial)
- [ ] [\[2502.04268\] Point2RBox-v2: Rethinking Point-supervised Oriented Object Detection with Spatial Layout Among Instances](https://arxiv.org/abs/2502.04268) (Tsinghua)
- [ ] [\[2502.04263\] Cross the Gap: Exposing the Intra-modal Misalignment in CLIP via Modality Inversion](https://arxiv.org/abs/2502.04263) (ICLR)
- [ ] [\[2502.04242\] A Theoretical Framework for Data Efficient Multi-Source Transfer Learning Based on Cramr-Rao Bound](https://arxiv.org/abs/2502.04242) (Tsinghua)
- [ ] [\[2502.04229\] Dark Distillation: Backdooring Distilled Datasets without Accessing Raw Data](https://arxiv.org/abs/2502.04229) (A*STAR,)
- [ ] [\[2502.04194\] The Best Instruction-Tuning Data are Those That Fit](https://arxiv.org/abs/2502.04194) (Illinois)
- [ ] [\[2502.04153\] UltraIF: Advancing Instruction Following from the Wild](https://arxiv.org/abs/2502.04153) (Shanghai AI Lab)
- [ ] [\[2502.04128\] Llasa: Scaling Train-Time and Inference-Time Compute for Llama-based Speech Synthesis](https://arxiv.org/abs/2502.04128) (HKUST)
- [ ] [\[2502.04098\] Efficient Few-Shot Continual Learning in Vision-Language Models](https://arxiv.org/abs/2502.04098) (Cambridge)
- [ ] [\[2502.04066\] Predicting Large Language Model Capabilities on Closed-Book QA Tasks Using Only Information Available Prior to Training](https://arxiv.org/abs/2502.04066) (Fudan)
- [ ] [\[2502.04043\] Probe-Free Low-Rank Activation Intervention](https://arxiv.org/abs/2502.04043) (CUHK)
- [ ] [\[2502.04040\] Leveraging Reasoning with Guidelines to Elicit and Utilize Knowledge for Enhancing Safety Alignment](https://arxiv.org/abs/2502.04040) (HKUST)
- [ ] [\[2502.03897\] UniForm: A Unified Diffusion Transformer for Audio-Video Generation](https://arxiv.org/abs/2502.03897) (NWPU)
- [ ] [\[2502.03852\] Pursuing Better Decision Boundaries for Long-Tailed Object Detection via Category Information Amount](https://arxiv.org/abs/2502.03852) (Xidian, ICLR)
- [ ] [\[2502.03804\] Understanding and Supporting Formal Email Exchange by Answering AI-Generated Questions](https://arxiv.org/abs/2502.03804) (University of Tokyo)
- [ ] [\[2502.03801\] SoK: Benchmarking Poisoning Attacks and Defenses in Federated Learning](https://arxiv.org/abs/2502.03801) (HKUST(GZ))
- [ ] [\[2502.03773\] ExpProof : Operationalizing Explanations for Confidential Models with ZKPs](https://arxiv.org/abs/2502.03773) (UCSD)
- [ ] [\[2502.03752\] PRISM: A Robust Framework for Skill-based Meta-Reinforcement Learning with Noisy Demonstrations](https://arxiv.org/abs/2502.03752) (ICML)
- [ ] [\[2502.03750\] Principal Curvatures Estimation with Applications to Single Cell Data](https://arxiv.org/abs/2502.03750) (University of Montreal)
- [ ] [\[2502.03715\] Boosting Knowledge Graph-based Recommendations through Confidence-Aware Augmentation with Large Language Models](https://arxiv.org/abs/2502.03715) (USTC)
- [ ] [\[2502.03708\] Aggregate and conquer: detecting and steering LLM concepts by combining nonlinear predictors over multiple layers](https://arxiv.org/abs/2502.03708) (UCSD)
- [ ] [\[2502.03699\] LLM Alignment as Retriever Optimization: An Information Retrieval Perspective](https://arxiv.org/abs/2502.03699) (Illinois)
- [ ] [\[2502.03688\] A Comparison of DeepSeek and Other LLMs](https://arxiv.org/abs/2502.03688) (CMU)
- [ ] [\[2502.03678\] Reflection-Window Decoding: Text Generation with Selective Refinement](https://arxiv.org/abs/2502.03678) (CMU)
- [ ] [\[2502.03669\] Unrealized Expectations: Comparing AI Methods vs Classical Algorithms for Maximum Independent Set](https://arxiv.org/abs/2502.03669) (Princeton)
- [ ] [\[2502.03622\] AdaPhish: AI-Powered Adaptive Defense and Education Resource Against Deceptive Emails](https://arxiv.org/abs/2502.03622) (University of Michigan)
- [ ] [\[2502.03568\] Code Simulation as a Proxy for High-order Tasks in Large Language Models](https://arxiv.org/abs/2502.03568) (Oxford)
- [ ] [\[2502.03502\] DC-VSR: Spatially and Temporally Consistent Video Super-Resolution with Video Diffusion Prior](https://arxiv.org/abs/2502.03502) (POSTECH)
- [ ] [\[2502.03499\] Omni-DNA: A Unified Genomic Foundation Model for Cross-Modal and Multi-Task Learning](https://arxiv.org/abs/2502.03499) (Microsoft)
- [ ] [\[2502.03482\] Can Domain Experts Rely on AI Appropriately? A Case Study on AI-Assisted Prostate Cancer MRI Diagnosis](https://arxiv.org/abs/2502.03482) (University of Michigan)

## 2025-02-06 (Thu)
- [ ] [\[2502.03369\] Learning from Active Human Involvement through Proxy Value Propagation](https://arxiv.org/abs/2502.03369) (NIPS)
- [ ] [\[2502.03368\] PalimpChat: Declarative and Interactive AI analytics](https://arxiv.org/abs/2502.03368) (MIT)
- [ ] [\[2502.03283\] SymAgent: A Neural-Symbolic Self-Learning Agent Framework for Complex Reasoning over Knowledge Graphs](https://arxiv.org/abs/2502.03283) (WHU)
- [ ] [\[2502.02883\] SensorChat: Answering Qualitative and Quantitative Questions during Long-Term Multimodal Sensor Interactions](https://arxiv.org/abs/2502.02883) (UCSD)
- [ ] [\[2502.02610\] Secure & Personalized Music-to-Video Generation via CHARCHA](https://arxiv.org/abs/2502.02610) (CMU, NIPS)
- [ ] [\[2502.03450\] A Schema-Guided Reason-while-Retrieve framework for Reasoning on Scene Graphs with Large-Language-Models (LLMs)](https://arxiv.org/abs/2502.03450) (GIT)
- [ ] [\[2502.03444\] Masked Autoencoders Are Effective Tokenizers for Diffusion Models](https://arxiv.org/abs/2502.03444) (CMU)
- [ ] [\[2502.03397\] SPRI: Aligning Large Language Models with Context-Situated Principles](https://arxiv.org/abs/2502.03397) (UT Austin)
- [ ] [\[2502.03395\] Benchmarking Time Series Forecasting Models: From Statistical Techniques to Foundation Models in Real-World Applications](https://arxiv.org/abs/2502.03395) (TUM)
- [ ] [\[2502.03383\] Transformers and Their Roles as Time Series Foundation Models](https://arxiv.org/abs/2502.03383) (HKU)
- [ ] [\[2502.03349\] Robust Autonomy Emerges from Self-Play](https://arxiv.org/abs/2502.03349) (Apple)
- [ ] [\[2502.03270\] When Pre-trained Visual Representations Fall Short: Limitations in Visuo-Motor Robot Learning](https://arxiv.org/abs/2502.03270) (University of Edinburgh)
- [ ] [\[2502.03199\] Improve Decoding Factuality by Token-wise Cross Layer Entropy of Large Language Models](https://arxiv.org/abs/2502.03199) (HIT)
- [ ] [\[2502.03147\] Scalable In-Context Learning on Tabular Data via Retrieval-Augmented Large Language Models](https://arxiv.org/abs/2502.03147) (Microsoft)
- [ ] [\[2502.03104\] Bellman Error Centering](https://arxiv.org/abs/2502.03104) (NUDT)
- [ ] [\[2502.03092\] E-3SFC: Communication-Efficient Federated Learning with Double-way Features Synthesizing](https://arxiv.org/abs/2502.03092) (Illinois)
- [ ] [\[2502.02988\] Training an LLM-as-a-Judge Model: Pipeline, Insights, and Practical Lessons](https://arxiv.org/abs/2502.02988) (Alibaba)
- [ ] [\[2502.02975\] TGB-Seq Benchmark: Challenging Temporal GNNs with Complex Sequential Dynamics](https://arxiv.org/abs/2502.02975) (University of Montreal, ICLR)
- [ ] [\[2502.02920\] Adaptive Budget Optimization for Multichannel Advertising Using Combinatorial Bandits](https://arxiv.org/abs/2502.02920) (EPFL)
- [ ] [\[2502.02917\] Interactive Symbolic Regression through Offline Reinforcement Learning: A Co-Design Framework](https://arxiv.org/abs/2502.02917) (EPFL)
- [ ] [\[2502.02912\] MobiCLR: Mobility Time Series Contrastive Learning for Urban Region Representations](https://arxiv.org/abs/2502.02912) (KAIST)
- [ ] [\[2502.02901\] Policy Abstraction and Nash Refinement in Tree-Exploiting PSRO](https://arxiv.org/abs/2502.02901) (University of Michigan)
- [ ] [\[2502.02896\] A Benchmark for the Detection of Metalinguistic Disagreements between LLMs and Knowledge Graphs](https://arxiv.org/abs/2502.02896) (UVA.NL)
- [ ] [\[2502.02871\] Position: Multimodal Large Language Models Can Significantly Advance Scientific Reasoning](https://arxiv.org/abs/2502.02871) (HKUST(GZ))
- [ ] [\[2502.02867\] Domain-Invariant Per-Frame Feature Extraction for Cross-Domain Imitation Learning with Visual Observations](https://arxiv.org/abs/2502.02867) (ICML)
- [ ] [\[2502.02863\] OceanChat: The Effect of Virtual Conversational AI Agents on Sustainable Attitude and Behavior Change](https://arxiv.org/abs/2502.02863) (MIT)
- [ ] [\[2502.02844\] Wolfpack Adversarial Attack for Robust Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2502.02844) (ICML)
- [ ] [\[2502.02834\] Task-Aware Virtual Training: Enhancing Generalization in Meta-Reinforcement Learning for Out-of-Distribution Tasks](https://arxiv.org/abs/2502.02834) (ICML)
- [ ] [\[2502.02797\] Upweighting Easy Samples in Fine-Tuning Mitigates Forgetting](https://arxiv.org/abs/2502.02797) (UT Austin)
- [ ] [\[2502.02780\] Classroom Simulacra: Building Contextual Student Generative Agents in Online Education for Learning Behavioral Simulation](https://arxiv.org/abs/2502.02780) (UCSD)
- [ ] [\[2502.02772\] Cross-Modality Embedding of Force and Language for Natural Human-Robot Communication](https://arxiv.org/abs/2502.02772) (MIT)
- [ ] [\[2502.02740\] Vision-Language Model Dialog Games for Self-Improvement](https://arxiv.org/abs/2502.02740) (Google)
- [ ] [\[2502.02732\] Peri-LN: Revisiting Layer Normalization in the Transformer Architecture](https://arxiv.org/abs/2502.02732) (KAIST)
- [ ] [\[2502.02690\] Controllable Video Generation with Provable Disentanglement](https://arxiv.org/abs/2502.02690) (CMU)
- [ ] [\[2502.02673\] MedRAX: Medical Reasoning Agent for Chest X-ray](https://arxiv.org/abs/2502.02673) (University of Toronto)
- [ ] [\[2502.02659\] A Training-Free Length Extrapolation Approach for LLMs: Greedy Attention Logit Interpolation (GALI)](https://arxiv.org/abs/2502.02659) (USyd)
- [ ] [\[2502.02617\] PolarQuant: Quantizing KV Caches with Polar Transformation](https://arxiv.org/abs/2502.02617) (KAIST)