
## 2025-02-14 (Fri)
- [ ] [\[2502.09601\] CoT-Valve: Length-Compressible Chain-of-Thought Tuning](https://arxiv.org/abs/2502.09601) (NUS)
- [ ] [\[2502.09565\] MDCrow: Automating Molecular Dynamics Workflows with Large Language Models](https://arxiv.org/abs/2502.09565) (University of Rochester)
- [ ] [\[2502.09560\] EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language Models for Vision-Driven Embodied Agents](https://arxiv.org/abs/2502.09560) (Illinois)
- [ ] [\[2502.09378\] A Deep Inverse-Mapping Model for a Flapping Robotic Wing](https://arxiv.org/abs/2502.09378) (ICLR)
- [ ] [\[2502.09224\] Order-Sorted Intensional Logic: Expressing Subtyping Polymorphism with Typing Assertions and Quantification over Concepts](https://arxiv.org/abs/2502.09224) (KU Leuven)
- [ ] [\[2502.09212\] LP-LM: No Hallucinations in Question Answering with Logic Programming](https://arxiv.org/abs/2502.09212) (Cornell)
- [ ] [\[2502.09211\] Visual Graph Question Answering with ASP and LLMs for Language Parsing](https://arxiv.org/abs/2502.09211) (ETH)
- [ ] [\[2502.09205\] Counterfactual Explanations as Plans](https://arxiv.org/abs/2502.09205) (University of Edinburgh)
- [ ] [\[2502.09053\] Game Theory Meets Large Language Models: A Systematic Survey](https://arxiv.org/abs/2502.09053) (Peking)
- [ ] [\[2502.09022\] Mechanistic Unveiling of Transformer Circuits: Self-Influence as a Key to Model Reasoning](https://arxiv.org/abs/2502.09022) (HIT)
- [ ] [\[2502.08922\] Self-Consistency of the Internal Reward Models Improves Self-Rewarding Language Models](https://arxiv.org/abs/2502.08922) (Fudan)
- [ ] [\[2502.08908\] Reinforced Large Language Model is a formal theorem prover](https://arxiv.org/abs/2502.08908) (Alibaba)
- [ ] [\[2502.08904\] MIH-TCCT: Mitigating Inconsistent Hallucinations in LLMs via Event-Driven Text-Code Cyclic Training](https://arxiv.org/abs/2502.08904) (Tsinghua)
- [ ] [\[2502.08673\] High-Throughput SAT Sampling](https://arxiv.org/abs/2502.08673) (Berkeley)
- [ ] [\[2502.09614\] DexTrack: Towards Generalizable Neural Tracking Control for Dexterous Manipulation from Human References](https://arxiv.org/abs/2502.09614) (ICLR)
- [ ] [\[2502.09604\] SelfCite: Self-Supervised Alignment for Context Attribution in Large Language Models](https://arxiv.org/abs/2502.09604) (MIT)
- [ ] [\[2502.09511\] Diffusion Models for Molecules: A Survey of Methods and Tasks](https://arxiv.org/abs/2502.09511) (IA CAS)
- [ ] [\[2502.09487\] Objective quantification of mood states using large language models](https://arxiv.org/abs/2502.09487) (UCL)
- [ ] [\[2502.09471\] Wholly-WOOD: Wholly Leveraging Diversified-quality Labels for Weakly-supervised Oriented Object Detection](https://arxiv.org/abs/2502.09471) (SJTU, TPAMI)
- [ ] [\[2502.09341\] Neural Spatiotemporal Point Processes: Trends and Challenges](https://arxiv.org/abs/2502.09341) (GIT)
- [ ] [\[2502.09307\] When the LM misunderstood the human chuckled: Analyzing garden path effects in humans and language models](https://arxiv.org/abs/2502.09307) (Tel Aviv)
- [ ] [\[2502.09271\] LiSA: Leveraging Link Recommender to Attack Graph Neural Networks via Subgraph Injection](https://arxiv.org/abs/2502.09271) (HKUST(GZ))
- [ ] [\[2502.09254\] AnomalyGFM: Graph Foundation Model for Zero/Few-shot Anomaly Detection](https://arxiv.org/abs/2502.09254) (UTS)
- [ ] [\[2502.09220\] Graphical Conditions for the Existence, Unicity and Number of Regular Models](https://arxiv.org/abs/2502.09220) (Inria)
- [ ] [\[2502.09218\] Data2Concept2Text: An Explainable Multilingual Framework for Data Analysis Narration](https://arxiv.org/abs/2502.09218) (Michigan State University)
- [ ] [\[2502.09125\] Automatic Pruning via Structured Lasso with Class-wise Information](https://arxiv.org/abs/2502.09125) (ETH)
- [ ] [\[2502.09122\] Improving Deep Regression with Tightness](https://arxiv.org/abs/2502.09122) (NUS, ICLR)
- [ ] [\[2502.09104\] One-shot Federated Learning Methods: A Practical Guide](https://arxiv.org/abs/2502.09104) (HKUST)
- [ ] [\[2502.09083\] Show Me the Work: Fact-Checkers' Requirements for Explainable Automated Fact-Checking](https://arxiv.org/abs/2502.09083) (University of Copenhagen)
- [ ] [\[2502.09082\] CoSER: Coordinating LLM-Based Persona Simulation of Established Roles](https://arxiv.org/abs/2502.09082) (Fudan)
- [ ] [\[2502.09046\] Criteria-Aware Graph Filtering: Extremely Fast Yet Accurate Multi-Criteria Recommendation](https://arxiv.org/abs/2502.09046) (KAIST)
- [ ] [\[2502.09039\] Large Images are Gaussians: High-Quality Large Image Representation with Levels of 2D Gaussian Splatting](https://arxiv.org/abs/2502.09039) (HKU)
- [ ] [\[2502.09020\] EventSTR: A Benchmark Dataset and Baselines for Event Stream based Scene Text Recognition](https://arxiv.org/abs/2502.09020) (Peking)
- [ ] [\[2502.08987\] Neural Force Field: Learning Generalized Physical Representation from a Few Examples](https://arxiv.org/abs/2502.08987) (Peking)
- [ ] [\[2502.08969\] SkyRover: A Modular Simulator for Cross-Domain Pathfinding](https://arxiv.org/abs/2502.08969) (Tongji)
- [ ] [\[2502.08958\] Biologically Plausible Brain Graph Transformer](https://arxiv.org/abs/2502.08958) (ICLR)
- [ ] [\[2502.08946\] The Stochastic Parrot on LLM's Shoulder: A Summative Assessment of Physical Concept Understanding](https://arxiv.org/abs/2502.08946) (JHU)
- [ ] [\[2502.08943\] Beyond the Singular: The Essential Role of Multiple Generations in Effective Benchmark Evaluation and Analysis](https://arxiv.org/abs/2502.08943) (Meta)
- [ ] [\[2502.08942\] Language in the Flow of Time: Time-Series-Paired Texts Weaved into a Unified Temporal Narrative](https://arxiv.org/abs/2502.08942) (Illinois)
- [ ] [\[2502.08941\] Analysis of Off-Policy $n$-Step TD-Learning with Linear Function Approximation](https://arxiv.org/abs/2502.08941) (KAIST)
- [ ] [\[2502.08898\] Learning in Strategic Queuing Systems with Small Buffers](https://arxiv.org/abs/2502.08898) (Berkeley)
- [ ] [\[2502.08896\] Communication is All You Need: Persuasion Dataset Construction via Multi-LLM Communication](https://arxiv.org/abs/2502.08896) (GIT)
- [ ] [\[2502.08884\] ShapeLib: designing a library of procedural 3D shape abstractions with Large Language Models](https://arxiv.org/abs/2502.08884) (UCL)
- [ ] [\[2502.08869\] Harnessing Vision Models for Time Series Analysis: A Survey](https://arxiv.org/abs/2502.08869) (Illinois)
- [ ] [\[2502.08792\] Auction Design using Value Prediction with Hallucinations](https://arxiv.org/abs/2502.08792) (NYU)
- [ ] [\[2502.08769\] Cluster and Predict Latents Patches for Improved Masked Image Modeling](https://arxiv.org/abs/2502.08769) (Meta)
- [ ] [\[2502.08696\] Scalable Discrete Diffusion Samplers: Combinatorial Optimization and Statistical Physics](https://arxiv.org/abs/2502.08696) (ICLR)
- [ ] [\[2502.08691\] AgentSociety: Large-Scale Simulation of LLM-Driven Generative Agents Advances Understanding of Human Behaviors and Society](https://arxiv.org/abs/2502.08691) (Tsinghua)
- [ ] [\[2502.08680\] Mathematical Reasoning in Large Language Models: Assessing Logical and Arithmetic Errors across Wide Numerical Ranges](https://arxiv.org/abs/2502.08680) (NYU)
- [ ] [\[2502.08661\] Few-shot_LLM_Synthetic_Data_with_Distribution_Matching](https://arxiv.org/abs/2502.08661) (Tsinghua)
- [ ] [\[2502.08658\] Analyzable Parameters Dominated Vehicle Platoon Dynamics Modeling and Analysis: A Physics-Encoded Deep Learning Approach](https://arxiv.org/abs/2502.08658) (Tsinghua)
- [ ] [\[2502.08657\] Refining Positive and Toxic Samples for Dual Safety Self-Alignment of LLMs with Minimal Human Interventions](https://arxiv.org/abs/2502.08657) (BUPT)
- [ ] [\[2502.06772\] ReasonFlux: Hierarchical LLM Reasoning via Scaling Thought Templates](https://arxiv.org/abs/2502.06772) (Princeton)

## 2025-02-13 (Thu)
- [ ] [\[2502.08547\] Representation Learning to Advance Multi-institutional Studies with Electronic Health Record Data](https://arxiv.org/abs/2502.08547) (Harvard)
- [ ] [\[2502.08336\] Salience-Invariant Consistent Policy Learning for Generalization in Visual Reinforcement Learning](https://arxiv.org/abs/2502.08336) (IA CAS)
- [ ] [\[2502.08235\] The Danger of Overthinking: Examining the Reasoning-Action Dilemma in Agentic Tasks](https://arxiv.org/abs/2502.08235) (Berkeley)
- [ ] [\[2502.07982\] Deep Semantic Graph Learning via LLM based Node Enhancement](https://arxiv.org/abs/2502.07982) (UCSD)
- [ ] [\[2502.07957\] Intrinsic Bias is Predicted by Pretraining Data and Correlates with Downstream Performance in Vision-Language Encoders](https://arxiv.org/abs/2502.07957) (CMU)
- [ ] [\[2502.08644\] Rhythmic sharing: A bio-inspired paradigm for zero-shot adaptation and learning in neural networks](https://arxiv.org/abs/2502.08644) (UMD)
- [ ] [\[2502.08606\] Distillation Scaling Laws](https://arxiv.org/abs/2502.08606) (Apple)
- [ ] [\[2502.08605\] CurvGAD: Leveraging Curvature for Enhanced Graph Anomaly Detection](https://arxiv.org/abs/2502.08605) (CMU)
- [ ] [\[2502.08597\] Learning in Markets with Heterogeneous Agents: Dynamics and Survival of Bayesian vs. No-Regret Learners](https://arxiv.org/abs/2502.08597) (Cornell)
- [ ] [\[2502.08586\] Commercial LLM Agents Are Already Vulnerable to Simple Yet Dangerous Attacks](https://arxiv.org/abs/2502.08586) (Columbia University)
- [ ] [\[2502.08574\] COAST: Intelligent Time-Adaptive Neural Operators](https://arxiv.org/abs/2502.08574) (Yale)
- [ ] [\[2502.08554\] Fostering Appropriate Reliance on Large Language Models: The Role of Explanations, Sources, and Inconsistencies](https://arxiv.org/abs/2502.08554) (Princeton)
- [ ] [\[2502.08550\] LLMs can implicitly learn from mistakes in-context](https://arxiv.org/abs/2502.08550) (Imperial)
- [ ] [\[2502.08518\] FedMHO: Heterogeneous One-Shot Federated Learning Towards Resource-Constrained Edge Devices](https://arxiv.org/abs/2502.08518) (MBZUAI)
- [ ] [\[2502.08512\] Measuring Diversity in Synthetic Datasets](https://arxiv.org/abs/2502.08512) (SYSU)
- [ ] [\[2502.08438\] Composite Sketch+Text Queries for Retrieving Objects with Elusive Names and Complex Interactions](https://arxiv.org/abs/2502.08438) (Microsoft)
- [ ] [\[2502.08436\] From Haystack to Needle: Label Space Reduction for Zero-shot Classification](https://arxiv.org/abs/2502.08436) (ICML)
- [ ] [\[2502.08340\] Hierarchical Learning-based Graph Partition for Large-scale Vehicle Routing Problems](https://arxiv.org/abs/2502.08340) (HKUST)
- [ ] [\[2502.08317\] Mitigating Hallucinations in Multimodal Spatial Relations through Constraint-Aware Prompting](https://arxiv.org/abs/2502.08317) (University of Rochester)
- [ ] [\[2502.08282\] Individualised Treatment Effects Estimation with Composite Treatments and Composite Outcomes](https://arxiv.org/abs/2502.08282) (Oxford)
- [ ] [\[2502.08279\] What Is That Talk About? A Video-to-Text Summarization Dataset for Scientific Presentations](https://arxiv.org/abs/2502.08279) (Cambridge)
- [ ] [\[2502.08226\] TRISHUL: Towards Region Identification and Screen Hierarchy Understanding for Large VLM based GUI Agents](https://arxiv.org/abs/2502.08226) (ICML)
- [ ] [\[2502.08211\] Quality over Quantity: Boosting Data Efficiency Through Ensembled Multimodal Data Curation](https://arxiv.org/abs/2502.08211) (SJTU)
- [ ] [\[2502.08161\] MixDec Sampling: A Soft Link-based Sampling Method of Graph Neural Network for Recommendation](https://arxiv.org/abs/2502.08161) (Tsinghua)
- [ ] [\[2502.08160\] Vertical Federated Learning in Practice: The Good, the Bad, and the Ugly](https://arxiv.org/abs/2502.08160) (NUS)
- [ ] [\[2502.08150\] Force Matching with Relativistic Constraints: A Physics-Inspired Approach to Stable and Efficient Generative Modeling](https://arxiv.org/abs/2502.08150) (HKU)
- [ ] [\[2502.08145\] Democratizing AI: Open-source Scalable LLM Training on GPU-based Supercomputers](https://arxiv.org/abs/2502.08145) (UMD)
- [ ] [\[2502.08101\] Rethinking Tokenized Graph Transformers for Node Classification](https://arxiv.org/abs/2502.08101) (HUST)
- [ ] [\[2502.08092\] GCoT: Chain-of-Thought Prompt Learning for Graphs](https://arxiv.org/abs/2502.08092) (USTC)
- [ ] [\[2502.08056\] Cognify: Supercharging Gen-AI Workflows With Hierarchical Autotuning](https://arxiv.org/abs/2502.08056) (UCSD)
- [ ] [\[2502.08021\] Model Selection for Off-policy Evaluation: New Algorithms and Experimental Protocol](https://arxiv.org/abs/2502.08021) (Illinois)
- [ ] [\[2502.08020\] Speculate, then Collaborate: Fusing Knowledge of Language Models during Decoding](https://arxiv.org/abs/2502.08020) (UMD)
- [ ] [\[2502.07980\] CIRCUIT: A Benchmark for Circuit Interpretation and Reasoning Capabilities of LLMs](https://arxiv.org/abs/2502.07980) (MIT)
- [ ] [\[2502.07963\] Caught in the Web of Words: Do LLMs Fall for Spin in Medical Literature?](https://arxiv.org/abs/2502.07963) (UT Austin)
- [ ] [\[2502.07864\] TransMLA: Multi-Head Latent Attention Is All You Need](https://arxiv.org/abs/2502.07864) (Peking)
- [ ] [\[2502.07862\] ADMN: A Layer-Wise Adaptive Multimodal Network for Dynamic Input Noise and Compute Resources](https://arxiv.org/abs/2502.07862) (UCLA)
- [ ] [\[2502.07861\] BalanceKV: KV Cache Compression through Discrepancy Theory](https://arxiv.org/abs/2502.07861) (KAIST)
- [ ] [\[2502.07856\] MRS: A Fast Sampler for Mean Reverting Diffusion based on ODE and SDE Solvers](https://arxiv.org/abs/2502.07856) (Alibaba, ICLR)
- [ ] [\[2502.07855\] Vision-Language Models for Edge Networks: A Comprehensive Survey](https://arxiv.org/abs/2502.07855) (MBZUAI)
- [ ] [\[2502.07849\] Understanding Classifier-Free Guidance: High-Dimensional Theory and Non-Linear Generalizations](https://arxiv.org/abs/2502.07849) (Meta)
- [ ] [\[2502.07832\] SHARP: Accelerating Language Model Inference by SHaring Adjacent layers with Recovery Parameters](https://arxiv.org/abs/2502.07832) (UCSD)
- [ ] [\[2502.07830\] Captured by Captions: On Memorization and its Mitigation in CLIP Models](https://arxiv.org/abs/2502.07830) (ICLR)
- [ ] [\[2502.07827\] Implicit Language Models are RNNs: Balancing Parallelization and Expressivity](https://arxiv.org/abs/2502.07827) (Microsoft)
- [ ] [\[2502.07825\] Pre-Trained Video Generative Models as World Simulators](https://arxiv.org/abs/2502.07825) (HKUST)
- [ ] [\[2502.07821\] Amnesia as a Catalyst for Enhancing Black Box Pixel Attacks in Image Classification and Object Detection](https://arxiv.org/abs/2502.07821) (NIPS)
- [ ] [\[2502.07814\] Satellite Observations Guided Diffusion Model for Accurate Meteorological States at Arbitrary Resolution](https://arxiv.org/abs/2502.07814) (CUHK)
- [ ] [\[2502.07794\] Regulatory Science Innovation for Generative AI and Large Language Models in Health and Medicine: A Global Call for Action](https://arxiv.org/abs/2502.07794) (NUS)

## 2025-02-12 (Wed)
- [ ] [\[2502.07709\] MAGELLAN: Metacognitive predictions of learning progress guide autotelic LLM agents in large goal spaces](https://arxiv.org/abs/2502.07709) (Inria)
- [ ] [\[2502.07663\] Human Decision-making is Susceptible to AI-driven Manipulation](https://arxiv.org/abs/2502.07663) (HKU)
- [ ] [\[2502.07503\] Harnessing Language's Fractal Geometry with Recursive Inference Scaling](https://arxiv.org/abs/2502.07503) (Google)
- [ ] [\[2502.07423\] Towards a Formal Theory of the Need for Competence via Computational Intrinsic Motivation](https://arxiv.org/abs/2502.07423) (Imperial)
- [ ] [\[2502.07374\] LLMs Can Easily Learn to Reason from Demonstrations Structure, not content, is what matters!](https://arxiv.org/abs/2502.07374) (Berkeley)
- [ ] [\[2502.07202\] Monte Carlo Tree Diffusion for System 2 Planning](https://arxiv.org/abs/2502.07202) (KAIST)
- [ ] [\[2502.07191\] Bag of Tricks for Inference-time Computation of LLM Reasoning](https://arxiv.org/abs/2502.07191) (HKUST)
- [ ] [\[2502.07190\] Understanding LLMs' Fluid Intelligence Deficiency: An Analysis of the ARC Task](https://arxiv.org/abs/2502.07190) (HKUST)
- [ ] [\[2502.07132\] Interactive Data Harmonization with LLM Agents](https://arxiv.org/abs/2502.07132) (NYU)
- [ ] [\[2502.07752\] Towards Efficient Optimizer Design for LLM via Structured Fisher Approximation with a Low-Rank Extension](https://arxiv.org/abs/2502.07752) (Microsoft)
- [ ] [\[2502.07737\] Next Block Prediction: Video Generation via Semi-Auto-Regressive Modeling](https://arxiv.org/abs/2502.07737) (Peking)
- [ ] [\[2502.07586\] We Can't Understand AI Using our Existing Vocabulary](https://arxiv.org/abs/2502.07586) (Google)
- [ ] [\[2502.07563\] LASP-2: Rethinking Sequence Parallelism for Linear Attention and Its Hybrid](https://arxiv.org/abs/2502.07563) (CUHK)
- [ ] [\[2502.07549\] HGTUL: A Hypergraph-based Model For Trajectory User Linking](https://arxiv.org/abs/2502.07549) (BUPT)
- [ ] [\[2502.07516\] The Devil is in the Prompts: De-Identification Traces Enhance Memorization Risks in Synthetic Chest X-Ray Generation](https://arxiv.org/abs/2502.07516) (University of Edinburgh)
- [ ] [\[2502.07408\] No Data, No Optimization: A Lightweight Method To Disrupt Neural Networks With Sign-Flips](https://arxiv.org/abs/2502.07408) (NVIDIA)
- [ ] [\[2502.07351\] Multi-Task-oriented Nighttime Haze Imaging Enhancer for Vision-driven Measurement Systems](https://arxiv.org/abs/2502.07351) (UESTC)
- [ ] [\[2502.07316\] CodeI/O: Condensing Reasoning Patterns via Code Input-Output Prediction](https://arxiv.org/abs/2502.07316) (HKUST)
- [ ] [\[2502.07279\] Exploratory Diffusion Policy for Unsupervised Reinforcement Learning](https://arxiv.org/abs/2502.07279) (Tsinghua)
- [ ] [\[2502.07276\] Dataset Ownership Verification in Contrastive Pre-trained Models](https://arxiv.org/abs/2502.07276) (ICLR)
- [ ] [\[2502.07274\] Cost-Efficient Continual Learning with Sufficient Exemplar Memory](https://arxiv.org/abs/2502.07274) (NYU)
- [ ] [\[2502.07250\] NARCE: A Mamba-Based Neural Algorithmic Reasoner Framework for Online Complex Event Detection](https://arxiv.org/abs/2502.07250) (UCLA)
- [ ] [\[2502.07244\] Linear Transformers as VAR Models: Aligning Autoregressive Attention Mechanisms with Autoregressive Forecasting](https://arxiv.org/abs/2502.07244) (GIT)
- [ ] [\[2502.07243\] Vevo: Controllable Zero-Shot Voice Imitation with Self-Supervised Disentanglement](https://arxiv.org/abs/2502.07243) (ICLR)
- [ ] [\[2502.07238\] Diffusion Suction Grasping with Large-Scale Parcel Dataset](https://arxiv.org/abs/2502.07238) (Tsinghua)
- [ ] [\[2502.07218\] LUNAR: LLM Unlearning via Neural Activation Redirection](https://arxiv.org/abs/2502.07218) (Cambridge)
- [ ] [\[2502.07216\] SparseFormer: Detecting Objects in HRW Shots via Sparse Vision Transformer](https://arxiv.org/abs/2502.07216) (ACMMM)
- [ ] [\[2502.07184\] Refine Knowledge of Large Language Models via Adaptive Contrastive Learning](https://arxiv.org/abs/2502.07184) (Tsinghua, ICLR)
- [ ] [\[2502.07154\] Rethinking Fine-Tuning when Scaling Test-Time Compute: Limiting Confidence Improves Mathematical Reasoning](https://arxiv.org/abs/2502.07154) (University of Michigan)
- [ ] [\[2502.07153\] Feature Importance Depends on Properties of the Data: Towards Choosing the Correct Explanations for Your Data and Decision Trees based Models](https://arxiv.org/abs/2502.07153) (Imperial)
- [ ] [\[2502.07115\] Online Scheduling for LLM Inference with KV Cache Constraints](https://arxiv.org/abs/2502.07115) (MIT)
- [ ] [\[2502.07088\] Kernels of Selfhood: GPT-4o shows humanlike patterns of cognitive consistency moderated by free choice](https://arxiv.org/abs/2502.07088) (BU)
- [ ] [\[2502.07071\] TRADES: Generating Realistic Market Simulations with Diffusion Models](https://arxiv.org/abs/2502.07071) (TUM)
- [ ] [\[2502.07064\] Contextual Thompson Sampling via Generation of Missing Data](https://arxiv.org/abs/2502.07064) (Imperial)
- [ ] [\[2502.07022\] AIMS.au: A Dataset for the Analysis of Modern Slavery Countermeasures in Corporate Statements](https://arxiv.org/abs/2502.07022) (ICLR)
- [ ] [\[2502.07001\] From Image to Video: An Empirical Study of Diffusion Representations](https://arxiv.org/abs/2502.07001) (Google)
- [ ] [\[2502.06994\] SyncMind: Measuring Agent Out-of-Sync Recovery in Collaborative Software Engineering](https://arxiv.org/abs/2502.06994) (Illinois)
- [ ] [\[2502.06919\] Select before Act: Spatially Decoupled Action Repetition for Continuous Control](https://arxiv.org/abs/2502.06919) (ICLR)
- [ ] [\[2502.06914\] UniZyme: A Unified Protein Cleavage Site Predictor Enhanced with Enzyme Active-Site Knowledge](https://arxiv.org/abs/2502.06914) (HKUST(GZ))
- [ ] [\[2502.06911\] Foundation Models for Anomaly Detection: Vision and Challenges](https://arxiv.org/abs/2502.06911) (MIT)
- [ ] [\[2502.06910\] TimeKAN: KAN-based Frequency Decomposition Learning Architecture for Long-term Time Series Forecasting](https://arxiv.org/abs/2502.06910) (Shanghai AI Lab)
- [ ] [\[2502.06909\] Satisfaction-Aware Incentive Scheme for Federated Learning in Industrial Metaverse: DRL-Based Stackbelberg Game Approach](https://arxiv.org/abs/2502.06909) (NTU)
- [ ] [\[2502.06905\] Lightweight Dataset Pruning without Full Training via Example Difficulty and Prediction Uncertainty](https://arxiv.org/abs/2502.06905) (KAIST)
- [ ] [\[2502.06901\] Enabling Autoregressive Models to Fill In Masked Tokens](https://arxiv.org/abs/2502.06901) (UCLA)
- [ ] [\[2502.06898\] Large Language Models for In-File Vulnerability Localization Can Be "Lost in the End"](https://arxiv.org/abs/2502.06898) (ETH)
- [ ] [\[2502.06892\] Certifying Language Model Robustness with Fuzzed Randomized Smoothing: An Efficient Defense Against Backdoor Attacks](https://arxiv.org/abs/2502.06892) (ICLR)
- [ ] [\[2502.06888\] Klotski: Efficient Mixture-of-Expert Inference via Expert-Aware Multi-Batch Pipeline](https://arxiv.org/abs/2502.06888) (SYSU)
- [ ] [\[2502.06887\] Gradient Based Method for the Fusion of Lattice Quantizers](https://arxiv.org/abs/2502.06887) (Peking)
- [ ] [\[2502.06885\] Topological derivative approach for deep neural network architecture adaptation](https://arxiv.org/abs/2502.06885) (UT Austin)
- [ ] [\[2502.06882\] Multi-Agent Simulator Drives Language Models for Legal Intensive Interaction](https://arxiv.org/abs/2502.06882) (Fudan)
- [ ] [\[2502.06875\] Beyond Vision: How Large Language Models Interpret Facial Expressions from Valence-Arousal Values](https://arxiv.org/abs/2502.06875) (Cambridge)
- [ ] [\[2502.06874\] Group Reasoning Emission Estimation Networks](https://arxiv.org/abs/2502.06874) (USyd)
- [ ] [\[2502.06872\] Towards Trustworthy Retrieval Augmented Generation for Large Language Models: A Survey](https://arxiv.org/abs/2502.06872) (PolyU)
- [ ] [\[2502.06864\] Knowledge Graph-Guided Retrieval Augmented Generation](https://arxiv.org/abs/2502.06864) (NJU)
- [ ] [\[2502.06863\] BF-GAN: Development of an AI-driven Bubbly Flow Image Generation Model Using Generative Adversarial Networks](https://arxiv.org/abs/2502.06863) (University of Tokyo)
- [ ] [\[2502.06861\] Design Considerations in Offline Preference-based RL](https://arxiv.org/abs/2502.06861) (Google)
- [ ] [\[2502.06857\] Gemstones: A Model Suite for Multi-Faceted Scaling Laws](https://arxiv.org/abs/2502.06857) (UMD)
- [ ] [\[2502.06848\] Transfer learning in Scalable Graph Neural Network for Improved Physical Simulation](https://arxiv.org/abs/2502.06848) (Peking)
- [ ] [\[2502.06846\] Prot2Chat: Protein LLM with Early Fusion of Sequence and Structure](https://arxiv.org/abs/2502.06846) (Peking)
- [ ] [\[2502.06834\] A Unified Knowledge-Distillation and Semi-Supervised Learning Framework to Improve Industrial Ads Delivery Systems](https://arxiv.org/abs/2502.06834) (Meta)
- [ ] [\[2502.06832\] Optimizing Robustness and Accuracy in Mixture of Experts: A Dual-Model Approach](https://arxiv.org/abs/2502.06832) (ICML)
- [ ] [\[2502.06827\] Learning to Synthesize Compatible Fashion Items Using Semantic Alignment and Collocation Classification: An Outfit Generation Framework](https://arxiv.org/abs/2502.06827) (HIT)
- [ ] [\[2502.06808\] On the Benefits of Attribute-Driven Graph Domain Adaptation](https://arxiv.org/abs/2502.06808) (Michigan State University, ICLR)
- [ ] [\[2502.06802\] Solving the Content Gap in Roblox Game Recommendations: LLM-Based Profile Generation and Reranking](https://arxiv.org/abs/2502.06802) (Columbia University)

## 2025-02-11 (Tue)
- [ ] [\[2502.06060\] Training Language Models for Social Deduction with Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2502.06060) (Stanford)
- [ ] [\[2502.05934\] Barriers and Pathways to Human-AI Alignment: A Game-Theoretic Approach](https://arxiv.org/abs/2502.05934) (CMU)
- [ ] [\[2502.05632\] Amorphous Fortress Online: Collaboratively Designing Open-Ended Multi-Agent AI and Game Environments](https://arxiv.org/abs/2502.05632) (NYU)
- [ ] [\[2502.05537\] Sequential Stochastic Combinatorial Optimization Using Hierarchal Reinforcement Learning](https://arxiv.org/abs/2502.05537) (UCLA)
- [ ] [\[2502.05442\] The Odyssey of the Fittest: Can Agents Survive and Still Be Good?](https://arxiv.org/abs/2502.05442) (UT Austin)
- [ ] [\[2502.06784\] RelGNN: Composite Message Passing for Relational Deep Learning](https://arxiv.org/abs/2502.06784) (Stanford)
- [ ] [\[2502.06779\] KARST: Multi-Kernel Kronecker Adaptation with Re-Scaling Transmission for Visual Classification](https://arxiv.org/abs/2502.06779) (HKUST)
- [ ] [\[2502.06776\] Towards Internet-Scale Training For Agents](https://arxiv.org/abs/2502.06776) (CMU)
- [ ] [\[2502.06751\] What makes a good feedforward computational graph?](https://arxiv.org/abs/2502.06751) (Google)
- [ ] [\[2502.06742\] Gradient Multi-Normalization for Stateless and Scalable LLM Training](https://arxiv.org/abs/2502.06742) (Microsoft)
- [ ] [\[2502.06733\] Dynamic Loss-Based Sample Reweighting for Improved Large Language Model Pretraining](https://arxiv.org/abs/2502.06733) (TUM, ICLR)
- [ ] [\[2502.06693\] Recent Advances, Applications and Open Challenges in Machine Learning for Health: Reflections from Research Roundtables at ML4H 2024 Symposium](https://arxiv.org/abs/2502.06693) (Illinois)
- [ ] [\[2502.06669\] Boosting Self-Efficacy and Performance of Large Language Models via Verbal Efficacy Stimulations](https://arxiv.org/abs/2502.06669) (UCAS)
- [ ] [\[2502.06635\] Steel-LLM:From Scratch to Open Source -- A Personal Journey in Building a Chinese-Centric LLM](https://arxiv.org/abs/2502.06635) (BUPT)
- [ ] [\[2502.06633\] Combining Large Language Models with Static Analyzers for Code Review Generation](https://arxiv.org/abs/2502.06633) (University of Montreal)
- [ ] [\[2502.06589\] Hephaestus: Improving Fundamental Agent Capabilities of Large Language Models through Continual Pre-Training](https://arxiv.org/abs/2502.06589) (GIT)
- [ ] [\[2502.06577\] The Minimal Search Space for Conditional Causal Bandits](https://arxiv.org/abs/2502.06577) (ICML)
- [ ] [\[2502.06516\] Boost-and-Skip: A Simple Guidance-Free Diffusion for Minority Generation](https://arxiv.org/abs/2502.06516) (KAIST)
- [ ] [\[2502.06490\] Recent Advances in Discrete Speech Tokens: A Review](https://arxiv.org/abs/2502.06490) (SJTU)
- [ ] [\[2502.06472\] KARMA: Leveraging Multi-Agent LLMs for Automated Knowledge Graph Enrichment](https://arxiv.org/abs/2502.06472) (Peking)
- [ ] [\[2502.06453\] MATH-Perturb: Benchmarking LLMs' Math Reasoning Abilities against Hard Perturbations](https://arxiv.org/abs/2502.06453) (Princeton)
- [ ] [\[2502.06432\] Prompt-SID: Learning Structural Representation Prompt via Latent Diffusion for Single-Image Denoising](https://arxiv.org/abs/2502.06432) (Tsinghua)
- [ ] [\[2502.06424\] CS-SHAP: Extending SHAP to Cyclic-Spectral Domain for Better Interpretability of Intelligent Fault Diagnosis](https://arxiv.org/abs/2502.06424) (SJTU)
- [ ] [\[2502.06415\] Systematic Outliers in Large Language Models](https://arxiv.org/abs/2502.06415) (IA CAS, ICLR)
- [ ] [\[2502.06348\] AiRacleX: Automated Detection of Price Oracle Manipulations via LLM-Driven Knowledge Mining and Prompt Generation](https://arxiv.org/abs/2502.06348) (A*STAR,)
- [ ] [\[2502.06327\] Prompt-Driven Continual Graph Learning](https://arxiv.org/abs/2502.06327) (BIT)
- [ ] [\[2502.06314\] From Pixels to Components: Eigenvector Masking for Visual Representation Learning](https://arxiv.org/abs/2502.06314) (ETH)
- [ ] [\[2502.06282\] Jakiro: Boosting Speculative Decoding with Decoupled Multi-Head via MoE](https://arxiv.org/abs/2502.06282) (XJTU)
- [ ] [\[2502.06274\] HODDI: A Dataset of High-Order Drug-Drug Interactions for Computational Pharmacovigilance](https://arxiv.org/abs/2502.06274) (Harvard)
- [ ] [\[2502.06215\] LessLeak-Bench: A First Investigation of Data Leakage in LLMs Across 83 Software Engineering Benchmarks](https://arxiv.org/abs/2502.06215) (WHU)
- [ ] [\[2502.06192\] Right Time to Learn:Promoting Generalization via Bio-inspired Spacing Effect in Knowledge Distillation](https://arxiv.org/abs/2502.06192) (Tsinghua)
- [ ] [\[2502.06167\] Universal Approximation of Visual Autoregressive Transformers](https://arxiv.org/abs/2502.06167) (HKU)
- [ ] [\[2502.06146\] Guided Exploration for Efficient Relational Model Learning](https://arxiv.org/abs/2502.06146) (MIT)
- [ ] [\[2502.06136\] Graph Neural Networks at a Fraction](https://arxiv.org/abs/2502.06136) (Microsoft)
- [ ] [\[2502.06134\] Integrating Sequence and Image Modeling in Irregular Medical Time Series Through Self-Supervised Learning](https://arxiv.org/abs/2502.06134) (ZJU)
- [ ] [\[2502.06117\] Revisiting Dynamic Graph Clustering via Matrix Factorization](https://arxiv.org/abs/2502.06117) (University of Tokyo)
- [ ] [\[2502.06106\] Circuit-tuning: A Mechanistic Approach for Identifying Parameter Redundancy and Fine-tuning Neural Networks](https://arxiv.org/abs/2502.06106) (BUPT)
- [ ] [\[2502.06096\] Post-detection inference for sequential changepoint localization](https://arxiv.org/abs/2502.06096) (CMU)
- [ ] [\[2502.06084\] Physics-Guided Foundation Model for Scientific Discovery: An Application to Aquatic Science](https://arxiv.org/abs/2502.06084) (UMD)
- [ ] [\[2502.06065\] Benchmarking Prompt Sensitivity in Large Language Models](https://arxiv.org/abs/2502.06065) (University of Toronto)
- [ ] [\[2502.06051\] Nearly Optimal Sample Complexity of Offline KL-Regularized Contextual Bandits under Single-Policy Concentrability](https://arxiv.org/abs/2502.06051) (UCLA)
- [ ] [\[2502.06038\] Provably Overwhelming Transformer Models with Designed Inputs](https://arxiv.org/abs/2502.06038) (UMD)
- [ ] [\[2502.05949\] Verifying Proportionality in Temporal Voting](https://arxiv.org/abs/2502.05949) (NUS)
- [ ] [\[2502.05932\] Skill Expansion and Composition in Parameter Space](https://arxiv.org/abs/2502.05932) (NUDT, ICLR)
- [ ] [\[2502.05892\] A Distributional Perspective on Word Learning in Neural Language Models](https://arxiv.org/abs/2502.05892) (UCSD)
- [ ] [\[2502.05887\] MTPChat: A Multimodal Time-Aware Persona Dataset for Conversational Agents](https://arxiv.org/abs/2502.05887) (UTS)
- [ ] [\[2502.05874\] MMGDreamer: Mixed-Modality Graph for Geometry-Controllable 3D Indoor Scene Generation](https://arxiv.org/abs/2502.05874) (Peking)
- [ ] [\[2502.05835\] Contrastive Representation Distillation via Multi-Scale Feature Decoupling](https://arxiv.org/abs/2502.05835) (Fudan)
- [ ] [\[2502.05832\] Compressing Model with Few Class-Imbalance Samples: An Out-of-Distribution Expedition](https://arxiv.org/abs/2502.05832) (NJU)
- [ ] [\[2502.05795\] The Curse of Depth in Large Language Models](https://arxiv.org/abs/2502.05795) (Oxford)
- [ ] [\[2502.05783\] WatchGuardian: Enabling User-Defined Personalized Just-in-Time Intervention on Smartwatch](https://arxiv.org/abs/2502.05783) (Columbia University)
- [ ] [\[2502.05777\] Predictive Crash Analytics for Traffic Safety using Deep Learning](https://arxiv.org/abs/2502.05777) (UT Austin)
- [ ] [\[2502.05772\] Effective Black-Box Multi-Faceted Attacks Breach Vision Large Language Model Guardrails](https://arxiv.org/abs/2502.05772) (CUHK)
- [ ] [\[2502.05749\] UniDB: A Unified Diffusion Bridge Framework via Stochastic Optimal Control](https://arxiv.org/abs/2502.05749) (ShanghaiTech)
- [ ] [\[2502.05740\] RECOVER: Designing a Large Language Model-based Remote Patient Monitoring System for Postoperative Gastrointestinal Cancer Care](https://arxiv.org/abs/2502.05740) (JHU)
- [ ] [\[2502.05739\] Mitigating Sensitive Information Leakage in LLMs4Code through Machine Unlearning](https://arxiv.org/abs/2502.05739) (BUPT)
- [ ] [\[2502.05713\] 4D VQ-GAN: Synthesising Medical Scans at Any Time Point for Personalised Disease Progression Modelling of Idiopathic Pulmonary Fibrosis](https://arxiv.org/abs/2502.05713) (UCL)
- [ ] [\[2502.05694\] Zero-Shot End-to-End Relation Extraction in Chinese: A Comparative Study of Gemini, LLaMA and ChatGPT](https://arxiv.org/abs/2502.05694) (UVA.NL)
- [ ] [\[2502.05574\] Event Stream-based Visual Object Tracking: HDETrack V2 and A High-Definition Benchmark](https://arxiv.org/abs/2502.05574) (Peking, CVPR)
- [ ] [\[2502.05567\] ATLAS: Autoformalizing Theorems through Lifting, Augmentation, and Synthesis of Data](https://arxiv.org/abs/2502.05567) (SJTU)
- [ ] [\[2502.05564\] TabICL: A Tabular Foundation Model for In-Context Learning on Large Data](https://arxiv.org/abs/2502.05564) (Inria)
- [ ] [\[2502.05547\] Dual Defense: Enhancing Privacy and Mitigating Poisoning Attacks in Federated Learning](https://arxiv.org/abs/2502.05547) (NIPS)
- [ ] [\[2502.05500\] Vision-Ultrasound Robotic System based on Deep Learning for Gas and Arc Hazard Detection in Manufacturing](https://arxiv.org/abs/2502.05500) (University of Michigan)
- [ ] [\[2502.05498\] Riemannian Manifold Learning for Stackelberg Games with Neural Flow Representations](https://arxiv.org/abs/2502.05498) (TUM)
- [ ] [\[2502.05467\] Position: LLMs Can be Good Tutors in Foreign Language Education](https://arxiv.org/abs/2502.05467) (Tsinghua)
- [ ] [\[2502.05431\] APE: Faster and Longer Context-Augmented Generation via Adaptive Parallel Encoding](https://arxiv.org/abs/2502.05431) (ICLR)
- [ ] [\[2502.05424\] SAMGPT: Text-free Graph Foundation Model for Multi-domain Pre-training and Cross-domain Adaptation](https://arxiv.org/abs/2502.05424) (USTC)
- [ ] [\[2502.05407\] The Complexity of Learning Sparse Superposed Features with Feedback](https://arxiv.org/abs/2502.05407) (UCSD)
- [ ] [\[2502.05344\] RAG-Verus: Repository-Level Program Verification with LLMs using Retrieval Augmented Generation](https://arxiv.org/abs/2502.05344) (University of Toronto)
- [ ] [\[2502.05310\] Oracular Programming: A Modular Foundation for Building LLM-Enabled Software](https://arxiv.org/abs/2502.05310) (CMU)
- [ ] [\[2502.05252\] GSM-Infinite: How Do Your LLMs Behave over Infinitely Increasing Context Length and Reasoning Complexity?](https://arxiv.org/abs/2502.05252) (Meta)
- [ ] [\[2502.05242\] SEER: Self-Explainability Enhancement of Large Language Models' Representations](https://arxiv.org/abs/2502.05242) (Shanghai AI Lab)
- [ ] [\[2502.05236\] Koel-TTS: Enhancing LLM based Speech Generation with Preference Alignment and Classifier Free Guidance](https://arxiv.org/abs/2502.05236) (NVIDIA)
- [ ] [\[2502.05234\] Optimizing Temperature for Language Models with Multi-Sample Inference](https://arxiv.org/abs/2502.05234) (CMU)
- [ ] [\[2502.05232\] Aligner-Encoders: Self-Attention Transformers Can Be Self-Transducers](https://arxiv.org/abs/2502.05232) (Google)
- [ ] [\[2502.05228\] Multi-Objective Mobile Damped Wave Algorithm (MOMDWA): A Novel Approach For Quantum System Control](https://arxiv.org/abs/2502.05228) (Columbia University)
- [ ] [\[2502.05227\] Robotouille: An Asynchronous Planning Benchmark for LLM Agents](https://arxiv.org/abs/2502.05227) (Cornell)
- [ ] [\[2502.05218\] FactorGCL: A Hypergraph-Based Factor Model with Temporal Residual Contrastive Learning for Stock Returns Prediction](https://arxiv.org/abs/2502.05218) (Tsinghua)
- [ ] [\[2502.05214\] CoRPA: Adversarial Image Generation for Chest X-rays Using Concept Vector Perturbations and Generative Models](https://arxiv.org/abs/2502.05214) (University of Edinburgh)
- [ ] [\[2502.05213\] DERMARK: A Dynamic, Efficient and Robust Multi-bit Watermark for Large Language Models](https://arxiv.org/abs/2502.05213) (USTC)
- [ ] [\[2502.05209\] Model Tampering Attacks Enable More Rigorous Evaluations of LLM Capabilities](https://arxiv.org/abs/2502.05209) (MIT)
- [ ] [\[2502.05206\] Safety at Scale: A Comprehensive Survey of Large Model Safety](https://arxiv.org/abs/2502.05206) (Fudan)
- [ ] [\[2410.13772\] Is Prior-Free Black-Box Non-Stationary Reinforcement Learning Feasible?](https://arxiv.org/abs/2410.13772) (Illinois)
- [ ] [\[2301.06943\] Self-supervised Domain Adaptation for Breaking the Limits of Low-quality Fundus Image Quality Enhancement](https://arxiv.org/abs/2301.06943) (Alibaba)

## 2025-02-10 (Mon)
- [ ] [\[2502.05007\] Analyzing Advanced AI Systems Against Definitions of Life and Consciousness](https://arxiv.org/abs/2502.05007) (MIT)
- [ ] [\[2502.04780\] SiriuS: Self-improving Multi-agent Systems via Bootstrapped Reasoning](https://arxiv.org/abs/2502.04780) (Stanford)
- [ ] [\[2502.04671\] ${\rm P{\small ROOF}W{\small ALA}}$: Multilingual Proof Data Synthesis and Theorem-Proving](https://arxiv.org/abs/2502.04671) (UT Austin)
- [ ] [\[2502.04567\] Preference Optimization via Contrastive Divergence: Your Reward Model is Secretly an NLL Estimator](https://arxiv.org/abs/2502.04567) (AWS)
- [ ] [\[2502.04512\] Safety is Essential for Responsible Open-Ended Systems](https://arxiv.org/abs/2502.04512) (Microsoft)
- [ ] [\[2502.04371\] PerPO: Perceptual Preference Optimization via Discriminative Rewarding](https://arxiv.org/abs/2502.04371) (UCAS)
- [ ] [\[2502.05172\] Joint MoE Scaling Laws: Mixture of Experts Can Be Memory Efficient](https://arxiv.org/abs/2502.05172) (UW)
- [ ] [\[2502.05151\] Transforming Science with Large Language Models: A Survey on AI-assisted Scientific Discovery, Experimentation, Content Generation, and Evaluation](https://arxiv.org/abs/2502.05151) (University of TÃ¼bingen)
- [ ] [\[2502.05147\] LP-DETR: Layer-wise Progressive Relations for Object Detection](https://arxiv.org/abs/2502.05147) (NYU)
- [ ] [\[2502.05111\] Flexible and Efficient Grammar-Constrained Decoding](https://arxiv.org/abs/2502.05111) (UCSD)
- [ ] [\[2502.05087\] Mitigating Unintended Memorization with LoRA in Federated Learning for LLMs](https://arxiv.org/abs/2502.05087) (EPFL)
- [ ] [\[2502.05085\] Causality can systematically address the monsters under the bench(marks)](https://arxiv.org/abs/2502.05085) (MPI)
- [ ] [\[2502.05084\] ChallengeMe: An Adversarial Learning-enabled Text Summarization Framework](https://arxiv.org/abs/2502.05084) (NYU)
- [ ] [\[2502.05060\] Preference-aware compensation policies for crowdsourced on-demand services](https://arxiv.org/abs/2502.05060) (TUM)
- [ ] [\[2502.05017\] Bridging Voting and Deliberation with Algorithms: Field Insights from vTaiwan and Kultur Komitee](https://arxiv.org/abs/2502.05017) (ETH)
- [ ] [\[2502.05001\] A New Paradigm in Tuning Learned Indexes: A Reinforcement Learning Enhanced Approach](https://arxiv.org/abs/2502.05001) (Cambridge)
- [ ] [\[2502.04951\] The Rising Threat to Emerging AI-Powered Search Engines](https://arxiv.org/abs/2502.04951) (HKUST(GZ))
- [ ] [\[2502.04935\] Conformal Prediction for Electricity Price Forecasting in the Day-Ahead and Real-Time Balancing Market](https://arxiv.org/abs/2502.04935) (University of Edinburgh)
- [ ] [\[2502.04923\] Cached Multi-Lora Composition for Multi-Concept Image Generation](https://arxiv.org/abs/2502.04923) (ICLR)
- [ ] [\[2502.04903\] Wavelet-Assisted Multi-Frequency Attention Network for Pansharpening](https://arxiv.org/abs/2502.04903) (IA CAS)
- [ ] [\[2502.04899\] Unified Approaches in Self-Supervised Event Stream Modeling: Progress and Prospects](https://arxiv.org/abs/2502.04899) (Microsoft)
- [ ] [\[2502.04878\] Sparse Autoencoders Do Not Find Canonical Units of Analysis](https://arxiv.org/abs/2502.04878) (ICLR)
- [ ] [\[2502.04794\] MedMimic: Physician-Inspired Multimodal Fusion for Early Diagnosis of Fever of Unknown Origin](https://arxiv.org/abs/2502.04794) (University of Tokyo)
- [ ] [\[2502.04790\] S$^2$-MAD: Breaking the Token Barrier to Enhance Multi-Agent Debate Efficiency](https://arxiv.org/abs/2502.04790) (HIT)
- [ ] [\[2502.04778\] Behavior-Regularized Diffusion Policy Optimization for Offline Reinforcement Learning](https://arxiv.org/abs/2502.04778) (NJU)
- [ ] [\[2502.04759\] Enhancing Phishing Email Identification with Large Language Models](https://arxiv.org/abs/2502.04759) (GIT)
- [ ] [\[2502.04747\] Every Software as an Agent: Blueprint and Case Study](https://arxiv.org/abs/2502.04747) (BUPT)
- [ ] [\[2502.04725\] Can Diffusion Models Learn Hidden Inter-Feature Rules Behind Images?](https://arxiv.org/abs/2502.04725) (HKU)
- [ ] [\[2502.04670\] CCS: Controllable and Constrained Sampling with Diffusion Models via Initial Noise Perturbation](https://arxiv.org/abs/2502.04670) (University of Michigan)
- [ ] [\[2502.04669\] A Comprehensive Review on Noise Control of Diffusion Model](https://arxiv.org/abs/2502.04669) (Columbia University)
- [ ] [\[2502.04658\] Shifting Attention to You: Personalized Brain-Inspired AI Models](https://arxiv.org/abs/2502.04658) (Vanderbilt University)
- [ ] [\[2502.04646\] Importance Sampling via Score-based Generative Models](https://arxiv.org/abs/2502.04646) (UT Austin)
- [ ] [\[2502.04645\] Cross-Encoder Rediscovers a Semantic Variant of BM25](https://arxiv.org/abs/2502.04645) (University of TÃ¼bingen)
- [ ] [\[2502.04638\] Learning Street View Representations with Spatiotemporal Contrast](https://arxiv.org/abs/2502.04638) (Peking)
- [ ] [\[2502.04636\] An Empirical Study of Code Obfuscation Practices in the Google Play Store](https://arxiv.org/abs/2502.04636) (USyd)
- [ ] [\[2502.04602\] Extracting and Understanding the Superficial Knowledge in Alignment](https://arxiv.org/abs/2502.04602) (UT Austin)
- [ ] [\[2502.04573\] Zero-shot Meta-learning for Tabular Prediction Tasks with Adversarially Pre-trained Transformer](https://arxiv.org/abs/2502.04573) (Berkeley)
- [ ] [\[2502.04515\] MedGNN: Towards Multi-resolution Spatiotemporal Graph Learning for Medical Time Series Classification](https://arxiv.org/abs/2502.04515) (BIT)
- [ ] [\[2502.04488\] Building A Unified AI-centric Language System: analysis, framework and future work](https://arxiv.org/abs/2502.04488) (Harvard)
- [ ] [\[2502.04476\] ADIFF: Explaining audio difference using natural language](https://arxiv.org/abs/2502.04476) (ICLR)
- [ ] [\[2502.04475\] Augmented Conditioning Is Enough For Effective Training Image Generation](https://arxiv.org/abs/2502.04475) (UT Austin)
- [ ] [\[2502.04469\] No Images, No Problem: Retaining Knowledge in Continual VQA with Questions-Only Memory](https://arxiv.org/abs/2502.04469) (Inria)
- [ ] [\[2502.04420\] KVTuner: Sensitivity-Aware Layer-wise Mixed Precision KV Cache Quantization for Efficient and Nearly Lossless LLM Inference](https://arxiv.org/abs/2502.04420) (CUHK)
- [ ] [\[2502.04419\] Understanding and Mitigating the Bias Inheritance in LLM-based Data Augmentation on Downstream Tasks](https://arxiv.org/abs/2502.04419) (CMU)
- [ ] [\[2502.04417\] NeuralMOVES: A lightweight and microscopic vehicle emission estimation model based on reverse engineering and surrogate learning](https://arxiv.org/abs/2502.04417) (MIT)
- [ ] [\[2502.04413\] MedRAG: Enhancing Retrieval-augmented Generation with Knowledge Graph-Elicited Reasoning for Healthcare Copilot](https://arxiv.org/abs/2502.04413) (NTU)
- [ ] [\[2502.04412\] Decoder-Only LLMs are Better Controllers for Diffusion Models](https://arxiv.org/abs/2502.04412) (SYSU)
- [ ] [\[2502.04407\] Illuminating Spaces: Deep Reinforcement Learning and Laser-Wall Partitioning for Architectural Layout Generation](https://arxiv.org/abs/2502.04407) (ETH)
- [ ] [\[2502.04406\] Calibrated Physics-Informed Uncertainty Quantification](https://arxiv.org/abs/2502.04406) (UCL)
- [ ] [\[2502.04399\] Online Location Planning for AI-Defined Vehicles: Optimizing Joint Tasks of Order Serving and Spatio-Temporal Heterogeneous Model Fine-Tuning](https://arxiv.org/abs/2502.04399) (NTU)
- [ ] [\[2502.04394\] DECT: Harnessing LLM-assisted Fine-Grained Linguistic Knowledge and Label-Switched and Label-Preserved Data Generation for Diagnosis of Alzheimer's Disease](https://arxiv.org/abs/2502.04394) (CUHK)
- [ ] [\[2502.04392\] Division-of-Thoughts: Harnessing Hybrid Language Model Synergy for Efficient On-Device Agents](https://arxiv.org/abs/2502.04392) (Tsinghua)
- [ ] [\[2502.04386\] Towards Fair Medical AI: Adversarial Debiasing of 3D CT Foundation Embeddings](https://arxiv.org/abs/2502.04386) (JHU)
- [ ] [\[2502.04385\] TexLiDAR: Automated Text Understanding for Panoramic LiDAR Data](https://arxiv.org/abs/2502.04385) (Tel Aviv)
- [ ] [\[2502.04382\] Sparse Autoencoders for Hypothesis Generation](https://arxiv.org/abs/2502.04382) (Berkeley)
- [ ] [\[2502.04380\] Diversity as a Reward: Fine-Tuning LLMs on a Mixture of Domain-Undetermined Data](https://arxiv.org/abs/2502.04380) (SYSU)
- [ ] [\[2502.04359\] Exploring Spatial Language Grounding Through Referring Expressions](https://arxiv.org/abs/2502.04359) (UCSD)
- [ ] [\[2502.04357\] Reusing Embeddings: Reproducible Reward Model Research in Large Language Model Alignment without GPUs](https://arxiv.org/abs/2502.04357) (Cambridge)
- [ ] [\[2502.04354\] Reviving The Classics: Active Reward Modeling in Large Language Model Alignment](https://arxiv.org/abs/2502.04354) (MIT)
- [ ] [\[2502.04352\] Investigating the Robustness of Deductive Reasoning with Large Language Models](https://arxiv.org/abs/2502.04352) (UVA.NL)
- [ ] [\[2502.04350\] CodeSteer: Symbolic-Augmented Language Models via Code/Text Guidance](https://arxiv.org/abs/2502.04350) (Harvard)
- [ ] [\[2502.04345\] JingFang: A Traditional Chinese Medicine Large Language Model of Expert-Level Medical Diagnosis and Syndrome Differentiation-Based Treatment](https://arxiv.org/abs/2502.04345) (BUPT)

## 2025-02-07 (Fri)
- [ ] [\[2502.03948\] Enhancing Online Learning Efficiency Through Heterogeneous Resource Integration with a Multi-Agent RAG System](https://arxiv.org/abs/2502.03948) (TUM)
- [ ] [\[2502.03544\] Gold-medalist Performance in Solving Olympiad Geometry with AlphaGeometry2](https://arxiv.org/abs/2502.03544) (Google)
- [ ] [\[2502.04326\] WorldSense: Evaluating Real-world Omnimodal Understanding for Multimodal LLMs](https://arxiv.org/abs/2502.04326) (SJTU)
- [ ] [\[2502.04308\] HOG-Diff: Higher-Order Guided Diffusion for Graph Generation](https://arxiv.org/abs/2502.04308) (Imperial)
- [ ] [\[2502.04268\] Point2RBox-v2: Rethinking Point-supervised Oriented Object Detection with Spatial Layout Among Instances](https://arxiv.org/abs/2502.04268) (Tsinghua)
- [ ] [\[2502.04263\] Cross the Gap: Exposing the Intra-modal Misalignment in CLIP via Modality Inversion](https://arxiv.org/abs/2502.04263) (ICLR)
- [ ] [\[2502.04242\] A Theoretical Framework for Data Efficient Multi-Source Transfer Learning Based on Cram¨¦r-Rao Bound](https://arxiv.org/abs/2502.04242) (Tsinghua)
- [ ] [\[2502.04229\] Dark Distillation: Backdooring Distilled Datasets without Accessing Raw Data](https://arxiv.org/abs/2502.04229) (A*STAR,)
- [ ] [\[2502.04194\] The Best Instruction-Tuning Data are Those That Fit](https://arxiv.org/abs/2502.04194) (Illinois)
- [ ] [\[2502.04153\] UltraIF: Advancing Instruction Following from the Wild](https://arxiv.org/abs/2502.04153) (Shanghai AI Lab)
- [ ] [\[2502.04128\] Llasa: Scaling Train-Time and Inference-Time Compute for Llama-based Speech Synthesis](https://arxiv.org/abs/2502.04128) (HKUST)
- [ ] [\[2502.04098\] Efficient Few-Shot Continual Learning in Vision-Language Models](https://arxiv.org/abs/2502.04098) (Cambridge)
- [ ] [\[2502.04066\] Predicting Large Language Model Capabilities on Closed-Book QA Tasks Using Only Information Available Prior to Training](https://arxiv.org/abs/2502.04066) (Fudan)
- [ ] [\[2502.04043\] Probe-Free Low-Rank Activation Intervention](https://arxiv.org/abs/2502.04043) (CUHK)
- [ ] [\[2502.04040\] Leveraging Reasoning with Guidelines to Elicit and Utilize Knowledge for Enhancing Safety Alignment](https://arxiv.org/abs/2502.04040) (HKUST)
- [ ] [\[2502.03897\] UniForm: A Unified Diffusion Transformer for Audio-Video Generation](https://arxiv.org/abs/2502.03897) (NWPU)
- [ ] [\[2502.03852\] Pursuing Better Decision Boundaries for Long-Tailed Object Detection via Category Information Amount](https://arxiv.org/abs/2502.03852) (Xidian, ICLR)
- [ ] [\[2502.03804\] Understanding and Supporting Formal Email Exchange by Answering AI-Generated Questions](https://arxiv.org/abs/2502.03804) (University of Tokyo)
- [ ] [\[2502.03801\] SoK: Benchmarking Poisoning Attacks and Defenses in Federated Learning](https://arxiv.org/abs/2502.03801) (HKUST(GZ))
- [ ] [\[2502.03773\] ExpProof : Operationalizing Explanations for Confidential Models with ZKPs](https://arxiv.org/abs/2502.03773) (UCSD)
- [ ] [\[2502.03752\] PRISM: A Robust Framework for Skill-based Meta-Reinforcement Learning with Noisy Demonstrations](https://arxiv.org/abs/2502.03752) (ICML)
- [ ] [\[2502.03750\] Principal Curvatures Estimation with Applications to Single Cell Data](https://arxiv.org/abs/2502.03750) (University of Montreal)
- [ ] [\[2502.03715\] Boosting Knowledge Graph-based Recommendations through Confidence-Aware Augmentation with Large Language Models](https://arxiv.org/abs/2502.03715) (USTC)
- [ ] [\[2502.03708\] Aggregate and conquer: detecting and steering LLM concepts by combining nonlinear predictors over multiple layers](https://arxiv.org/abs/2502.03708) (UCSD)
- [ ] [\[2502.03699\] LLM Alignment as Retriever Optimization: An Information Retrieval Perspective](https://arxiv.org/abs/2502.03699) (Illinois)
- [ ] [\[2502.03688\] A Comparison of DeepSeek and Other LLMs](https://arxiv.org/abs/2502.03688) (CMU)
- [ ] [\[2502.03678\] Reflection-Window Decoding: Text Generation with Selective Refinement](https://arxiv.org/abs/2502.03678) (CMU)
- [ ] [\[2502.03669\] Unrealized Expectations: Comparing AI Methods vs Classical Algorithms for Maximum Independent Set](https://arxiv.org/abs/2502.03669) (Princeton)
- [ ] [\[2502.03622\] AdaPhish: AI-Powered Adaptive Defense and Education Resource Against Deceptive Emails](https://arxiv.org/abs/2502.03622) (University of Michigan)
- [ ] [\[2502.03568\] Code Simulation as a Proxy for High-order Tasks in Large Language Models](https://arxiv.org/abs/2502.03568) (Oxford)
- [ ] [\[2502.03502\] DC-VSR: Spatially and Temporally Consistent Video Super-Resolution with Video Diffusion Prior](https://arxiv.org/abs/2502.03502) (POSTECH)
- [ ] [\[2502.03499\] Omni-DNA: A Unified Genomic Foundation Model for Cross-Modal and Multi-Task Learning](https://arxiv.org/abs/2502.03499) (Microsoft)
- [ ] [\[2502.03482\] Can Domain Experts Rely on AI Appropriately? A Case Study on AI-Assisted Prostate Cancer MRI Diagnosis](https://arxiv.org/abs/2502.03482) (University of Michigan)

## 2025-02-06 (Thu)
- [ ] [\[2502.03369\] Learning from Active Human Involvement through Proxy Value Propagation](https://arxiv.org/abs/2502.03369) (NIPS)
- [ ] [\[2502.03368\] PalimpChat: Declarative and Interactive AI analytics](https://arxiv.org/abs/2502.03368) (MIT)
- [ ] [\[2502.03283\] SymAgent: A Neural-Symbolic Self-Learning Agent Framework for Complex Reasoning over Knowledge Graphs](https://arxiv.org/abs/2502.03283) (WHU)
- [ ] [\[2502.02883\] SensorChat: Answering Qualitative and Quantitative Questions during Long-Term Multimodal Sensor Interactions](https://arxiv.org/abs/2502.02883) (UCSD)
- [ ] [\[2502.02610\] Secure & Personalized Music-to-Video Generation via CHARCHA](https://arxiv.org/abs/2502.02610) (CMU, NIPS)
- [ ] [\[2502.03450\] A Schema-Guided Reason-while-Retrieve framework for Reasoning on Scene Graphs with Large-Language-Models (LLMs)](https://arxiv.org/abs/2502.03450) (GIT)
- [ ] [\[2502.03444\] Masked Autoencoders Are Effective Tokenizers for Diffusion Models](https://arxiv.org/abs/2502.03444) (CMU)
- [ ] [\[2502.03397\] SPRI: Aligning Large Language Models with Context-Situated Principles](https://arxiv.org/abs/2502.03397) (UT Austin)
- [ ] [\[2502.03395\] Benchmarking Time Series Forecasting Models: From Statistical Techniques to Foundation Models in Real-World Applications](https://arxiv.org/abs/2502.03395) (TUM)
- [ ] [\[2502.03383\] Transformers and Their Roles as Time Series Foundation Models](https://arxiv.org/abs/2502.03383) (HKU)
- [ ] [\[2502.03349\] Robust Autonomy Emerges from Self-Play](https://arxiv.org/abs/2502.03349) (Apple)
- [ ] [\[2502.03270\] When Pre-trained Visual Representations Fall Short: Limitations in Visuo-Motor Robot Learning](https://arxiv.org/abs/2502.03270) (University of Edinburgh)
- [ ] [\[2502.03199\] Improve Decoding Factuality by Token-wise Cross Layer Entropy of Large Language Models](https://arxiv.org/abs/2502.03199) (HIT)
- [ ] [\[2502.03147\] Scalable In-Context Learning on Tabular Data via Retrieval-Augmented Large Language Models](https://arxiv.org/abs/2502.03147) (Microsoft)
- [ ] [\[2502.03104\] Bellman Error Centering](https://arxiv.org/abs/2502.03104) (NUDT)
- [ ] [\[2502.03092\] E-3SFC: Communication-Efficient Federated Learning with Double-way Features Synthesizing](https://arxiv.org/abs/2502.03092) (Illinois)
- [ ] [\[2502.02988\] Training an LLM-as-a-Judge Model: Pipeline, Insights, and Practical Lessons](https://arxiv.org/abs/2502.02988) (Alibaba)
- [ ] [\[2502.02975\] TGB-Seq Benchmark: Challenging Temporal GNNs with Complex Sequential Dynamics](https://arxiv.org/abs/2502.02975) (University of Montreal, ICLR)
- [ ] [\[2502.02920\] Adaptive Budget Optimization for Multichannel Advertising Using Combinatorial Bandits](https://arxiv.org/abs/2502.02920) (EPFL)
- [ ] [\[2502.02917\] Interactive Symbolic Regression through Offline Reinforcement Learning: A Co-Design Framework](https://arxiv.org/abs/2502.02917) (EPFL)
- [ ] [\[2502.02912\] MobiCLR: Mobility Time Series Contrastive Learning for Urban Region Representations](https://arxiv.org/abs/2502.02912) (KAIST)
- [ ] [\[2502.02901\] Policy Abstraction and Nash Refinement in Tree-Exploiting PSRO](https://arxiv.org/abs/2502.02901) (University of Michigan)
- [ ] [\[2502.02896\] A Benchmark for the Detection of Metalinguistic Disagreements between LLMs and Knowledge Graphs](https://arxiv.org/abs/2502.02896) (UVA.NL)
- [ ] [\[2502.02871\] Position: Multimodal Large Language Models Can Significantly Advance Scientific Reasoning](https://arxiv.org/abs/2502.02871) (HKUST(GZ))
- [ ] [\[2502.02867\] Domain-Invariant Per-Frame Feature Extraction for Cross-Domain Imitation Learning with Visual Observations](https://arxiv.org/abs/2502.02867) (ICML)
- [ ] [\[2502.02863\] OceanChat: The Effect of Virtual Conversational AI Agents on Sustainable Attitude and Behavior Change](https://arxiv.org/abs/2502.02863) (MIT)
- [ ] [\[2502.02844\] Wolfpack Adversarial Attack for Robust Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2502.02844) (ICML)
- [ ] [\[2502.02834\] Task-Aware Virtual Training: Enhancing Generalization in Meta-Reinforcement Learning for Out-of-Distribution Tasks](https://arxiv.org/abs/2502.02834) (ICML)
- [ ] [\[2502.02797\] Upweighting Easy Samples in Fine-Tuning Mitigates Forgetting](https://arxiv.org/abs/2502.02797) (UT Austin)
- [ ] [\[2502.02780\] Classroom Simulacra: Building Contextual Student Generative Agents in Online Education for Learning Behavioral Simulation](https://arxiv.org/abs/2502.02780) (UCSD)
- [ ] [\[2502.02772\] Cross-Modality Embedding of Force and Language for Natural Human-Robot Communication](https://arxiv.org/abs/2502.02772) (MIT)
- [ ] [\[2502.02740\] Vision-Language Model Dialog Games for Self-Improvement](https://arxiv.org/abs/2502.02740) (Google)
- [ ] [\[2502.02732\] Peri-LN: Revisiting Layer Normalization in the Transformer Architecture](https://arxiv.org/abs/2502.02732) (KAIST)
- [ ] [\[2502.02690\] Controllable Video Generation with Provable Disentanglement](https://arxiv.org/abs/2502.02690) (CMU)
- [ ] [\[2502.02673\] MedRAX: Medical Reasoning Agent for Chest X-ray](https://arxiv.org/abs/2502.02673) (University of Toronto)
- [ ] [\[2502.02659\] A Training-Free Length Extrapolation Approach for LLMs: Greedy Attention Logit Interpolation (GALI)](https://arxiv.org/abs/2502.02659) (USyd)
- [ ] [\[2502.02617\] PolarQuant: Quantizing KV Caches with Polar Transformation](https://arxiv.org/abs/2502.02617) (KAIST)