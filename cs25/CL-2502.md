
## 2025-02-21 (Fri)
- [ ] [\[2502.14860\] Aligning LLMs to Ask Good Questions A Case Study in Clinical Reasoning](https://arxiv.org/abs/2502.14860) (CMU)
- [ ] [\[2502.14791\] Rapid Word Learning Through Meta In-Context Learning](https://arxiv.org/abs/2502.14791) (Peking)
- [ ] [\[2502.14780\] ReVision: A Dataset and Baseline VLM for Privacy-Preserving Task-Oriented Visual Instruction Rewriting](https://arxiv.org/abs/2502.14780) (Yale)
- [ ] [\[2502.14778\] Harnessing PDF Data for Improving Japanese Large Multimodal Models](https://arxiv.org/abs/2502.14778) (University of Tokyo)
- [ ] [\[2502.14776\] SurveyX: Academic Survey Automation via Large Language Models](https://arxiv.org/abs/2502.14776) (USyd)
- [ ] [\[2502.14709\] Data-Efficient Pretraining with Group-Level Data Influence Modeling](https://arxiv.org/abs/2502.14709) (CMU)
- [ ] [\[2502.14644\] LIFT: Improving Long Context Understanding of Large Language Models through Long Input Fine-Tuning](https://arxiv.org/abs/2502.14644) (Peking)
- [ ] [\[2502.14642\] How Far are LLMs from Being Our Digital Twins? A Benchmark for Persona-Based Behavior Chain Simulation](https://arxiv.org/abs/2502.14642) (Peking)
- [ ] [\[2502.14638\] NAVIG: Natural Language-guided Analysis with Vision Language Models for Image Geo-localization](https://arxiv.org/abs/2502.14638) (Tsinghua)
- [ ] [\[2502.14613\] Behavioral Analysis of Information Salience in Large Language Models](https://arxiv.org/abs/2502.14613) (UT Austin)
- [ ] [\[2502.14541\] LLM-based User Profile Management for Recommender System](https://arxiv.org/abs/2502.14541) (KAIST)
- [ ] [\[2502.14529\] CORBA: Contagious Recursive Blocking Attacks on Multi-Agent Systems Based on Large Language Models](https://arxiv.org/abs/2502.14529) (USTC)
- [ ] [\[2502.14499\] MLGym: A New Framework and Benchmark for Advancing AI Research Agents](https://arxiv.org/abs/2502.14499) (Meta)
- [ ] [\[2502.14497\] Stories that (are) Move(d by) Markets: A Causal Exploration of Market Shocks and Semantic Shifts across Different Partisan Groups](https://arxiv.org/abs/2502.14497) (Oxford)
- [ ] [\[2502.14496\] Enhancing Language Multi-Agent Learning with Multi-Agent Credit Re-Assignment for Interactive Environment Generalization](https://arxiv.org/abs/2502.14496) (HKUST)
- [ ] [\[2502.14445\] PredictaBoard: Benchmarking LLM Score Predictability](https://arxiv.org/abs/2502.14445) (Cambridge)
- [ ] [\[2502.14427\] Token-Level Density-Based Uncertainty Quantification Methods for Eliciting Truthfulness of Large Language Models](https://arxiv.org/abs/2502.14427) (MBZUAI)
- [ ] [\[2502.14376\] A Similarity Paradigm Through Textual Regularization Without Forgetting](https://arxiv.org/abs/2502.14376) (SJTU)
- [ ] [\[2502.14356\] Full-Step-DPO: Self-Supervised Preference Optimization with Step-wise Rewards for Mathematical Reasoning](https://arxiv.org/abs/2502.14356) (NTU)
- [ ] [\[2502.14340\] Earlier Tokens Contribute More: Learning Direct Preference Optimization From Temporal Decay Perspective](https://arxiv.org/abs/2502.14340) (ICLR)
- [ ] [\[2502.14317\] ParallelComp: Parallel Long-Context Compressor for Length Extrapolation](https://arxiv.org/abs/2502.14317) (HKU)
- [ ] [\[2502.14315\] Unveiling Cultural Blind Spots: Analyzing the Limitations of mLLMs in Procedural Text Comprehension](https://arxiv.org/abs/2502.14315) (MBZUAI)
- [ ] [\[2502.14302\] MedHallu: A Comprehensive Benchmark for Detecting Medical Hallucinations in Large Language Models](https://arxiv.org/abs/2502.14302) (UT Austin)
- [ ] [\[2502.14285\] Vulnerability of Text-to-Image Models to Prompt Template Stealing: A Differential Evolution Approach](https://arxiv.org/abs/2502.14285) (USyd)
- [ ] [\[2502.14272\] Capturing Nuanced Preferences: Preference-Aligned Distillation for Small Language Models](https://arxiv.org/abs/2502.14272) (HKUST(GZ))
- [ ] [\[2502.14255\] Effects of Prompt Length on Domain-specific Tasks for Large Language Models](https://arxiv.org/abs/2502.14255) (GIT)
- [ ] [\[2502.14204\] On-the-fly Preference Alignment via Principle-Guided Decoding](https://arxiv.org/abs/2502.14204) (USTC, ICLR)
- [ ] [\[2502.14132\] Can Community Notes Replace Professional Fact-Checkers?](https://arxiv.org/abs/2502.14132) (University of Copenhagen)
- [ ] [\[2502.14127\] Which of These Best Describes Multiple Choice Evaluation with LLMs? A) Forced B) Flawed C) Fixable D) All of the Above](https://arxiv.org/abs/2502.14127) (UMD)
- [ ] [\[2502.14122\] Benchmarking LLMs for Political Science: A United Nations Perspective](https://arxiv.org/abs/2502.14122) (Meta)
- [ ] [\[2502.14083\] Are Rules Meant to be Broken? Understanding Multilingual Moral Reasoning as a Computational Pipeline with UniMoral](https://arxiv.org/abs/2502.14083) (University of Michigan)
- [ ] [\[2502.14051\] RocketKV: Accelerating Long-Context LLM Inference via Two-Stage KV Cache Compression](https://arxiv.org/abs/2502.14051) (GIT)
- [ ] [\[2502.14050\] Diversity-driven Data Selection for Language Model Tuning through Sparse Autoencoder](https://arxiv.org/abs/2502.14050) (Meta)
- [ ] [\[2502.14037\] DiffSampling: Enhancing Diversity and Accuracy in Neural Text Generation](https://arxiv.org/abs/2502.14037) (UCL)
- [ ] [\[2502.14008\] MaskPrune: Mask-based LLM Pruning for Layer-wise Uniform Structures](https://arxiv.org/abs/2502.14008) (NJU)
- [ ] [\[2502.14628\] PEARL: Towards Permutation-Resilient LLMs](https://arxiv.org/abs/2502.14628) (ICLR)
- [ ] [\[2502.14560\] Less is More: Improving LLM Alignment via Preference Data Selection](https://arxiv.org/abs/2502.14560) (USTC)
- [ ] [\[2502.14486\] How Jailbreak Defenses Work and Ensemble? A Mechanistic Investigation](https://arxiv.org/abs/2502.14486) (Fudan)
- [ ] [\[2502.14403\] A Macro- and Micro-Hierarchical Transfer Learning Framework for Cross-Domain Fake News Detection](https://arxiv.org/abs/2502.14403) (MIT)
- [ ] [\[2502.14354\] Self-Improvement Towards Pareto Optimality: Mitigating Preference Conflicts in Multi-Objective Alignment](https://arxiv.org/abs/2502.14354) (USTC)
- [ ] [\[2502.14321\] Beyond Self-Talk: A Communication-Centric Survey of LLM-Based Multi-Agent Systems](https://arxiv.org/abs/2502.14321) (BUPT)
- [ ] [\[2502.14311\] The Impact and Feasibility of Self-Confidence Shaping for AI-Assisted Decision-Making](https://arxiv.org/abs/2502.14311) (University of Tokyo)
- [ ] [\[2502.14276\] STeCa: Step-level Trajectory Calibration for LLM Agent Learning](https://arxiv.org/abs/2502.14276) (PolyU)
- [ ] [\[2502.14074\] Investigating Non-Transitivity in LLM-as-a-Judge](https://arxiv.org/abs/2502.14074) (UCL)
- [ ] [\[2502.14010\] Which Attention Heads Matter for In-Context Learning?](https://arxiv.org/abs/2502.14010) (Berkeley)

## 2025-02-20 (Thu)
- [ ] [\[2502.13954\] Latent Distribution Decoupling: A Probabilistic Framework for Uncertainty-Aware Multimodal Emotion Recognition](https://arxiv.org/abs/2502.13954) (Chongqing)
- [ ] [\[2502.13946\] Why Safeguarded Ships Run Aground? Aligned Large Language Models' Safety Mechanisms Tend to Be Anchored in The Template Region](https://arxiv.org/abs/2502.13946) (ZJU)
- [ ] [\[2502.13925\] Beyond Single Frames: Can LMMs Comprehend Temporal and Contextual Narratives in Image Sequences?](https://arxiv.org/abs/2502.13925) (Peking)
- [ ] [\[2502.13922\] LongPO: Long Context Self-Evolution of Large Language Models through Short-to-Long Preference Optimization](https://arxiv.org/abs/2502.13922) (Alibaba, ICLR)
- [ ] [\[2502.13913\] How Do LLMs Perform Two-Hop Reasoning in Context?](https://arxiv.org/abs/2502.13913) (Berkeley)
- [ ] [\[2502.13881\] PSCon: Toward Conversational Product Search](https://arxiv.org/abs/2502.13881) (UVA.NL)
- [ ] [\[2502.13725\] Adapting Large Language Models for Time Series Modeling via a Novel Parameter-efficient Adaptation Method](https://arxiv.org/abs/2502.13725) (NTU)
- [ ] [\[2502.13723\] Direct Value Optimization: Improving Chain-of-Thought Reasoning in LLMs with Refined Values](https://arxiv.org/abs/2502.13723) (UCL)
- [ ] [\[2502.13685\] MoM: Linear Sequence Modeling with Mixture-of-Memories](https://arxiv.org/abs/2502.13685) (CUHK)
- [ ] [\[2502.13674\] SCOPE: A Self-supervised Framework for Improving Faithfulness in Conditional Text Generation](https://arxiv.org/abs/2502.13674) (PSL University, ICLR)
- [ ] [\[2502.13652\] C2T: A Classifier-Based Tree Construction Method in Speculative Decoding](https://arxiv.org/abs/2502.13652) (Peking)
- [ ] [\[2502.13595\] MMTEB: Massive Multilingual Text Embedding Benchmark](https://arxiv.org/abs/2502.13595) (ICLR)
- [ ] [\[2502.13509\] Unlocking Multimodal Integration in EHRs: A Prompt Learning Framework for Language and Time Series Fusion](https://arxiv.org/abs/2502.13509) (ZJU)
- [ ] [\[2502.13474\] Towards Lightweight, Adaptive and Attribute-Aware Multi-Aspect Controllable Text Generation with Large Language Models](https://arxiv.org/abs/2502.13474) (ZJU)
- [ ] [\[2502.13442\] TreeCut: A Synthetic Unanswerable Math Word Problem Dataset for LLM Hallucination Evaluation](https://arxiv.org/abs/2502.13442) (Columbia University)
- [ ] [\[2502.13441\] The Self-Improvement Paradox: Can Language Models Bootstrap Reasoning Capabilities without External Scaffolding?](https://arxiv.org/abs/2502.13441) (ZJU)
- [ ] [\[2502.13428\] MCTS-KBQA: Monte Carlo Tree Search for Knowledge Base Question Answering](https://arxiv.org/abs/2502.13428) (Peking)
- [ ] [\[2502.13416\] Detecting LLM Fact-conflicting Hallucinations Enhanced by Temporal-logic-based Reasoning](https://arxiv.org/abs/2502.13416) (NUS)
- [ ] [\[2502.13383\] MM-Verify: Enhancing Multimodal Reasoning with Chain-of-Thought Verification](https://arxiv.org/abs/2502.13383) (UCAS)
- [ ] [\[2502.13349\] Event Segmentation Applications in Large Language Model Enabled Automated Recall Assessments](https://arxiv.org/abs/2502.13349) (University of Toronto)
- [ ] [\[2502.13347\] Craw4LLM: Efficient Web Crawling for LLM Pretraining](https://arxiv.org/abs/2502.13347) (Tsinghua)
- [ ] [\[2502.13311\] Training Turn-by-Turn Verifiers for Dialogue Tutoring Agents: The Curious Case of LLMs as Your Coding Tutors](https://arxiv.org/abs/2502.13311) (PolyU)
- [ ] [\[2502.13259\] HumT DumT: Measuring and controlling human-like language in LLMs](https://arxiv.org/abs/2502.13259) (Stanford)
- [ ] [\[2502.13246\] When People are Floods: Analyzing Dehumanizing Metaphors in Immigration Discourse with Large Language Models](https://arxiv.org/abs/2502.13246) (University of Michigan)
- [ ] [\[2502.13207\] Thinking Outside the (Gray) Box: A Context-Based Score for Assessing Value and Originality in Neural Text Generation](https://arxiv.org/abs/2502.13207) (UCL)
- [ ] [\[2502.13195\] Linguistic Generalizations are not Rules: Impacts on Evaluation of LMs](https://arxiv.org/abs/2502.13195) (Princeton)
- [ ] [\[2502.13193\] Private Text Generation by Seeding Large Language Model Prompts](https://arxiv.org/abs/2502.13193) (AWS)
- [ ] [\[2502.13943\] AdaptiveStep: Automatically Dividing Reasoning Step through Model Confidence](https://arxiv.org/abs/2502.13943) (SJTU)
- [ ] [\[2502.13920\] Exploring Personalized Health Support through Data-Driven, Theory-Guided LLMs: A Case Study in Sleep Health](https://arxiv.org/abs/2502.13920) (Cornell)
- [ ] [\[2502.13870\] SPEX: Scaling Feature Interaction Explanations for LLMs](https://arxiv.org/abs/2502.13870) (Berkeley)
- [ ] [\[2502.13811\] On the Duality between Gradient Transformations and Adapters](https://arxiv.org/abs/2502.13811) (MIT)
- [ ] [\[2502.13794\] LESA: Learnable LLM Layer Scaling-Up](https://arxiv.org/abs/2502.13794) (SJTU)
- [ ] [\[2502.13721\] Learning Novel Transformer Architecture for Time-series Forecasting](https://arxiv.org/abs/2502.13721) (NTU)
- [ ] [\[2502.13681\] An LLM-based Agent for Reliable Docker Environment Configuration](https://arxiv.org/abs/2502.13681) (HIT)
- [ ] [\[2502.13533\] Train Small, Infer Large: Memory-Efficient LoRA Training for Large Language Models](https://arxiv.org/abs/2502.13533) (NUS, ICLR)
- [ ] [\[2502.13344\] K-Paths: Reasoning over Graph Paths for Drug Repurposing and Drug Interaction Prediction](https://arxiv.org/abs/2502.13344) (University of Tübingen)
- [ ] [\[2502.13189\] MoBA: Mixture of Block Attention for Long-Context LLMs](https://arxiv.org/abs/2502.13189) (Tsinghua)
- [ ] [\[2502.12215\] Revisiting the Test-Time Scaling of o1-like Models: Do they Truly Possess Test-Time Scaling Capabilities?](https://arxiv.org/abs/2502.12215) (Fudan)

## 2025-02-19 (Wed)
- [ ] [\[2502.13127\] Facilitating Long Context Understanding via Supervised Chain-of-Thought Reasoning](https://arxiv.org/abs/2502.13127) (University of Rochester)
- [ ] [\[2502.13124\] NaturalReasoning: Reasoning in the Wild with 2.8M Challenging Questions](https://arxiv.org/abs/2502.13124) (Meta)
- [ ] [\[2502.13114\] The influence of motion features in temporal perception](https://arxiv.org/abs/2502.13114) (CNRS)
- [ ] [\[2502.13092\] Text2World: Benchmarking Large Language Models for Symbolic World Model Generation](https://arxiv.org/abs/2502.13092) (HKU)
- [ ] [\[2502.13031\] HPSS: Heuristic Prompting Strategy Search for LLM Evaluators](https://arxiv.org/abs/2502.13031) (Tsinghua)
- [ ] [\[2502.13010\] Adaptive Knowledge Graphs Enhance Medical Question Answering: Bridging the Gap Between LLMs and Evolving Medical Knowledge](https://arxiv.org/abs/2502.13010) (University of Toronto)
- [ ] [\[2502.12996\] Eager Updates For Overlapped Communication and Computation in DiLoCo](https://arxiv.org/abs/2502.12996) (Google)
- [ ] [\[2502.12992\] B-cos LM: Efficiently Transforming Pre-trained Language Models for Improved Explainability](https://arxiv.org/abs/2502.12992) (MPI)
- [ ] [\[2502.12921\] Q-STRUM Debate: Query-Driven Contrastive Summarization for Recommendation Comparison](https://arxiv.org/abs/2502.12921) (University of Toronto)
- [ ] [\[2502.12911\] Knapsack Optimization-based Schema Linking for LLM-based Text-to-SQL Generation](https://arxiv.org/abs/2502.12911) (PolyU)
- [ ] [\[2502.12859\] PAFT: Prompt-Agnostic Fine-Tuning](https://arxiv.org/abs/2502.12859) (Tsinghua)
- [ ] [\[2502.12853\] S$^2$R: Teaching LLMs to Self-verify and Self-correct via Reinforcement Learning](https://arxiv.org/abs/2502.12853) (Tsinghua)
- [ ] [\[2502.12825\] Reasoning and the Trusting Behavior of DeepSeek and GPT: An Experiment Revealing Hidden Fault Lines in Large Language Models](https://arxiv.org/abs/2502.12825) (NYU)
- [ ] [\[2502.12700\] Multi-Novelty: Improve the Diversity and Novelty of Contents Generated by Large Language Models via inference-time Multi-Views Brainstorming](https://arxiv.org/abs/2502.12700) (NUS)
- [ ] [\[2502.12633\] One Size doesn't Fit All: A Personalized Conversational Tutoring Agent for Mathematics Instruction](https://arxiv.org/abs/2502.12633) (WHU)
- [ ] [\[2502.12611\] Who Writes What: Unveiling the Impact of Author Roles on AI-generated Text Detection](https://arxiv.org/abs/2502.12611) (Peking)
- [ ] [\[2502.12598\] Bring Your Own Knowledge: A Survey of Methods for LLM Knowledge Expansion](https://arxiv.org/abs/2502.12598) (Bosch)
- [ ] [\[2502.12583\] LongFaith: Enhancing Long-Context Reasoning in LLMs with Faithful Synthetic Data](https://arxiv.org/abs/2502.12583) (HKUST)
- [ ] [\[2502.12565\] Self Iterative Label Refinement via Robust Unlabeled Learning](https://arxiv.org/abs/2502.12565) (University of Tokyo)
- [ ] [\[2502.12530\] Policy-to-Language: Train LLMs to Explain Decisions with Flow-Matching Generated Rewards](https://arxiv.org/abs/2502.12530) (Harvard)
- [ ] [\[2502.12510\] Aspect-Guided Multi-Level Perturbation Analysis of Large Language Models in Automated Peer Review](https://arxiv.org/abs/2502.12510) (Peking)
- [ ] [\[2502.12490\] UniGenCoder: Merging Seq2Seq and Seq2Tree Paradigms for Unified Code Generation](https://arxiv.org/abs/2502.12490) (Xiamen)
- [ ] [\[2502.12483\] The Knowledge Microscope: Features as Better Analytical Lenses than Neurons](https://arxiv.org/abs/2502.12483) (IA CAS)
- [ ] [\[2502.12455\] DSMoE: Matrix-Partitioned Experts with Dynamic Routing for Computation-Efficient Dense LLMs](https://arxiv.org/abs/2502.12455) (Tsinghua)
- [ ] [\[2502.12436\] Should I Trust You? Detecting Deception in Negotiations using Counterfactual RL](https://arxiv.org/abs/2502.12436) (UMD)
- [ ] [\[2502.12414\] Lost in Transcription, Found in Distribution Shift: Demystifying Hallucination in Speech Foundation Models](https://arxiv.org/abs/2502.12414) (MBZUAI)
- [ ] [\[2502.12411\] Gradient Co-occurrence Analysis for Detecting Unsafe Prompts in Large Language Models](https://arxiv.org/abs/2502.12411) (BUPT)
- [ ] [\[2502.12408\] On the Robust Approximation of ASR Metrics](https://arxiv.org/abs/2502.12408) (MBZUAI)
- [ ] [\[2502.12378\] Pragmatics in the Era of Large Language Models: A Survey on Datasets, Evaluation, Opportunities and Challenges](https://arxiv.org/abs/2502.12378) (Bosch)
- [ ] [\[2502.12317\] Can Language Models Learn Typologically Implausible Languages?](https://arxiv.org/abs/2502.12317) (MBZUAI)
- [ ] [\[2502.12214\] Zero Token-Driven Deep Thinking in LLMs: Unlocking the Full Potential of Existing Parameters via Cyclic Refinement](https://arxiv.org/abs/2502.12214) (Tsinghua)
- [ ] [\[2502.12189\] Self-supervised Attribute-aware Dynamic Preference Ranking Alignment](https://arxiv.org/abs/2502.12189) (USTC)
- [ ] [\[2502.13131\] Rethinking Diverse Human Preference Learning through Principal Component Analysis](https://arxiv.org/abs/2502.13131) (Illinois)
- [ ] [\[2502.12734\] Iron Sharpens Iron: Defending Against Attacks in Machine-Generated Text Detection with Adversarial Training](https://arxiv.org/abs/2502.12734) (XJTU)
- [ ] [\[2502.12678\] Multi-Step Alignment as Markov Games: An Optimistic Online Gradient Descent Approach with Convergence Guarantees](https://arxiv.org/abs/2502.12678) (EPFL)
- [ ] [\[2502.12586\] G-Refer: Graph Retrieval-Augmented Large Language Model for Explainable Recommendation](https://arxiv.org/abs/2502.12586) (CUHK)
- [ ] [\[2502.12561\] UXAgent: An LLM Agent-Based Usability Testing Framework for Web Design](https://arxiv.org/abs/2502.12561) (AWS)
- [ ] [\[2502.12442\] HopRAG: Multi-Hop Reasoning for Logic-Aware Retrieval-Augmented Generation](https://arxiv.org/abs/2502.12442) (HUST)
- [ ] [\[2502.12217\] Optimal Brain Iterative Merging: Mitigating Interference in LLM Merging](https://arxiv.org/abs/2502.12217) (Peking)
- [ ] [\[2502.12170\] MUDDFormer: Breaking Residual Bottlenecks in Transformers via Multiway Dynamic Dense Connections](https://arxiv.org/abs/2502.12170) (BUPT)

## 2025-02-18 (Tue)
- [ ] [\[2502.12150\] Idiosyncrasies in Large Language Models](https://arxiv.org/abs/2502.12150) (CMU)
- [ ] [\[2502.12123\] On the Query Complexity of Verifier-Assisted Language Generation](https://arxiv.org/abs/2502.12123) (CMU)
- [ ] [\[2502.12084\] VLM$^2$-Bench: A Closer Look at How Well VLMs Implicitly Link Explicit Matching Visual Cues](https://arxiv.org/abs/2502.12084) (CMU)
- [ ] [\[2502.12073\] Can LLMs Simulate Social Media Engagement? A Study on Action-Guided Response Generation](https://arxiv.org/abs/2502.12073) (GIT)
- [ ] [\[2502.12022\] Teaching LLMs According to Their Aptitude: Adaptive Reasoning for Mathematical Problem Solving](https://arxiv.org/abs/2502.12022) (HKUST)
- [ ] [\[2502.11995\] Presumed Cultural Identity: How Names Shape LLM Responses](https://arxiv.org/abs/2502.11995) (University of Copenhagen)
- [ ] [\[2502.11962\] Navigating the Helpfulness-Truthfulness Trade-Off with Uncertainty-Aware Instruction Fine-Tuning](https://arxiv.org/abs/2502.11962) (ETH)
- [ ] [\[2502.11932\] On Representational Dissociation of Language and Arithmetic in Large Language Models](https://arxiv.org/abs/2502.11932) (MBZUAI)
- [ ] [\[2502.11926\] BRIGHTER: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages](https://arxiv.org/abs/2502.11926) (Imperial)
- [ ] [\[2502.11916\] EssayJudge: A Multi-Granular Benchmark for Assessing Automated Essay Scoring Capabilities of Multimodal Large Language Models](https://arxiv.org/abs/2502.11916) (HKUST(GZ))
- [ ] [\[2502.11901\] Building A Proof-Oriented Programmer That Is 64% Better Than GPT-4o Under Data Scarsity](https://arxiv.org/abs/2502.11901) (Illinois)
- [ ] [\[2502.11890\] Revisiting Classification Taxonomy for Grammatical Errors](https://arxiv.org/abs/2502.11890) (Tsinghua)
- [ ] [\[2502.11689\] Improve LLM-as-a-Judge Ability as a General Ability](https://arxiv.org/abs/2502.11689) (Tsinghua)
- [ ] [\[2502.11688\] From Isolates to Families: Using Neural Networks for Automated Language Affiliation](https://arxiv.org/abs/2502.11688) (MPI)
- [ ] [\[2502.11681\] RIDE: Enhancing Large Language Model Alignment through Restyled In-Context Learning Demonstration Exemplars](https://arxiv.org/abs/2502.11681) (MIT)
- [ ] [\[2502.11671\] Diversity-Oriented Data Augmentation with Large Language Models](https://arxiv.org/abs/2502.11671) (UCAS)
- [ ] [\[2502.11598\] Can LLM Watermarks Robustly Prevent Unauthorized Knowledge Distillation?](https://arxiv.org/abs/2502.11598) (Tsinghua)
- [ ] [\[2502.11573\] InfiR : Crafting Effective Small Language Models and Multimodal Small Language Models in Reasoning](https://arxiv.org/abs/2502.11573) (PolyU)
- [ ] [\[2502.11546\] DCAD-2000: A Multilingual Dataset across 2000+ Languages with Data Cleaning as Anomaly Detection](https://arxiv.org/abs/2502.11546) (Tsinghua)
- [ ] [\[2502.11541\] MuSC: Improving Complex Instruction Following with Multi-granularity Self-Contrastive Training](https://arxiv.org/abs/2502.11541) (HIT)
- [ ] [\[2502.11525\] Training Large Language Models to be Better Rule Followers](https://arxiv.org/abs/2502.11525) (Peking)
- [ ] [\[2502.11517\] Learning to Keep a Promise: Scaling Language Model Decoding Parallelism with Learned Asynchronous Decoding](https://arxiv.org/abs/2502.11517) (MIT)
- [ ] [\[2502.11514\] Investigating Inference-time Scaling for Chain of Multi-modal Thought: A Preliminary Study](https://arxiv.org/abs/2502.11514) (Xiamen)
- [ ] [\[2502.11501\] Token Pruning in Multimodal Large Language Models: Are We Solving the Right Problem?](https://arxiv.org/abs/2502.11501) (Shanghai AI Lab)
- [ ] [\[2502.11494\] Stop Looking for Important Tokens in Multimodal Language Models: Duplication Matters More](https://arxiv.org/abs/2502.11494) (Shanghai AI Lab)
- [ ] [\[2502.11493\] DAST: Context-Aware Compression in LLMs via Dynamic Allocation of Soft Tokens](https://arxiv.org/abs/2502.11493) (Tsinghua)
- [ ] [\[2502.11491\] Ontology-Guided Reverse Thinking Makes Large Language Models Stronger on Knowledge Graph Question Answering](https://arxiv.org/abs/2502.11491) (BUPT)
- [ ] [\[2502.11476\] FastMCTS: A Simple Sampling Strategy for Data Synthesis](https://arxiv.org/abs/2502.11476) (Fudan)
- [ ] [\[2502.11460\] UnitCoder: Scalable Iterative Code Synthesis with Unit Test Guidance](https://arxiv.org/abs/2502.11460) (Fudan)
- [ ] [\[2502.11454\] UniCBE: An Uniformity-driven Comparing Based Evaluation Framework with Unified Multi-Objective Optimization](https://arxiv.org/abs/2502.11454) (ICLR)
- [ ] [\[2502.11451\] From Personas to Talks: Revisiting the Impact of Personas on LLM-Synthesized Emotional Support Conversations](https://arxiv.org/abs/2502.11451) (NUS)
- [ ] [\[2502.11380\] Exploring the Small World of Word Embeddings: A Comparative Study on Conceptual Spaces from LLMs of Different Scales](https://arxiv.org/abs/2502.11380) (Tsinghua)
- [ ] [\[2502.11355\] "Nuclear Deployed!": Analyzing Catastrophic Risks in Decision-making of Autonomous LLM Agents](https://arxiv.org/abs/2502.11355) (Berkeley)
- [ ] [\[2502.11345\] Hierarchical Graph Topic Modeling with Topic Tree-based Transformer](https://arxiv.org/abs/2502.11345) (HKUST(GZ))
- [ ] [\[2502.11268\] Improved Unbiased Watermark for Large Language Models](https://arxiv.org/abs/2502.11268) (UMD)
- [ ] [\[2502.11250\] Uncertainty-Aware Step-wise Verification with Generative Reward Models](https://arxiv.org/abs/2502.11250) (Oxford)
- [ ] [\[2502.11183\] Don't Get Lost in the Trees: Streamlining LLM Reasoning by Overcoming Tree Search Exploration Pitfalls](https://arxiv.org/abs/2502.11183) (Xiamen)
- [ ] [\[2502.11177\] The Mirage of Model Editing: Revisiting Evaluation in the Wild](https://arxiv.org/abs/2502.11177) (ICT CAS)
- [ ] [\[2502.11176\] LogiDynamics: Unraveling the Dynamics of Logical Inference in Large Language Model Reasoning](https://arxiv.org/abs/2502.11176) (HKUST)
- [ ] [\[2502.11123\] DuplexMamba: Enhancing Real-time Speech Conversations with Duplex and Streaming Capabilities](https://arxiv.org/abs/2502.11123) (HIT)
- [ ] [\[2502.11113\] Valuable Hallucinations: Realizable Non-realistic Propositions](https://arxiv.org/abs/2502.11113) (Tianjin)
- [ ] [\[2502.11095\] A Survey of Large Language Models in Psychotherapy: Current Landscape and Future Directions](https://arxiv.org/abs/2502.11095) (UTS)
- [ ] [\[2502.11075\] Exposing Numeracy Gaps: A Benchmark to Evaluate Fundamental Numerical Abilities in Large Language Models](https://arxiv.org/abs/2502.11075) (PolyU)
- [ ] [\[2502.11018\] GRIFFIN: Effective Token Alignment for Faster Speculative Decoding](https://arxiv.org/abs/2502.11018) (Fudan)
- [ ] [\[2502.10996\] RAS: Retrieval-And-Structuring for Knowledge-Intensive LLM Generation](https://arxiv.org/abs/2502.10996) (Illinois)
- [ ] [\[2502.10990\] FinMTEB: Finance Massive Text Embedding Benchmark](https://arxiv.org/abs/2502.10990) (HKUST)
- [ ] [\[2502.10921\] Evolving Hate Speech Online: An Adaptive Framework for Detection and Mitigation](https://arxiv.org/abs/2502.10921) (UW)
- [ ] [\[2502.10881\] CiteCheck: Towards Accurate Citation Faithfulness Detection](https://arxiv.org/abs/2502.10881) (HKUST(GZ))
- [ ] [\[2502.10871\] The Representation and Recall of Interwoven Structured Knowledge in LLMs: A Geometric and Layered Analysis](https://arxiv.org/abs/2502.10871) (Imperial)
- [ ] [\[2502.10852\] Multilingual Encoder Knows more than You Realize: Shared Weights Pretraining for Extremely Low-Resource Languages](https://arxiv.org/abs/2502.10852) (SJTU)
- [ ] [\[2502.10760\] Why is prompting hard? Understanding prompts on binary sequence predictors](https://arxiv.org/abs/2502.10760) (Google)
- [ ] [\[2502.10749\] LoRE-Merging: Exploring Low-Rank Estimation For Large Language Model Merging](https://arxiv.org/abs/2502.10749) (HKU)
- [ ] [\[2502.10739\] BASE-SQL: A powerful open source Text-To-SQL baseline approach](https://arxiv.org/abs/2502.10739) (USTC)
- [ ] [\[2502.10709\] An Empirical Analysis of Uncertainty in Large Language Model Evaluations](https://arxiv.org/abs/2502.10709) (ICLR)
- [ ] [\[2502.10641\] Toward Equitable Access: Leveraging Crowdsourced Reviews to Investigate Public Perceptions of Health Resource Accessibility](https://arxiv.org/abs/2502.10641) (University of Michigan)
- [ ] [\[2502.10596\] Post-training an LLM for RAG? Train on Self-Generated Demonstrations](https://arxiv.org/abs/2502.10596) (Meta)
- [ ] [\[2502.12085\] APB: Accelerating Distributed Long-Context Inference by Passing Compressed Context Blocks across GPUs](https://arxiv.org/abs/2502.12085) (Tsinghua)
- [ ] [\[2502.12081\] Unhackable Temporal Rewarding for Scalable Video MLLMs](https://arxiv.org/abs/2502.12081) (ICLR)
- [ ] [\[2502.11919\] From Text to Trust: Empowering AI-assisted Decision Making with Adaptive LLM-powered Analysis](https://arxiv.org/abs/2502.11919) (JHU)
- [ ] [\[2502.11882\] Leveraging Dual Process Theory in Language Agent Framework for Real-time Simultaneous Human-AI Collaboration](https://arxiv.org/abs/2502.11882) (SJTU)
- [ ] [\[2502.11799\] Table-Critic: A Multi-Agent Framework for Collaborative Criticism and Refinement in Table Reasoning](https://arxiv.org/abs/2502.11799) (UCAS)
- [ ] [\[2502.11645\] Deviation Ratings: A General, Clone-Invariant Rating Method](https://arxiv.org/abs/2502.11645) (Google)
- [ ] [\[2502.11554\] Toward Metaphor-Fluid Conversation Design for Voice User Interfaces](https://arxiv.org/abs/2502.11554) (Illinois)
- [ ] [\[2502.11466\] GiFT: Gibbs Fine-Tuning for Code Generation](https://arxiv.org/abs/2502.11466) (NTU)
- [ ] [\[2502.11442\] Multi-Turn Multi-Modal Question Clarification for Enhanced Conversational Understanding](https://arxiv.org/abs/2502.11442) (University of Copenhagen)
- [ ] [\[2502.11367\] Sparse Autoencoder Features for Classifications and Transferability](https://arxiv.org/abs/2502.11367) (Harvard)
- [ ] [\[2502.11360\] GeoDANO: Geometric VLM with Domain Agnostic Vision Encoder](https://arxiv.org/abs/2502.11360) (POSTECH)
- [ ] [\[2502.11271\] OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning](https://arxiv.org/abs/2502.11271) (Stanford)
- [ ] [\[2502.11140\] VisPath: Automated Visualization Code Synthesis via Multi-Path Reasoning and Feedback-Driven Optimization](https://arxiv.org/abs/2502.11140) (Tsinghua)
- [ ] [\[2502.11021\] Leveraging Uncertainty Estimation for Efficient LLM Routing](https://arxiv.org/abs/2502.11021) (AWS)
- [ ] [\[2502.10867\] A Tutorial on LLM Reasoning: Relevant Methods behind ChatGPT o1](https://arxiv.org/abs/2502.10867) (UCL)
- [ ] [\[2502.10563\] Accelerating Unbiased LLM Evaluation via Synthetic Feedback](https://arxiv.org/abs/2502.10563) (CMU)
- [ ] [\[2502.10505\] Preference learning made easy: Everything should be understood through win rate](https://arxiv.org/abs/2502.10505) (NYU)
- [ ] [\[2502.10454\] One Example Shown, Many Concepts Known! Counterexample-Driven Conceptual Reasoning in Mathematical LLMs](https://arxiv.org/abs/2502.10454) (Tsinghua)
- [ ] [\[2502.10453\] Linking Cryptoasset Attribution Tags to Knowledge Graph Entities: An LLM-based Approach](https://arxiv.org/abs/2502.10453) (UTS)
- [ ] [\[2502.10447\] MoHAVE: Mixture of Hierarchical Audio-Visual Experts for Robust Speech Recognition](https://arxiv.org/abs/2502.10447) (KAIST)

## 2025-02-17 (Mon)
- [ ] [\[2502.10388\] Aspect-Oriented Summarization for Psychiatric Short-Term Readmission Prediction](https://arxiv.org/abs/2502.10388) (Harvard)
- [ ] [\[2502.10373\] OWLS: Scaling Laws for Multilingual Speech Recognition and Translation Models](https://arxiv.org/abs/2502.10373) (CMU)
- [ ] [\[2502.10361\] Enhancing Multilingual LLM Pretraining with Model-Based Data Selection](https://arxiv.org/abs/2502.10361) (EPFL)
- [ ] [\[2502.10341\] Organize the Web: Constructing Domains Enhances Pre-Training Data Curation](https://arxiv.org/abs/2502.10341) (Princeton)
- [ ] [\[2502.10338\] Evaluating the Meta- and Object-Level Reasoning of Large Language Models for Question Answering](https://arxiv.org/abs/2502.10338) (University of Edinburgh)
- [ ] [\[2502.09689\] Large Language Models and Provenance Metadata for Determining the Relevance of Images and Videos in News Stories](https://arxiv.org/abs/2502.09689) (Stanford)
- [ ] [\[2502.09647\] Unveiling Simplicities of Attention: Adaptive Long-Context Head Identification](https://arxiv.org/abs/2502.09647) (ETH)
- [ ] [\[2502.10378\] Unknown Word Detection for English as a Second Language (ESL) Learners Using Gaze and Pre-trained Language Models](https://arxiv.org/abs/2502.10378) (Tsinghua)
- [ ] [\[2502.10162\] Revisiting Generalization Power of a DNN in Terms of Symbolic Interactions](https://arxiv.org/abs/2502.10162) (SJTU)
- [ ] [\[2502.09990\] X-Boundary: Establishing Exact Safety Boundary to Shield LLMs from Multi-Turn Jailbreaks without Compromising Usability](https://arxiv.org/abs/2502.09990) (Shanghai AI Lab)
- [ ] [\[2502.09969\] Data Valuation using Neural Networks for Efficient Instruction Fine-Tuning](https://arxiv.org/abs/2502.09969) (Illinois)
- [ ] [\[2502.09933\] MIR-Bench: Benchmarking LLM's Long-Context Intelligence via Many-Shot In-Context Inductive Reasoning](https://arxiv.org/abs/2502.09933) (Illinois)
- [ ] [\[2502.09870\] A Taxonomy of Linguistic Expressions That Contribute To Anthropomorphism of Language Technologies](https://arxiv.org/abs/2502.09870) (CMU)
- [ ] [\[2502.09863\] Solvable Dynamics of Self-Supervised Word Embeddings and the Emergence of Analogical Reasoning](https://arxiv.org/abs/2502.09863) (Berkeley)
- [ ] [\[2502.09858\] Automated Hypothesis Validation with Agentic Sequential Falsifications](https://arxiv.org/abs/2502.09858) (Stanford)
- [ ] [\[2502.09767\] Non-Markovian Discrete Diffusion with Causal Language Models](https://arxiv.org/abs/2502.09767) (Yale)
- [ ] [\[2502.09715\] Evaluating GPT's Capability in Identifying Stages of Cognitive Impairment from Electronic Health Data](https://arxiv.org/abs/2502.09715) (Harvard)

## 2025-02-14 (Fri)
- [ ] [\[2502.09604\] SelfCite: Self-Supervised Alignment for Context Attribution in Large Language Models](https://arxiv.org/abs/2502.09604) (MIT)
- [ ] [\[2502.09487\] Objective quantification of mood states using large language models](https://arxiv.org/abs/2502.09487) (UCL)
- [ ] [\[2502.09419\] On multi-token prediction for efficient LLM inference](https://arxiv.org/abs/2502.09419) (EPFL)
- [ ] [\[2502.09307\] When the LM misunderstood the human chuckled: Analyzing garden path effects in humans and language models](https://arxiv.org/abs/2502.09307) (Tel Aviv)
- [ ] [\[2502.09192\] Thinking beyond the anthropomorphic paradigm benefits LLM research](https://arxiv.org/abs/2502.09192) (Oxford)
- [ ] [\[2502.09120\] The influence of visual and linguistic cues on ignorance inference in Vision-Language Models (VLMs)](https://arxiv.org/abs/2502.09120) (Sungkyunkwan University)
- [ ] [\[2502.09097\] A Hybrid Transformer Model for Fake News Detection: Leveraging Bayesian Optimization and Bidirectional Recurrent Unit](https://arxiv.org/abs/2502.09097) (Berkeley)
- [ ] [\[2502.09082\] CoSER: Coordinating LLM-Based Persona Simulation of Established Roles](https://arxiv.org/abs/2502.09082) (Fudan)
- [ ] [\[2502.09073\] Enhancing RAG with Active Learning on Conversation Records: Reject Incapables and Answer Capables](https://arxiv.org/abs/2502.09073) (HUST)
- [ ] [\[2502.09017\] Diversity Enhances an LLM's Performance in RAG and Long-context Task](https://arxiv.org/abs/2502.09017) (Salesforce)
- [ ] [\[2502.09004\] Hope vs. Hate: Understanding User Interactions with LGBTQ+ News Content in Mainstream US News Media through the Lens of Hope Speech](https://arxiv.org/abs/2502.09004) (Rochester Institute of Technology)
- [ ] [\[2502.08954\] Medicine on the Edge: Comparative Performance Analysis of On-Device LLMs for Clinical Reasoning](https://arxiv.org/abs/2502.08954) (Stanford)
- [ ] [\[2502.08946\] The Stochastic Parrot on LLM's Shoulder: A Summative Assessment of Physical Concept Understanding](https://arxiv.org/abs/2502.08946) (JHU)
- [ ] [\[2502.08943\] Beyond the Singular: The Essential Role of Multiple Generations in Effective Benchmark Evaluation and Analysis](https://arxiv.org/abs/2502.08943) (Meta)
- [ ] [\[2502.08910\] InfiniteHiP: Extending Language Model Context Up to 3 Million Tokens on a Single GPU](https://arxiv.org/abs/2502.08910) (KAIST)
- [ ] [\[2502.08896\] Communication is All You Need: Persuasion Dataset Construction via Multi-LLM Communication](https://arxiv.org/abs/2502.08896) (GIT)
- [ ] [\[2502.08888\] LLM-Enhanced Multiple Instance Learning for Joint Rumor and Stance Detection with Social Context Information](https://arxiv.org/abs/2502.08888) (BU)
- [ ] [\[2502.08866\] BrainWavLM: Fine-tuning Speech Representations with Brain Responses to Language](https://arxiv.org/abs/2502.08866) (UT Austin)
- [ ] [\[2502.08796\] A Systematic Review on the Evaluation of Large Language Models in Theory of Mind Tasks](https://arxiv.org/abs/2502.08796) (University of Tübingen)
- [ ] [\[2502.08788\] If Multi-Agent Debate is the Answer, What is the Question?](https://arxiv.org/abs/2502.08788) (Shanghai AI Lab, TIP)
- [ ] [\[2502.08773\] Universal Model Routing for Efficient LLM Inference](https://arxiv.org/abs/2502.08773) (Google)
- [ ] [\[2502.08669\] Assessing the Impact of the Quality of Textual Data on Feature Representation and Machine Learning Models](https://arxiv.org/abs/2502.08669) (MIT)
- [ ] [\[2502.08661\] Few-shot_LLM_Synthetic_Data_with_Distribution_Matching](https://arxiv.org/abs/2502.08661) (Tsinghua)
- [ ] [\[2502.08660\] Semantic Role Labeling: A Systematical Survey](https://arxiv.org/abs/2502.08660) (HIT)
- [ ] [\[2502.08657\] Refining Positive and Toxic Samples for Dual Safety Self-Alignment of LLMs with Minimal Human Interventions](https://arxiv.org/abs/2502.08657) (BUPT)
- [ ] [\[2502.09601\] CoT-Valve: Length-Compressible Chain-of-Thought Tuning](https://arxiv.org/abs/2502.09601) (NUS)
- [ ] [\[2502.09597\] Do LLMs Recognize Your Preferences? Evaluating Personalized Preference Following in LLMs](https://arxiv.org/abs/2502.09597) (UCLA, ICLR)
- [ ] [\[2502.09560\] EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language Models for Vision-Driven Embodied Agents](https://arxiv.org/abs/2502.09560) (Illinois)
- [ ] [\[2502.09213\] Neuro-Symbolic Contrastive Learning for Cross-domain Inference](https://arxiv.org/abs/2502.09213) (University of Tokyo)
- [ ] [\[2502.09212\] LP-LM: No Hallucinations in Question Answering with Logic Programming](https://arxiv.org/abs/2502.09212) (Cornell)
- [ ] [\[2502.09083\] Show Me the Work: Fact-Checkers' Requirements for Explainable Automated Fact-Checking](https://arxiv.org/abs/2502.09083) (University of Copenhagen)
- [ ] [\[2502.08680\] Mathematical Reasoning in Large Language Models: Assessing Logical and Arithmetic Errors across Wide Numerical Ranges](https://arxiv.org/abs/2502.08680) (NYU)

## 2025-02-13 (Thu)
- [ ] [\[2502.08550\] LLMs can implicitly learn from mistakes in-context](https://arxiv.org/abs/2502.08550) (Imperial)
- [ ] [\[2502.08512\] Measuring Diversity in Synthetic Datasets](https://arxiv.org/abs/2502.08512) (SYSU)
- [ ] [\[2502.08507\] Explanation based In-Context Demonstrations Retrieval for Multilingual Grammatical Error Correction](https://arxiv.org/abs/2502.08507) (Peking)
- [ ] [\[2502.08436\] From Haystack to Needle: Label Space Reduction for Zero-shot Classification](https://arxiv.org/abs/2502.08436) (ICML)
- [ ] [\[2502.08317\] Mitigating Hallucinations in Multimodal Spatial Relations through Constraint-Aware Prompting](https://arxiv.org/abs/2502.08317) (University of Rochester)
- [ ] [\[2502.08279\] What Is That Talk About? A Video-to-Text Summarization Dataset for Scientific Presentations](https://arxiv.org/abs/2502.08279) (Cambridge)
- [ ] [\[2502.08246\] Inference-time sparse attention with asymmetric indexing](https://arxiv.org/abs/2502.08246) (Meta)
- [ ] [\[2502.08178\] ParetoRAG: Leveraging Sentence-Context Attention for Robust and Efficient Retrieval-Augmented Generation](https://arxiv.org/abs/2502.08178) (Alibaba)
- [ ] [\[2502.08092\] GCoT: Chain-of-Thought Prompt Learning for Graphs](https://arxiv.org/abs/2502.08092) (USTC)
- [ ] [\[2502.08080\] NLI under the Microscope: What Atomic Hypothesis Decomposition Reveals](https://arxiv.org/abs/2502.08080) (UMD)
- [ ] [\[2502.08059\] On Mechanistic Circuits for Extractive Question-Answering](https://arxiv.org/abs/2502.08059) (UMD)
- [ ] [\[2502.08020\] Speculate, then Collaborate: Fusing Knowledge of Language Models during Decoding](https://arxiv.org/abs/2502.08020) (UMD)
- [ ] [\[2502.08009\] The Geometry of Prompting: Unveiling Distinct Mechanisms of Task Adaptation in Language Models](https://arxiv.org/abs/2502.08009) (NYU)
- [ ] [\[2502.07963\] Caught in the Web of Words: Do LLMs Fall for Spin in Medical Literature?](https://arxiv.org/abs/2502.07963) (UT Austin)
- [ ] [\[2502.07912\] Elevating Legal LLM Responses: Harnessing Trainable Logical Structures and Semantic Knowledge with Legal Reasoning](https://arxiv.org/abs/2502.07912) (Nankai)
- [ ] [\[2502.07904\] Intelligent Legal Assistant: An Interactive Clarification System for Legal Question Answering](https://arxiv.org/abs/2502.07904) (Nankai)
- [ ] [\[2502.08606\] Distillation Scaling Laws](https://arxiv.org/abs/2502.08606) (Apple)
- [ ] [\[2502.08524\] LLM Pretraining with Continuous Concepts](https://arxiv.org/abs/2502.08524) (KAIST)
- [ ] [\[2502.08438\] Composite Sketch+Text Queries for Retrieving Objects with Elusive Names and Complex Interactions](https://arxiv.org/abs/2502.08438) (Microsoft)
- [ ] [\[2502.08205\] Wisdom of the Crowds in Forecasting: Forecast Summarization for Supporting Future Event Prediction](https://arxiv.org/abs/2502.08205) (MPI)
- [ ] [\[2502.07855\] Vision-Language Models for Edge Networks: A Comprehensive Survey](https://arxiv.org/abs/2502.07855) (MBZUAI)

## 2025-02-12 (Wed)
- [ ] [\[2502.07776\] Auditing Prompt Caching in Language Model APIs](https://arxiv.org/abs/2502.07776) (Stanford)
- [ ] [\[2502.07616\] Tractable Transformers for Flexible Conditional Generation](https://arxiv.org/abs/2502.07616) (UCLA)
- [ ] [\[2502.07586\] We Can't Understand AI Using our Existing Vocabulary](https://arxiv.org/abs/2502.07586) (Google)
- [ ] [\[2502.07555\] O1 Embedder: Let Retrievers Think Before Action](https://arxiv.org/abs/2502.07555) (USTC)
- [ ] [\[2502.07544\] Grammar Control in Dialogue Response Generation for Language Learning Chatbots](https://arxiv.org/abs/2502.07544) (EPFL)
- [ ] [\[2502.07541\] Corporate Greenwashing Detection in Text - a Survey](https://arxiv.org/abs/2502.07541) (Inria)
- [ ] [\[2502.07490\] Mask-Enhanced Autoregressive Prediction: Pay Less Attention to Learn More](https://arxiv.org/abs/2502.07490) (Oxford)
- [ ] [\[2502.07365\] LongReD: Mitigating Short-Text Degradation of Long-Context Large Language Models via Restoration Distillation](https://arxiv.org/abs/2502.07365) (NUS)
- [ ] [\[2502.07346\] BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models](https://arxiv.org/abs/2502.07346) (NJU)
- [ ] [\[2502.07316\] CodeI/O: Condensing Reasoning Patterns via Code Input-Output Prediction](https://arxiv.org/abs/2502.07316) (HKUST)
- [ ] [\[2502.07272\] GENERator: A Long-Context Generative Genomic Foundation Model](https://arxiv.org/abs/2502.07272) (Alibaba)
- [ ] [\[2502.07184\] Refine Knowledge of Large Language Models via Adaptive Contrastive Learning](https://arxiv.org/abs/2502.07184) (Tsinghua, ICLR)
- [ ] [\[2502.07131\] TWICE: What Advantages Can Low-Resource Domain-Specific Embedding Model Bring? - A Case Study on Korea Financial Texts](https://arxiv.org/abs/2502.07131) (ICLR)
- [ ] [\[2502.07101\] SMAB: MAB based word Sensitivity Estimation Framework and its Applications in Adversarial Text Generation](https://arxiv.org/abs/2502.07101) (MBZUAI)
- [ ] [\[2502.07077\] Multi-turn Evaluation of Anthropomorphic Behaviours in Large Language Models](https://arxiv.org/abs/2502.07077) (Oxford)
- [ ] [\[2502.07068\] Specializing Large Language Models to Simulate Survey Response Distributions for Global Populations](https://arxiv.org/abs/2502.07068) (University of Copenhagen)
- [ ] [\[2502.07022\] AIMS.au: A Dataset for the Analysis of Modern Slavery Countermeasures in Corporate Statements](https://arxiv.org/abs/2502.07022) (ICLR)
- [ ] [\[2502.07004\] Demystifying Singular Defects in Large Language Models](https://arxiv.org/abs/2502.07004) (EPFL)
- [ ] [\[2502.06990\] Investigating the Zone of Proximal Development of Language Models for In-Context Learning](https://arxiv.org/abs/2502.06990) (ETH)
- [ ] [\[2502.06882\] Multi-Agent Simulator Drives Language Models for Legal Intensive Interaction](https://arxiv.org/abs/2502.06882) (Fudan)
- [ ] [\[2502.06874\] Group Reasoning Emission Estimation Networks](https://arxiv.org/abs/2502.06874) (USyd)
- [ ] [\[2502.06872\] Towards Trustworthy Retrieval Augmented Generation for Large Language Models: A Survey](https://arxiv.org/abs/2502.06872) (PolyU)
- [ ] [\[2502.06864\] Knowledge Graph-Guided Retrieval Augmented Generation](https://arxiv.org/abs/2502.06864) (NJU)
- [ ] [\[2502.07663\] Human Decision-making is Susceptible to AI-driven Manipulation](https://arxiv.org/abs/2502.07663) (HKU)
- [ ] [\[2502.07563\] LASP-2: Rethinking Sequence Parallelism for Linear Attention and Its Hybrid](https://arxiv.org/abs/2502.07563) (CUHK)
- [ ] [\[2502.07263\] Hidden Division of Labor in Scientific Teams Revealed Through 1.6 Million LaTeX Files](https://arxiv.org/abs/2502.07263) (Stanford)
- [ ] [\[2502.07088\] Kernels of Selfhood: GPT-4o shows humanlike patterns of cognitive consistency moderated by free choice](https://arxiv.org/abs/2502.07088) (BU)
- [ ] [\[2502.06994\] SyncMind: Measuring Agent Out-of-Sync Recovery in Collaborative Software Engineering](https://arxiv.org/abs/2502.06994) (Illinois)
- [ ] [\[2502.06901\] Enabling Autoregressive Models to Fill In Masked Tokens](https://arxiv.org/abs/2502.06901) (UCLA)
- [ ] [\[2502.06875\] Beyond Vision: How Large Language Models Interpret Facial Expressions from Valence-Arousal Values](https://arxiv.org/abs/2502.06875) (Cambridge)
- [ ] [\[2502.06802\] Solving the Content Gap in Roblox Game Recommendations: LLM-Based Profile Generation and Reranking](https://arxiv.org/abs/2502.06802) (Columbia University)

## 2025-02-11 (Tue)
- [ ] <5>[\[2502.06772\] ReasonFlux: Hierarchical LLM Reasoning via Scaling Thought Templates](https://arxiv.org/abs/2502.06772) (Princeton)
- [ ] [\[2502.06766\] Exploiting Sparsity for Long Context Inference: Million Token Contexts on Commodity GPUs](https://arxiv.org/abs/2502.06766) (UMD)
- [ ] [\[2502.06703\] Can 1B LLM Surpass 405B LLM? Rethinking Compute-Optimal Test-Time Scaling](https://arxiv.org/abs/2502.06703) (Shanghai AI Lab)
- [ ] [\[2502.06669\] Boosting Self-Efficacy and Performance of Large Language Models via Verbal Efficacy Stimulations](https://arxiv.org/abs/2502.06669) (UCAS)
- [ ] [\[2502.06635\] Steel-LLM:From Scratch to Open Source -- A Personal Journey in Building a Chinese-Centric LLM](https://arxiv.org/abs/2502.06635) (BUPT)
- [ ] [\[2502.06604\] Do we really have to filter out random noise in pre-training data for language models?](https://arxiv.org/abs/2502.06604) (Peking)
- [ ] [\[2502.06589\] Hephaestus: Improving Fundamental Agent Capabilities of Large Language Models through Continual Pre-Training](https://arxiv.org/abs/2502.06589) (GIT)
- [ ] [\[2502.06563\] Large Language Models Meet Symbolic Provers for Logical Reasoning Evaluation](https://arxiv.org/abs/2502.06563) (ICLR)
- [ ] [\[2502.06472\] KARMA: Leveraging Multi-Agent LLMs for Automated Knowledge Graph Enrichment](https://arxiv.org/abs/2502.06472) (Peking)
- [ ] [\[2502.06415\] Systematic Outliers in Large Language Models](https://arxiv.org/abs/2502.06415) (IA CAS, ICLR)
- [ ] [\[2502.06282\] Jakiro: Boosting Speculative Decoding with Decoupled Multi-Head via MoE](https://arxiv.org/abs/2502.06282) (XJTU)
- [ ] [\[2502.06258\] Emergent Response Planning in LLM](https://arxiv.org/abs/2502.06258) (Shanghai AI Lab)
- [ ] [\[2502.06204\] Non-literal Understanding of Number Words by Language Models](https://arxiv.org/abs/2502.06204) (University of Tübingen)
- [ ] [\[2502.06150\] Scaling Public Health Text Annotation: Zero-Shot Learning vs. Crowdsourcing for Improved Efficiency and Labeling Accuracy](https://arxiv.org/abs/2502.06150) (University of Toronto)
- [ ] [\[2502.06148\] Optimizing Knowledge Integration in Retrieval-Augmented Generation with Self-Selection](https://arxiv.org/abs/2502.06148) (USTC)
- [ ] [\[2502.06147\] LegalViz: Legal Text Visualization by Text To Diagram Generation](https://arxiv.org/abs/2502.06147) (University of Tokyo)
- [ ] [\[2502.06139\] LCIRC: A Recurrent Compression Approach for Efficient Long-form Context and Query Dependent Modeling in LLMs](https://arxiv.org/abs/2502.06139) (Google)
- [ ] [\[2502.06115\] Task-driven Layerwise Additive Activation Intervention](https://arxiv.org/abs/2502.06115) (CUHK)
- [ ] [\[2502.06065\] Benchmarking Prompt Sensitivity in Large Language Models](https://arxiv.org/abs/2502.06065) (University of Toronto)
- [ ] [\[2502.05911\] GRAIT: Gradient-Driven Refusal-Aware Instruction Tuning for Effective Hallucination Mitigation](https://arxiv.org/abs/2502.05911) (Shanghai AI Lab)
- [ ] [\[2502.05892\] A Distributional Perspective on Word Learning in Neural Language Models](https://arxiv.org/abs/2502.05892) (UCSD)
- [ ] [\[2502.05887\] MTPChat: A Multimodal Time-Aware Persona Dataset for Conversational Agents](https://arxiv.org/abs/2502.05887) (UTS)
- [ ] [\[2502.05878\] Enhancing Financial Time-Series Forecasting with Retrieval-Augmented Large Language Models](https://arxiv.org/abs/2502.05878) (WHU)
- [ ] [\[2502.05867\] Self-Training Large Language Models for Tool-Use Without Demonstrations](https://arxiv.org/abs/2502.05867) (University of Edinburgh)
- [ ] [\[2502.05694\] Zero-Shot End-to-End Relation Extraction in Chinese: A Comparative Study of Gemini, LLaMA and ChatGPT](https://arxiv.org/abs/2502.05694) (UVA.NL)
- [ ] [\[2502.05628\] AnyEdit: Edit Any Knowledge Encoded in Language Models](https://arxiv.org/abs/2502.05628) (USTC)
- [ ] [\[2502.05605\] ARIES: Stimulating Self-Refinement of Large Language Models by Iterative Preference Optimization](https://arxiv.org/abs/2502.05605) (UCL)
- [ ] [\[2502.05567\] ATLAS: Autoformalizing Theorems through Lifting, Augmentation, and Synthesis of Data](https://arxiv.org/abs/2502.05567) (SJTU)
- [ ] [\[2502.05551\] FRAMES: Boosting LLMs with A Four-Quadrant Multi-Stage Pretraining Strategy](https://arxiv.org/abs/2502.05551) (Peking)
- [ ] [\[2502.05478\] OntoTune: Ontology-Driven Self-training for Aligning Large Language Models](https://arxiv.org/abs/2502.05478) (ZJU)
- [ ] [\[2502.05467\] Position: LLMs Can be Good Tutors in Foreign Language Education](https://arxiv.org/abs/2502.05467) (Tsinghua)
- [ ] [\[2502.05424\] SAMGPT: Text-free Graph Foundation Model for Multi-domain Pre-training and Cross-domain Adaptation](https://arxiv.org/abs/2502.05424) (USTC)
- [ ] [\[2502.05400\] Dynamic Noise Preference Optimization for LLM Self-Improvement via Synthetic Data](https://arxiv.org/abs/2502.05400) (NYU)
- [ ] [\[2502.05389\] The Role of Prosody in Spoken Question Answering](https://arxiv.org/abs/2502.05389) (University of Edinburgh)
- [ ] [\[2502.05252\] GSM-Infinite: How Do Your LLMs Behave over Infinitely Increasing Context Length and Reasoning Complexity?](https://arxiv.org/abs/2502.05252) (Meta)
- [ ] [\[2502.05242\] SEER: Self-Explainability Enhancement of Large Language Models' Representations](https://arxiv.org/abs/2502.05242) (Shanghai AI Lab)
- [ ] [\[2502.05196\] LLMs Provide Unstable Answers to Legal Questions](https://arxiv.org/abs/2502.05196) (JHU)
- [ ] [\[2502.06556\] ProjectTest: A Project-level LLM Unit Test Generation Benchmark and Impact of Error Fixing Mechanisms](https://arxiv.org/abs/2502.06556) (Salesforce)
- [ ] [\[2502.06453\] MATH-Perturb: Benchmarking LLMs' Math Reasoning Abilities against Hard Perturbations](https://arxiv.org/abs/2502.06453) (Princeton)
- [ ] [\[2502.06252\] Evaluating Entity Retrieval in Electronic Health Records: a Semantic Gap Perspective](https://arxiv.org/abs/2502.06252) (Tsinghua)
- [ ] [\[2502.06215\] LessLeak-Bench: A First Investigation of Data Leakage in LLMs Across 83 Software Engineering Benchmarks](https://arxiv.org/abs/2502.06215) (WHU)
- [ ] [\[2502.06167\] Universal Approximation of Visual Autoregressive Transformers](https://arxiv.org/abs/2502.06167) (HKU)
- [ ] [\[2502.06130\] Self-Correcting Decoding with Generative Feedback for Mitigating Hallucinations in Large Vision-Language Models](https://arxiv.org/abs/2502.06130) (ICLR)
- [ ] [\[2502.06106\] Circuit-tuning: A Mechanistic Approach for Identifying Parameter Redundancy and Fine-tuning Neural Networks](https://arxiv.org/abs/2502.06106) (BUPT)
- [ ] [\[2502.06101\] RALLRec: Improving Retrieval Augmented Large Language Model Recommendation with Representation Learning](https://arxiv.org/abs/2502.06101) (Tsinghua)
- [ ] [\[2502.06075\] Deconstructing Depression Stigma: Integrating AI-driven Data Collection and Analysis with Causal Knowledge Graphs](https://arxiv.org/abs/2502.06075) (NUS)
- [ ] [\[2502.06060\] Training Language Models for Social Deduction with Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2502.06060) (Stanford)
- [ ] [\[2502.06042\] Scaling Laws for Forgetting during Finetuning with Pretraining Data Injection](https://arxiv.org/abs/2502.06042) (Apple)
- [ ] [\[2502.05425\] Toward Copyright Integrity and Verifiability via Multi-Bit Watermarking for Intelligent Transportation Systems](https://arxiv.org/abs/2502.05425) (BUPT)
- [ ] [\[2502.05234\] Optimizing Temperature for Language Models with Multi-Sample Inference](https://arxiv.org/abs/2502.05234) (CMU)
- [ ] [\[2502.05227\] Robotouille: An Asynchronous Planning Benchmark for LLM Agents](https://arxiv.org/abs/2502.05227) (Cornell)
- [ ] [\[2502.05206\] Safety at Scale: A Comprehensive Survey of Large Model Safety](https://arxiv.org/abs/2502.05206) (Fudan)

## 2025-02-10 (Mon)
- [ ] [\[2502.05163\] DuoGuard: A Two-Player RL-Driven Framework for Multilingual LLM Guardrails](https://arxiv.org/abs/2502.05163) (UCLA)
- [ ] [\[2502.05151\] Transforming Science with Large Language Models: A Survey on AI-assisted Scientific Discovery, Experimentation, Content Generation, and Evaluation](https://arxiv.org/abs/2502.05151) (University of Tübingen)
- [ ] [\[2502.05150\] CodeSCM: Causal Analysis for Multi-Modal Code Generation](https://arxiv.org/abs/2502.05150) (Columbia University)
- [ ] [\[2502.05111\] Flexible and Efficient Grammar-Constrained Decoding](https://arxiv.org/abs/2502.05111) (UCSD)
- [ ] [\[2502.05084\] ChallengeMe: An Adversarial Learning-enabled Text Summarization Framework](https://arxiv.org/abs/2502.05084) (NYU)
- [ ] [\[2502.05036\] nvAgent: Automated Data Visualization from Natural Language via Collaborative Agent Workflow](https://arxiv.org/abs/2502.05036) (HUST)
- [ ] [\[2502.04964\] CoCoA: A Generalized Approach to Uncertainty Quantification by Integrating Confidence and Consistency of LLM Outputs](https://arxiv.org/abs/2502.04964) (MBZUAI)
- [ ] [\[2502.04790\] S$^2$-MAD: Breaking the Token Barrier to Enhance Multi-Agent Debate Efficiency](https://arxiv.org/abs/2502.04790) (HIT)
- [ ] [\[2502.04655\] Before It's Too Late: A State Space Model for the Early Prediction of Misinformation and Disinformation Engagement](https://arxiv.org/abs/2502.04655) (UTS)
- [ ] [\[2502.04625\] Phonetic Reconstruction of the Consonant System of Middle Chinese via Mixed Integer Optimization](https://arxiv.org/abs/2502.04625) (Peking)
- [ ] [\[2502.04602\] Extracting and Understanding the Superficial Knowledge in Alignment](https://arxiv.org/abs/2502.04602) (UT Austin)
- [ ] [\[2502.04564\] My LLM might Mimic AAE -- But When Should it?](https://arxiv.org/abs/2502.04564) (UMD)
- [ ] [\[2502.04537\] Multilingual Non-Autoregressive Machine Translation without Knowledge Distillation](https://arxiv.org/abs/2502.04537) (University of Alberta)
- [ ] [\[2502.04535\] A Decoding Algorithm for Length-Control Summarization Based on Directed Acyclic Transformers](https://arxiv.org/abs/2502.04535) (University of Alberta)
- [ ] [\[2502.04528\] Group-Adaptive Threshold Optimization for Robust AI-Generated Text Detection](https://arxiv.org/abs/2502.04528) (MIT)
- [ ] [\[2502.04520\] Linear Correlation in LM's Compositional Generalization and Hallucination](https://arxiv.org/abs/2502.04520) (UCSD)
- [ ] [\[2502.04510\] Heterogeneous Swarms: Jointly Optimizing Model Roles and Weights for Multi-LLM Systems](https://arxiv.org/abs/2502.04510) (Google)
- [ ] [\[2502.04488\] Building A Unified AI-centric Language System: analysis, framework and future work](https://arxiv.org/abs/2502.04488) (Harvard)
- [ ] [\[2502.04413\] MedRAG: Enhancing Retrieval-augmented Generation with Knowledge Graph-Elicited Reasoning for Healthcare Copilot](https://arxiv.org/abs/2502.04413) (NTU)
- [ ] [\[2502.04394\] DECT: Harnessing LLM-assisted Fine-Grained Linguistic Knowledge and Label-Switched and Label-Preserved Data Generation for Diagnosis of Alzheimer's Disease](https://arxiv.org/abs/2502.04394) (CUHK)
- [ ] [\[2502.04392\] Division-of-Thoughts: Harnessing Hybrid Language Model Synergy for Efficient On-Device Agents](https://arxiv.org/abs/2502.04392) (Tsinghua)
- [ ] [\[2502.04382\] Sparse Autoencoders for Hypothesis Generation](https://arxiv.org/abs/2502.04382) (Berkeley)
- [ ] [\[2502.04380\] Diversity as a Reward: Fine-Tuning LLMs on a Mixture of Domain-Undetermined Data](https://arxiv.org/abs/2502.04380) (SYSU)
- [ ] [\[2502.04375\] An Analysis for Reasoning Bias of Language Models with Small Initialization](https://arxiv.org/abs/2502.04375) (SJTU)
- [ ] [\[2502.04359\] Exploring Spatial Language Grounding Through Referring Expressions](https://arxiv.org/abs/2502.04359) (UCSD)
- [ ] [\[2502.04357\] Reusing Embeddings: Reproducible Reward Model Research in Large Language Model Alignment without GPUs](https://arxiv.org/abs/2502.04357) (Cambridge)
- [ ] [\[2502.04354\] Reviving The Classics: Active Reward Modeling in Large Language Model Alignment](https://arxiv.org/abs/2502.04354) (MIT)
- [ ] [\[2502.04352\] Investigating the Robustness of Deductive Reasoning with Large Language Models](https://arxiv.org/abs/2502.04352) (UVA.NL)
- [ ] [\[2502.04350\] CodeSteer: Symbolic-Augmented Language Models via Code/Text Guidance](https://arxiv.org/abs/2502.04350) (Harvard)
- [ ] [\[2502.04345\] JingFang: A Traditional Chinese Medicine Large Language Model of Expert-Level Medical Diagnosis and Syndrome Differentiation-Based Treatment](https://arxiv.org/abs/2502.04345) (BUPT)
- [ ] [\[2502.05172\] Joint MoE Scaling Laws: Mixture of Experts Can Be Memory Efficient](https://arxiv.org/abs/2502.05172) (UW)
- [ ] [\[2502.05171\] Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach](https://arxiv.org/abs/2502.05171) (UMD)
- [ ] [\[2502.05159\] A Lightweight Method to Disrupt Memorized Sequences in LLM](https://arxiv.org/abs/2502.05159) (UCSD)
- [ ] [\[2502.05087\] Mitigating Unintended Memorization with LoRA in Federated Learning for LLMs](https://arxiv.org/abs/2502.05087) (EPFL)
- [ ] [\[2502.04751\] Holistically Guided Monte Carlo Tree Search for Intricate Information Seeking](https://arxiv.org/abs/2502.04751) (NUS)
- [ ] [\[2502.04643\] Confidence Elicitation: A New Attack Vector for Large Language Models](https://arxiv.org/abs/2502.04643) (A*STAR,, ICLR)
- [ ] [\[2502.04576\] Self-Regulation and Requesting Interventions](https://arxiv.org/abs/2502.04576) (CMU)
- [ ] [\[2502.04463\] Training Language Models to Reason Efficiently](https://arxiv.org/abs/2502.04463) (CMU)
- [ ] [\[2502.04420\] KVTuner: Sensitivity-Aware Layer-wise Mixed Precision KV Cache Quantization for Efficient and Nearly Lossless LLM Inference](https://arxiv.org/abs/2502.04420) (CUHK)
- [ ] [\[2502.04419\] Understanding and Mitigating the Bias Inheritance in LLM-based Data Augmentation on Downstream Tasks](https://arxiv.org/abs/2502.04419) (CMU)
- [ ] [\[2502.04412\] Decoder-Only LLMs are Better Controllers for Diffusion Models](https://arxiv.org/abs/2502.04412) (SYSU)
- [ ] [\[2502.04371\] PerPO: Perceptual Preference Optimization via Discriminative Rewarding](https://arxiv.org/abs/2502.04371) (UCAS)

## 2025-02-07 (Fri)
- [ ] [\[2502.04314\] BOUQuET: dataset, Benchmark and Open initiative for Universal Quality Evaluation in Translation](https://arxiv.org/abs/2502.04314) (Meta)
- [ ] [\[2502.04295\] Beyond Prompt Content: Enhancing LLM Performance via Content-Format Integrated Prompt Optimization](https://arxiv.org/abs/2502.04295) (Microsoft)
- [ ] [\[2502.04234\] A Classification System Approach in Predicting Chinese Censorship](https://arxiv.org/abs/2502.04234) (NYU)
- [ ] [\[2502.04194\] The Best Instruction-Tuning Data are Those That Fit](https://arxiv.org/abs/2502.04194) (Illinois)
- [ ] [\[2502.04153\] UltraIF: Advancing Instruction Following from the Wild](https://arxiv.org/abs/2502.04153) (Shanghai AI Lab)
- [ ] [\[2502.04134\] The Order Effect: Investigating Prompt Sensitivity in Closed-Source LLMs](https://arxiv.org/abs/2502.04134) (Berkeley)
- [ ] [\[2502.04077\] AttentionPredictor: Temporal Pattern Matters for Efficient LLM Inference](https://arxiv.org/abs/2502.04077) (USTC)
- [ ] [\[2502.04075\] Controllable Emotion Generation with Emotion Vectors](https://arxiv.org/abs/2502.04075) (Fudan)
- [ ] [\[2502.04066\] Predicting Large Language Model Capabilities on Closed-Book QA Tasks Using Only Information Available Prior to Training](https://arxiv.org/abs/2502.04066) (Fudan)
- [ ] [\[2502.04037\] Exploring Imbalanced Annotations for Effective In-Context Learning](https://arxiv.org/abs/2502.04037) (SUSTech)
- [ ] [\[2502.03860\] BOLT: Bootstrap Long Chain-of-Thought in Language Models without Distillation](https://arxiv.org/abs/2502.03860) (Salesforce)
- [ ] [\[2502.03805\] Identify Critical KV Cache in LLM Inference from an Output Perturbation Perspective](https://arxiv.org/abs/2502.03805) (USTC)
- [ ] [\[2502.03708\] Aggregate and conquer: detecting and steering LLM concepts by combining nonlinear predictors over multiple layers](https://arxiv.org/abs/2502.03708) (UCSD)
- [ ] [\[2502.03699\] LLM Alignment as Retriever Optimization: An Information Retrieval Perspective](https://arxiv.org/abs/2502.03699) (Illinois)
- [ ] [\[2502.03688\] A Comparison of DeepSeek and Other LLMs](https://arxiv.org/abs/2502.03688) (CMU)
- [ ] [\[2502.03678\] Reflection-Window Decoding: Text Generation with Selective Refinement](https://arxiv.org/abs/2502.03678) (CMU)
- [ ] [\[2502.03647\] Looking for the Inner Music: Probing LLMs' Understanding of Literary Style](https://arxiv.org/abs/2502.03647) (Cornell)
- [ ] [\[2502.04128\] Llasa: Scaling Train-Time and Inference-Time Compute for Llama-based Speech Synthesis](https://arxiv.org/abs/2502.04128) (HKUST)
- [ ] [\[2502.04040\] Leveraging Reasoning with Guidelines to Elicit and Utilize Knowledge for Enhancing Safety Alignment](https://arxiv.org/abs/2502.04040) (HKUST)
- [ ] [\[2502.03948\] Enhancing Online Learning Efficiency Through Heterogeneous Resource Integration with a Multi-Agent RAG System](https://arxiv.org/abs/2502.03948) (TUM)
- [ ] [\[2502.03692\] DocMIA: Document-Level Membership Inference Attacks against DocVQA Models](https://arxiv.org/abs/2502.03692) (ICLR)
- [ ] [\[2501.16207\] From Informal to Formal -- Incorporating and Evaluating LLMs on Natural Language Requirements to Verifiable Formal Proofs](https://arxiv.org/abs/2501.16207) (HKUST)
- [ ] [\[2501.10711\] How Should I Build A Benchmark? Revisiting Code-Related Benchmarks For LLMs](https://arxiv.org/abs/2501.10711) (HKUST)

## 2025-02-06 (Thu)
- [ ] [\[2502.03397\] SPRI: Aligning Large Language Models with Context-Situated Principles](https://arxiv.org/abs/2502.03397) (UT Austin)
- [ ] [\[2502.03373\] Demystifying Long Chain-of-Thought Reasoning in LLMs](https://arxiv.org/abs/2502.03373) (CMU)
- [ ] [\[2502.03358\] Minerva: A Programmable Memory Test Benchmark for Language Models](https://arxiv.org/abs/2502.03358) (Microsoft)
- [ ] [\[2502.03199\] Improve Decoding Factuality by Token-wise Cross Layer Entropy of Large Language Models](https://arxiv.org/abs/2502.03199) (HIT)
- [ ] [\[2502.03147\] Scalable In-Context Learning on Tabular Data via Retrieval-Augmented Large Language Models](https://arxiv.org/abs/2502.03147) (Microsoft)
- [ ] [\[2502.03080\] IAO Prompting: Making Knowledge Flow Explicit in LLMs through Structured Reasoning Templates](https://arxiv.org/abs/2502.03080) (UCL)
- [ ] [\[2502.03034\] Knowledge Distillation from Large Language Models for Household Energy Modeling](https://arxiv.org/abs/2502.03034) (MBZUAI)
- [ ] [\[2502.02988\] Training an LLM-as-a-Judge Model: Pipeline, Insights, and Practical Lessons](https://arxiv.org/abs/2502.02988) (Alibaba)
- [ ] [\[2502.02896\] A Benchmark for the Detection of Metalinguistic Disagreements between LLMs and Knowledge Graphs](https://arxiv.org/abs/2502.02896) (UVA.NL)
- [ ] [\[2502.02871\] Position: Multimodal Large Language Models Can Significantly Advance Scientific Reasoning](https://arxiv.org/abs/2502.02871) (HKUST(GZ))
- [ ] [\[2502.02696\] How Inclusively do LMs Perceive Social and Moral Norms?](https://arxiv.org/abs/2502.02696) (GIT)
- [ ] [\[2502.02672\] Transformers Boost the Performance of Decision Trees on Tabular Data across Sample Sizes](https://arxiv.org/abs/2502.02672) (UMD)
- [ ] [\[2502.02659\] A Training-Free Length Extrapolation Approach for LLMs: Greedy Attention Logit Interpolation (GALI)](https://arxiv.org/abs/2502.02659) (USyd)
- [ ] [\[2502.03283\] SymAgent: A Neural-Symbolic Self-Learning Agent Framework for Complex Reasoning over Knowledge Graphs](https://arxiv.org/abs/2502.03283) (WHU)
- [ ] [\[2502.02770\] Twilight: Adaptive Attention Sparsity with Hierarchical Top-$p$ Pruning](https://arxiv.org/abs/2502.02770) (Tsinghua)
- [ ] [\[2502.02732\] Peri-LN: Revisiting Layer Normalization in the Transformer Architecture](https://arxiv.org/abs/2502.02732) (KAIST)