
## 2025-02-12 (Wed)
- [ ] [\[2502.07776\] Auditing Prompt Caching in Language Model APIs](https://arxiv.org/abs/2502.07776) (Stanford)
- [ ] [\[2502.07616\] Tractable Transformers for Flexible Conditional Generation](https://arxiv.org/abs/2502.07616) (UCLA)
- [ ] [\[2502.07586\] We Can't Understand AI Using our Existing Vocabulary](https://arxiv.org/abs/2502.07586) (Google)
- [ ] [\[2502.07555\] O1 Embedder: Let Retrievers Think Before Action](https://arxiv.org/abs/2502.07555) (USTC)
- [ ] [\[2502.07544\] Grammar Control in Dialogue Response Generation for Language Learning Chatbots](https://arxiv.org/abs/2502.07544) (EPFL)
- [ ] [\[2502.07541\] Corporate Greenwashing Detection in Text - a Survey](https://arxiv.org/abs/2502.07541) (Inria)
- [ ] [\[2502.07490\] Mask-Enhanced Autoregressive Prediction: Pay Less Attention to Learn More](https://arxiv.org/abs/2502.07490) (Oxford)
- [ ] [\[2502.07365\] LongReD: Mitigating Short-Text Degradation of Long-Context Large Language Models via Restoration Distillation](https://arxiv.org/abs/2502.07365) (NUS)
- [ ] [\[2502.07346\] BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models](https://arxiv.org/abs/2502.07346) (NJU)
- [ ] [\[2502.07316\] CodeI/O: Condensing Reasoning Patterns via Code Input-Output Prediction](https://arxiv.org/abs/2502.07316) (HKUST)
- [ ] [\[2502.07272\] GENERator: A Long-Context Generative Genomic Foundation Model](https://arxiv.org/abs/2502.07272) (Alibaba)
- [ ] [\[2502.07184\] Refine Knowledge of Large Language Models via Adaptive Contrastive Learning](https://arxiv.org/abs/2502.07184) (Tsinghua, ICLR)
- [ ] [\[2502.07131\] TWICE: What Advantages Can Low-Resource Domain-Specific Embedding Model Bring? - A Case Study on Korea Financial Texts](https://arxiv.org/abs/2502.07131) (ICLR)
- [ ] [\[2502.07101\] SMAB: MAB based word Sensitivity Estimation Framework and its Applications in Adversarial Text Generation](https://arxiv.org/abs/2502.07101) (MBZUAI)
- [ ] [\[2502.07077\] Multi-turn Evaluation of Anthropomorphic Behaviours in Large Language Models](https://arxiv.org/abs/2502.07077) (Oxford)
- [ ] [\[2502.07068\] Specializing Large Language Models to Simulate Survey Response Distributions for Global Populations](https://arxiv.org/abs/2502.07068) (University of Copenhagen)
- [ ] [\[2502.07022\] AIMS.au: A Dataset for the Analysis of Modern Slavery Countermeasures in Corporate Statements](https://arxiv.org/abs/2502.07022) (ICLR)
- [ ] [\[2502.07004\] Demystifying Singular Defects in Large Language Models](https://arxiv.org/abs/2502.07004) (EPFL)
- [ ] [\[2502.06990\] Investigating the Zone of Proximal Development of Language Models for In-Context Learning](https://arxiv.org/abs/2502.06990) (ETH)
- [ ] [\[2502.06882\] Multi-Agent Simulator Drives Language Models for Legal Intensive Interaction](https://arxiv.org/abs/2502.06882) (Fudan)
- [ ] [\[2502.06874\] Group Reasoning Emission Estimation Networks](https://arxiv.org/abs/2502.06874) (USyd)
- [ ] [\[2502.06872\] Towards Trustworthy Retrieval Augmented Generation for Large Language Models: A Survey](https://arxiv.org/abs/2502.06872) (PolyU)
- [ ] [\[2502.06864\] Knowledge Graph-Guided Retrieval Augmented Generation](https://arxiv.org/abs/2502.06864) (NJU)
- [ ] [\[2502.07663\] Human Decision-making is Susceptible to AI-driven Manipulation](https://arxiv.org/abs/2502.07663) (HKU)
- [ ] [\[2502.07563\] LASP-2: Rethinking Sequence Parallelism for Linear Attention and Its Hybrid](https://arxiv.org/abs/2502.07563) (CUHK)
- [ ] [\[2502.07263\] Hidden Division of Labor in Scientific Teams Revealed Through 1.6 Million LaTeX Files](https://arxiv.org/abs/2502.07263) (Stanford)
- [ ] [\[2502.07088\] Kernels of Selfhood: GPT-4o shows humanlike patterns of cognitive consistency moderated by free choice](https://arxiv.org/abs/2502.07088) (BU)
- [ ] [\[2502.06994\] SyncMind: Measuring Agent Out-of-Sync Recovery in Collaborative Software Engineering](https://arxiv.org/abs/2502.06994) (Illinois)
- [ ] [\[2502.06901\] Enabling Autoregressive Models to Fill In Masked Tokens](https://arxiv.org/abs/2502.06901) (UCLA)
- [ ] [\[2502.06875\] Beyond Vision: How Large Language Models Interpret Facial Expressions from Valence-Arousal Values](https://arxiv.org/abs/2502.06875) (Cambridge)
- [ ] [\[2502.06802\] Solving the Content Gap in Roblox Game Recommendations: LLM-Based Profile Generation and Reranking](https://arxiv.org/abs/2502.06802) (Columbia University)

## 2025-02-11 (Tue)
- [ ] <5>[\[2502.06772\] ReasonFlux: Hierarchical LLM Reasoning via Scaling Thought Templates](https://arxiv.org/abs/2502.06772) (Princeton)
- [ ] [\[2502.06766\] Exploiting Sparsity for Long Context Inference: Million Token Contexts on Commodity GPUs](https://arxiv.org/abs/2502.06766) (UMD)
- [ ] [\[2502.06703\] Can 1B LLM Surpass 405B LLM? Rethinking Compute-Optimal Test-Time Scaling](https://arxiv.org/abs/2502.06703) (Shanghai AI Lab)
- [ ] [\[2502.06669\] Boosting Self-Efficacy and Performance of Large Language Models via Verbal Efficacy Stimulations](https://arxiv.org/abs/2502.06669) (UCAS)
- [ ] [\[2502.06635\] Steel-LLM:From Scratch to Open Source -- A Personal Journey in Building a Chinese-Centric LLM](https://arxiv.org/abs/2502.06635) (BUPT)
- [ ] [\[2502.06604\] Do we really have to filter out random noise in pre-training data for language models?](https://arxiv.org/abs/2502.06604) (Peking)
- [ ] [\[2502.06589\] Hephaestus: Improving Fundamental Agent Capabilities of Large Language Models through Continual Pre-Training](https://arxiv.org/abs/2502.06589) (GIT)
- [ ] [\[2502.06563\] Large Language Models Meet Symbolic Provers for Logical Reasoning Evaluation](https://arxiv.org/abs/2502.06563) (ICLR)
- [ ] [\[2502.06472\] KARMA: Leveraging Multi-Agent LLMs for Automated Knowledge Graph Enrichment](https://arxiv.org/abs/2502.06472) (Peking)
- [ ] [\[2502.06415\] Systematic Outliers in Large Language Models](https://arxiv.org/abs/2502.06415) (IA CAS, ICLR)
- [ ] [\[2502.06282\] Jakiro: Boosting Speculative Decoding with Decoupled Multi-Head via MoE](https://arxiv.org/abs/2502.06282) (XJTU)
- [ ] [\[2502.06258\] Emergent Response Planning in LLM](https://arxiv.org/abs/2502.06258) (Shanghai AI Lab)
- [ ] [\[2502.06204\] Non-literal Understanding of Number Words by Language Models](https://arxiv.org/abs/2502.06204) (University of Tübingen)
- [ ] [\[2502.06150\] Scaling Public Health Text Annotation: Zero-Shot Learning vs. Crowdsourcing for Improved Efficiency and Labeling Accuracy](https://arxiv.org/abs/2502.06150) (University of Toronto)
- [ ] [\[2502.06148\] Optimizing Knowledge Integration in Retrieval-Augmented Generation with Self-Selection](https://arxiv.org/abs/2502.06148) (USTC)
- [ ] [\[2502.06147\] LegalViz: Legal Text Visualization by Text To Diagram Generation](https://arxiv.org/abs/2502.06147) (University of Tokyo)
- [ ] [\[2502.06139\] LCIRC: A Recurrent Compression Approach for Efficient Long-form Context and Query Dependent Modeling in LLMs](https://arxiv.org/abs/2502.06139) (Google)
- [ ] [\[2502.06115\] Task-driven Layerwise Additive Activation Intervention](https://arxiv.org/abs/2502.06115) (CUHK)
- [ ] [\[2502.06065\] Benchmarking Prompt Sensitivity in Large Language Models](https://arxiv.org/abs/2502.06065) (University of Toronto)
- [ ] [\[2502.05911\] GRAIT: Gradient-Driven Refusal-Aware Instruction Tuning for Effective Hallucination Mitigation](https://arxiv.org/abs/2502.05911) (Shanghai AI Lab)
- [ ] [\[2502.05892\] A Distributional Perspective on Word Learning in Neural Language Models](https://arxiv.org/abs/2502.05892) (UCSD)
- [ ] [\[2502.05887\] MTPChat: A Multimodal Time-Aware Persona Dataset for Conversational Agents](https://arxiv.org/abs/2502.05887) (UTS)
- [ ] [\[2502.05878\] Enhancing Financial Time-Series Forecasting with Retrieval-Augmented Large Language Models](https://arxiv.org/abs/2502.05878) (WHU)
- [ ] [\[2502.05867\] Self-Training Large Language Models for Tool-Use Without Demonstrations](https://arxiv.org/abs/2502.05867) (University of Edinburgh)
- [ ] [\[2502.05694\] Zero-Shot End-to-End Relation Extraction in Chinese: A Comparative Study of Gemini, LLaMA and ChatGPT](https://arxiv.org/abs/2502.05694) (UVA.NL)
- [ ] [\[2502.05628\] AnyEdit: Edit Any Knowledge Encoded in Language Models](https://arxiv.org/abs/2502.05628) (USTC)
- [ ] [\[2502.05605\] ARIES: Stimulating Self-Refinement of Large Language Models by Iterative Preference Optimization](https://arxiv.org/abs/2502.05605) (UCL)
- [ ] [\[2502.05567\] ATLAS: Autoformalizing Theorems through Lifting, Augmentation, and Synthesis of Data](https://arxiv.org/abs/2502.05567) (SJTU)
- [ ] [\[2502.05551\] FRAMES: Boosting LLMs with A Four-Quadrant Multi-Stage Pretraining Strategy](https://arxiv.org/abs/2502.05551) (Peking)
- [ ] [\[2502.05478\] OntoTune: Ontology-Driven Self-training for Aligning Large Language Models](https://arxiv.org/abs/2502.05478) (ZJU)
- [ ] [\[2502.05467\] Position: LLMs Can be Good Tutors in Foreign Language Education](https://arxiv.org/abs/2502.05467) (Tsinghua)
- [ ] [\[2502.05424\] SAMGPT: Text-free Graph Foundation Model for Multi-domain Pre-training and Cross-domain Adaptation](https://arxiv.org/abs/2502.05424) (USTC)
- [ ] [\[2502.05400\] Dynamic Noise Preference Optimization for LLM Self-Improvement via Synthetic Data](https://arxiv.org/abs/2502.05400) (NYU)
- [ ] [\[2502.05389\] The Role of Prosody in Spoken Question Answering](https://arxiv.org/abs/2502.05389) (University of Edinburgh)
- [ ] [\[2502.05252\] GSM-Infinite: How Do Your LLMs Behave over Infinitely Increasing Context Length and Reasoning Complexity?](https://arxiv.org/abs/2502.05252) (Meta)
- [ ] [\[2502.05242\] SEER: Self-Explainability Enhancement of Large Language Models' Representations](https://arxiv.org/abs/2502.05242) (Shanghai AI Lab)
- [ ] [\[2502.05196\] LLMs Provide Unstable Answers to Legal Questions](https://arxiv.org/abs/2502.05196) (JHU)
- [ ] [\[2502.06556\] ProjectTest: A Project-level LLM Unit Test Generation Benchmark and Impact of Error Fixing Mechanisms](https://arxiv.org/abs/2502.06556) (Salesforce)
- [ ] [\[2502.06453\] MATH-Perturb: Benchmarking LLMs' Math Reasoning Abilities against Hard Perturbations](https://arxiv.org/abs/2502.06453) (Princeton)
- [ ] [\[2502.06252\] Evaluating Entity Retrieval in Electronic Health Records: a Semantic Gap Perspective](https://arxiv.org/abs/2502.06252) (Tsinghua)
- [ ] [\[2502.06215\] LessLeak-Bench: A First Investigation of Data Leakage in LLMs Across 83 Software Engineering Benchmarks](https://arxiv.org/abs/2502.06215) (WHU)
- [ ] [\[2502.06167\] Universal Approximation of Visual Autoregressive Transformers](https://arxiv.org/abs/2502.06167) (HKU)
- [ ] [\[2502.06130\] Self-Correcting Decoding with Generative Feedback for Mitigating Hallucinations in Large Vision-Language Models](https://arxiv.org/abs/2502.06130) (ICLR)
- [ ] [\[2502.06106\] Circuit-tuning: A Mechanistic Approach for Identifying Parameter Redundancy and Fine-tuning Neural Networks](https://arxiv.org/abs/2502.06106) (BUPT)
- [ ] [\[2502.06101\] RALLRec: Improving Retrieval Augmented Large Language Model Recommendation with Representation Learning](https://arxiv.org/abs/2502.06101) (Tsinghua)
- [ ] [\[2502.06075\] Deconstructing Depression Stigma: Integrating AI-driven Data Collection and Analysis with Causal Knowledge Graphs](https://arxiv.org/abs/2502.06075) (NUS)
- [ ] [\[2502.06060\] Training Language Models for Social Deduction with Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2502.06060) (Stanford)
- [ ] [\[2502.06042\] Scaling Laws for Forgetting during Finetuning with Pretraining Data Injection](https://arxiv.org/abs/2502.06042) (Apple)
- [ ] [\[2502.05425\] Toward Copyright Integrity and Verifiability via Multi-Bit Watermarking for Intelligent Transportation Systems](https://arxiv.org/abs/2502.05425) (BUPT)
- [ ] [\[2502.05234\] Optimizing Temperature for Language Models with Multi-Sample Inference](https://arxiv.org/abs/2502.05234) (CMU)
- [ ] [\[2502.05227\] Robotouille: An Asynchronous Planning Benchmark for LLM Agents](https://arxiv.org/abs/2502.05227) (Cornell)
- [ ] [\[2502.05206\] Safety at Scale: A Comprehensive Survey of Large Model Safety](https://arxiv.org/abs/2502.05206) (Fudan)

## 2025-02-10 (Mon)
- [ ] [\[2502.05163\] DuoGuard: A Two-Player RL-Driven Framework for Multilingual LLM Guardrails](https://arxiv.org/abs/2502.05163) (UCLA)
- [ ] [\[2502.05151\] Transforming Science with Large Language Models: A Survey on AI-assisted Scientific Discovery, Experimentation, Content Generation, and Evaluation](https://arxiv.org/abs/2502.05151) (University of Tübingen)
- [ ] [\[2502.05150\] CodeSCM: Causal Analysis for Multi-Modal Code Generation](https://arxiv.org/abs/2502.05150) (Columbia University)
- [ ] [\[2502.05111\] Flexible and Efficient Grammar-Constrained Decoding](https://arxiv.org/abs/2502.05111) (UCSD)
- [ ] [\[2502.05084\] ChallengeMe: An Adversarial Learning-enabled Text Summarization Framework](https://arxiv.org/abs/2502.05084) (NYU)
- [ ] [\[2502.05036\] nvAgent: Automated Data Visualization from Natural Language via Collaborative Agent Workflow](https://arxiv.org/abs/2502.05036) (HUST)
- [ ] [\[2502.04964\] CoCoA: A Generalized Approach to Uncertainty Quantification by Integrating Confidence and Consistency of LLM Outputs](https://arxiv.org/abs/2502.04964) (MBZUAI)
- [ ] [\[2502.04790\] S$^2$-MAD: Breaking the Token Barrier to Enhance Multi-Agent Debate Efficiency](https://arxiv.org/abs/2502.04790) (HIT)
- [ ] [\[2502.04655\] Before It's Too Late: A State Space Model for the Early Prediction of Misinformation and Disinformation Engagement](https://arxiv.org/abs/2502.04655) (UTS)
- [ ] [\[2502.04625\] Phonetic Reconstruction of the Consonant System of Middle Chinese via Mixed Integer Optimization](https://arxiv.org/abs/2502.04625) (Peking)
- [ ] [\[2502.04602\] Extracting and Understanding the Superficial Knowledge in Alignment](https://arxiv.org/abs/2502.04602) (UT Austin)
- [ ] [\[2502.04564\] My LLM might Mimic AAE -- But When Should it?](https://arxiv.org/abs/2502.04564) (UMD)
- [ ] [\[2502.04537\] Multilingual Non-Autoregressive Machine Translation without Knowledge Distillation](https://arxiv.org/abs/2502.04537) (University of Alberta)
- [ ] [\[2502.04535\] A Decoding Algorithm for Length-Control Summarization Based on Directed Acyclic Transformers](https://arxiv.org/abs/2502.04535) (University of Alberta)
- [ ] [\[2502.04528\] Group-Adaptive Threshold Optimization for Robust AI-Generated Text Detection](https://arxiv.org/abs/2502.04528) (MIT)
- [ ] [\[2502.04520\] Linear Correlation in LM's Compositional Generalization and Hallucination](https://arxiv.org/abs/2502.04520) (UCSD)
- [ ] [\[2502.04510\] Heterogeneous Swarms: Jointly Optimizing Model Roles and Weights for Multi-LLM Systems](https://arxiv.org/abs/2502.04510) (Google)
- [ ] [\[2502.04488\] Building A Unified AI-centric Language System: analysis, framework and future work](https://arxiv.org/abs/2502.04488) (Harvard)
- [ ] [\[2502.04413\] MedRAG: Enhancing Retrieval-augmented Generation with Knowledge Graph-Elicited Reasoning for Healthcare Copilot](https://arxiv.org/abs/2502.04413) (NTU)
- [ ] [\[2502.04394\] DECT: Harnessing LLM-assisted Fine-Grained Linguistic Knowledge and Label-Switched and Label-Preserved Data Generation for Diagnosis of Alzheimer's Disease](https://arxiv.org/abs/2502.04394) (CUHK)
- [ ] [\[2502.04392\] Division-of-Thoughts: Harnessing Hybrid Language Model Synergy for Efficient On-Device Agents](https://arxiv.org/abs/2502.04392) (Tsinghua)
- [ ] [\[2502.04382\] Sparse Autoencoders for Hypothesis Generation](https://arxiv.org/abs/2502.04382) (Berkeley)
- [ ] [\[2502.04380\] Diversity as a Reward: Fine-Tuning LLMs on a Mixture of Domain-Undetermined Data](https://arxiv.org/abs/2502.04380) (SYSU)
- [ ] [\[2502.04375\] An Analysis for Reasoning Bias of Language Models with Small Initialization](https://arxiv.org/abs/2502.04375) (SJTU)
- [ ] [\[2502.04359\] Exploring Spatial Language Grounding Through Referring Expressions](https://arxiv.org/abs/2502.04359) (UCSD)
- [ ] [\[2502.04357\] Reusing Embeddings: Reproducible Reward Model Research in Large Language Model Alignment without GPUs](https://arxiv.org/abs/2502.04357) (Cambridge)
- [ ] [\[2502.04354\] Reviving The Classics: Active Reward Modeling in Large Language Model Alignment](https://arxiv.org/abs/2502.04354) (MIT)
- [ ] [\[2502.04352\] Investigating the Robustness of Deductive Reasoning with Large Language Models](https://arxiv.org/abs/2502.04352) (UVA.NL)
- [ ] [\[2502.04350\] CodeSteer: Symbolic-Augmented Language Models via Code/Text Guidance](https://arxiv.org/abs/2502.04350) (Harvard)
- [ ] [\[2502.04345\] JingFang: A Traditional Chinese Medicine Large Language Model of Expert-Level Medical Diagnosis and Syndrome Differentiation-Based Treatment](https://arxiv.org/abs/2502.04345) (BUPT)
- [ ] [\[2502.05172\] Joint MoE Scaling Laws: Mixture of Experts Can Be Memory Efficient](https://arxiv.org/abs/2502.05172) (UW)
- [ ] [\[2502.05171\] Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach](https://arxiv.org/abs/2502.05171) (UMD)
- [ ] [\[2502.05159\] A Lightweight Method to Disrupt Memorized Sequences in LLM](https://arxiv.org/abs/2502.05159) (UCSD)
- [ ] [\[2502.05087\] Mitigating Unintended Memorization with LoRA in Federated Learning for LLMs](https://arxiv.org/abs/2502.05087) (EPFL)
- [ ] [\[2502.04751\] Holistically Guided Monte Carlo Tree Search for Intricate Information Seeking](https://arxiv.org/abs/2502.04751) (NUS)
- [ ] [\[2502.04643\] Confidence Elicitation: A New Attack Vector for Large Language Models](https://arxiv.org/abs/2502.04643) (A*STAR,, ICLR)
- [ ] [\[2502.04576\] Self-Regulation and Requesting Interventions](https://arxiv.org/abs/2502.04576) (CMU)
- [ ] [\[2502.04463\] Training Language Models to Reason Efficiently](https://arxiv.org/abs/2502.04463) (CMU)
- [ ] [\[2502.04420\] KVTuner: Sensitivity-Aware Layer-wise Mixed Precision KV Cache Quantization for Efficient and Nearly Lossless LLM Inference](https://arxiv.org/abs/2502.04420) (CUHK)
- [ ] [\[2502.04419\] Understanding and Mitigating the Bias Inheritance in LLM-based Data Augmentation on Downstream Tasks](https://arxiv.org/abs/2502.04419) (CMU)
- [ ] [\[2502.04412\] Decoder-Only LLMs are Better Controllers for Diffusion Models](https://arxiv.org/abs/2502.04412) (SYSU)
- [ ] [\[2502.04371\] PerPO: Perceptual Preference Optimization via Discriminative Rewarding](https://arxiv.org/abs/2502.04371) (UCAS)

## 2025-02-07 (Fri)
- [ ] [\[2502.04314\] BOUQuET: dataset, Benchmark and Open initiative for Universal Quality Evaluation in Translation](https://arxiv.org/abs/2502.04314) (Meta)
- [ ] [\[2502.04295\] Beyond Prompt Content: Enhancing LLM Performance via Content-Format Integrated Prompt Optimization](https://arxiv.org/abs/2502.04295) (Microsoft)
- [ ] [\[2502.04234\] A Classification System Approach in Predicting Chinese Censorship](https://arxiv.org/abs/2502.04234) (NYU)
- [ ] [\[2502.04194\] The Best Instruction-Tuning Data are Those That Fit](https://arxiv.org/abs/2502.04194) (Illinois)
- [ ] [\[2502.04153\] UltraIF: Advancing Instruction Following from the Wild](https://arxiv.org/abs/2502.04153) (Shanghai AI Lab)
- [ ] [\[2502.04134\] The Order Effect: Investigating Prompt Sensitivity in Closed-Source LLMs](https://arxiv.org/abs/2502.04134) (Berkeley)
- [ ] [\[2502.04077\] AttentionPredictor: Temporal Pattern Matters for Efficient LLM Inference](https://arxiv.org/abs/2502.04077) (USTC)
- [ ] [\[2502.04075\] Controllable Emotion Generation with Emotion Vectors](https://arxiv.org/abs/2502.04075) (Fudan)
- [ ] [\[2502.04066\] Predicting Large Language Model Capabilities on Closed-Book QA Tasks Using Only Information Available Prior to Training](https://arxiv.org/abs/2502.04066) (Fudan)
- [ ] [\[2502.04037\] Exploring Imbalanced Annotations for Effective In-Context Learning](https://arxiv.org/abs/2502.04037) (SUSTech)
- [ ] [\[2502.03860\] BOLT: Bootstrap Long Chain-of-Thought in Language Models without Distillation](https://arxiv.org/abs/2502.03860) (Salesforce)
- [ ] [\[2502.03805\] Identify Critical KV Cache in LLM Inference from an Output Perturbation Perspective](https://arxiv.org/abs/2502.03805) (USTC)
- [ ] [\[2502.03708\] Aggregate and conquer: detecting and steering LLM concepts by combining nonlinear predictors over multiple layers](https://arxiv.org/abs/2502.03708) (UCSD)
- [ ] [\[2502.03699\] LLM Alignment as Retriever Optimization: An Information Retrieval Perspective](https://arxiv.org/abs/2502.03699) (Illinois)
- [ ] [\[2502.03688\] A Comparison of DeepSeek and Other LLMs](https://arxiv.org/abs/2502.03688) (CMU)
- [ ] [\[2502.03678\] Reflection-Window Decoding: Text Generation with Selective Refinement](https://arxiv.org/abs/2502.03678) (CMU)
- [ ] [\[2502.03647\] Looking for the Inner Music: Probing LLMs' Understanding of Literary Style](https://arxiv.org/abs/2502.03647) (Cornell)
- [ ] [\[2502.04128\] Llasa: Scaling Train-Time and Inference-Time Compute for Llama-based Speech Synthesis](https://arxiv.org/abs/2502.04128) (HKUST)
- [ ] [\[2502.04040\] Leveraging Reasoning with Guidelines to Elicit and Utilize Knowledge for Enhancing Safety Alignment](https://arxiv.org/abs/2502.04040) (HKUST)
- [ ] [\[2502.03948\] Enhancing Online Learning Efficiency Through Heterogeneous Resource Integration with a Multi-Agent RAG System](https://arxiv.org/abs/2502.03948) (TUM)
- [ ] [\[2502.03692\] DocMIA: Document-Level Membership Inference Attacks against DocVQA Models](https://arxiv.org/abs/2502.03692) (ICLR)
- [ ] [\[2501.16207\] From Informal to Formal -- Incorporating and Evaluating LLMs on Natural Language Requirements to Verifiable Formal Proofs](https://arxiv.org/abs/2501.16207) (HKUST)
- [ ] [\[2501.10711\] How Should I Build A Benchmark? Revisiting Code-Related Benchmarks For LLMs](https://arxiv.org/abs/2501.10711) (HKUST)

## 2025-02-06 (Thu)
- [ ] [\[2502.03397\] SPRI: Aligning Large Language Models with Context-Situated Principles](https://arxiv.org/abs/2502.03397) (UT Austin)
- [ ] [\[2502.03373\] Demystifying Long Chain-of-Thought Reasoning in LLMs](https://arxiv.org/abs/2502.03373) (CMU)
- [ ] [\[2502.03358\] Minerva: A Programmable Memory Test Benchmark for Language Models](https://arxiv.org/abs/2502.03358) (Microsoft)
- [ ] [\[2502.03199\] Improve Decoding Factuality by Token-wise Cross Layer Entropy of Large Language Models](https://arxiv.org/abs/2502.03199) (HIT)
- [ ] [\[2502.03147\] Scalable In-Context Learning on Tabular Data via Retrieval-Augmented Large Language Models](https://arxiv.org/abs/2502.03147) (Microsoft)
- [ ] [\[2502.03080\] IAO Prompting: Making Knowledge Flow Explicit in LLMs through Structured Reasoning Templates](https://arxiv.org/abs/2502.03080) (UCL)
- [ ] [\[2502.03034\] Knowledge Distillation from Large Language Models for Household Energy Modeling](https://arxiv.org/abs/2502.03034) (MBZUAI)
- [ ] [\[2502.02988\] Training an LLM-as-a-Judge Model: Pipeline, Insights, and Practical Lessons](https://arxiv.org/abs/2502.02988) (Alibaba)
- [ ] [\[2502.02896\] A Benchmark for the Detection of Metalinguistic Disagreements between LLMs and Knowledge Graphs](https://arxiv.org/abs/2502.02896) (UVA.NL)
- [ ] [\[2502.02871\] Position: Multimodal Large Language Models Can Significantly Advance Scientific Reasoning](https://arxiv.org/abs/2502.02871) (HKUST(GZ))
- [ ] [\[2502.02696\] How Inclusively do LMs Perceive Social and Moral Norms?](https://arxiv.org/abs/2502.02696) (GIT)
- [ ] [\[2502.02672\] Transformers Boost the Performance of Decision Trees on Tabular Data across Sample Sizes](https://arxiv.org/abs/2502.02672) (UMD)
- [ ] [\[2502.02659\] A Training-Free Length Extrapolation Approach for LLMs: Greedy Attention Logit Interpolation (GALI)](https://arxiv.org/abs/2502.02659) (USyd)
- [ ] [\[2502.03283\] SymAgent: A Neural-Symbolic Self-Learning Agent Framework for Complex Reasoning over Knowledge Graphs](https://arxiv.org/abs/2502.03283) (WHU)
- [ ] [\[2502.02770\] Twilight: Adaptive Attention Sparsity with Hierarchical Top-$p$ Pruning](https://arxiv.org/abs/2502.02770) (Tsinghua)
- [ ] [\[2502.02732\] Peri-LN: Revisiting Layer Normalization in the Transformer Architecture](https://arxiv.org/abs/2502.02732) (KAIST)

