- [ ] [\[2401.00029\] 6D-Diff: A Keypoint Diffusion Framework for 6D Object Pose Estimation](https://arxiv.org/abs/2401.00029) (NTU, CVPR)
- [ ] [\[2401.00094\] Generating Enhanced Negatives for Training Language-Based Object Detectors](https://arxiv.org/abs/2401.00094) (CVPR)
- [ ] [\[2401.00208\] Inpaint4DNeRF: Promptable Spatio-Temporal NeRF Inpainting with Generative Diffusion Models](https://arxiv.org/abs/2401.00208) (HKUST)
- [ ] [\[2401.00247\] Probing the Limits and Capabilities of Diffusion Models for the Anatomic Editing of Digital Twins](https://arxiv.org/abs/2401.00247) (MIT)
- [ ] [\[2401.00268\] COMMA: Co-Articulated Multi-Modal Learning](https://arxiv.org/abs/2401.00268) (Tianjin)
- [ ] [\[2401.00271\] HybridGait: A Benchmark for Spatial-Temporal Cloth-Changing Gait Recognition with Hybrid Explorations](https://arxiv.org/abs/2401.00271) (Fudan)
- [ ] [\[2401.00343\] SHARE: Single-view Human Adversarial REconstruction](https://arxiv.org/abs/2401.00343) (UMD)
- [ ] [\[2401.00374\] EMAGE: Towards Unified Holistic Co-Speech Gesture Generation via Expressive Masked Audio Gesture Modeling](https://arxiv.org/abs/2401.00374) (CVPR)
- [ ] [\[2401.00390\] Horizontal Federated Computer Vision](https://arxiv.org/abs/2401.00390) (UT Austin)
- [ ] [\[2401.00416\] SVFAP: Self-supervised Video Facial Affect Perceiver](https://arxiv.org/abs/2401.00416) (Tsinghua)
- [ ] [\[2401.00435\] Bidirectional Trained Tree-Structured Decoder for Handwritten Mathematical Expression Recognition](https://arxiv.org/abs/2401.00435) (USTC)
- [ ] [\[2401.00442\] A Comprehensive Overview of Fish-Eye Camera Distortion Correction Methods](https://arxiv.org/abs/2401.00442) (SUSTech)
- [ ] [\[2401.00456\] Double-well Net for Image Segmentation](https://arxiv.org/abs/2401.00456) (BU)
- [ ] [\[2401.00496\] SAR-RARP50: Segmentation of surgical instrumentation and Action Recognition on Robot-Assisted Radical Prostatectomy Challenge](https://arxiv.org/abs/2401.00496) (UCL)
- [ ] [\[2401.00616\] GD^2-NeRF: Generative Detail Compensation via GAN and Diffusion for One-shot Generalizable Neural Radiance Fields](https://arxiv.org/abs/2401.00616) (ZJU)
- [ ] [\[2401.00708\] Revisiting Nonlocal Self-Similarity from Continuous Representation](https://arxiv.org/abs/2401.00708) (XJTU)
- [ ] [\[2401.00711\] Text2Avatar: Text to 3D Human Avatar Generation with Codebook-Driven Body Controllable Attribute](https://arxiv.org/abs/2401.00711) (Tsinghua)
- [ ] [\[2401.00729\] NightRain: Nighttime Video Deraining via Adaptive-Rain-Removal and Adaptive-Correction](https://arxiv.org/abs/2401.00729) (NUS)
- [ ] [\[2401.00789\] Retrieval-Augmented Egocentric Video Captioning](https://arxiv.org/abs/2401.00789) (CVPR)
- [ ] [\[2401.00847\] Mocap Everyone Everywhere: Lightweight Motion Capture With Smartwatches and a Head-Mounted Camera](https://arxiv.org/abs/2401.00847) (CVPR)
- [ ] [\[2401.00896\] TrailBlazer: Trajectory Control for Diffusion-Based Video Generation](https://arxiv.org/abs/2401.00896) (NVIDIA)
- [ ] [\[2401.00897\] Masked Modeling for Self-supervised Representation Learning on Vision and Beyond](https://arxiv.org/abs/2401.00897) (NJU)
- [ ] [\[2401.00909\] Taming Mode Collapse in Score Distillation for Text-to-3D Generation](https://arxiv.org/abs/2401.00909) (UT Austin)
- [ ] [\[2401.00912\] ScatterFormer: Efficient Voxel Transformer with Scattered Linear Attention](https://arxiv.org/abs/2401.00912) (PolyU, ECCV)
- [ ] [\[2401.00921\] Skeleton2vec: A Self-supervised Learning Framework with Contextualized Target Representations for Skeleton Sequence](https://arxiv.org/abs/2401.00921) (CVPR)
- [ ] [\[2401.00986\] Real-Time Object Detection in Occluded Environment with Background Cluttering Effects Using Deep Learning](https://arxiv.org/abs/2401.00986) (BIT)
- [ ] [\[2401.01010\] Unsupervised Continual Anomaly Detection with Contrastively-learned Prompt](https://arxiv.org/abs/2401.01010) (SUSTech)
- [ ] [\[2401.01074\] AliFuse: Aligning and Fusing Multi-modal Medical Data for Computer-Aided Diagnosis](https://arxiv.org/abs/2401.01074) (SJTU)
- [ ] [\[2401.01075\] Depth-discriminative Metric Learning for Monocular 3D Object Detection](https://arxiv.org/abs/2401.01075) (NIPS)
- [ ] [\[2401.01093\] Exploring Hyperspectral Anomaly Detection with Human Vision: A Small Target Aware Detector](https://arxiv.org/abs/2401.01093) (Xidian)
- [ ] [\[2401.01102\] Dual Teacher Knowledge Distillation with Domain Alignment for Face Anti-spoofing](https://arxiv.org/abs/2401.01102) (SUSTech)
- [ ] [\[2401.01107\] CityPulse: Fine-Grained Assessment of Urban Change with Street View Time Series](https://arxiv.org/abs/2401.01107) (UCSD)
- [ ] [\[2401.01128\] SSP: A Simple and Safe automatic Prompt engineering method towards realistic image synthesis on LVM](https://arxiv.org/abs/2401.01128) (UESTC)
- [ ] [\[2401.01175\] Learning Surface Scattering Parameters From SAR Images Using Differentiable Ray Tracing](https://arxiv.org/abs/2401.01175) (Fudan)
- [ ] [\[2401.01178\] GBSS:a global building semantic segmentation dataset for large-scale remote sensing building extraction](https://arxiv.org/abs/2401.01178) (WHU)
- [ ] [\[2401.01180\] Accurate and Efficient Urban Street Tree Inventory with Deep Learning on Mobile Phone Imagery](https://arxiv.org/abs/2401.01180) (MIT)
- [ ] [\[2401.01216\] Noise-NeRF: Hide Information in Neural Radiance Fields using Trainable Noise](https://arxiv.org/abs/2401.01216) (USTC)
- [ ] [\[2401.01219\] Distribution Matching for Multi-Task Learning of Classification Tasks: a Large-Scale Study on Faces & Beyond](https://arxiv.org/abs/2401.01219) (Imperial)
- [ ] [\[2401.01244\] Temporal Adaptive RGBT Tracking with Modality Prompt](https://arxiv.org/abs/2401.01244) (Xidian)
- [ ] [\[2401.01391\] On Optimal Sampling for Learning SDF Using MLPs Equipped with Positional Encoding](https://arxiv.org/abs/2401.01391) (HKU)
- [ ] [\[2401.01445\] Indoor Obstacle Discovery on Reflective Ground via Monocular Camera](https://arxiv.org/abs/2401.01445) (HUST)
- [ ] [\[2401.01454\] A Survey on Autonomous Driving Datasets: Statistics, Annotation Quality, and a Future Outlook](https://arxiv.org/abs/2401.01454) (TUM)
- [ ] [\[2401.01461\] Efficient Hybrid Zoom using Camera Fusion on Mobile Phones](https://arxiv.org/abs/2401.01461) (Google, SIGGRAPH)
- [ ] [\[2401.01482\] Incorporating Geo-Diverse Knowledge into Prompting for Increased Geographical Robustness in Object Recognition](https://arxiv.org/abs/2401.01482) (CVPR)
- [ ] [\[2401.01505\] Sports-QA: A Large-Scale Video Question Answering Benchmark for Complex and Professional Sports](https://arxiv.org/abs/2401.01505) (NUDT)
- [ ] [\[2401.01522\] LORE++: Logical Location Regression Network for Table Structure Recognition with Pre-training](https://arxiv.org/abs/2401.01522) (ZJU)
- [ ] [\[2401.01529\] Glance and Focus: Memory Prompting for Multi-Event Video Question Answering](https://arxiv.org/abs/2401.01529) (NIPS)
- [ ] [\[2401.01544\] Collaborative Perception for Connected and Autonomous Driving: Challenges, Possible Solutions and Opportunities](https://arxiv.org/abs/2401.01544) (HKU)
- [ ] [\[2401.01552\] CRA-PCN: Point Cloud Completion with Intra- and Inter-level Cross-Resolution Transformers](https://arxiv.org/abs/2401.01552) (NJU)
- [ ] [\[2401.01577\] Test-Time Personalization with Meta Prompt for Gaze Estimation](https://arxiv.org/abs/2401.01577) (University of Toronto)
- [ ] [\[2401.01578\] Context-Guided Spatio-Temporal Video Grounding](https://arxiv.org/abs/2401.01578) (IS CAS)
- [ ] [\[2401.01643\] S3Net: Innovating Stereo Matching and Semantic Segmentation with a Single-Branch Semantic Stereo Network in Satellite Epipolar Imagery](https://arxiv.org/abs/2401.01643) (WHU)
- [ ] [\[2401.01646\] Prototypical Information Bottlenecking and Disentangling for Multimodal Cancer Survival Prediction](https://arxiv.org/abs/2401.01646) (HKUST)
- [ ] [\[2401.01686\] ODTrack: Online Dense Temporal Token Learning for Visual Tracking](https://arxiv.org/abs/2401.01686) (HIT)
- [ ] [\[2401.01724\] Lightweight Adaptive Feature De-drifting for Compressed Image Classification](https://arxiv.org/abs/2401.01724) (USTC)
- [ ] [\[2401.01736\] Few-shot Adaptation of Multi-modal Foundation Models: A Survey](https://arxiv.org/abs/2401.01736) (HKUST)
  
  - [x] [\[2401.01764\] Understanding the Detrimental Class-level Effects of Data Augmentation](https://arxiv.org/abs/2401.01764) (NIPS, NYU)

- [ ] [\[2401.01823\] Detours for Navigating Instructional Videos](https://arxiv.org/abs/2401.01823) (CVPR)
- [ ] [\[2401.01839\] Frequency Domain Modality-invariant Feature Learning for Visible-infrared Person Re-Identification](https://arxiv.org/abs/2401.01839) (USTC)
- [ ] [\[2401.01887\] LEAP-VO: Long-term Effective Any Point Tracking for Visual Odometry](https://arxiv.org/abs/2401.01887) (CVPR)
- [ ] [\[2401.01912\] Shrinking Your TimeStep: Towards Low-Latency Neuromorphic Object Recognition with Spiking Neural Network](https://arxiv.org/abs/2401.01912) (UESTC)
- [ ] [\[2401.01922\] Unsupervised Object-Centric Learning from Multiple Unspecified Viewpoints](https://arxiv.org/abs/2401.01922) (Fudan)
- [ ] [\[2401.01970\] FMGS: Foundation Model Embedded 3D Gaussian Splatting for Holistic 3D Scene Understanding](https://arxiv.org/abs/2401.01970) (Google)
- [ ] [\[2401.01974\] Towards Truly Zero-shot Compositional Visual Reasoning with LLMs as Programmers](https://arxiv.org/abs/2401.01974) (Google)
- [ ] [\[2401.01984\] AUPIMO: Redefining Visual Anomaly Detection Benchmarks with High Speed and Low Tolerance](https://arxiv.org/abs/2401.01984) (PSL University)
- [ ] [\[2401.02015\] Improving Diffusion-Based Image Synthesis with Context Prediction](https://arxiv.org/abs/2401.02015) (NIPS)
- [ ] [\[2401.02094\] PILoRA: Prototype Guided Incremental LoRA for Federated Class-Incremental Learning](https://arxiv.org/abs/2401.02094) (ECCV)
- [ ] [\[2401.02097\] Preserving Image Properties Through Initializations in Diffusion Models](https://arxiv.org/abs/2401.02097) (Illinois)
- [ ] [\[2401.02126\] Unified Diffusion-Based Rigid and Non-Rigid Editing with Text and Image Guidance](https://arxiv.org/abs/2401.02126) (HUST)
- [ ] [\[2401.02138\] Explore Human Parsing Modality for Action Recognition](https://arxiv.org/abs/2401.02138) (SYSU)
- [ ] [\[2401.02141\] Bayesian Intrinsic Groupwise Image Registration: Unsupervised Disentanglement of Anatomy and Geometry](https://arxiv.org/abs/2401.02141) (UW)
- [ ] [\[2401.02142\] GUESS:GradUally Enriching SyntheSis for Text-Driven Human Motion Generation](https://arxiv.org/abs/2401.02142) (XJTU)
- [ ] [\[2401.02150\] Marginal Debiased Network for Fair Visual Recognition](https://arxiv.org/abs/2401.02150) (BUPT)
- [ ] [\[2401.02162\] Frequency Domain Nuances Mining for Visible-Infrared Person Re-identification](https://arxiv.org/abs/2401.02162) (Xiamen)
- [ ] [\[2401.02241\] Slot-guided Volumetric Object Radiance Fields](https://arxiv.org/abs/2401.02241) (NIPS)
- [ ] [\[2401.02292\] GridFormer: Point-Grid Transformer for Surface Reconstruction](https://arxiv.org/abs/2401.02292) (Tsinghua)
- [ ] [\[2401.02313\] SuperEdge: Towards a Generalization Model for Self-Supervised Edge Detection](https://arxiv.org/abs/2401.02313) (HIT)
- [ ] [\[2401.02317\] BA-SAM: Scalable Bias-Mode Attention Mask for Segment Anything Model](https://arxiv.org/abs/2401.02317) (CVPR)
- [ ] [\[2401.02326\] ClassWise-SAM-Adapter: Parameter Efficient Fine-tuning Adapts Segment Anything to SAR Domain for Semantic Segmentation](https://arxiv.org/abs/2401.02326) (Fudan)
- [ ] [\[2401.02335\] Linguistic Profiling of Deepfakes: An Open Database for Next-Generation Deepfake Detection](https://arxiv.org/abs/2401.02335) (XJTU)
- [ ] [\[2401.02384\] ChartAssisstant: A Universal Chart Multimodal Language Model via Chart-to-Table Pre-training and Multitask Instruction Tuning](https://arxiv.org/abs/2401.02384) (Shanghai AI Lab)
- [ ] [\[2401.02416\] ODIN: A Single Model for 2D and 3D Segmentation](https://arxiv.org/abs/2401.02416) (Stanford, CVPR)
- [ ] [\[2401.02430\] Automated Classification of Model Errors on ImageNet](https://arxiv.org/abs/2401.02430) (NIPS)
- [ ] [\[2401.02433\] FedDiff: Diffusion Model Driven Federated Learning for Multi-Modal and Multi-Clients](https://arxiv.org/abs/2401.02433) (Xidian)
- [ ] [\[2401.02436\] Compressed 3D Gaussian Splatting for Accelerated Novel View Synthesis](https://arxiv.org/abs/2401.02436) (TUM)
- [ ] [\[2401.02600\] Object-oriented backdoor attack against image captioning](https://arxiv.org/abs/2401.02600) (Fudan)
- [ ] [\[2401.02610\] DHGCN: Dynamic Hop Graph Convolution Network for Self-Supervised Point Cloud Learning](https://arxiv.org/abs/2401.02610) (Peking)
- [ ] [\[2401.02614\] Scaling and Masking: A New Paradigm of Data Sampling for Image and Video Quality Assessment](https://arxiv.org/abs/2401.02614) (Xidian)
- [ ] [\[2401.02616\] FED-NeRF: Achieve High 3D Consistency and Temporal Coherence for Face Video Editing on Dynamic NeRF](https://arxiv.org/abs/2401.02616) (HKUST)
- [ ] [\[2401.02717\] Complementary Information Mutual Learning for Multimodality Medical Image Segmentation](https://arxiv.org/abs/2401.02717) (Fudan)
- [ ] [\[2401.02957\] Denoising Vision Transformers](https://arxiv.org/abs/2401.02957) (ECCV)
- [ ] [\[2401.03043\] Learning Multimodal Volumetric Features for Large-Scale Neuron Tracing](https://arxiv.org/abs/2401.03043) (USTC)
- [ ] [\[2401.03048\] Latte: Latent Diffusion Transformer for Video Generation](https://arxiv.org/abs/2401.03048) (Shanghai AI Lab)
- [ ] [\[2401.03142\] Explicit Visual Prompts for Visual Object Tracking](https://arxiv.org/abs/2401.03142) (HIT)
- [ ] [\[2401.03149\] CaMML: Context-Aware Multimodal Learner for Large Models](https://arxiv.org/abs/2401.03149) (CUHK)
- [ ] [\[2401.03153\] An Event-Oriented Diffusion-Refinement Method for Sparse Events Completion](https://arxiv.org/abs/2401.03153) (Tsinghua)
- [ ] [\[2401.03157\] ImageLab: Simplifying Image Processing Exploration for Novices and Experts Alike](https://arxiv.org/abs/2401.03157) (USyd)
- [ ] [\[2401.03179\] Multimodal Informative ViT: Information Aggregation and Distribution for Hyperspectral and LiDAR Classification](https://arxiv.org/abs/2401.03179) (Xidian)
- [ ] [\[2401.03182\] Distribution-aware Interactive Attention Network and Large-scale Cloud Recognition Benchmark on FY-4A Satellite Image](https://arxiv.org/abs/2401.03182) (Xidian)
- [ ] [\[2401.03203\] Hi-Map: Hierarchical Factorized Radiance Field for High-Fidelity Monocular Dense Mapping](https://arxiv.org/abs/2401.03203) (HKUST)
- [ ] [\[2401.03312\] Exploiting Data Hierarchy as a New Modality for Contrastive Learning](https://arxiv.org/abs/2401.03312) (Cornell)
- [ ] [\[2401.03349\] Image Inpainting via Tractable Steering of Diffusion Models](https://arxiv.org/abs/2401.03349) (UCLA)
- [ ] [\[2401.03379\] Towards Effective Multiple-in-One Image Restoration: A Sequential and Prompt Learning Strategy](https://arxiv.org/abs/2401.03379) (PolyU)
- [ ] [\[2401.03637\] Inverse-like Antagonistic Scene Text Spotting via Reading-Order Estimation and Dynamic Sampling](https://arxiv.org/abs/2401.03637) (TIP)
- [ ] [\[2401.03707\] FMA-Net: Flow-Guided Dynamic Filtering and Iterative Feature Refinement with Multi-Attention for Joint Video Super-Resolution and Deblurring](https://arxiv.org/abs/2401.03707) (KAIST, CVPR)
- [ ] [\[2401.03742\] Flowmind2Digital: The First Comprehensive Flowmind Recognition and Conversion Approach](https://arxiv.org/abs/2401.03742) (Xidian)
- [ ] [\[2401.03753\] Color-$S^{4}L$: Self-supervised Semi-supervised Learning with Image Colorization](https://arxiv.org/abs/2401.03753) (HIT)
- [ ] [\[2401.03765\] InvariantOODG: Learning Invariant Features of Point Clouds for Out-of-Distribution Generalization](https://arxiv.org/abs/2401.03765) (Peking)
- [ ] [\[2401.03785\] Identifying Important Group of Pixels using Interactions](https://arxiv.org/abs/2401.03785) (CVPR)
- [ ] [\[2401.03800\] MvKSR: Multi-view Knowledge-guided Scene Recovery for Hazy and Rainy Degradation](https://arxiv.org/abs/2401.03800) (PolyU)
- [ ] [\[2401.03828\] A multimodal gesture recognition dataset for desktop human-computer interaction](https://arxiv.org/abs/2401.03828) (Xidian)
- [ ] [\[2401.03835\] Limitations of Data-Driven Spectral Reconstruction -- Optics-Aware Analysis and Mitigation](https://arxiv.org/abs/2401.03835) (POSTECH)
- [ ] [\[2401.03854\] TIER: Text-Image Encoder-based Regression for AIGC Image Quality Assessment](https://arxiv.org/abs/2401.03854) (Peking)
- [ ] [\[2401.03870\] Gramformer: Learning Crowd Counting via Graph-Modulated Transformer](https://arxiv.org/abs/2401.03870) (XJTU)
- [ ] [\[2401.03901\] STAIR: Spatial-Temporal Reasoning with Auditable Intermediate Results for Video Question Answering](https://arxiv.org/abs/2401.03901) (Peking)
- [ ] [\[2401.04290\] StarCraftImage: A Dataset For Prototyping Spatial Reasoning Methods For Multi-Agent Environments](https://arxiv.org/abs/2401.04290) (CVPR)
- [ ] [\[2401.04317\] Vision Reimagined: AI-Powered Breakthroughs in WiFi Indoor Imaging](https://arxiv.org/abs/2401.04317) (HKUST)
- [ ] [\[2401.04325\] RadarCam-Depth: Radar-Camera Fusion for Depth Estimation with Learned Metric Scale](https://arxiv.org/abs/2401.04325) (Caltech)
- [ ] [\[2401.04339\] Memory-Efficient Fine-Tuning for Quantized Diffusion Model](https://arxiv.org/abs/2401.04339) (ECCV)
- [ ] [\[2401.04350\] Pre-trained Model Guided Fine-Tuning for Zero-Shot Adversarial Robustness](https://arxiv.org/abs/2401.04350) (CVPR)
- [ ] [\[2401.04357\] Iterative Feedback Network for Unsupervised Point Cloud Registration](https://arxiv.org/abs/2401.04357) (XJTU)
- [ ] [\[2401.04435\] Uncertainty-aware Sampling for Long-tailed Semi-supervised Learning](https://arxiv.org/abs/2401.04435) (TPAMI)
- [ ] [\[2401.04441\] Image classification network enhancement methods based on knowledge injection](https://arxiv.org/abs/2401.04441) (Xidian)
- [ ] [\[2401.04486\] Take A Shortcut Back: Mitigating the Gradient Vanishing for Training Spiking Neural Networks](https://arxiv.org/abs/2401.04486) (Peking)
- [ ] [\[2401.04575\] Let's Go Shopping (LGS) -- Web-Scale Image-Text Dataset for Visual Concept Understanding](https://arxiv.org/abs/2401.04575) (Berkeley)
- [ ] [\[2401.04578\] Effective pruning of web-scale datasets based on complexity of concept clusters](https://arxiv.org/abs/2401.04578) (University of Tübingen, ICLR)
- [ ] [\[2401.04614\] Generic Knowledge Boosted Pre-training For Remote Sensing Images](https://arxiv.org/abs/2401.04614) (Peking)
- [ ] [\[2401.04680\] CoordGate: Efficiently Computing Spatially-Varying Convolutions in Convolutional Neural Networks](https://arxiv.org/abs/2401.04680) (Oxford)
- [ ] [\[2401.04716\] Low-Resource Vision Challenges for Foundation Models](https://arxiv.org/abs/2401.04716) (CVPR)
- [ ] [\[2401.04727\] Revisiting Adversarial Training at Scale](https://arxiv.org/abs/2401.04727) (CVPR)
- [ ] [\[2401.04728\] Morphable Diffusion: 3D-Consistent Diffusion for Single-image Avatar Creation](https://arxiv.org/abs/2401.04728) (CVPR)
- [ ] [\[2401.04730\] A Simple Baseline for Spoken Language to Sign Language Translation with 3D Avatars](https://arxiv.org/abs/2401.04730) (ECCV)
- [ ] [\[2401.04739\] Content-Conditioned Generation of Stylized Free hand Sketches](https://arxiv.org/abs/2401.04739) (Xidian)
- [ ] [\[2401.04861\] CTNeRF: Cross-Time Transformer for Dynamic Neural Radiance Field from Monocular Video](https://arxiv.org/abs/2401.04861) (A*STAR,)
- [ ] [\[2401.04872\] Knowledge-aware Graph Transformer for Pedestrian Trajectory Prediction](https://arxiv.org/abs/2401.04872) (USyd)
- [ ] [\[2401.04903\] SnapCap: Efficient Snapshot Compressive Video Captioning](https://arxiv.org/abs/2401.04903) (Xidian)
- [ ] [\[2401.04921\] Diffusion-based Pose Refinement and Muti-hypothesis Generation for 3D Human Pose Estimaiton](https://arxiv.org/abs/2401.04921) (Peking)
- [ ] [\[2401.04942\] Latency-aware Road Anomaly Segmentation in Videos: A Photorealistic Dataset and New Metrics](https://arxiv.org/abs/2401.04942) (Tsinghua)
- [ ] [\[2401.04961\] ECC-PolypDet: Enhanced CenterNet with Contrastive Learning for Automatic Polyp Detection](https://arxiv.org/abs/2401.04961) (SYSU)
- [ ] [\[2401.04962\] Large Model based Sequential Keyframe Extraction for Video Summarization](https://arxiv.org/abs/2401.04962) (BUPT)
- [ ] [\[2401.04984\] MGNet: Learning Correspondences via Multiple Graphs](https://arxiv.org/abs/2401.04984) (NTU)
- [ ] [\[2401.05010\] Less is More: A Closer Look at Semantic-based Few-Shot Learning](https://arxiv.org/abs/2401.05010) (ZJU)
- [ ] [\[2401.05011\] Dual-Perspective Knowledge Enrichment for Semi-Supervised 3D Object Detection](https://arxiv.org/abs/2401.05011) (NTU)
- [ ] [\[2401.05014\] Source-Free Cross-Modal Knowledge Transfer by Unleashing the Potential of Task-Irrelevant Data](https://arxiv.org/abs/2401.05014) (HKUST(GZ))
- [ ] [\[2401.05093\] SwiMDiff: Scene-wide Matching Contrastive Learning with Diffusion Constraint for Remote Sensing Image](https://arxiv.org/abs/2401.05093) (Xidian)
- [ ] [\[2401.05153\] CrossDiff: Exploring Self-Supervised Representation of Pansharpening via Cross-Predictive Diffusion Model](https://arxiv.org/abs/2401.05153) (NWPU)
- [ ] [\[2401.05167\] Watermark Text Pattern Spotting in Document Images](https://arxiv.org/abs/2401.05167) (AWS)
- [ ] [\[2401.05224\] Do Vision and Language Encoders Represent the World Similarly?](https://arxiv.org/abs/2401.05224) (CVPR)
- [ ] [\[2401.05252\] PIXART-{\delta}: Fast and Controllable Image Generation with Latent Consistency Models](https://arxiv.org/abs/2401.05252) (Tsinghua)
- [ ] [\[2401.05335\] InseRF: Text-Driven Generative Object Insertion in Neural 3D Scenes](https://arxiv.org/abs/2401.05335) (ETH)
- [ ] [\[2401.05336\] Towards Online Sign Language Recognition and Translation](https://arxiv.org/abs/2401.05336) (Microsoft)
- [ ] [\[2401.05338\] STR-Cert: Robustness Certification for Deep Text Recognition on Deep Learning Pipelines and Vision Transformers](https://arxiv.org/abs/2401.05338) (Oxford)
- [ ] [\[2401.05339\] MicroGlam: Microscopic Skin Image Dataset with Cosmetics](https://arxiv.org/abs/2401.05339) (University of Tokyo)
- [ ] [\[2401.05353\] ImbaGCD: Imbalanced Generalized Category Discovery](https://arxiv.org/abs/2401.05353) (CUHK)
- [ ] [\[2401.05362\] DualTeacher: Bridging Coexistence of Unlabelled Classes for Semi-supervised Incremental Object Detection](https://arxiv.org/abs/2401.05362) (Tsinghua)
- [ ] [\[2401.05401\] Domain Similarity-Perceived Label Assignment for Domain Generalized Underwater Object Detection](https://arxiv.org/abs/2401.05401) (KU Leuven)
- [ ] [\[2401.05577\] VLP: Vision Language Planning for Autonomous Driving](https://arxiv.org/abs/2401.05577) (CVPR)
- [ ] [\[2401.05593\] Reverse Projection: Real-Time Local Space Texture Mapping](https://arxiv.org/abs/2401.05593) (CMU, SIGGRAPH)
- [ ] [\[2401.05625\] Face-GPS: A Comprehensive Technique for Quantifying Facial Muscle Dynamics in Videos](https://arxiv.org/abs/2401.05625) (Stanford)
- [ ] [\[2401.05633\] Transforming Image Super-Resolution: A ConvFormer-based Efficient Approach](https://arxiv.org/abs/2401.05633) (HIT, TIP)
- [ ] [\[2401.05646\] Masked Attribute Description Embedding for Cloth-Changing Person Re-identification](https://arxiv.org/abs/2401.05646) (Xidian)
- [ ] [\[2401.05676\] Exploring Self- and Cross-Triplet Correlations for Human-Object Interaction Detection](https://arxiv.org/abs/2401.05676) (HIT)
- [ ] [\[2401.05698\] HiCMAE: Hierarchical Contrastive Masked Autoencoder for Self-Supervised Audio-Visual Emotion Recognition](https://arxiv.org/abs/2401.05698) (Tsinghua)
- [ ] [\[2401.05735\] Object-Centric Diffusion for Efficient Video Editing](https://arxiv.org/abs/2401.05735) (ECCV)
- [ ] [\[2401.05738\] LKCA: Large Kernel Convolutional Attention](https://arxiv.org/abs/2401.05738) (UESTC)
- [ ] [\[2401.05752\] Learning Generalizable Models via Disentangling Spurious and Enhancing Potential Correlations](https://arxiv.org/abs/2401.05752) (NJU)
- [ ] [\[2401.05806\] CLIP-Driven Semantic Discovery Network for Visible-Infrared Person Re-Identification](https://arxiv.org/abs/2401.05806) (BIT)
- [ ] [\[2401.05870\] HiCAST: Highly Customized Arbitrary Style Transfer with Adapter Enhanced Diffusion Models](https://arxiv.org/abs/2401.05870) (ETH)
- [ ] [\[2401.05906\] PartSTAD: 2D-to-3D Part Segmentation Task Adaptation](https://arxiv.org/abs/2401.05906) (KAIST, ECCV)
- [ ] [\[2401.05925\] Learning Segmented 3D Gaussians via Efficient Feature Unprojection for Zero-shot Neural Scene Segmentation](https://arxiv.org/abs/2401.05925) (XJTU)
- [ ] [\[2401.06009\] Sea ice detection using concurrent multispectral and synthetic aperture radar imagery](https://arxiv.org/abs/2401.06009) (Alan Turing Institute)
- [ ] [\[2401.06013\] Surgical-DINO: Adapter Learning of Foundation Models for Depth Estimation in Endoscopic Surgery](https://arxiv.org/abs/2401.06013) (CUHK)
- [ ] [\[2401.06035\] RAVEN: Rethinking Adversarial Video Generation with Efficient Tri-plane Networks](https://arxiv.org/abs/2401.06035) (Inria)
- [ ] [\[2401.06127\] E$^{2}$GAN: Efficient Training of Efficient GANs for Image-to-Image Translation](https://arxiv.org/abs/2401.06127) (ICML)
- [ ] [\[2401.06129\] Distilling Vision-Language Models on Millions of Videos](https://arxiv.org/abs/2401.06129) (CVPR)
- [ ] [\[2401.06144\] DFU: scale-robust diffusion model for zero-shot super-resolution image generation](https://arxiv.org/abs/2401.06144) (GIT)
- [ ] [\[2401.06159\] FRED: Towards a Full Rotation-Equivariance in Aerial Image Object Detection](https://arxiv.org/abs/2401.06159) (KAIST)
- [ ] [\[2401.06191\] TriNeRFLet: A Wavelet Based Triplane NeRF Representation](https://arxiv.org/abs/2401.06191) (Tel Aviv, ECCV)
- [ ] [\[2401.06197\] Efficient Deformable ConvNets: Rethinking Dynamic and Sparse Operator for Vision Applications](https://arxiv.org/abs/2401.06197) (Tsinghua)
- [ ] [\[2401.06287\] Hierarchical Augmentation and Distillation for Class Incremental Audio-Visual Video Recognition](https://arxiv.org/abs/2401.06287) (USTC, TPAMI)
- [ ] [\[2401.06310\] ViSAGe: A Global-Scale Analysis of Visual Stereotypes in Text-to-Image Generation](https://arxiv.org/abs/2401.06310) (Google)
- [ ] [\[2401.06312\] Video Super-Resolution Transformer with Masked Inter&Intra-Frame Attention](https://arxiv.org/abs/2401.06312) (Xidian, CVPR)
- [ ] [\[2401.06331\] Application Of Vision-Language Models For Assessing Osteoarthritis Disease Severity](https://arxiv.org/abs/2401.06331) (University of Alberta)
- [ ] [\[2401.06374\] SamLP: A Customized Segment Anything Model for License Plate Detection](https://arxiv.org/abs/2401.06374) (NWPU)
- [ ] [\[2401.06395\] ModaVerse: Efficiently Transforming Modalities with LLMs](https://arxiv.org/abs/2401.06395) (CVPR)
- [ ] [\[2401.06430\] Mutual Distillation Learning For Person Re-Identification](https://arxiv.org/abs/2401.06430) (BUPT)
- [ ] [\[2401.06442\] RotationDrag: Point-based Image Editing with Rotated Diffusion Features](https://arxiv.org/abs/2401.06442) (Nankai)
- [ ] [\[2401.06521\] Exploring Diverse Representations for Open Set Recognition](https://arxiv.org/abs/2401.06521) (Tianjin)
- [ ] [\[2401.06542\] Robustness-Aware 3D Object Detection in Autonomous Driving: A Review and Outlook](https://arxiv.org/abs/2401.06542) (Queensland)
- [ ] [\[2401.06548\] Enhancing Consistency and Mitigating Bias: A Data Replay Approach for Incremental Learning](https://arxiv.org/abs/2401.06548) (Tsinghua)
- [ ] [\[2401.06578\] 360DVD: Controllable Panorama Video Generation with 360-Degree Video Diffusion Model](https://arxiv.org/abs/2401.06578) (Peking)
- [ ] [\[2401.06762\] Seeing the roads through the trees: A benchmark for modeling spatial dependencies with aerial imagery](https://arxiv.org/abs/2401.06762) (Microsoft)
- [ ] [\[2401.06825\] Multi-Memory Matching for Unsupervised Visible-Infrared Person Re-Identification](https://arxiv.org/abs/2401.06825) (Xiamen, ECCV)
- [ ] [\[2401.06969\] Domain Adaptation for Large-Vocabulary Object Detectors](https://arxiv.org/abs/2401.06969) (Xidian)
- [ ] [\[2401.06978\] ENTED: Enhanced Neural Texture Extraction and Distribution for Reference-based Blind Face Restoration](https://arxiv.org/abs/2401.06978) (HKUST)
- [ ] [\[2401.07014\] Weak Labeling for Cropland Mapping in Africa](https://arxiv.org/abs/2401.07014) (Microsoft)
- [ ] [\[2401.07061\] Dual-View Data Hallucination with Semantic Relation Guidance for Few-Shot Image Recognition](https://arxiv.org/abs/2401.07061) (SYSU)
- [ ] [\[2401.07087\] Exploring Adversarial Attacks against Latent Diffusion Model from the Perspective of Adversarial Transferability](https://arxiv.org/abs/2401.07087) (SYSU)
- [ ] [\[2401.07114\] Revisiting Sampson Approximations for Geometric Estimation Problems](https://arxiv.org/abs/2401.07114) (MPI)
- [ ] [\[2401.07139\] Deep Blind Super-Resolution for Satellite Video](https://arxiv.org/abs/2401.07139) (WHU)
- [ ] [\[2401.07218\] Self-supervised Event-based Monocular Depth Estimation using Cross-modal Consistency](https://arxiv.org/abs/2401.07218) (ZJU)
- [ ] [\[2401.07245\] MIMIC: Mask Image Pre-training with Mix Contrastive Fine-tuning for Facial Expression Recognition](https://arxiv.org/abs/2401.07245) (GIT)
- [ ] [\[2401.07251\] 3D Landmark Detection on Human Point Clouds: A Benchmark and A Dual Cascade Point Transformer Framework](https://arxiv.org/abs/2401.07251) (GIT)
- [ ] [\[2401.07402\] Improved Implicit Neural Representation with Fourier Reparameterized Training](https://arxiv.org/abs/2401.07402) (CVPR)
- [ ] [\[2401.07437\] BoNuS: Boundary Mining for Nuclei Segmentation with Partial Point Labels](https://arxiv.org/abs/2401.07437) (HKUST)
- [ ] [\[2401.07457\] Concept-Guided Prompt Learning for Generalization in Vision-Language Models](https://arxiv.org/abs/2401.07457) (SUSTech)
- [ ] [\[2401.07459\] Semantic Segmentation in Multiple Adverse Weather Conditions with Domain Knowledge Retention](https://arxiv.org/abs/2401.07459) (NUS)
- [ ] [\[2401.07477\] CascadeV-Det: Cascade Point Voting for 3D Object Detection](https://arxiv.org/abs/2401.07477) (BIT)
- [ ] [\[2401.07502\] Compositional Oil Spill Detection Based on Object Detector and Adapted Segment Anything Model from SAR Images](https://arxiv.org/abs/2401.07502) (PolyU)
- [ ] [\[2401.07567\] Bias-Conflict Sample Synthesis and Adversarial Removal Debias Strategy for Temporal Sentence Grounding in Video](https://arxiv.org/abs/2401.07567) (HIT)
- [ ] [\[2401.07579\] PMFSNet: Polarized Multi-scale Feature Self-attention Network For Lightweight Medical Image Segmentation](https://arxiv.org/abs/2401.07579) (UESTC)
- [ ] [\[2401.07584\] Collaboratively Self-supervised Video Representation Learning for Action Recognition](https://arxiv.org/abs/2401.07584) (Microsoft)
- [ ] [\[2401.07586\] Curriculum for Crowd Counting -- Is it Worthy?](https://arxiv.org/abs/2401.07586) (ICCV)
- [ ] [\[2401.07591\] Multimodal Crowd Counting with Pix2Pix GANs](https://arxiv.org/abs/2401.07591) (ICCV)
- [ ] [\[2401.07629\] Fine-Grained Prototypes Distillation for Few-Shot Object Detection](https://arxiv.org/abs/2401.07629) (NWPU)
- [ ] [\[2401.07709\] Towards Efficient Diffusion-Based Image Editing with Instant Attention Masks](https://arxiv.org/abs/2401.07709) (Xiamen)
- [ ] [\[2401.07721\] Graph Transformer GANs with Graph Masked Modeling for Architectural Layout Generation](https://arxiv.org/abs/2401.07721) (ETH, CVPR)
- [ ] [\[2401.07746\] Sparsity-based background removal for STORM super-resolution images](https://arxiv.org/abs/2401.07746) (TUM)
- [ ] [\[2401.07931\] Vertical Federated Image Segmentation](https://arxiv.org/abs/2401.07931) (UT Austin)
- [ ] [\[2401.07951\] Image Similarity using An Ensemble of Context-Sensitive Models](https://arxiv.org/abs/2401.07951) (Oxford)
- [ ] [\[2401.08014\] Convolutional Neural Network Compression via Dynamic Parameter Rank Pruning](https://arxiv.org/abs/2401.08014) (Rochester Institute of Technology)
- [ ] [\[2401.08035\] BanglaNet: Bangla Handwritten Character Recognition using Ensembling of Convolutional Neural Network](https://arxiv.org/abs/2401.08035) (UT Austin)
- [ ] [\[2401.08036\] 3D Lane Detection from Front or Surround-View using Joint-Modeling & Matching](https://arxiv.org/abs/2401.08036) (WHU)
- [ ] [\[2401.08049\] EmoTalker: Emotionally Editable Talking Face Generation via Diffusion Model](https://arxiv.org/abs/2401.08049) (USTC)
- [ ] [\[2401.08056\] Robust Tiny Object Detection in Aerial Images amidst Label Noise](https://arxiv.org/abs/2401.08056) (WHU)
- [ ] [\[2401.08066\] Achieve Fairness without Demographics for Dermatological Disease Diagnosis](https://arxiv.org/abs/2401.08066) (CUHK)
- [ ] [\[2401.08107\] Deep Shape-Texture Statistics for Completely Blind Image Quality Evaluation](https://arxiv.org/abs/2401.08107) (ZJU)
- [ ] [\[2401.08111\] Mobile Contactless Palmprint Recognition: Use of Multiscale, Multimodel Embeddings](https://arxiv.org/abs/2401.08111) (Michigan State University)
- [ ] [\[2401.08115\] No-Clean-Reference Image Super-Resolution: Application to Electron Microscopy](https://arxiv.org/abs/2401.08115) (TUM)
- [ ] [\[2401.08117\] E2HQV: High-Quality Video Generation from Event Camera via Theory-Inspired Model-Aided Deep Learning](https://arxiv.org/abs/2401.08117) (BU)
- [ ] [\[2401.08123\] The Devil is in the Details: Boosting Guided Depth Super-Resolution via Rethinking Cross-Modal Alignment and Aggregation](https://arxiv.org/abs/2401.08123) (Nankai)
- [ ] [\[2401.08154\] TLIC: Learned Image Compression with ROI-Weighted Distortion and Bit Allocation](https://arxiv.org/abs/2401.08154) (Peking)
- [ ] [\[2401.08194\] End-to-End Optimized Image Compression with the Frequency-Oriented Transform](https://arxiv.org/abs/2401.08194) (Peking)
- [ ] [\[2401.08256\] Multitask Learning in Minimally Invasive Surgical Vision: A Review](https://arxiv.org/abs/2401.08256) (Tongji)
- [ ] [\[2401.08276\] AesBench: An Expert Benchmark for Multimodal Large Language Models on Image Aesthetics Perception](https://arxiv.org/abs/2401.08276) (NTU)
- [ ] [\[2401.08328\] Un-Mixing Test-Time Normalization Statistics: Combatting Label Temporal Correlation](https://arxiv.org/abs/2401.08328) (ICLR)
- [ ] [\[2401.08345\] Multi-view Distillation based on Multi-modal Fusion for Few-shot Action Recognition(CLIP-$\mathrm{M^2}$DF)](https://arxiv.org/abs/2401.08345) (XJTU)
- [ ] [\[2401.08392\] DoraemonGPT: Toward Understanding Dynamic Scenes with Large Language Models (Exemplified as A Video Agent)](https://arxiv.org/abs/2401.08392) (ZJU)
- [ ] [\[2401.08407\] Cross-Domain Few-Shot Segmentation via Iterative Support-Query Correspondence Mining](https://arxiv.org/abs/2401.08407) (HUST, CVPR)
- [ ] [\[2401.08474\] TUMTraf Event: Calibration and Fusion Resulting in a Dataset for Roadside Event-Based and RGB Cameras](https://arxiv.org/abs/2401.08474) (TUM)
- [ ] [\[2401.08501\] ValUES: A Framework for Systematic Validation of Uncertainty Estimation in Semantic Segmentation](https://arxiv.org/abs/2401.08501) (ICLR)
- [ ] [\[2401.08503\] Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis](https://arxiv.org/abs/2401.08503) (ICLR)
- [ ] [\[2401.08522\] Video Quality Assessment Based on Swin TransformerV2 and Coarse to Fine Strategy](https://arxiv.org/abs/2401.08522) (USTC)
- [ ] [\[2401.08527\] MICA: Towards Explainable Skin Lesion Diagnosis via Multi-Level Image-Concept Alignment](https://arxiv.org/abs/2401.08527) (HKUST)
- [ ] [\[2401.08573\] WAVES: Benchmarking the Robustness of Image Watermarks](https://arxiv.org/abs/2401.08573) (UMD, ICML)
- [ ] [\[2401.08604\] SAM4UDASS: When SAM Meets Unsupervised Domain Adaptive Semantic Segmentation in Intelligent Vehicles](https://arxiv.org/abs/2401.08604) (SJTU)
- [ ] [\[2401.08615\] Online Anomaly Detection over Live Social Video Streaming](https://arxiv.org/abs/2401.08615) (MIT)
- [ ] [\[2401.08633\] Creating Visual Effects with Neural Radiance Fields](https://arxiv.org/abs/2401.08633) (Berkeley)
- [ ] [\[2401.08639\] One-Step Diffusion Distillation via Deep Equilibrium Models](https://arxiv.org/abs/2401.08639) (CMU, NIPS)
- [ ] [\[2401.08687\] DA-BEV: Unsupervised Domain Adaptation for Bird's Eye View Perception](https://arxiv.org/abs/2401.08687) (Xidian)
- [ ] [\[2401.08725\] Revealing Vulnerabilities in Stable Diffusion via Targeted Attacks](https://arxiv.org/abs/2401.08725) (Tianjin)
- [ ] [\[2401.08739\] EgoGen: An Egocentric Synthetic Data Generator](https://arxiv.org/abs/2401.08739) (CVPR)
- [ ] [\[2401.08741\] Fixed Point Diffusion Models](https://arxiv.org/abs/2401.08741) (Oxford)
- [ ] [\[2401.08742\] Efficient4D: Fast Dynamic 3D Object Generation from a Single-view Video](https://arxiv.org/abs/2401.08742) (Fudan)
- [ ] [\[2401.08809\] Learning Implicit Representation for Reconstructing Articulated Objects](https://arxiv.org/abs/2401.08809) (ICLR)
- [ ] [\[2401.08815\] Adversarial Supervision Makes Layout-to-Image Diffusion Models Thrive](https://arxiv.org/abs/2401.08815) (ICLR)
- [ ] [\[2401.08860\] Cross-Level Multi-Instance Distillation for Self-Supervised Fine-Grained Visual Categorization](https://arxiv.org/abs/2401.08860) (WHU)
- [ ] [\[2401.08865\] The Effect of Intrinsic Dataset Properties on Generalization: Unraveling Learning Differences Between Natural and Medical Images](https://arxiv.org/abs/2401.08865) (ICLR)
- [ ] [\[2401.08903\] Rethinking Impersonation and Dodging Attacks on Face Recognition Systems](https://arxiv.org/abs/2401.08903) (HUST, ACMMM)
- [ ] [\[2401.08937\] ICON: Incremental CONfidence for Joint Pose and Radiance Field Optimization](https://arxiv.org/abs/2401.08937) (Meta)
- [ ] [\[2401.09029\] Cross-modality Guidance-aided Multi-modal Learning with Dual Attention for MRI Brain Tumor Grading](https://arxiv.org/abs/2401.09029) (CUHK)
- [ ] [\[2401.09048\] Compose and Conquer: Diffusion-Based 3D Depth Aware Composable Image Synthesis](https://arxiv.org/abs/2401.09048) (ICLR)
- [ ] [\[2401.09050\] Consistent3D: Towards Consistent High-Fidelity Text-to-3D Generation with Deterministic Sampling Prior](https://arxiv.org/abs/2401.09050) (NTU, CVPR)
- [ ] [\[2401.09109\] Trapped in texture bias? A large scale comparison of deep instance segmentation](https://arxiv.org/abs/2401.09109) (University of Tübingen, ECCV)
- [ ] [\[2401.09146\] Continuous Piecewise-Affine Based Motion Model for Image Animation](https://arxiv.org/abs/2401.09146) (SJTU)
- [ ] [\[2401.09232\] Dynamic Relation Transformer for Contextual Text Block Detection](https://arxiv.org/abs/2401.09232) (USTC)
- [ ] [\[2401.09266\] P$^2$OT: Progressive Partial Optimal Transport for Deep Imbalanced Clustering](https://arxiv.org/abs/2401.09266) (ICLR)
- [ ] [\[2401.09271\] PixelDINO: Semi-Supervised Semantic Segmentation for Detecting Permafrost Disturbances](https://arxiv.org/abs/2401.09271) (TUM)
- [ ] [\[2401.09296\] Tight Fusion of Events and Inertial Measurements for Direct Velocity Estimation](https://arxiv.org/abs/2401.09296) (ShanghaiTech)
- [ ] [\[2401.09413\] POP-3D: Open-Vocabulary 3D Occupancy Prediction from Images](https://arxiv.org/abs/2401.09413) (NIPS)
- [ ] [\[2401.09417\] Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model](https://arxiv.org/abs/2401.09417) (HUST)
- [ ] [\[2401.09443\] CRD: Collaborative Representation Distance for Practical Anomaly Detection](https://arxiv.org/abs/2401.09443) (NWPU)
- [ ] [\[2401.09496\] Learning to Generalize over Subpartitions for Heterogeneity-aware Domain Adaptive Nuclei Segmentation](https://arxiv.org/abs/2401.09496) (USyd)
- [ ] [\[2401.09515\] Enhancing Surveillance Camera FOV Quality via Semantic Line Detection and Classification with Deep Hough Transform](https://arxiv.org/abs/2401.09515) (AWS)
- [ ] [\[2401.09518\] On-Off Pattern Encoding and Path-Count Encoding as Deep Neural Network Representations](https://arxiv.org/abs/2401.09518) (KAIST)
- [ ] [\[2401.09709\] P2Seg: Pointly-supervised Segmentation via Mutual Distillation](https://arxiv.org/abs/2401.09709) (ICLR)
- [ ] [\[2401.09716\] HCVP: Leveraging Hierarchical Contrastive Visual Prompt for Domain Generalization](https://arxiv.org/abs/2401.09716) (UCSD)
- [ ] [\[2401.09736\] Measuring the Discrepancy between 3D Geometric Models using Directional Distance Fields](https://arxiv.org/abs/2401.09736) (Tianjin)
- [ ] [\[2401.09763\] CLIP Model for Images to Textual Prompts Based on Top-k Neighbors](https://arxiv.org/abs/2401.09763) (WHU)
- [ ] [\[2401.09773\] SEINE: Structure Encoding and Interaction Network for Nuclei Instance Segmentation](https://arxiv.org/abs/2401.09773) (HIT)
- [ ] [\[2401.09786\] Adaptive Self-training Framework for Fine-grained Scene Graph Generation](https://arxiv.org/abs/2401.09786) (ICLR)
- [ ] [\[2401.09883\] Question-Answer Cross Language Image Matching for Weakly Supervised Semantic Segmentation](https://arxiv.org/abs/2401.09883) (ACMMM)
- [ ] [\[2401.09895\] Skeleton-Guided Instance Separation for Fine-Grained Segmentation in Microscopy](https://arxiv.org/abs/2401.09895) (SJTU)
- [ ] [\[2401.09962\] CustomVideo: Customizing Text-to-Video Generation with Multiple Subjects](https://arxiv.org/abs/2401.09962) (Peking)
- [ ] [\[2401.09997\] BPDO:Boundary Points Dynamic Optimization for Arbitrary Shape Scene Text Detection](https://arxiv.org/abs/2401.09997) (IS CAS)
- [ ] [\[2401.10017\] Text Region Multiple Information Perception Network for Scene Text Detection](https://arxiv.org/abs/2401.10017) (IS CAS)
- [ ] [\[2401.10039\] GPT4Ego: Unleashing the Potential of Pre-trained Models for Zero-Shot Egocentric Action Recognition](https://arxiv.org/abs/2401.10039) (USyd)
- [ ] [\[2401.10090\] Cross-Modality Perturbation Synergy Attack for Person Re-identification](https://arxiv.org/abs/2401.10090) (Xiamen)
- [ ] [\[2401.10171\] SHINOBI: Shape and Illumination using Neural Object Decomposition via BRDF Optimization In-the-wild](https://arxiv.org/abs/2401.10171) (CVPR)
- [ ] [\[2401.10178\] Neural Echos: Depthwise Convolutional Filters Replicate Biological Receptive Fields](https://arxiv.org/abs/2401.10178) (MIT)
- [ ] [\[2401.10208\] MM-Interleaved: Interleaved Image-Text Generative Modeling via Multi-modal Feature Synchronizer](https://arxiv.org/abs/2401.10208) (Tsinghua)
- [ ] [\[2401.10215\] GPAvatar: Generalizable and Precise Head Avatar from Image(s)](https://arxiv.org/abs/2401.10215) (ICLR)
- [ ] [\[2401.10222\] Supervised Fine-tuning in turn Improves Visual Foundation Models](https://arxiv.org/abs/2401.10222) (Tsinghua)
- [ ] [\[2401.10224\] The Manga Whisperer: Automatically Generating Transcriptions for Comics](https://arxiv.org/abs/2401.10224) (CVPR)
- [ ] [\[2401.10227\] A Simple Latent Diffusion Approach for Panoptic Segmentation and Mask Inpainting](https://arxiv.org/abs/2401.10227) (ECCV)
- [ ] [\[2401.10229\] OMG-Seg: Is One Model Good Enough For All Segmentation?](https://arxiv.org/abs/2401.10229) (NTU)
- [ ] [\[2401.10254\] Beyond the Frame: Single and mutilple video summarization method with user-defined length](https://arxiv.org/abs/2401.10254) (Illinois)
- [ ] [\[2401.10416\] DataViz3D: An Novel Method Leveraging Online Holographic Modeling for Extensive Dataset Preprocessing and Visualization](https://arxiv.org/abs/2401.10416) (NYU)
- [ ] [\[2401.10442\] Path Choice Matters for Clear Attribution in Path Methods](https://arxiv.org/abs/2401.10442) (ICLR)
- [ ] [\[2401.10461\] Learning to Robustly Reconstruct Low-light Dynamic Scenes from Spike Streams](https://arxiv.org/abs/2401.10461) (ECCV)
- [ ] [\[2401.10501\] Enhancing medical vision-language contrastive learning via inter-matching relation modelling](https://arxiv.org/abs/2401.10501) (USyd)
- [ ] [\[2401.10512\] Exploring Color Invariance through Image-Level Ensemble Learning](https://arxiv.org/abs/2401.10512) (Xiamen)
- [ ] [\[2401.10529\] Mementos: A Comprehensive Benchmark for Multimodal Large Language Model Reasoning over Image Sequences](https://arxiv.org/abs/2401.10529) (UMD)
- [ ] [\[2401.10537\] Learning Position-Aware Implicit Neural Network for Real-World Face Inpainting](https://arxiv.org/abs/2401.10537) (Microsoft)
- [ ] [\[2401.10556\] Symbol as Points: Panoptic Symbol Spotting via Point-based Representation](https://arxiv.org/abs/2401.10556) (ICLR)
- [ ] [\[2401.10564\] Dream360: Diverse and Immersive Outdoor Virtual Scene Creation via Transformer-Based 360 Image Outpainting](https://arxiv.org/abs/2401.10564) (USTC)
- [ ] [\[2401.10588\] DGL: Dynamic Global-Local Prompt Tuning for Text-Video Retrieval](https://arxiv.org/abs/2401.10588) (UTS)
- [ ] [\[2401.10608\] M2ORT: Many-To-One Regression Transformer for Spatial Transcriptomics Prediction from Histopathology Images](https://arxiv.org/abs/2401.10608) (ZJU)
- [ ] [\[2401.10666\] MixNet: Towards Effective and Efficient UHD Low-Light Image Enhancement](https://arxiv.org/abs/2401.10666) (USTC)
- [ ] [\[2401.10711\] Weakly Supervised Gaussian Contrastive Grounding with Large Multimodal Models for Video Question Answering](https://arxiv.org/abs/2401.10711) (Fudan, ACMMM)
- [ ] [\[2401.10712\] Q&A Prompts: Discovering Rich Visual Clues through Mining Question-Answer Prompts for VQA requiring Diverse World Knowledge](https://arxiv.org/abs/2401.10712) (Fudan, ECCV)
- [ ] [\[2401.10752\] HiCD: Change Detection in Quality-Varied Images via Hierarchical Correlation Distillation](https://arxiv.org/abs/2401.10752) (WHU)
- [ ] [\[2401.10815\] RAD-DINO: Exploring Scalable Medical Image Encoders Beyond Text Supervision](https://arxiv.org/abs/2401.10815) (Microsoft)
- [ ] [\[2401.10831\] Understanding Video Transformers via Universal Concept Discovery](https://arxiv.org/abs/2401.10831) (CVPR)
- [ ] [\[2401.10848\] Source-Free and Image-Only Unsupervised Domain Adaptation for Category Level Object Pose Estimation](https://arxiv.org/abs/2401.10848) (MPI, ICLR)
- [ ] [\[2401.10886\] SCENES: Subpixel Correspondence Estimation With Epipolar Supervision](https://arxiv.org/abs/2401.10886) (Oxford)
- [ ] [\[2401.10890\] Event detection from novel data sources: Leveraging satellite imagery alongside GPS traces](https://arxiv.org/abs/2401.10890) (UW)
- [ ] [\[2401.10891\] Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data](https://arxiv.org/abs/2401.10891) (CVPR)
- [ ] [\[2401.10962\] One Step Learning, One Step Review](https://arxiv.org/abs/2401.10962) (USTC)
- [ ] [\[2401.11002\] Fast Registration of Photorealistic Avatars for VR Facial Animation](https://arxiv.org/abs/2401.11002) (ECCV)
- [ ] [\[2401.11110\] VONet: Unsupervised Video Object Learning With Parallel U-Net Attention and Object-wise Sequential VAE](https://arxiv.org/abs/2401.11110) (ICLR)
- [ ] [\[2401.11115\] MotionMix: Weakly-Supervised Diffusion for Controllable Motion Generation](https://arxiv.org/abs/2401.11115) (NTU)
- [ ] [\[2401.11122\] Spatial Structure Constraints for Weakly Supervised Semantic Segmentation](https://arxiv.org/abs/2401.11122) (TIP)
- [ ] [\[2401.11170\] Inducing High Energy-Latency of Large Vision-Language Models with Verbose Images](https://arxiv.org/abs/2401.11170) (Tsinghua, ICLR)
- [ ] [\[2401.11204\] Towards Category Unification of 3D Single Object Tracking on Point Clouds](https://arxiv.org/abs/2401.11204) (SJTU)
- [ ] [\[2401.11228\] Unifying Visual and Vision-Language Tracking via Contrastive Learning](https://arxiv.org/abs/2401.11228) (USTC)
- [ ] [\[2401.11239\] Product-Level Try-on: Characteristics-preserving Try-on with Realistic Clothes Shading and Wrinkles](https://arxiv.org/abs/2401.11239) (ETH)
- [ ] [\[2401.11243\] LRP-QViT: Mixed-Precision Vision Transformer Quantization via Layer-wise Relevance Propagation](https://arxiv.org/abs/2401.11243) (Rochester Institute of Technology)
- [ ] [\[2401.11414\] S$^3$M-Net: Joint Learning of Semantic Segmentation and Stereo Matching for Autonomous Driving](https://arxiv.org/abs/2401.11414) (Tongji)
- [ ] [\[2401.11425\] Grayscale Image Colorization with GAN and CycleGAN in Different Image Domain](https://arxiv.org/abs/2401.11425) (CMU)
- [ ] [\[2401.11430\] Exploring Diffusion Time-steps for Unsupervised Representation Learning](https://arxiv.org/abs/2401.11430) (NTU, ICLR)
- [ ] [\[2401.11436\] Geometric Prior Guided Feature Representation Learning for Long-Tailed Classification](https://arxiv.org/abs/2401.11436) (Xidian)
- [ ] [\[2401.11448\] Adaptive Betweenness Clustering for Semi-Supervised Domain Adaptation](https://arxiv.org/abs/2401.11448) (HKU, TIP)
- [ ] [\[2401.11485\] ColorVideoVDP: A visual difference predictor for image, video and display distortions](https://arxiv.org/abs/2401.11485) (Cambridge)
- [ ] [\[2401.11511\] MobileARLoc: On-device Robust Absolute Localisation for Pervasive Markerless Mobile AR](https://arxiv.org/abs/2401.11511) (HKUST)
- [ ] [\[2401.11535\] EndoGS: Deformable Endoscopic Tissues Reconstruction with Gaussian Splatting](https://arxiv.org/abs/2401.11535) (HKU)
- [ ] [\[2401.11544\] Hierarchical Prompts for Rehearsal-free Continual Learning](https://arxiv.org/abs/2401.11544) (USTC, TPAMI)
- [ ] [\[2401.11649\] M2-CLIP: A Multimodal, Multi-task Adapting Framework for Video Action Recognition](https://arxiv.org/abs/2401.11649) (TUM)
- [ ] [\[2401.11654\] ActionHub: A Large-scale Action Video Description Dataset for Zero-shot Action Recognition](https://arxiv.org/abs/2401.11654) (HKUST(GZ))
- [ ] [\[2401.11673\] MVSFormer++: Revealing the Devil in Transformer's Details for Multi-View Stereo](https://arxiv.org/abs/2401.11673) (ICLR)
- [ ] [\[2401.11674\] Memory-Efficient Prompt Tuning for Incremental Histopathology Classification](https://arxiv.org/abs/2401.11674) (HKU)
- [ ] [\[2401.11708\] Mastering Text-to-Image Diffusion: Recaptioning, Planning, and Generating with Multimodal LLMs](https://arxiv.org/abs/2401.11708) (ICML)
- [ ] [\[2401.11713\] Medical Image Debiasing by Learning Adaptive Agreement from a Biased Council](https://arxiv.org/abs/2401.11713) (HKUST)
- [ ] [\[2401.11738\] MetaSeg: Content-Aware Meta-Net for Omni-Supervised Semantic Segmentation](https://arxiv.org/abs/2401.11738) (Chongqing)
- [ ] [\[2401.11739\] EmerDiff: Emerging Pixel-level Semantic Knowledge in Diffusion Models](https://arxiv.org/abs/2401.11739) (University of Toronto, ICLR)
- [ ] [\[2401.11767\] Concealed Object Segmentation with Hierarchical Coherence Modeling](https://arxiv.org/abs/2401.11767) (SYSU)
- [ ] [\[2401.11775\] Collaborative Position Reasoning Network for Referring Image Segmentation](https://arxiv.org/abs/2401.11775) (Fudan)
- [ ] [\[2401.11783\] Full-Body Motion Reconstruction with Sparse Sensing from Graph Perspective](https://arxiv.org/abs/2401.11783) (Tsinghua)
- [ ] [\[2401.11874\] Detect-Order-Construct: A Tree Construction based Approach for Hierarchical Document Structure Analysis](https://arxiv.org/abs/2401.11874) (USTC)
- [ ] [\[2401.11913\] Large receptive field strategy and important feature extraction strategy in 3D object detection](https://arxiv.org/abs/2401.11913) (Tongji)
- [ ] [\[2401.12051\] CloSe: A 3D Clothing Segmentation Dataset and Model](https://arxiv.org/abs/2401.12051) (UVA.NL)
- [ ] [\[2401.12168\] SpatialVLM: Endowing Vision-Language Models with Spatial Reasoning Capabilities](https://arxiv.org/abs/2401.12168) (MIT)
- [ ] [\[2401.12198\] LONEStar: The Lunar Flashlight Optical Navigation Experiment](https://arxiv.org/abs/2401.12198) (GIT)
- [ ] [\[2401.12215\] Less Could Be Better: Parameter-efficient Fine-tuning Advances Medical Vision Foundation Models](https://arxiv.org/abs/2401.12215) (Xiamen)
- [ ] [\[2401.12217\] Exploring Simple Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2401.12217) (Oxford)
- [ ] [\[2401.12414\] Icy Moon Surface Simulation and Stereo Depth Estimation for Sampling Autonomy](https://arxiv.org/abs/2401.12414) (NASA)
- [ ] [\[2401.12421\] AdaEmbed: Semi-supervised Domain Adaptation in the Embedding Space](https://arxiv.org/abs/2401.12421) (Stanford)
- [ ] [\[2401.12433\] A Novel Garment Transfer Method Supervised by Distilled Knowledge of Virtual Try-on Model](https://arxiv.org/abs/2401.12433) (ZJU)
- [ ] [\[2401.12439\] MAST: Video Polyp Segmentation with a Mixture-Attention Siamese Transformer](https://arxiv.org/abs/2401.12439) (NWPU)
- [ ] [\[2401.12452\] Self-supervised Learning of LiDAR 3D Point Clouds via 2D-3D Neural Calibration](https://arxiv.org/abs/2401.12452) (Xidian)
- [ ] [\[2401.12471\] Training-Free Action Recognition and Goal Inference with Dynamic Frame Selection](https://arxiv.org/abs/2401.12471) (A*STAR,)
- [ ] [\[2401.12479\] TD^2-Net: Toward Denoising and Debiasing for Dynamic Scene Graph Generation](https://arxiv.org/abs/2401.12479) (USTC)
- [ ] [\[2401.12480\] Explore Synergistic Interaction Across Frames for Interactive Video Object Segmentation](https://arxiv.org/abs/2401.12480) (ZJU)
- [ ] [\[2401.12561\] EndoGaussian: Real-time Gaussian Splatting for Dynamic Endoscopic Scene Reconstruction](https://arxiv.org/abs/2401.12561) (CUHK)
- [ ] [\[2401.12568\] NeRF-AD: Neural Radiance Field with Attention-based Disentanglement for Talking Face Synthesis](https://arxiv.org/abs/2401.12568) (Tianjin)
- [ ] [\[2401.12694\] Pragmatic Communication in Multi-Agent Collaborative Perception](https://arxiv.org/abs/2401.12694) (SJTU)
- [ ] [\[2401.12743\] Correlation-Embedded Transformer Tracking: A Single-Branch Framework](https://arxiv.org/abs/2401.12743) (TPAMI)
- [ ] [\[2401.12751\] PSDF: Prior-Driven Neural Implicit Surface Learning for Multi-view Reconstruction](https://arxiv.org/abs/2401.12751) (NTU)
- [ ] [\[2401.12835\] SGTR+: End-to-end Scene Graph Generation with Transformer](https://arxiv.org/abs/2401.12835) (ShanghaiTech, TPAMI)
- [ ] [\[2401.12862\] FedRSU: Federated Learning for Scene Flow Estimation on Roadside Units](https://arxiv.org/abs/2401.12862) (SJTU)
- [ ] [\[2401.12975\] HAZARD Challenge: Embodied Decision Making in Dynamically Changing Environments](https://arxiv.org/abs/2401.12975) (ICLR)
- [ ] [\[2401.12979\] GALA: Generating Animatable Layered Assets from a Single Scan](https://arxiv.org/abs/2401.12979) (Meta)
- [ ] [\[2401.13081\] Free Form Medical Visual Question Answering in Radiology](https://arxiv.org/abs/2401.13081) (NYU)
- [ ] [\[2401.13087\] Open-source data pipeline for street-view images: a case study on community mobility during COVID-19 pandemic](https://arxiv.org/abs/2401.13087) (UW)
- [ ] [\[2401.13172\] ADMap: Anti-disturbance framework for reconstructing online vectorized HD map](https://arxiv.org/abs/2401.13172) (ZJU)
- [ ] [\[2401.13205\] Boosting the Transferability of Adversarial Examples via Local Mixup and Adaptive Step Size](https://arxiv.org/abs/2401.13205) (BUPT)
- [ ] [\[2401.13213\] Common-Sense Bias Discovery and Mitigation for Classification Tasks](https://arxiv.org/abs/2401.13213) (NYU)
- [ ] [\[2401.13264\] Enhancing cross-domain detection: adaptive class-aware contrastive transformer](https://arxiv.org/abs/2401.13264) (SJTU)
- [ ] [\[2401.13267\] Dynamic Traceback Learning for Medical Report Generation](https://arxiv.org/abs/2401.13267) (USyd)
- [ ] [\[2401.13311\] ConTextual: Evaluating Context-Sensitive Text-Rich Visual Reasoning in Large Multimodal Models](https://arxiv.org/abs/2401.13311) (UCLA)
- [ ] [\[2401.13329\] Generative Video Diffusion for Unseen Cross-Domain Video Moment Retrieval](https://arxiv.org/abs/2401.13329) (Peking)
- [ ] [\[2401.13357\] Linear Relative Pose Estimation Founded on Pose-only Imaging Geometry](https://arxiv.org/abs/2401.13357) (SJTU)
- [ ] [\[2401.13363\] Do You Guys Want to Dance: Zero-Shot Compositional Human Dance Generation with Multiple Persons](https://arxiv.org/abs/2401.13363) (Xidian)
- [ ] [\[2401.13386\] Privacy-Preserving Face Recognition in Hybrid Frequency-Color Domain](https://arxiv.org/abs/2401.13386) (ICCV)
- [ ] [\[2401.13405\] Synthetic data enables faster annotation and robust segmentation for multi-object grasping in clutter](https://arxiv.org/abs/2401.13405) (Imperial)
- [ ] [\[2401.13432\] Semi-Supervised Coupled Thin-Plate Spline Model for Rotation Correction and Beyond](https://arxiv.org/abs/2401.13432) (NTU, TPAMI)
- [ ] [\[2401.13505\] Generative Human Motion Stylization in Latent Space](https://arxiv.org/abs/2401.13505) (ICLR)
- [ ] [\[2401.13516\] Delocate: Detection and Localization for Deepfake Videos with Randomly-Located Tampered Traces](https://arxiv.org/abs/2401.13516) (NTU)
- [ ] [\[2401.13531\] QAGait: Revisit Gait Recognition from a Quality Perspective](https://arxiv.org/abs/2401.13531) (BUPT)
- [ ] [\[2401.13560\] SegMamba: Long-range Sequential Modeling Mamba For 3D Medical Image Segmentation](https://arxiv.org/abs/2401.13560) (HKUST(GZ))
- [ ] [\[2401.13627\] Scaling Up to Excellence: Practicing Model Scaling for Photo-Realistic Image Restoration In the Wild](https://arxiv.org/abs/2401.13627) (CVPR)
- [ ] [\[2401.13697\] Toward Robust Multimodal Learning using Multimodal Foundational Models](https://arxiv.org/abs/2401.13697) (SYSU)
- [ ] [\[2401.13714\] Value-Driven Mixed-Precision Quantization for Patch-Based Inference on Microcontrollers](https://arxiv.org/abs/2401.13714) (HUST)
- [ ] [\[2401.13785\] Unified Spatio-Temporal Tri-Perspective View Representation for 3D Semantic Occupancy Prediction](https://arxiv.org/abs/2401.13785) (UMD)
- [ ] [\[2401.13795\] Diffuse to Choose: Enriching Image Conditioned Inpainting in Latent Diffusion Models for Virtual Try-All](https://arxiv.org/abs/2401.13795) (AWS)
- [ ] [\[2401.13837\] Democratizing Fine-grained Visual Recognition with Large Language Models](https://arxiv.org/abs/2401.13837) (ICLR)
- [ ] [\[2401.13856\] LAA-Net: Localized Artifact Attention Network for Quality-Agnostic and Generalizable Deepfake Detection](https://arxiv.org/abs/2401.13856) (CVPR)
- [ ] [\[2401.13888\] Knowledge Guided Entity-aware Video Captioning and A Basketball Benchmark](https://arxiv.org/abs/2401.13888) (SJTU)
- [ ] [\[2401.13937\] Self-supervised Video Object Segmentation with Distillation Learning of Deformable Attention](https://arxiv.org/abs/2401.13937) (HKUST)
- [ ] [\[2401.13961\] TriSAM: Tri-Plane SAM for zero-shot cortical blood vessel segmentation in VEM images](https://arxiv.org/abs/2401.13961) (Harvard)
- [ ] [\[2401.13964\] An Extensible Framework for Open Heterogeneous Collaborative Perception](https://arxiv.org/abs/2401.13964) (ICLR)
- [ ] [\[2401.14115\] MIFI: MultI-camera Feature Integration for Roust 3D Distracted Driver Activity Recognition](https://arxiv.org/abs/2401.14115) (USTC)
- [ ] [\[2401.14142\] Energy-Based Concept Bottleneck Models: Unifying Prediction, Concept Intervention, and Probabilistic Interpretations](https://arxiv.org/abs/2401.14142) (UW, ICLR)
- [ ] [\[2401.14168\] Vivim: a Video Vision Mamba for Medical Video Segmentation](https://arxiv.org/abs/2401.14168) (HKUST(GZ))
- [ ] [\[2401.14257\] Sketch2NeRF: Multi-view Sketch-guided Text-to-3D Generation](https://arxiv.org/abs/2401.14257) (SYSU)
- [ ] [\[2401.14285\] POUR-Net: A Population-Prior-Aided Over-Under-Representation Network for Low-Count PET Attenuation Map Generation](https://arxiv.org/abs/2401.14285) (Yale)
- [ ] [\[2401.14325\] Unlocking Past Information: Temporal Embeddings in Cooperative Bird's Eye View Prediction](https://arxiv.org/abs/2401.14325) (TUM)
- [ ] [\[2401.14354\] Learning Robust Generalizable Radiance Field with Visibility and Feature Augmented Point Representation](https://arxiv.org/abs/2401.14354) (HKUST(GZ), ICLR)
- [ ] [\[2401.14405\] Multimodal Pathway: Improve Transformers with Irrelevant Data from Other Modalities](https://arxiv.org/abs/2401.14405) (CUHK, CVPR)
- [ ] [\[2401.14486\] CloudTracks: A Dataset for Localizing Ship Tracks in Satellite Images of Clouds](https://arxiv.org/abs/2401.14486) (Stanford)
- [ ] [\[2401.14555\] Revisiting Active Learning in the Era of Vision Foundation Models](https://arxiv.org/abs/2401.14555) (Stanford)
- [ ] [\[2401.14587\] CNG-SFDA: Clean-and-Noisy Region Guided Online-Offline Source-Free Domain Adaptation](https://arxiv.org/abs/2401.14587) (POSTECH)
- [ ] [\[2401.14626\] Towards Lifelong Scene Graph Generation with Knowledge-ware In-context Prompt Learning](https://arxiv.org/abs/2401.14626) (UESTC)
- [ ] [\[2401.14641\] Super Efficient Neural Network for Compression Artifacts Reduction and Super Resolution](https://arxiv.org/abs/2401.14641) (AWS)
- [ ] [\[2401.14707\] Mitigating Feature Gap for Adversarial Robustness by Feature Disentanglement](https://arxiv.org/abs/2401.14707) (Xidian)
- [ ] [\[2401.14718\] A Survey on Future Frame Synthesis: Bridging Deterministic and Generative Approaches](https://arxiv.org/abs/2401.14718) (Tsinghua)
- [ ] [\[2401.14729\] Sketch and Refine: Towards Fast and Accurate Lane Detection](https://arxiv.org/abs/2401.14729) (NJU)
- [ ] [\[2401.14785\] SimpleEgo: Predicting Probabilistic Body Pose from Egocentric Cameras](https://arxiv.org/abs/2401.14785) (MPI)
- [ ] [\[2401.14828\] TIP-Editor: An Accurate 3D Editor Following Both Text-Prompts And Image-Prompts](https://arxiv.org/abs/2401.14828) (SYSU, SIGGRAPH)
- [ ] [\[2401.14838\] Multi-modality action recognition based on dual feature shift in vehicle cabin monitoring](https://arxiv.org/abs/2401.14838) (NTU)
- [ ] [\[2401.14856\] Memory-Inspired Temporal Prompt Interaction for Text-Image Classification](https://arxiv.org/abs/2401.14856) (ZJU)
- [ ] [\[2401.14861\] Implicit Neural Representation for Physics-driven Actuated Soft Bodies](https://arxiv.org/abs/2401.14861) (ETH, SIGGRAPH)
- [ ] [\[2401.15071\] From GPT-4 to Gemini and Beyond: Assessing the Landscape of MLLMs on Generalizability, Trustworthiness and Causality through Four Modalities](https://arxiv.org/abs/2401.15071) (Shanghai AI Lab)
- [ ] [\[2401.15075\] Annotated Hands for Generative Models](https://arxiv.org/abs/2401.15075) (GIT)
- [ ] [\[2401.15261\] Vanishing-Point-Guided Video Semantic Segmentation of Driving Scenes](https://arxiv.org/abs/2401.15261) (CVPR)
- [ ] [\[2401.15282\] GEM: Boost Simple Network for Glass Surface Segmentation via Segment Anything Model and Data Synthesis](https://arxiv.org/abs/2401.15282) (HUST)
- [ ] [\[2401.15287\] Applications of Tao General Difference in Discrete Domain](https://arxiv.org/abs/2401.15287) (Tsinghua)
- [ ] [\[2401.15288\] STAC: Leveraging Spatio-Temporal Data Associations For Efficient Cross-Camera Streaming and Analytics](https://arxiv.org/abs/2401.15288) (Illinois)
- [ ] [\[2401.15296\] A Survey on 3D Skeleton Based Person Re-Identification: Approaches, Designs, Challenges, and Future Directions](https://arxiv.org/abs/2401.15296) (NTU)
- [ ] [\[2401.15319\] You Only Look Bottom-Up for Monocular 3D Object Detection](https://arxiv.org/abs/2401.15319) (HUST)
- [ ] [\[2401.15365\] An open dataset for oracle bone script recognition and decipherment](https://arxiv.org/abs/2401.15365) (HUST)
- [ ] [\[2401.15414\] An Implicit Physical Face Model Driven by Expression and Style](https://arxiv.org/abs/2401.15414) (SIGGRAPH)
- [ ] [\[2401.15458\] A New Method for Vehicle Logo Recognition Based on Swin Transformer](https://arxiv.org/abs/2401.15458) (SJTU)
- [ ] [\[2401.15473\] iDeLog: Iterative Dual Spatial and Kinematic Extraction of Sigma-Lognormal Parameters](https://arxiv.org/abs/2401.15473) (TPAMI)
- [ ] [\[2401.15563\] BrepGen: A B-rep Generative Diffusion Model with Structured Latent Geometry](https://arxiv.org/abs/2401.15563) (SIGGRAPH)
- [ ] [\[2401.15578\] ASCNet: Asymmetric Sampling Correction Network for Infrared Image Destriping](https://arxiv.org/abs/2401.15578) (Xidian)
- [ ] [\[2401.15583\] SCTransNet: Spatial-channel Cross Transformer Network for Infrared Small Target Detection](https://arxiv.org/abs/2401.15583) (Xidian)
- [ ] [\[2401.15646\] Improving Data Augmentation for Robust Visual Question Answering with Effective Curriculum Learning](https://arxiv.org/abs/2401.15646) (ZJU)
- [ ] [\[2401.15647\] UP-CrackNet: Unsupervised Pixel-Wise Road Crack Detection via Adversarial Image Restoration](https://arxiv.org/abs/2401.15647) (NTU)
- [ ] [\[2401.15652\] Continuous-Multiple Image Outpainting in One-Step via Positional Query and A Diffusion-based Approach](https://arxiv.org/abs/2401.15652) (ICLR)
- [ ] [\[2401.15657\] Data-Free Generalized Zero-Shot Learning](https://arxiv.org/abs/2401.15657) (HKU)
- [ ] [\[2401.15668\] Lips Are Lying: Spotting the Temporal Inconsistency between Audio and Visual in Lip-Syncing DeepFakes](https://arxiv.org/abs/2401.15668) (WHU)
- [ ] [\[2401.15687\] Media2Face: Co-speech Facial Animation Generation With Multi-Modality Guidance](https://arxiv.org/abs/2401.15687) (HKU)
- [ ] [\[2401.15688\] Divide and Conquer: Language Models can Plan and Self-Correct for Compositional Text-to-Image Generation](https://arxiv.org/abs/2401.15688) (Tsinghua)
- [ ] [\[2401.15726\] Long-Term Typhoon Trajectory Prediction: A Physics-Conditioned Approach Without Reanalysis Data](https://arxiv.org/abs/2401.15726) (ICLR)
- [ ] [\[2401.15785\] Real-time object detection and robotic manipulation for agriculture using a YOLO-based learning approach](https://arxiv.org/abs/2401.15785) (Fudan)
- [ ] [\[2401.15820\] Knowledge-Aware Neuron Interpretation for Scene Classification](https://arxiv.org/abs/2401.15820) (Tsinghua)
- [ ] [\[2401.15859\] Diffusion Facial Forgery Detection](https://arxiv.org/abs/2401.15859) (NUS)
- [ ] [\[2401.15864\] Spatial Decomposition and Temporal Fusion based Inter Prediction for Learned Video Compression](https://arxiv.org/abs/2401.15864) (USTC)
- [ ] [\[2401.15865\] LiDAR-PTQ: Post-Training Quantization for Point Cloud 3D Object Detection](https://arxiv.org/abs/2401.15865) (ICLR)
- [ ] [\[2401.15885\] Rectify the Regression Bias in Long-Tailed Object Detection](https://arxiv.org/abs/2401.15885) (NJU)
- [ ] [\[2401.15902\] A Concise but High-performing Network for Image Guided Depth Completion in Autonomous Driving](https://arxiv.org/abs/2401.15902) (HUST)
- [ ] [\[2401.15914\] Overcoming the Pitfalls of Vision-Language Model Finetuning for OOD Generalization](https://arxiv.org/abs/2401.15914) (NTU, ICLR)
- [ ] [\[2401.15947\] MoE-LLaVA: Mixture of Experts for Large Vision-Language Models](https://arxiv.org/abs/2401.15947) (Peking)
- [ ] [\[2401.15977\] Motion-I2V: Consistent and Controllable Image-to-Video Generation with Explicit Motion Modeling](https://arxiv.org/abs/2401.15977) (CUHK)
- [ ] [\[2401.16035\] Second Order Kinematic Surface Fitting in Anatomical Structures](https://arxiv.org/abs/2401.16035) (TUM)
- [ ] [\[2401.16051\] Dynamic Prototype Adaptation with Distillation for Few-shot Point Cloud Segmentation](https://arxiv.org/abs/2401.16051) (CMU)
- [ ] [\[2401.16173\] Reconstructing Close Human Interactions from Multiple Views](https://arxiv.org/abs/2401.16173) (ZJU, SIGGRAPH)
- [ ] [\[2401.16224\] Diffutoon: High-Resolution Editable Toon Shading via Diffusion Models](https://arxiv.org/abs/2401.16224) (Alibaba)
- [ ] [\[2401.16305\] MixSup: Mixed-grained Supervision for Label-efficient LiDAR-based 3D Object Detection](https://arxiv.org/abs/2401.16305) (ICLR)
- [ ] [\[2401.16393\] Amazon's 2023 Drought: Sentinel-1 Reveals Extreme Rio Negro River Contraction](https://arxiv.org/abs/2401.16393) (UCLA)
- [ ] [\[2401.16402\] A Survey on Visual Anomaly Detection: Challenge, Approach, and Prospect](https://arxiv.org/abs/2401.16402) (ZJU)
- [ ] [\[2401.16416\] Endo-4DGS: Endoscopic Monocular Scene Reconstruction with 4D Gaussian Splatting](https://arxiv.org/abs/2401.16416) (UCL)
- [ ] [\[2401.16420\] InternLM-XComposer2: Mastering Free-form Text-Image Composition and Comprehension in Vision-Language Large Model](https://arxiv.org/abs/2401.16420) (Shanghai AI Lab)
- [ ] [\[2401.16456\] SHViT: Single-Head Vision Transformer with Memory Efficient Macro Design](https://arxiv.org/abs/2401.16456) (CVPR)
- [ ] [\[2401.16465\] DressCode: Autoregressively Sewing and Generating Garments from Text Guidance](https://arxiv.org/abs/2401.16465) (ShanghaiTech)
- [ ] [\[2401.16468\] InstructIR: High-Quality Image Restoration Following Human Instructions](https://arxiv.org/abs/2401.16468) (ECCV)
- [ ] [\[2401.16634\] The Why, When, and How to Use Active Learning in Large-Data-Driven 3D Object Detection for Safe Autonomous Driving: An Empirical Exploration](https://arxiv.org/abs/2401.16634) (UCSD)
- [ ] [\[2401.16700\] Towards Precise 3D Human Pose Estimation with Multi-Perspective Spatial-Temporal Relational Transformers](https://arxiv.org/abs/2401.16700) (Xidian)
- [ ] [\[2401.16702\] Multi-granularity Correspondence Learning from Long-term Noisy Videos](https://arxiv.org/abs/2401.16702) (ICLR)
- [ ] [\[2401.16741\] MESA: Matching Everything by Segmenting Anything](https://arxiv.org/abs/2401.16741) (CVPR)
- [ ] [\[2401.16753\] MuSc: Zero-Shot Industrial Anomaly Classification and Segmentation with Mutual Scoring of the Unlabeled Images](https://arxiv.org/abs/2401.16753) (ICLR)
- [ ] [\[2401.16764\] BoostDream: Efficient Refining for High-Quality Text-to-3D Generation from Multi-View Diffusion](https://arxiv.org/abs/2401.16764) (Alibaba)
- [ ] [\[2401.16822\] EarthGPT: A Universal Multi-modal Large Language Model for Multi-sensor Image Comprehension in Remote Sensing Domain](https://arxiv.org/abs/2401.16822) (BIT)
- [ ] [\[2401.17023\] MF-MOS: A Motion-Focused Model for Moving Object Segmentation](https://arxiv.org/abs/2401.17023) (NUDT)
- [ ] [\[2401.17038\] Towards Assessing the Synthetic-to-Measured Adversarial Vulnerability of SAR ATR](https://arxiv.org/abs/2401.17038) (NUDT)
- [ ] [\[2401.17053\] BlockFusion: Expandable 3D Scene Generation using Latent Tri-plane Extrapolation](https://arxiv.org/abs/2401.17053) (University of Tokyo, SIGGRAPH)
- [ ] [\[2401.17093\] StrokeNUWA: Tokenizing Strokes for Vector Graphic Synthesis](https://arxiv.org/abs/2401.17093) (Microsoft)
- [ ] [\[2401.17098\] Deep Learning-Driven Approach for Handwritten Chinese Character Classification](https://arxiv.org/abs/2401.17098) (HKUST)
- [ ] [\[2401.17203\] CPR++: Object Localization via Single Coarse Point Supervision](https://arxiv.org/abs/2401.17203) (TPAMI)
- [ ] [\[2401.17343\] YTCommentQA: Video Question Answerability in Instructional Videos](https://arxiv.org/abs/2401.17343) (KAIST)
- [ ] [\[2401.17603\] Topology-Aware Latent Diffusion for 3D Shape Generation](https://arxiv.org/abs/2401.17603) (NTU)
- [ ] [\[2401.17604\] Computation and Parameter Efficient Multi-Modal Fusion Transformer for Cued Speech Recognition](https://arxiv.org/abs/2401.17604) (HKUST(GZ))
- [ ] [\[2401.17609\] LaneGraph2Seq: Lane Topology Extraction with Language Model via Vertex-Edge Encoding and Connectivity Enhancement](https://arxiv.org/abs/2401.17609) (Fudan)
- [ ] [\[2401.17664\] Image Anything: Towards Reasoning-coherent and Training-free Multi-modal Image Generation](https://arxiv.org/abs/2401.17664) (HKUST(GZ))
- [ ] [\[2401.17766\] Fine-Grained Zero-Shot Learning: Advances, Challenges, and Prospects](https://arxiv.org/abs/2401.17766) (Queensland)
- [ ] [\[2401.17773\] SNP-S3: Shared Network Pre-training and Significant Semantic Strengthening for Various Video-Text Tasks](https://arxiv.org/abs/2401.17773) (Peking)
- [ ] [\[2401.17797\] M2-RAAP: A Multi-Modal Recipe for Advancing Adaptation-based Pre-training towards Effective and Efficient Zero-shot Video-text Retrieval](https://arxiv.org/abs/2401.17797) (NTU)
- [ ] [\[2401.17868\] Convolution Meets LoRA: Parameter Efficient Finetuning for Segment Anything Model](https://arxiv.org/abs/2401.17868) (Tsinghua, ICLR)
- [ ] [\[2401.17879\] AEROBLADE: Training-Free Detection of Latent Diffusion Images Using Autoencoder Reconstruction Error](https://arxiv.org/abs/2401.17879) (CVPR)
- [ ] [\[2401.17981\] Enhancing Multimodal Large Language Models with Vision Detection Models: An Empirical Study](https://arxiv.org/abs/2401.17981) (SYSU)
- [ ] [\[2401.17992\] Multilinear Operator Networks](https://arxiv.org/abs/2401.17992) (ICLR)
- [ ] [\[2401.18075\] CARFF: Conditional Auto-encoded Radiance Field for 3D Scene Forecasting](https://arxiv.org/abs/2401.18075) (ECCV)
- [ ] [\[2402.00033\] LF-ViT: Reducing Spatial Redundancy in Vision Transformer for Efficient Image Recognition](https://arxiv.org/abs/2402.00033) (HIT)
- [ ] [\[2402.00261\] Understanding Neural Network Systems for Image Analysis using Vector Spaces and Inverse Maps](https://arxiv.org/abs/2402.00261) (UCLA)
- [ ] [\[2402.00290\] MEIA: Multimodal Embodied Perception and Interaction in Unknown Environments](https://arxiv.org/abs/2402.00290) (SYSU)
- [ ] [\[2402.00304\] Invariance-powered Trustworthy Defense via Remove Then Restore](https://arxiv.org/abs/2402.00304) (Chongqing)
- [ ] [\[2402.00319\] SCO-VIST: Social Interaction Commonsense Knowledge-based Visual Storytelling](https://arxiv.org/abs/2402.00319) (USyd)
- [ ] [\[2402.00321\] SmartCooper: Vehicular Collaborative Perception with Adaptive Fusion and Judger Mechanism](https://arxiv.org/abs/2402.00321) (HKU)
- [ ] [\[2402.00407\] InfMAE: A Foundation Model in Infrared Modality](https://arxiv.org/abs/2402.00407) (SYSU)
- [ ] [\[2402.00422\] Lightweight Pixel Difference Networks for Efficient Visual Representation Learning](https://arxiv.org/abs/2402.00422) (NUDT, TPAMI)
- [ ] [\[2402.00606\] Dynamic Texture Transfer using PatchMatch and Transformers](https://arxiv.org/abs/2402.00606) (Peking)
- [ ] [\[2402.00627\] CapHuman: Capture Your Moments in Parallel Universes](https://arxiv.org/abs/2402.00627) (CVPR)
- [ ] [\[2402.00672\] Exploring Homogeneous and Heterogeneous Consistent Label Associations for Unsupervised Visible-Infrared Person ReID](https://arxiv.org/abs/2402.00672) (Xidian)
- [ ] [\[2402.00752\] On the Error Analysis of 3D Gaussian Splatting and an Optimal Projection Strategy](https://arxiv.org/abs/2402.00752) (ECCV)
- [ ] [\[2402.00763\] 360-GS: Layout-guided Panoramic Gaussian Splatting For Indoor Roaming](https://arxiv.org/abs/2402.00763) (NJU)
- [ ] [\[2402.00827\] GaussianStyle: Gaussian Head Avatar via StyleGAN](https://arxiv.org/abs/2402.00827) (GIT)
- [ ] [\[2402.00863\] Geometry Transfer for Stylizing Radiance Fields](https://arxiv.org/abs/2402.00863) (CVPR)
- [ ] [\[2402.00864\] ViCA-NeRF: View-Consistency-Aware 3D Editing of Neural Radiance Fields](https://arxiv.org/abs/2402.00864) (NIPS)
- [ ] [\[2402.00865\] Towards Optimal Feature-Shaping Methods for Out-of-Distribution Detection](https://arxiv.org/abs/2402.00865) (ICLR)
- [ ] [\[2402.00868\] We're Not Using Videos Effectively: An Updated Domain Adaptive Video Segmentation Baseline](https://arxiv.org/abs/2402.00868) (GIT)
- [ ] [\[2402.01002\] AI-generated faces influence gender stereotypes and racial homogenization](https://arxiv.org/abs/2402.01002) (NYU)
- [ ] [\[2402.01049\] IMUGPT 2.0: Language-Based Cross Modality Transfer for Sensor-Based Human Activity Recognition](https://arxiv.org/abs/2402.01049) (GIT)
- [ ] [\[2402.01162\] 2AFC Prompting of Large Multimodal Models for Image Quality Assessment](https://arxiv.org/abs/2402.01162) (NTU)
- [ ] [\[2402.01166\] A Comprehensive Survey on 3D Content Generation](https://arxiv.org/abs/2402.01166) (NTU)
- [ ] [\[2402.01187\] DeepBranchTracer: A Generally-Applicable Approach to Curvilinear Structure Reconstruction Using Multi-Feature Learning](https://arxiv.org/abs/2402.01187) (ZJU)
- [ ] [\[2402.01188\] Segment Any Change](https://arxiv.org/abs/2402.01188) (Stanford)
- [ ] [\[2402.01191\] Unsupervised Generation of Pseudo Normal PET from MRI with Diffusion Model for Epileptic Focus Localization](https://arxiv.org/abs/2402.01191) (SJTU)
- [ ] [\[2402.01217\] ID-NeRF: Indirect Diffusion-guided Neural Radiance Fields for Generalizable View Synthesis](https://arxiv.org/abs/2402.01217) (SYSU)
- [ ] [\[2402.01220\] Delving into Decision-based Black-box Attacks on Semantic Segmentation](https://arxiv.org/abs/2402.01220) (Fudan)
- [ ] [\[2402.01239\] PRIME: Protect Your Videos From Malicious Editing](https://arxiv.org/abs/2402.01239) (NTU)
- [ ] [\[2402.01289\] UCVC: A Unified Contextual Video Compression Framework with Joint P-frame and B-frame Coding](https://arxiv.org/abs/2402.01289) (Peking)
- [ ] [\[2402.01331\] A general framework for rotation invariant point cloud analysis](https://arxiv.org/abs/2402.01331) (Peking)
- [ ] [\[2402.01345\] Skip \n: A Simple Method to Reduce Hallucination in Large Vision-Language Models](https://arxiv.org/abs/2402.01345) (Tianjin)
- [ ] [\[2402.01355\] FindingEmo: An Image Dataset for Emotion Recognition in the Wild](https://arxiv.org/abs/2402.01355) (KU Leuven)
- [ ] [\[2402.01368\] LIR: A Lightweight Baseline for Image Restoration](https://arxiv.org/abs/2402.01368) (UESTC)
- [ ] [\[2402.01393\] ALERT-Transformer: Bridging Asynchronous and Synchronous Machine Learning for Real-Time Event-based Spatio-Temporal Data](https://arxiv.org/abs/2402.01393) (ICML)
- [ ] [\[2402.01422\] EmoSpeaker: One-shot Fine-grained Emotion-Controlled Talking Face Generation](https://arxiv.org/abs/2402.01422) (Xidian)
- [ ] [\[2402.01461\] Visual Gyroscope: Combination of Deep Learning Features and Direct Alignment for Panoramic Stabilization](https://arxiv.org/abs/2402.01461) (CNRS)
- [ ] [\[2402.01516\] Cross-view Masked Diffusion Transformers for Person Image Synthesis](https://arxiv.org/abs/2402.01516) (KAIST, ICML)
- [ ] [\[2402.01557\] Deep Continuous Networks](https://arxiv.org/abs/2402.01557) (ICML)
- [ ] [\[2402.01915\] Robust Inverse Graphics via Probabilistic Inference](https://arxiv.org/abs/2402.01915) (Google, ICML)
- [ ] [\[2402.01974\] Hypergraph-Transformer (HGT) for Interactive Event Prediction in Laparoscopic and Robotic Surgery](https://arxiv.org/abs/2402.01974) (Harvard)
- [ ] [\[2402.02003\] GenFace: A Large-Scale Fine-Grained Face Forgery Benchmark and Cross Appearance-Edge Learning](https://arxiv.org/abs/2402.02003) (BU)
- [ ] [\[2402.02012\] Precise Knowledge Transfer via Flow Matching](https://arxiv.org/abs/2402.02012) (MBZUAI)
- [ ] [\[2402.02029\] ScribFormer: Transformer Makes CNN Work Better for Scribble-based Medical Image Segmentation](https://arxiv.org/abs/2402.02029) (Xiamen)
- [ ] [\[2402.02045\] MLIP: Enhancing Medical Visual Representation with Divergence Encoder and Knowledge-guided Contrastive Learning](https://arxiv.org/abs/2402.02045) (HUST)
- [ ] [\[2402.02046\] TCI-Former: Thermal Conduction-Inspired Transformer for Infrared Small Target Detection](https://arxiv.org/abs/2402.02046) (Alibaba)
- [ ] [\[2402.02060\] DiffVein: A Unified Diffusion Network for Finger Vein Segmentation and Authentication](https://arxiv.org/abs/2402.02060) (Tsinghua)
- [ ] [\[2402.02067\] RIDERS: Radar-Infrared Depth Estimation for Robust Sensing](https://arxiv.org/abs/2402.02067) (TUM)
- [ ] [\[2402.02085\] DeCoF: Generated Video Detection via Frame Consistency: The First Benchmark Dataset](https://arxiv.org/abs/2402.02085) (USTC)
- [ ] [\[2402.02094\] Deep Semantic-Visual Alignment for Zero-Shot Remote Sensing Image Scene Classification](https://arxiv.org/abs/2402.02094) (BUPT, ISPRS)
- [ ] [\[2402.02103\] D\'ej\`a Vu Memorization in Vision-Language Models](https://arxiv.org/abs/2402.02103) (Meta)
- [ ] [\[2402.02105\] ParZC: Parametric Zero-Cost Proxies for Efficient NAS](https://arxiv.org/abs/2402.02105) (NUDT)
- [ ] [\[2402.02112\] S-NeRF++: Autonomous Driving Simulation via Neural Reconstruction and Generation](https://arxiv.org/abs/2402.02112) (Fudan)
- [ ] [\[2402.02141\] Zero-shot sketch-based remote sensing image retrieval based on multi-level and attention-guided tokenization](https://arxiv.org/abs/2402.02141) (WHU)
- [ ] [\[2402.02149\] Improving Diffusion Models for Inverse Problems Using Optimal Posterior Covariance](https://arxiv.org/abs/2402.02149) (SJTU)
- [ ] [\[2402.02150\] Data-Driven Prediction of Seismic Intensity Distributions Featuring Hybrid Classification-Regression Models](https://arxiv.org/abs/2402.02150) (University of Tokyo)
- [ ] [\[2402.02205\] GPT-4V as Traffic Assistant: An In-depth Look at Vision Language Model on Complex Traffic Events](https://arxiv.org/abs/2402.02205) (TUM)
- [ ] [\[2402.02210\] Wavelet-Decoupling Contrastive Enhancement Network for Fine-Grained Skeleton-Based Action Recognition](https://arxiv.org/abs/2402.02210) (BIT)
- [ ] [\[2402.02217\] CoFiNet: Unveiling Camouflaged Objects with Multi-Scale Finesse](https://arxiv.org/abs/2402.02217) (BIT)
- [ ] [\[2402.02235\] Image Fusion via Vision-Language Model](https://arxiv.org/abs/2402.02235) (ICML)
- [ ] [\[2402.02242\] Parameter-Efficient Fine-Tuning for Pre-Trained Vision Models: A Survey](https://arxiv.org/abs/2402.02242) (SJTU)
- [ ] [\[2402.02286\] Multi-Level Aggregation and Recursive Alignment Architecture for Efficient Parallel Inference Segmentation Network](https://arxiv.org/abs/2402.02286) (NWPU)
- [ ] [\[2402.02327\] Bootstrapping Audio-Visual Segmentation by Strengthening Audio Cues](https://arxiv.org/abs/2402.02327) (USTC)
- [ ] [\[2402.02339\] Uncertainty-Aware Testing-Time Optimization for 3D Human Pose Estimation](https://arxiv.org/abs/2402.02339) (ETH)
- [ ] [\[2402.02340\] Learning Semantic Proxies from Visual Prompts for Parameter-Efficient Fine-Tuning in Deep Metric Learning](https://arxiv.org/abs/2402.02340) (ICLR)
- [ ] [\[2402.02352\] Region-Based Representations Revisited](https://arxiv.org/abs/2402.02352) (CVPR)
- [ ] [\[2402.02367\] Exploring Intrinsic Properties of Medical Images for Self-Supervised Binary Semantic Segmentation](https://arxiv.org/abs/2402.02367) (NYU)
- [ ] [\[2402.02382\] Revisiting the Power of Prompt for Visual Tuning](https://arxiv.org/abs/2402.02382) (ICML)
- [ ] [\[2402.02430\] Exploiting Low-level Representations for Ultra-Fast Road Segmentation](https://arxiv.org/abs/2402.02430) (HUST)
- [ ] [\[2402.02431\] Learning Mutual Excitation for Hand-to-Hand and Human-to-Human Interaction Recognition](https://arxiv.org/abs/2402.02431) (Peking)
- [ ] [\[2402.02433\] Uncertainty-Aware Perceiver](https://arxiv.org/abs/2402.02433) (KAIST)
- [ ] [\[2402.02444\] BECLR: Batch Enhanced Contrastive Few-Shot Learning](https://arxiv.org/abs/2402.02444) (ICLR)
- [ ] [\[2402.02662\] Image-Caption Encoding for Improving Zero-Shot Generalization](https://arxiv.org/abs/2402.02662) (UCSD)
- [ ] [\[2402.02736\] Using Motion Cues to Supervise Single-Frame Body Pose and Shape Estimation in Low Data Regimes](https://arxiv.org/abs/2402.02736) (EPFL)
- [ ] [\[2402.02797\] Joint Attention-Guided Feature Fusion Network for Saliency Detection of Surface Defects](https://arxiv.org/abs/2402.02797) (USTC)
- [ ] [\[2402.02800\] Extreme Two-View Geometry From Object Poses with Diffusion Models](https://arxiv.org/abs/2402.02800) (ShanghaiTech)
- [ ] [\[2402.02851\] Enhancing Compositional Generalization via Compositional Feature Alignment](https://arxiv.org/abs/2402.02851) (Illinois)
- [ ] [\[2402.02887\] Time-, Memory- and Parameter-Efficient Visual Adaptation](https://arxiv.org/abs/2402.02887) (Google)
- [ ] [\[2402.02956\] AdaTreeFormer: Few Shot Domain Adaptation for Tree Counting from a Single High-Resolution Image](https://arxiv.org/abs/2402.02956) (Tongji, ISPRS)
- [ ] [\[2402.02972\] Retrieval-Augmented Score Distillation for Text-to-3D Generation](https://arxiv.org/abs/2402.02972) (ICML)
- [ ] [\[2402.02985\] Applying Unsupervised Semantic Segmentation to High-Resolution UAV Imagery for Enhanced Road Scene Parsing](https://arxiv.org/abs/2402.02985) (UMD)
- [ ] [\[2402.03019\] Taylor Videos for Action Recognition](https://arxiv.org/abs/2402.03019) (ICML)
- [ ] [\[2402.03040\] InteractiveVideo: User-Centric Controllable Video Generation with Synergistic Multimodal Instructions](https://arxiv.org/abs/2402.03040) (BIT)
- [ ] [\[2402.03093\] AI-Enhanced Virtual Reality in Medicine: A Comprehensive Survey](https://arxiv.org/abs/2402.03093) (ZJU)
- [ ] [\[2402.03094\] Cross-Domain Few-Shot Object Detection via Enhanced Open-Set Object Detector](https://arxiv.org/abs/2402.03094) (Fudan, ECCV)
- [ ] [\[2402.03095\] Transcending Adversarial Perturbations: Manifold-Aided Adversarial Examples with Legitimate Semantics](https://arxiv.org/abs/2402.03095) (ZJU)
- [ ] [\[2402.03119\] Good Teachers Explain: Explanation-Enhanced Knowledge Distillation](https://arxiv.org/abs/2402.03119) (ECCV)
- [ ] [\[2402.03161\] Video-LaVIT: Unified Video-Language Pre-training with Decoupled Visual-Motional Tokenization](https://arxiv.org/abs/2402.03161) (Peking)
- [ ] [\[2402.03162\] Direct-a-Video: Customized Video Generation with User-Directed Camera Movement and Object Motion](https://arxiv.org/abs/2402.03162) (Tianjin)
- [ ] [\[2402.03188\] Towards mitigating uncann(eye)ness in face swaps via gaze-centric loss terms](https://arxiv.org/abs/2402.03188) (UW)
- [ ] [\[2402.03235\] ActiveAnno3D -- An Active Learning Framework for Multi-Modal 3D Object Detection](https://arxiv.org/abs/2402.03235) (TUM)
- [ ] [\[2402.03241\] FROSTER: Frozen CLIP Is A Strong Teacher for Open-Vocabulary Action Recognition](https://arxiv.org/abs/2402.03241) (HKU, ICLR)
- [ ] [\[2402.03286\] Training-Free Consistent Text-to-Image Generation](https://arxiv.org/abs/2402.03286) (SIGGRAPH)
- [ ] [\[2402.03307\] 4D-Rotor Gaussian Splatting: Towards Efficient Novel View Synthesis for Dynamic Scenes](https://arxiv.org/abs/2402.03307) (Peking, SIGGRAPH)
- [ ] [\[2402.03309\] AONeuS: A Neural Rendering Framework for Acoustic-Optical Sensor Fusion](https://arxiv.org/abs/2402.03309) (CMU, SIGGRAPH)
- [ ] [\[2402.03311\] HASSOD: Hierarchical Adaptive Self-Supervised Object Detection](https://arxiv.org/abs/2402.03311) (NIPS)
- [ ] [\[2402.03312\] Test-Time Adaptation for Depth Completion](https://arxiv.org/abs/2402.03312) (Yale)
- [ ] [\[2402.03317\] SpecFormer: Guarding Vision Transformer Robustness via Maximum Singular Value Penalization](https://arxiv.org/abs/2402.03317) (Microsoft, ECCV)
- [ ] [\[2402.03325\] Connect Later: Improving Fine-tuning for Robustness with Targeted Augmentations](https://arxiv.org/abs/2402.03325) (ICML)
- [ ] [\[2402.03327\] Uni3D-LLM: Unifying Point Cloud Perception, Generation and Editing with Large Language Models](https://arxiv.org/abs/2402.03327) (Shanghai AI Lab)
- [ ] [\[2402.03348\] Respect the model: Fine-grained and Robust Explanation with Sharing Ratio Decomposition](https://arxiv.org/abs/2402.03348) (ICLR)
- [ ] [\[2402.03445\] Denoising Diffusion via Image-Based Rendering](https://arxiv.org/abs/2402.03445) (ICLR)
- [ ] [\[2402.03466\] Physics-Encoded Graph Neural Networks for Deformation Prediction under Contact](https://arxiv.org/abs/2402.03466) (TUM)
- [ ] [\[2402.03631\] CAT-SAM: Conditional Tuning for Few-Shot Adaptation of Segment Anything Model](https://arxiv.org/abs/2402.03631) (ECCV)
- [ ] [\[2402.03690\] 3Doodle: Compact Abstraction of Objects with 3D Strokes](https://arxiv.org/abs/2402.03690) (SIGGRAPH)
- [ ] [\[2402.03708\] SISP: A Benchmark Dataset for Fine-grained Ship Instance Segmentation in Panchromatic Satellite Images](https://arxiv.org/abs/2402.03708) (NJU)
- [ ] [\[2402.03795\] Energy-based Domain-Adaptive Segmentation with Depth Guidance](https://arxiv.org/abs/2402.03795) (KAIST)
- [ ] [\[2402.03908\] EscherNet: A Generative Model for Scalable View Synthesis](https://arxiv.org/abs/2402.03908) (CVPR)
- [ ] [\[2402.03917\] Elastic Feature Consolidation for Cold Start Exemplar-Free Incremental Learning](https://arxiv.org/abs/2402.03917) (ICLR)
- [ ] [\[2402.04009\] Low-rank Attention Side-Tuning for Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2402.04009) (NJU)
- [ ] [\[2402.04013\] Privacy Leakage on DNNs: A Survey of Model Inversion Attacks and Defenses](https://arxiv.org/abs/2402.04013) (HIT)
- [ ] [\[2402.04064\] Multi-class Road Defect Detection and Segmentation using Spatial and Channel-wise Attention for Autonomous Road Repairing](https://arxiv.org/abs/2402.04064) (Cambridge)
- [ ] [\[2402.04087\] A Hard-to-Beat Baseline for Training-free CLIP-based Adaptation](https://arxiv.org/abs/2402.04087) (USTC, ICLR)
- [ ] [\[2402.04097\] Analysis of Deep Image Prior and Exploiting Self-Guidance for Image Reconstruction](https://arxiv.org/abs/2402.04097) (Michigan State University)
- [ ] [\[2402.04101\] VRMM: A Volumetric Relightable Morphable Head Model](https://arxiv.org/abs/2402.04101) (SIGGRAPH)
- [ ] [\[2402.04178\] SHIELD : An Evaluation Benchmark for Face Spoofing and Forgery Detection with Multimodal Large Language Models](https://arxiv.org/abs/2402.04178) (BU)
- [ ] [\[2402.04236\] CogCoM: Train Large Vision-Language Models Diving into Details through Chain of Manipulations](https://arxiv.org/abs/2402.04236) (Tsinghua)
- [ ] [\[2402.04297\] Road Surface Defect Detection -- From Image-based to Non-image-based: A Survey](https://arxiv.org/abs/2402.04297) (Cambridge)
- [ ] [\[2402.04416\] Multimodal Unsupervised Domain Generalization by Retrieving Across the Modality Gap](https://arxiv.org/abs/2402.04416) (BU)
- [ ] [\[2402.04476\] Dual-View Visual Contextualization for Web Navigation](https://arxiv.org/abs/2402.04476) (CVPR)
- [ ] [\[2402.04555\] FM-Fusion: Instance-aware Semantic Mapping Boosted by Vision-Language Foundation Models](https://arxiv.org/abs/2402.04555) (HKUST)
- [ ] [\[2402.04558\] DMAT: A Dynamic Mask-Aware Transformer for Human De-occlusion](https://arxiv.org/abs/2402.04558) (NWPU)
- [ ] [\[2402.04615\] ScreenAI: A Vision-Language Model for UI and Infographics Understanding](https://arxiv.org/abs/2402.04615) (Google)
- [ ] [\[2402.04625\] Noise Map Guidance: Inversion with Spatial Context for Real Image Editing](https://arxiv.org/abs/2402.04625) (ICLR)
- [ ] [\[2402.04672\] G-NAS: Generalizable Neural Architecture Search for Single Domain Generalization Object Detection](https://arxiv.org/abs/2402.04672) (SJTU)
- [ ] [\[2402.04717\] InstructScene: Instruction-Driven 3D Indoor Scene Synthesis with Semantic Graph Prior](https://arxiv.org/abs/2402.04717) (Peking, ICLR)
- [ ] [\[2402.04754\] Towards Aligned Layout Generation via Diffusion Model with Aesthetic Constraints](https://arxiv.org/abs/2402.04754) (ICLR)
- [ ] [\[2402.04756\] Boundary-aware Contrastive Learning for Semi-supervised Nuclei Instance Segmentation](https://arxiv.org/abs/2402.04756) (HIT)
- [ ] [\[2402.04829\] NeRF as a Non-Distant Environment Emitter in Physics-based Inverse Rendering](https://arxiv.org/abs/2402.04829) (Tsinghua, SIGGRAPH)
- [ ] [\[2402.04841\] Data-efficient Large Vision Models through Sequential Autoregression](https://arxiv.org/abs/2402.04841) (USyd)
- [ ] [\[2402.04929\] Source-Free Domain Adaptation with Diffusion-Guided Source Data Generation](https://arxiv.org/abs/2402.04929) (GIT)
- [ ] [\[2402.04930\] Blue noise for diffusion models](https://arxiv.org/abs/2402.04930) (SIGGRAPH)
- [ ] [\[2402.05375\] Get What You Want, Not What You Don't: Image Content Suppression for Text-to-Image Diffusion Models](https://arxiv.org/abs/2402.05375) (ICLR)
- [ ] [\[2402.05382\] Task-customized Masked AutoEncoder via Mixture of Cluster-conditional Experts](https://arxiv.org/abs/2402.05382) (HKUST, ICLR)
- [ ] [\[2402.05408\] MIGC: Multi-Instance Generation Controller for Text-to-Image Synthesis](https://arxiv.org/abs/2402.05408) (CVPR)
- [ ] [\[2402.05410\] SpirDet: Towards Efficient, Accurate and Lightweight Infrared Small Target Detector](https://arxiv.org/abs/2402.05410) (NWPU)
- [ ] [\[2402.05472\] Question Aware Vision Transformer for Multimodal Reasoning](https://arxiv.org/abs/2402.05472) (AWS)
- [ ] [\[2402.05589\] RESMatch: Referring Expression Segmentation in a Semi-Supervised Manner](https://arxiv.org/abs/2402.05589) (ZJU)
- [ ] [\[2402.05655\] Real-time Holistic Robot Pose Estimation with Unknown States](https://arxiv.org/abs/2402.05655) (Peking, ECCV)
- [ ] [\[2402.05712\] DiffSpeaker: Speech-Driven 3D Facial Animation with Diffusion Transformer](https://arxiv.org/abs/2402.05712) (SenseTime)
- [ ] [\[2402.05746\] Editable Scene Simulation for Autonomous Driving via Collaborative LLM-Agents](https://arxiv.org/abs/2402.05746) (CMU, CVPR)
- [ ] [\[2402.05747\] Jacquard V2: Refining Datasets using the Human In the Loop Data Correction Method](https://arxiv.org/abs/2402.05747) (NTU)
- [ ] [\[2402.05804\] InkSight: Offline-to-Online Handwriting Conversion by Learning to Read and Write](https://arxiv.org/abs/2402.05804) (Google)
- [ ] [\[2402.05860\] Privacy-Preserving Synthetic Continual Semantic Segmentation for Robotic Surgery](https://arxiv.org/abs/2402.05860) (UCL)
- [ ] [\[2402.05861\] Memory Consolidation Enables Long-Context Video Understanding](https://arxiv.org/abs/2402.05861) (Google)
- [ ] [\[2402.05869\] Adaptive Surface Normal Constraint for Geometric Estimation from Monocular Images](https://arxiv.org/abs/2402.05869) (Tsinghua, TPAMI)
- [ ] [\[2402.05917\] Point-VOS: Pointing Up Video Object Segmentation](https://arxiv.org/abs/2402.05917) (Google, CVPR)
- [ ] [\[2402.05935\] SPHINX-X: Scaling Data and Parameters for a Family of Multi-modal Large Language Models](https://arxiv.org/abs/2402.05935) (Shanghai AI Lab, ICML)
- [ ] [\[2402.05937\] InstaGen: Enhancing Object Detection by Training on Synthetic Dataset](https://arxiv.org/abs/2402.05937) (SJTU, CVPR)
- [ ] [\[2402.06118\] ViGoR: Improving Visual Grounding of Large Vision Language Models with Fine-Grained Reward Modeling](https://arxiv.org/abs/2402.06118) (UT Austin)
- [ ] [\[2402.06136\] SIR: Multi-view Inverse Rendering with Decomposable Shadow for Indoor Scenes](https://arxiv.org/abs/2402.06136) (PolyU)
- [ ] [\[2402.06149\] HeadStudio: Text to Animatable Head Avatars with 3D Gaussian Splatting](https://arxiv.org/abs/2402.06149) (ZJU)
- [ ] [\[2402.06185\] Development and validation of an artificial intelligence model to accurately predict spinopelvic parameters](https://arxiv.org/abs/2402.06185) (University of Michigan)
- [ ] [\[2402.06190\] Masked LoGoNet: Fast and Accurate 3D Image Analysis for Medical Domain](https://arxiv.org/abs/2402.06190) (Illinois)
- [ ] [\[2402.06244\] Quantifying and Enhancing Multi-modal Robustness with Modality Preference](https://arxiv.org/abs/2402.06244) (ICLR)
- [ ] [\[2402.06315\] Multisource Semisupervised Adversarial Domain Generalization Network for Cross-Scene Sea-Land Clutter Classification](https://arxiv.org/abs/2402.06315) (NWPU)
- [ ] [\[2402.06423\] CurveFormer++: 3D Lane Detection by Curve Propagation with Temporal Curve Queries and Attention](https://arxiv.org/abs/2402.06423) (USTC)
- [ ] [\[2402.06446\] ControlUDA: Controllable Diffusion-assisted Unsupervised Domain Adaptation for Cross-Weather Semantic Segmentation](https://arxiv.org/abs/2402.06446) (TUM)
- [ ] [\[2402.06499\] BarlowTwins-CXR : Enhancing Chest X-Ray abnormality localization in heterogeneous data with cross-domain self-supervised learning](https://arxiv.org/abs/2402.06499) (University of Montreal)
- [ ] [\[2402.06521\] Reconstructing facade details using MLS point clouds and Bag-of-Words approach](https://arxiv.org/abs/2402.06521) (TUM)
- [ ] [\[2402.06599\] On the Out-Of-Distribution Generalization of Multimodal Large Language Models](https://arxiv.org/abs/2402.06599) (Tsinghua)
- [ ] [\[2402.06801\] Fingerprinting New York City's Scaffolding Problem with Longitudinal Dashcam Data](https://arxiv.org/abs/2402.06801) (Cornell)
- [ ] [\[2402.06854\] Gyroscope-Assisted Motion Deblurring Network](https://arxiv.org/abs/2402.06854) (HIT)
- [ ] [\[2402.06951\] Semantic Object-level Modeling for Robust Visual Camera Relocalization](https://arxiv.org/abs/2402.06951) (BIT)
- [ ] [\[2402.06985\] OSSAR: Towards Open-Set Surgical Activity Recognition in Robot-assisted Surgery](https://arxiv.org/abs/2402.06985) (CUHK)
- [ ] [\[2402.06991\] Reciprocal Visibility](https://arxiv.org/abs/2402.06991) (DLR)
- [ ] [\[2402.07059\] Domain Adaptable Fine-Tune Distillation Framework For Advancing Farm Surveillance](https://arxiv.org/abs/2402.07059) (MBZUAI)
- [ ] [\[2402.07116\] Q-Bench+: A Benchmark for Multi-modal Foundation Models on Low-level Vision from Single Images to Pairs](https://arxiv.org/abs/2402.07116) (NTU, TPAMI)
  
  - [ ] [\[2402.07181\] 3D Gaussian as a New Era: A Survey](https://arxiv.org/abs/2402.07181) (Fudan)

- [ ] [\[2402.07207\] GALA3D: Towards Text-to-3D Complex Scene Generation via Layout-guided Generative Gaussian Splatting](https://arxiv.org/abs/2402.07207) (Peking)
- [ ] [\[2402.07270\] Open-ended VQA benchmarking of Vision-Language models by exploiting Classification datasets and their semantic hierarchy](https://arxiv.org/abs/2402.07270) (ICLR)
- [ ] [\[2402.07320\] Towards Explainable, Safe Autonomous Driving with Language Embeddings for Novelty Identification and Active Learning: Framework and Experimental Analysis with Real-World Data Sets](https://arxiv.org/abs/2402.07320) (UCSD)
- [ ] [\[2402.07403\] Make it more specific: A novel uncertainty based airway segmentation application on 3D U-Net and its variants](https://arxiv.org/abs/2402.07403) (Imperial)
- [ ] [\[2402.07410\] A Closer Look at the Robustness of Contrastive Language-Image Pre-Training (CLIP)](https://arxiv.org/abs/2402.07410) (NIPS)
- [ ] [\[2402.07417\] An Empirical Study Into What Matters for Calibrating Vision-Language Models](https://arxiv.org/abs/2402.07417) (ICML)
- [ ] [\[2402.07635\] Collaborative Semantic Occupancy Prediction with Hybrid Feature Fusion in Connected Automated Vehicles](https://arxiv.org/abs/2402.07635) (CVPR)
- [ ] [\[2402.07642\] A Flow-based Credibility Metric for Safety-critical Pedestrian Detection](https://arxiv.org/abs/2402.07642) (Bosch)
- [ ] [\[2402.07677\] GBOT: Graph-Based 3D Object Tracking for Augmented Reality-Assisted Assembly Guidance](https://arxiv.org/abs/2402.07677) (TUM)
