- [ ] [\[2403.11107\] Self-supervised co-salient object detection via feature correspondence at multiple scales](https://arxiv.org/abs/2403.11107) (ECCV)
- [ ] [\[2403.11113\] Local-consistent Transformation Learning for Rotation-invariant Point Cloud Analysis](https://arxiv.org/abs/2403.11113) (WHU, CVPR)
- [ ] [\[2403.11120\] Unifying Feature and Cost Aggregation with Transformers for Semantic and Visual Correspondence](https://arxiv.org/abs/2403.11120) (Microsoft, ICLR)
- [ ] [\[2403.11121\] A Versatile Framework for Multi-scene Person Re-identification](https://arxiv.org/abs/2403.11121) (TPAMI)
- [ ] [\[2403.11127\] GRA: Detecting Oriented Objects through Group-wise Rotating and Attention](https://arxiv.org/abs/2403.11127) (Tsinghua)
- [ ] [\[2403.11131\] Omni-Recon: Harnessing Image-based Rendering for General-Purpose Neural Radiance Fields](https://arxiv.org/abs/2403.11131) (ECCV)
- [ ] [\[2403.11157\] Selective Hourglass Mapping for Universal Image Restoration Based on Diffusion Model](https://arxiv.org/abs/2403.11157) (CVPR)
- [ ] [\[2403.11162\] CGI-DM: Digital Copyright Authentication for Diffusion Models via Contrasting Gradient Inversion](https://arxiv.org/abs/2403.11162) (SJTU, CVPR)
- [ ] [\[2403.11184\] DuPL: Dual Student with Trustworthy Progressive Learning for Robust Weakly Supervised Semantic Segmentation](https://arxiv.org/abs/2403.11184) (CVPR)
- [ ] [\[2403.11186\] NetTrack: Tracking Highly Dynamic Objects with a Net](https://arxiv.org/abs/2403.11186) (Tongji, CVPR)
- [ ] [\[2403.11192\] Self-Supervised Video Desmoking for Laparoscopic Surgery](https://arxiv.org/abs/2403.11192) (PolyU)
- [ ] [\[2403.11193\] Neural Markov Random Field for Stereo Matching](https://arxiv.org/abs/2403.11193) (CUHK, CVPR)
- [ ] [\[2403.11207\] MindEye2: Shared-Subject Models Enable fMRI-To-Image With 1 Hour of Data](https://arxiv.org/abs/2403.11207) (ICML)
- [ ] [\[2403.11211\] RCdpia: A Renal Carcinoma Digital Pathology Image Annotation dataset based on pathologists](https://arxiv.org/abs/2403.11211) (ZJU)
- [ ] [\[2403.11220\] CPA-Enhancer: Chain-of-Thought Prompted Adaptive Enhancer for Object Detection under Unknown Degradations](https://arxiv.org/abs/2403.11220) (ZJU)
- [ ] [\[2403.11222\] SpikeNeRF: Learning Neural Radiance Fields from Continuous Spike Stream](https://arxiv.org/abs/2403.11222) (CVPR)
- [ ] [\[2403.11229\] Concatenate, Fine-tuning, Re-training: A SAM-enabled Framework for Semi-supervised 3D Medical Image Segmentation](https://arxiv.org/abs/2403.11229) (NJU)
- [ ] [\[2403.11234\] Universal Semi-Supervised Domain Adaptation by Mitigating Common-Class Bias](https://arxiv.org/abs/2403.11234) (CVPR)
- [ ] [\[2403.11256\] Uncertainty-Aware Pseudo-Label Filtering for Source-Free Unsupervised Domain Adaptation](https://arxiv.org/abs/2403.11256) (HIT)
- [ ] [\[2403.11270\] Bilateral Propagation Network for Depth Completion](https://arxiv.org/abs/2403.11270) (CVPR)
- [ ] [\[2403.11273\] BrightDreamer: Generic 3D Gaussian Generative Framework for Fast Text-to-3D Synthesis](https://arxiv.org/abs/2403.11273) (HKUST(GZ))
- [ ] [\[2403.11284\] Fast Personalized Text-to-Image Syntheses With Attention Injection](https://arxiv.org/abs/2403.11284) (ShanghaiTech)
- [ ] [\[2403.11299\] SQ-LLaVA: Self-Questioning for Large Vision-Language Assistant](https://arxiv.org/abs/2403.11299) (ECCV)
- [ ] [\[2403.11310\] A Dual-Augmentor Framework for Domain Generalization in 3D Human Pose Estimation](https://arxiv.org/abs/2403.11310) (CVPR)
- [ ] [\[2403.11324\] GeoGaussian: Geometry-aware Gaussian Splatting for Scene Rendering](https://arxiv.org/abs/2403.11324) (ECCV)
- [ ] [\[2403.11364\] Creating Seamless 3D Maps Using Radiance Fields](https://arxiv.org/abs/2403.11364) (Rochester Institute of Technology)
- [ ] [\[2403.11370\] DynamicGlue: Epipolar and Time-Informed Data Association in Dynamic Environments using Graph Neural Networks](https://arxiv.org/abs/2403.11370) (TUM)
- [ ] [\[2403.11380\] Boosting Order-Preserving and Transferability for Neural Architecture Search: a Joint Architecture Refined Search and Fine-tuning Approach](https://arxiv.org/abs/2403.11380) (CVPR)
- [ ] [\[2403.11397\] Defense Against Adversarial Attacks on No-Reference Image Quality Models with Gradient Norm Regularization](https://arxiv.org/abs/2403.11397) (CVPR)
- [ ] [\[2403.11427\] BAGS: Building Animatable Gaussian Splatting from a Monocular Video with Diffusion Priors](https://arxiv.org/abs/2403.11427) (Peking)
- [ ] [\[2403.11447\] Motion-aware 3D Gaussian Splatting for Efficient Dynamic Scene Reconstruction](https://arxiv.org/abs/2403.11447) (USTC)
- [ ] [\[2403.11448\] Robust Overfitting Does Matter: Test-Time Adversarial Purification With FGSM](https://arxiv.org/abs/2403.11448) (Chongqing, CVPR)
- [ ] [\[2403.11450\] Zero-shot Compound Expression Recognition with Visual Language Model at the 6th ABAW Challenge](https://arxiv.org/abs/2403.11450) (USTC)
- [ ] [\[2403.11463\] Siamese Learning with Joint Alignment and Regression for Weakly-Supervised Video Paragraph Grounding](https://arxiv.org/abs/2403.11463) (SYSU, CVPR)
- [ ] [\[2403.11468\] Collage Prompting: Budget-Friendly Visual Recognition with GPT-4V](https://arxiv.org/abs/2403.11468) (WHU)
- [ ] [\[2403.11469\] Generative Motion Stylization of Cross-structure Characters within Canonical Motion Space](https://arxiv.org/abs/2403.11469) (WHU, ACMMM)
- [ ] [\[2403.11481\] VideoAgent: A Memory-augmented Multimodal Agent for Video Understanding](https://arxiv.org/abs/2403.11481) (ECCV)
- [ ] [\[2403.11492\] SmartRefine: A Scenario-Adaptive Refinement Framework for Efficient Motion Prediction](https://arxiv.org/abs/2403.11492) (CVPR)
- [ ] [\[2403.11530\] Continual Forgetting for Pre-trained Vision Models](https://arxiv.org/abs/2403.11530) (CVPR)
- [ ] [\[2403.11549\] Boosting Continual Learning of Vision-Language Models via Mixture-of-Experts Adapters](https://arxiv.org/abs/2403.11549) (CVPR)
- [ ] [\[2403.11561\] Learning Unified Reference Representation for Unsupervised Multi-class Anomaly Detection](https://arxiv.org/abs/2403.11561) (Fudan, ECCV)
- [ ] [\[2403.11614\] CRS-Diff: Controllable Remote Sensing Image Generation with Diffusion Model](https://arxiv.org/abs/2403.11614) (XJTU)
- [ ] [\[2403.11625\] GaussNav: Gaussian Splatting for Visual Navigation](https://arxiv.org/abs/2403.11625) (USTC)
- [ ] [\[2403.11641\] Arc2Face: A Foundation Model for ID-Consistent Human Faces](https://arxiv.org/abs/2403.11641) (ECCV)
- [ ] [\[2403.11650\] Prioritized Semantic Learning for Zero-shot Instance Navigation](https://arxiv.org/abs/2403.11650) (HKUST(GZ), ECCV)
- [ ] [\[2403.11665\] Normalized Validity Scores for DNNs in Regression based Eye Feature Extraction](https://arxiv.org/abs/2403.11665) (University of Tübingen)
- [ ] [\[2403.11674\] Towards Generalizing to Unseen Domains with Few Labels](https://arxiv.org/abs/2403.11674) (CVPR)
- [ ] [\[2403.11675\] Better (pseudo-)labels for semi-supervised instance segmentation](https://arxiv.org/abs/2403.11675) (Berkeley)
- [ ] [\[2403.11678\] Exploring 3D-aware Latent Spaces for Efficiently Learning Numerous Scenes](https://arxiv.org/abs/2403.11678) (CVPR)
- [ ] [\[2403.11679\] NEDS-SLAM: A Neural Explicit Dense Semantic SLAM Framework using 3D Gaussian Splatting](https://arxiv.org/abs/2403.11679) (HIT)
- [ ] [\[2403.11703\] LLaVA-UHD: an LMM Perceiving Any Aspect Ratio and High-Resolution Images](https://arxiv.org/abs/2403.11703) (Tsinghua)
- [ ] [\[2403.11708\] Implicit Discriminative Knowledge Learning for Visible-Infrared Person Re-Identification](https://arxiv.org/abs/2403.11708) (Chongqing, CVPR)
- [ ] [\[2403.11735\] LSKNet: A Foundation Lightweight Backbone for Remote Sensing](https://arxiv.org/abs/2403.11735) (UCL)
- [ ] [\[2403.11755\] Meta-Prompting for Automating Zero-shot Visual Recognition with LLMs](https://arxiv.org/abs/2403.11755) (ECCV)
- [ ] [\[2403.11771\] Modality-Agnostic fMRI Decoding of Vision and Language](https://arxiv.org/abs/2403.11771) (CNRS)
- [ ] [\[2403.11792\] SETA: Semantic-Aware Token Augmentation for Domain Generalization](https://arxiv.org/abs/2403.11792) (NJU)
- [ ] [\[2403.11796\] OpenOcc: Open Vocabulary 3D Scene Reconstruction via Occupancy Representation](https://arxiv.org/abs/2403.11796) (Fudan)
- [ ] [\[2403.11803\] Federated Modality-specific Encoders and Multimodal Anchors for Personalized Brain Tumor Segmentation](https://arxiv.org/abs/2403.11803) (Xiamen)
- [ ] [\[2403.11808\] Dynamic Tuning Towards Parameter and Inference Efficiency for ViT Adaptation](https://arxiv.org/abs/2403.11808) (Alibaba)
- [ ] [\[2403.11812\] Aerial Lifting: Neural Urban Semantic and Building Instance Lifting from Aerial Imagery](https://arxiv.org/abs/2403.11812) (CVPR)
- [ ] [\[2403.11817\] HVDistill: Transferring Knowledge from Images to Point Clouds via Unsupervised Hybrid-View Distillation](https://arxiv.org/abs/2403.11817) (USTC)
- [ ] [\[2403.11870\] IDF-CR: Iterative Diffusion Process for Divide-and-Conquer Cloud Removal in Remote-sensing Images](https://arxiv.org/abs/2403.11870) (SYSU)
- [ ] [\[2403.11875\] Towards Real-Time Fast Unmanned Aerial Vehicle Detection Using Dynamic Vision Sensors](https://arxiv.org/abs/2403.11875) (ETH)
- [ ] [\[2403.11882\] ReGenNet: Towards Human Action-Reaction Synthesis](https://arxiv.org/abs/2403.11882) (CVPR)
- [ ] [\[2403.11899\] GNeRP: Gaussian-guided Neural Reconstruction of Reflective Objects with Noisy Polarization Priors](https://arxiv.org/abs/2403.11899) (HKUST, ICLR)
- [ ] [\[2403.11909\] RoGUENeRF: A Robust Geometry-Consistent Universal Enhancer for NeRF](https://arxiv.org/abs/2403.11909) (ECCV)
- [ ] [\[2403.11942\] Exploring Facial Expression Recognition through Semi-Supervised Pretraining and Temporal Modeling](https://arxiv.org/abs/2403.11942) (USTC)
- [ ] [\[2403.11956\] Subjective-Aligned Dataset and Metric for Text-to-Video Quality Assessment](https://arxiv.org/abs/2403.11956) (SJTU, ACMMM)
- [ ] [\[2403.11959\] IVAC-P2L: Leveraging Irregular Repetition Priors for Improving Video Action Counting](https://arxiv.org/abs/2403.11959) (XJTU)
- [ ] [\[2403.11961\] Enhanced Event-Based Video Reconstruction with Motion Compensation](https://arxiv.org/abs/2403.11961) (Imperial)
- [ ] [\[2403.11999\] HIRI-ViT: Scaling Vision Transformer with High Resolution Inputs](https://arxiv.org/abs/2403.11999) (TPAMI)
- [ ] [\[2403.12002\] DreamMotion: Space-Time Self-Similar Score Distillation for Zero-Shot Video Editing](https://arxiv.org/abs/2403.12002) (ECCV)
- [ ] [\[2403.12003\] GenView: Enhancing View Quality with Pretrained Generative Model for Self-Supervised Learning](https://arxiv.org/abs/2403.12003) (HIT)
- [ ] [\[2403.12019\] LN3Diff: Scalable Latent Neural Fields Diffusion for Speedy 3D Generation](https://arxiv.org/abs/2403.12019) (ECCV)
- [ ] [\[2403.12026\] FlexCap: Generating Rich, Localized, and Flexible Captions in Images](https://arxiv.org/abs/2403.12026) (CMU)
- [ ] [\[2403.12028\] Ultraman: Single Image 3D Human Reconstruction with Ultra Speed and Detail](https://arxiv.org/abs/2403.12028) (Tsinghua)
- [ ] [\[2403.12029\] Align and Distill: Unifying and Improving Domain Adaptive Object Detection](https://arxiv.org/abs/2403.12029) (MIT)
- [ ] [\[2403.12030\] Expandable Subspace Ensemble for Pre-Trained Model-Based Class-Incremental Learning](https://arxiv.org/abs/2403.12030) (NJU, CVPR)
- [ ] [\[2403.12033\] HiKER-SGG: Hierarchical Knowledge Enhanced Robust Scene Graph Generation](https://arxiv.org/abs/2403.12033) (CVPR)
- [ ] [\[2403.12034\] VFusion3D: Learning Scalable 3D Generative Models from Video Diffusion Models](https://arxiv.org/abs/2403.12034) (Meta, ECCV)
- [ ] [\[2403.12035\] CoCoCo: Improving Text-Guided Video Inpainting for Better Consistency, Controllability and Compatibility](https://arxiv.org/abs/2403.12035) (CUHK)
- [ ] [\[2403.12038\] Zero-Shot Image Feature Consensus with Deep Functional Maps](https://arxiv.org/abs/2403.12038) (Stanford)
- [ ] [\[2403.12042\] Exploring Pre-trained Text-to-Video Diffusion Models for Referring Video Object Segmentation](https://arxiv.org/abs/2403.12042) (ECCV)
- [ ] [\[2403.12047\] Alpha-wolves and Alpha-mammals: Exploring Dictionary Attacks on Iris Recognition Systems](https://arxiv.org/abs/2403.12047) (Michigan State University)
- [ ] [\[2403.12052\] A Dataset and Benchmark for Copyright Infringement Unlearning from Text-to-Image Diffusion Models](https://arxiv.org/abs/2403.12052) (Berkeley)
- [ ] [\[2403.12063\] Consistency Model is an Effective Posterior Sample Approximation for Diffusion Inverse Solvers](https://arxiv.org/abs/2403.12063) (NYU)
- [ ] [\[2403.12080\] Evaluating Terrain-Dependent Performance for Martian Frost Detection in Visible Satellite Observations](https://arxiv.org/abs/2403.12080) (NASA)
- [ ] [\[2403.12098\] Deep Generative Design for Mass Production](https://arxiv.org/abs/2403.12098) (KAIST)
- [ ] [\[2403.12154\] ThermoNeRF: Multimodal Neural Radiance Fields for Thermal Novel View Synthesis](https://arxiv.org/abs/2403.12154) (EPFL)
- [ ] [\[2403.12194\] The POLAR Traverse Dataset: A Dataset of Stereo Camera Images Simulating Traverses across Lunar Polar Terrain under Extreme Lighting Conditions](https://arxiv.org/abs/2403.12194) (CMU)
- [ ] [\[2403.12198\] FLex: Joint Pose and Dynamic Radiance Fields Optimization for Stereo Endoscopic Videos](https://arxiv.org/abs/2403.12198) (TUM)
- [ ] [\[2403.12202\] DeCoTR: Enhancing Depth Completion with 2D and 3D Attentions](https://arxiv.org/abs/2403.12202) (CVPR)
- [ ] [\[2403.12365\] GaussianFlow: Splatting Gaussian Dynamics for 4D Content Creation](https://arxiv.org/abs/2403.12365) (Google)
- [ ] [\[2403.12370\] XPose: eXplainable Human Pose Estimation](https://arxiv.org/abs/2403.12370) (HKUST)
- [ ] [\[2403.12416\] Eye-gaze Guided Multi-modal Alignment for Medical Representation Learning](https://arxiv.org/abs/2403.12416) (NWPU)
- [ ] [\[2403.12425\] Multimodal Fusion Method with Spatiotemporal Sequences and Relationship Learning for Valence-Arousal Estimation](https://arxiv.org/abs/2403.12425) (USTC)
- [ ] [\[2403.12429\] TransformMix: Learning Transformation and Mixing Strategies from Data](https://arxiv.org/abs/2403.12429) (HKUST)
- [ ] [\[2403.12445\] Boosting Transferability in Vision-Language Attacks via Diversification along the Intersection Region of Adversarial Trajectory](https://arxiv.org/abs/2403.12445) (ECCV)
- [ ] [\[2403.12450\] Intention Action Anticipation Model with Guide-Feedback Loop Mechanism](https://arxiv.org/abs/2403.12450) (Chongqing)
- [ ] [\[2403.12455\] CLIP-VIS: Adapting CLIP for Open-Vocabulary Video Instance Segmentation](https://arxiv.org/abs/2403.12455) (Chongqing)
- [ ] [\[2403.12457\] Privacy-Preserving Face Recognition Using Trainable Feature Subtraction](https://arxiv.org/abs/2403.12457) (Fudan, CVPR)
- [ ] [\[2403.12473\] PostoMETRO: Pose Token Enhanced Mesh Transformer for Robust 3D Human Mesh Recovery](https://arxiv.org/abs/2403.12473) (USTC)
- [ ] [\[2403.12493\] A Trainable Feature Extractor Module for Deep Neural Networks and Scanpath Classification](https://arxiv.org/abs/2403.12493) (University of Tübingen)
- [ ] [\[2403.12494\] Task-Customized Mixture of Adapters for General Image Fusion](https://arxiv.org/abs/2403.12494) (CVPR)
- [ ] [\[2403.12505\] Semantics, Distortion, and Style Matter: Towards Source-free UDA for Panoramic Segmentation](https://arxiv.org/abs/2403.12505) (HKUST, CVPR)
- [ ] [\[2403.12532\] UniBind: LLM-Augmented Unified and Balanced Representation Space to Bind Them All](https://arxiv.org/abs/2403.12532) (HKUST, CVPR)
- [ ] [\[2403.12534\] ExACT: Language-guided Conceptual Reasoning and Uncertainty Estimation for Event-based Action Recognition and More](https://arxiv.org/abs/2403.12534) (HKUST(GZ), CVPR)
- [ ] [\[2403.12536\] Vox-Fusion++: Voxel-based Neural Implicit Dense Tracking and Mapping with Multi-maps](https://arxiv.org/abs/2403.12536) (ZJU)
- [ ] [\[2403.12537\] Prompt-Guided Adaptive Model Transformation for Whole Slide Image Classification](https://arxiv.org/abs/2403.12537) (HKUST)
- [ ] [\[2403.12559\] Confidence Self-Calibration for Multi-Label Class-Incremental Learning](https://arxiv.org/abs/2403.12559) (ECCV)
- [ ] [\[2403.12570\] Adapting Visual-Language Models for Generalizable Anomaly Detection in Medical Images](https://arxiv.org/abs/2403.12570) (CVPR)
- [ ] [\[2403.12572\] Compound Expression Recognition via Multi Model Ensemble](https://arxiv.org/abs/2403.12572) (USTC)
- [ ] [\[2403.12574\] EAS-SNN: End-to-End Adaptive Sampling and Representation for Event-based Detection with Recurrent Spiking Neural Networks](https://arxiv.org/abs/2403.12574) (ECCV)
- [ ] [\[2403.12580\] Real-IAD: A Real-World Multi-View Dataset for Benchmarking Versatile Industrial Anomaly Detection](https://arxiv.org/abs/2403.12580) (CVPR)
- [ ] [\[2403.12702\] Learning Cross-view Visual Geo-localization without Ground Truth](https://arxiv.org/abs/2403.12702) (WHU)
- [ ] [\[2403.12707\] Selective Domain-Invariant Feature for Generalizable Deepfake Detection](https://arxiv.org/abs/2403.12707) (Xiamen)
- [ ] [\[2403.12770\] Multispectral Image Restoration by Generalized Opponent Transformation Total Variation](https://arxiv.org/abs/2403.12770) (HKU)
- [ ] [\[2403.12777\] Discover and Mitigate Multiple Biased Subgroups in Image Classifiers](https://arxiv.org/abs/2403.12777) (CVPR)
- [ ] [\[2403.12800\] Learning Neural Volumetric Pose Features for Camera Localization](https://arxiv.org/abs/2403.12800) (USTC, ECCV)
- [ ] [\[2403.12801\] RelationVLM: Making Large Vision-Language Models Understand Visual Relations](https://arxiv.org/abs/2403.12801) (USTC)
- [ ] [\[2403.12803\] DreamDA: Generative Data Augmentation with Diffusion Models](https://arxiv.org/abs/2403.12803) (Shanghai AI Lab)
- [ ] [\[2403.12806\] VisualCritic: Making LMMs Perceive Visual Quality Like Humans](https://arxiv.org/abs/2403.12806) (Microsoft)
- [ ] [\[2403.12839\] Global-guided Focal Neural Radiance Field for Large-scale Scene Rendering](https://arxiv.org/abs/2403.12839) (Tsinghua)
- [ ] [\[2403.12870\] PoNQ: a Neural QEM-based Mesh Representation](https://arxiv.org/abs/2403.12870) (Inria)
- [ ] [\[2403.12884\] HYDRA: A Hyper Agent for Dynamic Compositional Visual Reasoning](https://arxiv.org/abs/2403.12884) (ECCV)
- [ ] [\[2403.12931\] You Only Sample Once: Taming One-Step Text-to-Image Synthesis by Self-Cooperative Diffusion GANs](https://arxiv.org/abs/2403.12931) (HKUST)
- [ ] [\[2403.12933\] Zero-Reference Low-Light Enhancement via Physical Quadruple Priors](https://arxiv.org/abs/2403.12933) (CVPR)
- [ ] [\[2403.12957\] GVGEN: Text-to-3D Generation with Volumetric Representation](https://arxiv.org/abs/2403.12957) (ECCV)
- [ ] [\[2403.12961\] TexTile: A Differentiable Metric for Texture Tileability](https://arxiv.org/abs/2403.12961) (CVPR)
- [ ] [\[2403.12962\] FRESCO: Spatial-Temporal Correspondence for Zero-Shot Video Translation](https://arxiv.org/abs/2403.12962) (Peking, CVPR)
- [ ] [\[2403.12965\] Wear-Any-Way: Manipulable Virtual Try-on via Sparse Correspondence Alignment](https://arxiv.org/abs/2403.12965) (Alibaba)
- [ ] [\[2403.12983\] OSSCAR: One-Shot Structured Pruning in Vision and Language Models with Combinatorial Optimization](https://arxiv.org/abs/2403.12983) (MIT)
- [ ] [\[2403.12986\] BaCon: Boosting Imbalanced Semi-supervised Learning via Balanced Feature-Level Contrastive Learning](https://arxiv.org/abs/2403.12986) (Google)
- [ ] [\[2403.13129\] Better Call SAL: Towards Learning to Segment Anything in Lidar](https://arxiv.org/abs/2403.13129) (ECCV)
- [ ] [\[2403.13171\] LUWA Dataset: Learning Lithic Use-Wear Analysis on Microscopic Images](https://arxiv.org/abs/2403.13171) (NYU, CVPR)
- [ ] [\[2403.13190\] 3D Semantic MapNet: Building Maps for Multi-Object Re-Identification in 3D](https://arxiv.org/abs/2403.13190) (GIT)
- [ ] [\[2403.13206\] Depth-guided NeRF Training via Earth Mover's Distance](https://arxiv.org/abs/2403.13206) (ECCV)
- [ ] [\[2403.13261\] Self-Supervised Class-Agnostic Motion Prediction with Spatial and Temporal Consistency Regularizations](https://arxiv.org/abs/2403.13261) (NTU, CVPR)
- [ ] [\[2403.13263\] SC-Tune: Unleashing Self-Consistent Referential Comprehension in Large Vision Language Models](https://arxiv.org/abs/2403.13263) (CVPR)
- [ ] [\[2403.13293\] Building Optimal Neural Architectures using Interpretable Knowledge](https://arxiv.org/abs/2403.13293) (CVPR)
- [ ] [\[2403.13298\] Rotary Position Embedding for Vision Transformer](https://arxiv.org/abs/2403.13298) (ECCV)
- [ ] [\[2403.13304\] DetDiffusion: Synergizing Generative and Perceptive Models for Enhanced Data Generation and Perception](https://arxiv.org/abs/2403.13304) (Tsinghua, CVPR)
- [ ] [\[2403.13338\] Adaptive Critical Subgraph Mining for Cognitive Impairment Conversion Prediction with T1-MRI-based Brain Network](https://arxiv.org/abs/2403.13338) (USTC)
- [ ] [\[2403.13347\] vid-TLDR: Training Free Token merging for Light-weight Video Transformer](https://arxiv.org/abs/2403.13347) (CVPR)
- [ ] [\[2403.13351\] OrthCaps: An Orthogonal CapsNet with Sparse Attention Routing and Pruning](https://arxiv.org/abs/2403.13351) (HIT)
- [ ] [\[2403.13352\] AGFSync: Leveraging AI-Generated Feedback for Preference Optimization in Text-to-Image Generation](https://arxiv.org/abs/2403.13352) (Peking)
- [ ] [\[2403.13378\] IIDM: Image-to-Image Diffusion Model for Semantic Image Synthesis](https://arxiv.org/abs/2403.13378) (SYSU)
- [ ] [\[2403.13392\] Robust image segmentation model based on binary level set](https://arxiv.org/abs/2403.13392) (Chongqing)
- [ ] [\[2403.13408\] S2DM: Sector-Shaped Diffusion Models for Video Generation](https://arxiv.org/abs/2403.13408) (ShanghaiTech)
- [ ] [\[2403.13417\] Diversified and Personalized Multi-rater Medical Image Segmentation](https://arxiv.org/abs/2403.13417) (CVPR)
- [ ] [\[2403.13430\] MTP: Advancing Remote Sensing Foundation Model via Multi-Task Pretraining](https://arxiv.org/abs/2403.13430) (WHU)
- [ ] [\[2403.13438\] SpatialPIN: Enhancing Spatial Reasoning Capabilities of Vision-Language Models through Prompting and Interacting 3D Priors](https://arxiv.org/abs/2403.13438) (Oxford)
- [ ] [\[2403.13479\] Deepfake Detection without Deepfakes: Generalization via Synthetic Frequency Patterns Injection](https://arxiv.org/abs/2403.13479) (NVIDIA)
- [ ] [\[2403.13480\] A Unified Optimal Transport Framework for Cross-Modal Retrieval with Noisy Labels](https://arxiv.org/abs/2403.13480) (XJTU)
- [ ] [\[2403.13507\] FMM-Attack: A Flow-based Multi-modal Adversarial Attack on Video-based LLMs](https://arxiv.org/abs/2403.13507) (Tsinghua)
- [ ] [\[2403.13512\] Scale Decoupled Distillation](https://arxiv.org/abs/2403.13512) (UESTC, CVPR)
- [ ] [\[2403.13535\] IDAdapter: Learning Mixed Features for Tuning-Free Personalization of Text-to-Image Models](https://arxiv.org/abs/2403.13535) (Peking)
- [ ] [\[2403.13548\] Diversity-aware Channel Pruning for StyleGAN Compression](https://arxiv.org/abs/2403.13548) (CVPR)
- [ ] [\[2403.13556\] Find n' Propagate: Open-Vocabulary 3D Object Detection in Urban Environments](https://arxiv.org/abs/2403.13556) (University of Tokyo, ECCV)
- [ ] [\[2403.13570\] Portrait4D-v2: Pseudo Multi-View Data Creates Better 4D Head Synthesizer](https://arxiv.org/abs/2403.13570) (ECCV)
- [ ] [\[2403.13589\] ReGround: Improving Textual and Spatial Grounding at No Cost](https://arxiv.org/abs/2403.13589) (ECCV)
- [ ] [\[2403.13647\] Meta-Point Learning and Refining for Category-Agnostic Pose Estimation](https://arxiv.org/abs/2403.13647) (SJTU, CVPR)
- [ ] [\[2403.13660\] ProMamba: Prompt-Mamba for polyp segmentation](https://arxiv.org/abs/2403.13660) (Peking)
- [ ] [\[2403.13667\] DanceCamera3D: 3D Camera Movement Synthesis with Music and Dance](https://arxiv.org/abs/2403.13667) (Tsinghua, CVPR)
- [ ] [\[2403.13678\] AUD-TGN: Advancing Action Unit Detection with Temporal Convolution and GPT-2 in Wild Audiovisual Contexts](https://arxiv.org/abs/2403.13678) (USTC)
- [ ] [\[2403.13683\] DVMNet: Computing Relative Pose for Unseen Objects Beyond Hypotheses](https://arxiv.org/abs/2403.13683) (CVPR)
- [ ] [\[2403.13684\] SPTNet: An Efficient Alternative Framework for Generalized Category Discovery with Spatial Prompt Tuning](https://arxiv.org/abs/2403.13684) (HKU, ICLR)
- [ ] [\[2403.13798\] Hierarchical NeuroSymbolic Approach for Comprehensive and Explainable Action Quality Assessment](https://arxiv.org/abs/2403.13798) (Princeton, CVPR)
- [ ] [\[2403.13803\] Bounding Box Stability against Feature Dropout Reflects Detector Generalization across Environments](https://arxiv.org/abs/2403.13803) (CUHK, ICLR)
- [ ] [\[2403.13805\] RAR: Retrieving And Ranking Augmented MLLMs for Visual Recognition](https://arxiv.org/abs/2403.13805) (WHU)
- [ ] [\[2403.13808\] On Pretraining Data Diversity for Self-Supervised Learning](https://arxiv.org/abs/2403.13808) (ECCV)
- [ ] [\[2403.13826\] Measuring Diversity in Co-creative Image Generation](https://arxiv.org/abs/2403.13826) (USyd)
- [ ] [\[2403.13965\] ConGeo: Robust Cross-view Geo-localization across Ground View Variations](https://arxiv.org/abs/2403.13965) (WHU, ECCV)
- [ ] [\[2403.13972\] UP-FacE: User-predictable Fine-grained Face Shape Editing](https://arxiv.org/abs/2403.13972) (KU Leuven)
- [ ] [\[2403.14003\] Multi-Modal Hallucination Control by Visual Information Grounding](https://arxiv.org/abs/2403.14003) (EPFL)
- [ ] [\[2403.14082\] EventDance: Unsupervised Source-free Cross-modal Adaptation for Event-based Object Recognition](https://arxiv.org/abs/2403.14082) (HKUST, CVPR)
- [ ] [\[2403.14101\] Text-Enhanced Data-free Approach for Federated Class-Incremental Learning](https://arxiv.org/abs/2403.14101) (CVPR)
- [ ] [\[2403.14103\] MaskSAM: Towards Auto-prompt SAM with Mask Classification for Medical Image Segmentation](https://arxiv.org/abs/2403.14103) (University of Michigan)
- [ ] [\[2403.14104\] Existence Is Chaos: Enhancing 3D Human Motion Prediction with Uncertainty Consideration](https://arxiv.org/abs/2403.14104) (ZJU)
- [ ] [\[2403.14119\] C-TPT: Calibrated Test-Time Prompt Tuning for Vision-Language Models via Text Feature Dispersion](https://arxiv.org/abs/2403.14119) (Illinois, ICLR)
- [ ] [\[2403.14121\] External Knowledge Enhanced 3D Scene Generation from Sketch](https://arxiv.org/abs/2403.14121) (ECCV)
- [ ] [\[2403.14133\] 3D Object Detection from Point Cloud via Voting Step Diffusion](https://arxiv.org/abs/2403.14133) (Xidian)
- [ ] [\[2403.14148\] Efficient Video Diffusion Models via Content-Frame Motion-Latent Decomposition](https://arxiv.org/abs/2403.14148) (ICLR)
- [ ] [\[2403.14158\] Volumetric Environment Representation for Vision-Language Navigation](https://arxiv.org/abs/2403.14158) (CVPR)
- [ ] [\[2403.14174\] Unified Static and Dynamic Network: Efficient Temporal Filtering for Video Grounding](https://arxiv.org/abs/2403.14174) (USTC)
- [ ] [\[2403.14183\] OTSeg: Multi-prompt Sinkhorn Attention for Zero-Shot Semantic Segmentation](https://arxiv.org/abs/2403.14183) (ECCV)
- [ ] [\[2403.14198\] Unleashing Unlabeled Data: A Paradigm for Cross-View Geo-Localization](https://arxiv.org/abs/2403.14198) (CVPR)
- [ ] [\[2403.14233\] SoftPatch: Unsupervised Anomaly Detection with Noisy Data](https://arxiv.org/abs/2403.14233) (NIPS)
- [ ] [\[2403.14240\] Weak Supervision with Arbitrary Single Frame for Micro- and Macro-expression Spotting](https://arxiv.org/abs/2403.14240) (UESTC)
- [ ] [\[2403.14270\] Scene-Graph ViT: End-to-End Open-Vocabulary Visual Relationship Detection](https://arxiv.org/abs/2403.14270) (ECCV)
- [ ] [\[2403.14354\] LDTR: Transformer-based Lane Detection with Anchor-chain Representation](https://arxiv.org/abs/2403.14354) (UESTC)
- [ ] [\[2403.14362\] Less but Better: Enabling Generalized Zero-shot Learning Towards Unseen Domains by Intrinsic Learning from Redundant LLM Semantics](https://arxiv.org/abs/2403.14362) (ZJU)
- [ ] [\[2403.14392\] A Bag of Tricks for Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2403.14392) (Google)
- [ ] [\[2403.14401\] Pensieve: Retrospect-then-Compare Mitigates Visual Hallucination](https://arxiv.org/abs/2403.14401) (Peking)
- [ ] [\[2403.14410\] GLC++: Source-Free Universal Domain Adaptation through Global-Local Clustering and Contrastive Affinity Learning](https://arxiv.org/abs/2403.14410) (SJTU, CVPR)
- [ ] [\[2403.14418\] OA-CNNs: Omni-Adaptive Sparse CNNs for 3D Semantic Segmentation](https://arxiv.org/abs/2403.14418) (CVPR)
- [ ] [\[2403.14430\] Ranking Distillation for Open-Ended Video Question Answering with Insufficient Labels](https://arxiv.org/abs/2403.14430) (SYSU, CVPR)
- [ ] [\[2403.14442\] RoDLA: Benchmarking the Robustness of Document Layout Analysis Models](https://arxiv.org/abs/2403.14442) (CVPR)
- [ ] [\[2403.14513\] View-decoupled Transformer for Person Re-identification under Aerial-ground Camera Network](https://arxiv.org/abs/2403.14513) (JHU, CVPR)
- [ ] [\[2403.14548\] DINO-Tracker: Taming DINO for Self-Supervised Point Tracking in a Single Video](https://arxiv.org/abs/2403.14548) (ECCV)
- [ ] [\[2403.14552\] Token Transformation Matters: Towards Faithful Post-hoc Explanation for Vision Transformer](https://arxiv.org/abs/2403.14552) (CMU, CVPR)
- [ ] [\[2403.14594\] VXP: Voxel-Cross-Pixel Large-scale Image-LiDAR Place Recognition](https://arxiv.org/abs/2403.14594) (Microsoft)
- [ ] [\[2403.14610\] T-Rex2: Towards Generic Object Detection via Text-Visual Prompt Synergy](https://arxiv.org/abs/2403.14610) (HKUST)
- [ ] [\[2403.14624\] MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems?](https://arxiv.org/abs/2403.14624) (Shanghai AI Lab, ECCV)
- [ ] [\[2403.14627\] MVSplat: Efficient 3D Gaussian Splatting from Sparse Multi-View Images](https://arxiv.org/abs/2403.14627) (ECCV)
- [ ] [\[2403.14628\] Zero-Shot Multi-Object Scene Completion](https://arxiv.org/abs/2403.14628) (ECCV)
- [ ] [\[2403.14772\] Improving Robustness to Model Inversion Attacks via Sparse Coding Architectures](https://arxiv.org/abs/2403.14772) (ECCV)
- [ ] [\[2403.14774\] Few-Shot Adversarial Prompt Learning on Vision-Language Models](https://arxiv.org/abs/2403.14774) (USyd)
- [ ] [\[2403.14781\] Champ: Controllable and Consistent Human Image Animation with 3D Parametric Guidance](https://arxiv.org/abs/2403.14781) (NJU)
- [ ] [\[2403.14836\] Evaluating Panoramic 3D Estimation in Indoor Lighting Analysis](https://arxiv.org/abs/2403.14836) (CMU)
- [ ] [\[2403.14837\] Osmosis: RGBD Diffusion Prior for Underwater Image Restoration](https://arxiv.org/abs/2403.14837) (ECCV)
- [ ] [\[2403.14839\] Hyperspectral Neural Radiance Fields](https://arxiv.org/abs/2403.14839) (GIT)
- [ ] [\[2403.14852\] KeyPoint Relative Position Encoding for Face Recognition](https://arxiv.org/abs/2403.14852) (CVPR)
- [ ] [\[2403.14870\] VidLA: Video-Language Alignment at Scale](https://arxiv.org/abs/2403.14870) (CVPR)
- [ ] [\[2403.14886\] DSGG: Dense Relation Transformer for an End-to-end Scene Graph Generation](https://arxiv.org/abs/2403.14886) (ShanghaiTech, CVPR)
- [ ] [\[2403.14966\] DreamFlow: High-Quality Text-to-3D Generation by Approximating Probability Flow](https://arxiv.org/abs/2403.14966) (Google, ICLR)
- [ ] [\[2403.14973\] Pose-Aware Self-Supervised Learning with Viewpoint Trajectory Regularization](https://arxiv.org/abs/2403.14973) (Berkeley, ECCV)
- [ ] [\[2403.15008\] Tri-Perspective View Decomposition for Geometry-Aware Depth Completion](https://arxiv.org/abs/2403.15008) (HUST, CVPR)
- [ ] [\[2403.15010\] Clean-image Backdoor Attacks](https://arxiv.org/abs/2403.15010) (ZJU)
- [ ] [\[2403.15019\] BSNet: Box-Supervised Simulation-assisted Mean Teacher for 3D Instance Segmentation](https://arxiv.org/abs/2403.15019) (USTC)
- [ ] [\[2403.15063\] Towards a Comprehensive, Efficient and Promptable Anatomic Structure Segmentation Model using 3D Whole-body CT Scans](https://arxiv.org/abs/2403.15063) (Alibaba)
- [ ] [\[2403.15098\] UniTraj: A Unified Framework for Scalable Vehicle Trajectory Prediction](https://arxiv.org/abs/2403.15098) (EPFL, ECCV)
- [ ] [\[2403.15119\] An Open-World, Diverse, Cross-Spatial-Temporal Benchmark for Dynamic Wild Person Re-Identification](https://arxiv.org/abs/2403.15119) (Chongqing)
- [ ] [\[2403.15127\] Gradient-based Sampling for Class Imbalanced Semi-supervised Object Detection](https://arxiv.org/abs/2403.15127) (SYSU, ICCV)
- [ ] [\[2403.15132\] Transfer CLIP for Generalizable Image Denoising](https://arxiv.org/abs/2403.15132) (CVPR)
- [ ] [\[2403.15139\] Deep Generative Model based Rate-Distortion for Image Downscaling Assessment](https://arxiv.org/abs/2403.15139) (CVPR)
- [ ] [\[2403.15161\] FastCAD: Real-Time CAD Retrieval and Alignment from Scans and Videos](https://arxiv.org/abs/2403.15161) (Cambridge)
- [ ] [\[2403.15173\] LSK3DNet: Towards Effective and Efficient 3D Perception with Large Sparse Kernels](https://arxiv.org/abs/2403.15173) (CVPR)
- [ ] [\[2403.15192\] SFOD: Spiking Fusion Object Detector](https://arxiv.org/abs/2403.15192) (CVPR)
- [ ] [\[2403.15209\] MSCoTDet: Language-driven Multi-modal Fusion for Improved Multispectral Pedestrian Detection](https://arxiv.org/abs/2403.15209) (KAIST)
- [ ] [\[2403.15212\] GCN-DevLSTM: Path Development for Skeleton-Based Action Recognition](https://arxiv.org/abs/2403.15212) (UCL)
- [ ] [\[2403.15234\] Shadow Generation for Composite Image Using Diffusion model](https://arxiv.org/abs/2403.15234) (CVPR)
- [ ] [\[2403.15241\] IS-Fusion: Instance-Scene Collaborative Fusion for Multimodal 3D Object Detection](https://arxiv.org/abs/2403.15241) (CVPR)
- [ ] [\[2403.15272\] WSCLoc: Weakly-Supervised Sparse-View Camera Relocalization](https://arxiv.org/abs/2403.15272) (Oxford)
- [ ] [\[2403.15317\] Point-DETR3D: Leveraging Imagery Data with Spatial Point Prior for Weakly Semi-supervised 3D Object Detection](https://arxiv.org/abs/2403.15317) (Peking)
- [ ] [\[2403.15330\] Selectively Informative Description can Reduce Undesired Embedding Entanglements in Text-to-Image Personalization](https://arxiv.org/abs/2403.15330) (CVPR)
- [ ] [\[2403.15356\] Neural Plasticity-Inspired Multimodal Foundation Model for Earth Observation](https://arxiv.org/abs/2403.15356) (TUM)
- [ ] [\[2403.15370\] Augmented Reality based Simulated Data (ARSim) with multi-view consistency for AV perception networks](https://arxiv.org/abs/2403.15370) (NVIDIA)
- [ ] [\[2403.15377\] InternVideo2: Scaling Foundation Models for Multimodal Video Understanding](https://arxiv.org/abs/2403.15377) (ECCV)
- [ ] [\[2403.15378\] Long-CLIP: Unlocking the Long-Text Capability of CLIP](https://arxiv.org/abs/2403.15378) (SJTU, ECCV)
- [ ] [\[2403.15383\] ThemeStation: Generating Theme-Aware 3D Assets from Few Exemplars](https://arxiv.org/abs/2403.15383) (HKUST, SIGGRAPH)
- [ ] [\[2403.15389\] DiffusionMTL: Learning Multi-Task Denoising Diffusion Model from Partially Annotated Data](https://arxiv.org/abs/2403.15389) (CVPR)
- [ ] [\[2403.15474\] EC-IoU: Orienting Safety for Object Detectors via Ego-Centric Intersection-over-Union](https://arxiv.org/abs/2403.15474) (TUM)
- [ ] [\[2403.15476\] Learning to Infer Generative Template Programs for Visual Concepts](https://arxiv.org/abs/2403.15476) (ICML)
- [ ] [\[2403.15559\] An Optimization Framework to Enforce Multi-View Consistency for Texturing 3D Meshes](https://arxiv.org/abs/2403.15559) (Alibaba)
- [ ] [\[2403.15593\] FairerCLIP: Debiasing CLIP's Zero-Shot Predictions using Functions in RKHSs](https://arxiv.org/abs/2403.15593) (ICLR)
- [ ] [\[2403.15612\] InterFusion: Text-Driven Generation of 3D Human-Object Interaction](https://arxiv.org/abs/2403.15612) (ECCV)
- [ ] [\[2403.15664\] What Do You See in Vehicle? Comprehensive Vision Solution for In-Vehicle Gaze Estimation](https://arxiv.org/abs/2403.15664) (CVPR)
- [ ] [\[2403.15679\] DS-NeRV: Implicit Neural Video Representation with Decomposed Static and Dynamic Codes](https://arxiv.org/abs/2403.15679) (CVPR)
- [ ] [\[2403.15693\] Technical Report: Masked Skeleton Sequence Modeling for Learning Larval Zebrafish Behavior Latent Embeddings](https://arxiv.org/abs/2403.15693) (UCL)
- [ ] [\[2403.15705\] SUP-NeRF: A Streamlined Unification of Pose Estimation and NeRF for Monocular 3D Object Reconstruction](https://arxiv.org/abs/2403.15705) (Michigan State University)
- [ ] [\[2403.15709\] Contact-aware Human Motion Generation from Textual Descriptions](https://arxiv.org/abs/2403.15709) (NTU)
- [ ] [\[2403.15750\] iDAT: inverse Distillation Adapter-Tuning](https://arxiv.org/abs/2403.15750) (SJTU)
- [ ] [\[2403.15765\] Towards Human-Like Machine Comprehension: Few-Shot Relational Learning in Visually-Rich Documents](https://arxiv.org/abs/2403.15765) (SJTU)
- [ ] [\[2403.15789\] In-Context Matting](https://arxiv.org/abs/2403.15789) (CVPR)
- [ ] [\[2403.15835\] Once for Both: Single Stage of Importance and Sparsity Search for Vision Transformer Compression](https://arxiv.org/abs/2403.15835) (CVPR)
- [ ] [\[2403.15836\] VLM-CPL: Consensus Pseudo Labels from Vision-Language Models for Human Annotation-Free Pathological Image Classification](https://arxiv.org/abs/2403.15836) (UESTC)
- [ ] [\[2403.15876\] Cognitive resilience: Unraveling the proficiency of image-captioning models to interpret masked visual content](https://arxiv.org/abs/2403.15876) (Tsinghua, ICLR)
- [ ] [\[2403.15891\] Human Motion Prediction under Unexpected Perturbation](https://arxiv.org/abs/2403.15891) (UCL)
- [ ] [\[2403.15931\] X-Portrait: Expressive Portrait Animation with Hierarchical Motion Attention](https://arxiv.org/abs/2403.15931) (SIGGRAPH)
- [ ] [\[2403.15947\] Deep Domain Adaptation: A Sim2Real Neural Approach for Improving Eye-Tracking Systems](https://arxiv.org/abs/2403.15947) (Rochester Institute of Technology)
- [ ] [\[2403.15992\] BIMCV-R: A Landmark Dataset for 3D CT Text-Image Retrieval](https://arxiv.org/abs/2403.15992) (USTC)
- [ ] [\[2403.16002\] SDSTrack: Self-Distillation Symmetric Adapter Learning for Multi-Modal Visual Object Tracking](https://arxiv.org/abs/2403.16002) (ZJU, CVPR)
- [ ] [\[2403.16005\] Knowledge-Enhanced Dual-stream Zero-shot Composed Image Retrieval](https://arxiv.org/abs/2403.16005) (CVPR)
- [ ] [\[2403.16020\] PaPr: Training-Free One-Step Patch Pruning with Lightweight ConvNets for Faster Inference](https://arxiv.org/abs/2403.16020) (Bosch, ECCV)
- [ ] [\[2403.16048\] Edit3K: Universal Representation Learning for Video Editing Components](https://arxiv.org/abs/2403.16048) (IS CAS)
- [ ] [\[2403.16051\] Segment Anything Model for Road Network Graph Extraction](https://arxiv.org/abs/2403.16051) (CMU)
- [ ] [\[2403.16080\] PKU-DyMVHumans: A Multi-View Video Benchmark for High-Fidelity Dynamic Human Modeling](https://arxiv.org/abs/2403.16080) (Peking, CVPR)
- [ ] [\[2403.16112\] Opportunities and challenges in the application of large artificial intelligence models in radiology](https://arxiv.org/abs/2403.16112) (NUDT)
- [ ] [\[2403.16124\] Enhancing Visual Continual Learning with Language-Guided Supervision](https://arxiv.org/abs/2403.16124) (CVPR)
- [ ] [\[2403.16131\] Salience DETR: Enhancing Detection Transformer with Hierarchical Salience Filtering Refinement](https://arxiv.org/abs/2403.16131) (XJTU, CVPR)
- [ ] [\[2403.16141\] Entity-NeRF: Detecting and Removing Moving Entities in Urban Scenes](https://arxiv.org/abs/2403.16141) (CVPR)
- [ ] [\[2403.16182\] EgoExoLearn: A Dataset for Bridging Asynchronous Ego- and Exo-centric View of Procedural Activities in Real World](https://arxiv.org/abs/2403.16182) (CVPR)
- [ ] [\[2403.16194\] Pose-Guided Self-Training with Two-Stage Clustering for Unsupervised Landmark Discovery](https://arxiv.org/abs/2403.16194) (MBZUAI, CVPR)
- [ ] [\[2403.16205\] Blur2Blur: Blur Conversion for Unsupervised Image Deblurring on Unknown Domains](https://arxiv.org/abs/2403.16205) (MBZUAI, CVPR)
- [ ] [\[2403.16210\] Frankenstein: Generating Semantic-Compositional 3D Scenes in One Tri-Plane](https://arxiv.org/abs/2403.16210) (SJTU, SIGGRAPH)
- [ ] [\[2403.16224\] Inverse Rendering of Glossy Objects via the Neural Plenoptic Function and Radiance Fields](https://arxiv.org/abs/2403.16224) (CVPR)
- [ ] [\[2403.16270\] Constricting Normal Latent Space for Anomaly Detection with Normal-only Training Data](https://arxiv.org/abs/2403.16270) (MBZUAI)
- [ ] [\[2403.16370\] GoodSAM: Bridging Domain and Capacity Gaps via Segment Anything Model for Distortion-aware Panoramic Semantic Segmentation](https://arxiv.org/abs/2403.16370) (HKUST(GZ), CVPR)
- [ ] [\[2403.16376\] Elite360D: Towards Efficient 360 Depth Estimation via Semantic- and Distance-Aware Bi-Projection Fusion](https://arxiv.org/abs/2403.16376) (HKUST(GZ), CVPR)
- [ ] [\[2403.16379\] FlashEval: Towards Fast and Accurate Evaluation of Text-to-image Diffusion Generative Models](https://arxiv.org/abs/2403.16379) (SJTU, CVPR)
- [ ] [\[2403.16385\] Synthesize Step-by-Step: Tools, Templates and LLMs as Data Generators for Reasoning-Based Chart VQA](https://arxiv.org/abs/2403.16385) (JHU, CVPR)
- [ ] [\[2403.16386\] Dia-LLaMA: Towards Large Language Model-driven CT Report Generation](https://arxiv.org/abs/2403.16386) (HKUST)
- [ ] [\[2403.16387\] Text-IF: Leveraging Semantic Text Guidance for Degradation-Aware and Interactive Image Fusion](https://arxiv.org/abs/2403.16387) (CVPR)
- [ ] [\[2403.16400\] ASDF: Assembly State Detection Utilizing Late Fusion by Integrating 6D Pose Estimation](https://arxiv.org/abs/2403.16400) (TUM)
- [ ] [\[2403.16407\] A Survey on Long Video Generation: Challenges, Methods, and Prospects](https://arxiv.org/abs/2403.16407) (Xidian)
- [ ] [\[2403.16412\] Unsupervised Template-assisted Point Cloud Shape Correspondence Network](https://arxiv.org/abs/2403.16412) (USTC, CVPR)
- [ ] [\[2403.16422\] Refining Text-to-Image Generation: Towards Accurate Training-Free Glyph-Enhanced Image Generation](https://arxiv.org/abs/2403.16422) (GIT)
- [ ] [\[2403.16428\] Benchmarks and Challenges in Pose Estimation for Egocentric Hand Interactions with Objects](https://arxiv.org/abs/2403.16428) (ECCV)
- [ ] [\[2403.16440\] RCBEVDet: Radar-camera Fusion in Bird's Eye View for 3D Object Detection](https://arxiv.org/abs/2403.16440) (UESTC, CVPR)
- [ ] [\[2403.16450\] Camera-aware Label Refinement for Unsupervised Person Re-identification](https://arxiv.org/abs/2403.16450) (XJTU)
- [ ] [\[2403.16481\] REFRAME: Reflective Surface Real-Time Rendering for Mobile Devices](https://arxiv.org/abs/2403.16481) (ECCV)
- [ ] [\[2403.16499\] Self-Supervised Learning for Medical Image Data with Anatomy-Oriented Imaging Planes](https://arxiv.org/abs/2403.16499) (UESTC)
- [ ] [\[2403.16510\] Make-Your-Anchor: A Diffusion-based 2D Avatar Generation Framework](https://arxiv.org/abs/2403.16510) (CVPR)
- [ ] [\[2403.16513\] Let Real Images be as a Judger, Spotting Fake Images Synthesized with Generative Models](https://arxiv.org/abs/2403.16513) (WHU)
- [ ] [\[2403.16520\] CMViM: Contrastive Masked Vim Autoencoder for 3D Multi-modal Representation Learning for AD classification](https://arxiv.org/abs/2403.16520) (PolyU)
- [ ] [\[2403.16528\] Open-Set Recognition in the Age of Vision-Language Models](https://arxiv.org/abs/2403.16528) (ECCV)
- [ ] [\[2403.16536\] VMRNN: Integrating Vision Mamba and LSTM for Efficient and Accurate Spatiotemporal Forecasting](https://arxiv.org/abs/2403.16536) (HKUST(GZ))
- [ ] [\[2403.16539\] Data-Efficient 3D Visual Grounding via Order-Aware Referring](https://arxiv.org/abs/2403.16539) (NVIDIA)
- [ ] [\[2403.16605\] SatSynth: Augmenting Image-Mask Pairs through Diffusion Models for Aerial Semantic Segmentation](https://arxiv.org/abs/2403.16605) (CVPR)
- [ ] [\[2403.16646\] Clustering Propagation for Universal Medical Image Segmentation](https://arxiv.org/abs/2403.16646) (CVPR)
- [ ] [\[2403.16736\] Creating a Digital Twin of Spinal Surgery: A Proof of Concept](https://arxiv.org/abs/2403.16736) (ETH)
- [ ] [\[2403.16788\] HPL-ESS: Hybrid Pseudo-Labeling for Unsupervised Event-based Semantic Segmentation](https://arxiv.org/abs/2403.16788) (Shanghai AI Lab)
- [ ] [\[2403.16794\] CurbNet: Curb Detection Framework Based on LiDAR Point Cloud Segmentation](https://arxiv.org/abs/2403.16794) (HKUST)
- [ ] [\[2403.16831\] UrbanVLP: Multi-Granularity Vision-Language Pretraining for Urban Region Profiling](https://arxiv.org/abs/2403.16831) (USTC)
- [ ] [\[2403.16848\] Multiple Object Tracking as ID Prediction](https://arxiv.org/abs/2403.16848) (NJU)
- [ ] [\[2403.16885\] CVT-xRF: Contrastive In-Voxel Transformer for 3D Consistent Radiance Fields from Sparse Inputs](https://arxiv.org/abs/2403.16885) (CVPR)
- [ ] [\[2403.16921\] PropTest: Automatic Property Testing for Improved Visual Programming](https://arxiv.org/abs/2403.16921) (Columbia University)
- [ ] [\[2403.16937\] Hyperspherical Classification with Dynamic Label-to-Prototype Assignment](https://arxiv.org/abs/2403.16937) (CMU, CVPR)
- [ ] [\[2403.16996\] DriveCoT: Integrating Chain-of-Thought Reasoning with End-to-End Driving](https://arxiv.org/abs/2403.16996) (HKU)
- [ ] [\[2403.16997\] Composed Video Retrieval via Enriched Context and Discriminative Embeddings](https://arxiv.org/abs/2403.16997) (CVPR)
- [ ] [\[2403.17000\] Learning Spatial Adaptation and Temporal Coherence in Diffusion Models for Video Super-Resolution](https://arxiv.org/abs/2403.17000) (USTC, CVPR)
- [ ] [\[2403.17001\] VP3D: Unleashing 2D Visual Prompt for Text-to-3D Generation](https://arxiv.org/abs/2403.17001) (CVPR)
- [ ] [\[2403.17004\] SD-DiT: Unleashing the Power of Self-supervised Discrimination in Diffusion Transformer](https://arxiv.org/abs/2403.17004) (PolyU, CVPR)
- [ ] [\[2403.17005\] TRIP: Temporal Residual Learning with Image Noise Prior for Image-to-Video Diffusion Models](https://arxiv.org/abs/2403.17005) (USTC, CVPR)
- [ ] [\[2403.17006\] Invertible Diffusion Models for Compressed Sensing](https://arxiv.org/abs/2403.17006) (Peking)
- [ ] [\[2403.17188\] LOTUS: Evasive and Resilient Backdoor Attacks through Sub-Partitioning](https://arxiv.org/abs/2403.17188) (Microsoft, CVPR)
- [ ] [\[2403.17301\] Physical 3D Adversarial Attacks against Monocular Depth Estimation in Autonomous Driving](https://arxiv.org/abs/2403.17301) (CVPR)
- [ ] [\[2403.17334\] OVER-NAV: Elevating Iterative Vision-and-Language Navigation with Open-Vocabulary Detection and StructurEd Representation](https://arxiv.org/abs/2403.17334) (HKU, CVPR)
- [ ] [\[2403.17360\] Activity-Biometrics: Person Identification from Daily Activities](https://arxiv.org/abs/2403.17360) (CVPR)
- [ ] [\[2403.17373\] AIDE: An Automatic Data Engine for Object Detection in Autonomous Driving](https://arxiv.org/abs/2403.17373) (CVPR)
- [ ] [\[2403.17387\] Decoupled Pseudo-labeling for Semi-Supervised Monocular 3D Object Detection](https://arxiv.org/abs/2403.17387) (CVPR)
- [ ] [\[2403.17390\] SSF3D: Strict Semi-Supervised 3D Object Detection with Switching Filter](https://arxiv.org/abs/2403.17390) (SJTU)

- [ ] [\[2403.17420\] Learning to Visually Localize Sound Sources from Mixtures without Prior Source Knowledge](https://arxiv.org/abs/2403.17420) (Illinois, CVPR)
- [ ] [\[2403.17422\] InterHandGen: Two-Hand Interaction Generation via Cascaded Reverse Diffusion](https://arxiv.org/abs/2403.17422) (CVPR)
- [ ] [\[2403.17423\] Test-time Adaptation Meets Image Enhancement: Improving Accuracy via Uncertainty-aware Logit Switching](https://arxiv.org/abs/2403.17423) (University of Tokyo)
- [ ] [\[2403.17465\] LaRE^2: Latent Reconstruction Error Based Method for Diffusion-Generated Image Detection](https://arxiv.org/abs/2403.17465) (CVPR)
- [ ] [\[2403.17477\] DiffGaze: A Diffusion Model for Continuous Gaze Sequence Generation on 360{\deg} Images](https://arxiv.org/abs/2403.17477) (KU Leuven)
- [ ] [\[2403.17496\] Dr.Hair: Reconstructing Scalp-Connected Hair Strands without Pre-training via Differentiable Rendering of Line Segments](https://arxiv.org/abs/2403.17496) (CVPR)
- [ ] [\[2403.17502\] SeNM-VAE: Semi-Supervised Noise Modeling with Hierarchical Variational Autoencoder](https://arxiv.org/abs/2403.17502) (Tsinghua)
- [ ] [\[2403.17530\] Boosting Few-Shot Learning with Disentangled Self-Supervised Learning and Meta-Learning for Medical Image Classification](https://arxiv.org/abs/2403.17530) (University of Edinburgh)
- [ ] [\[2403.17537\] NeRF-HuGS: Improved Neural Radiance Fields in Non-static Scenes Using Heuristics-Guided Segmentation](https://arxiv.org/abs/2403.17537) (SYSU, CVPR)
- [ ] [\[2403.17550\] DeepMIF: Deep Monotonic Implicit Fields for Large-Scale LiDAR 3D Mapping](https://arxiv.org/abs/2403.17550) (TUM)
- [ ] [\[2403.17589\] Dual Memory Networks: A Versatile Adaptation Approach for Vision-Language Models](https://arxiv.org/abs/2403.17589) (CVPR)
- [ ] [\[2403.17610\] MMVP: A Multimodal MoCap Dataset with Vision and Pressure Sensors](https://arxiv.org/abs/2403.17610) (CVPR)
- [ ] [\[2403.17631\] AniArtAvatar: Animatable 3D Art Avatar from a Single Image](https://arxiv.org/abs/2403.17631) (SJTU)
- [ ] [\[2403.17638\] Learning with Unreliability: Fast Few-shot Voxel Radiance Fields with Relative Geometric Consistency](https://arxiv.org/abs/2403.17638) (CVPR)
- [ ] [\[2403.17691\] Not All Similarities Are Created Equal: Leveraging Data-Driven Biases to Inform GenAI Copyright Disputes](https://arxiv.org/abs/2403.17691) (Tel Aviv)
- [ ] [\[2403.17695\] PlainMamba: Improving Non-Hierarchical Mamba in Visual Recognition](https://arxiv.org/abs/2403.17695) (University of Edinburgh)
- [ ] [\[2403.17708\] Panonut360: A Head and Eye Tracking Dataset for Panoramic Video](https://arxiv.org/abs/2403.17708) (ACMMM)
- [ ] [\[2403.17709\] Groupwise Query Specialization and Quality-Aware Multi-Assignment for Transformer-based Visual Relationship Detection](https://arxiv.org/abs/2403.17709) (CVPR)
- [ ] [\[2403.17749\] Multi-Task Dense Prediction via Mixture of Low-Rank Experts](https://arxiv.org/abs/2403.17749) (CVPR)
- [ ] [\[2403.17761\] Makeup Prior Models for 3D Facial Makeup Estimation and Applications](https://arxiv.org/abs/2403.17761) (CVPR)
- [ ] [\[2403.17823\] Efficient Image Pre-Training with Siamese Cropped Masked Autoencoders](https://arxiv.org/abs/2403.17823) (ECCV)
- [ ] [\[2403.17830\] Assessment of Multimodal Large Language Models in Alignment with Human Values](https://arxiv.org/abs/2403.17830) (Shanghai AI Lab)
- [ ] [\[2403.17839\] ReMamber: Referring Image Segmentation with Mamba Twister](https://arxiv.org/abs/2403.17839) (ECCV)
- [ ] [\[2403.17869\] To Supervise or Not to Supervise: Understanding and Addressing the Key Challenges of Point Cloud Transfer Learning](https://arxiv.org/abs/2403.17869) (ECCV)
- [ ] [\[2403.17870\] Boosting Diffusion Models with Moving Average Sampling in Frequency Domain](https://arxiv.org/abs/2403.17870) (USTC, CVPR)
- [ ] [\[2403.17879\] Low-Latency Neural Stereo Streaming](https://arxiv.org/abs/2403.17879) (CVPR)
- [ ] [\[2403.17888\] 2D Gaussian Splatting for Geometrically Accurate Radiance Fields](https://arxiv.org/abs/2403.17888) (ShanghaiTech)
- [ ] [\[2403.17915\] Leveraging Near-Field Lighting for Monocular Depth Estimation from Endoscopy Videos](https://arxiv.org/abs/2403.17915) (ECCV)
- [ ] [\[2403.17924\] AID: Attention Interpolation of Text-to-Image Diffusion](https://arxiv.org/abs/2403.17924) (NUS)
- [ ] [\[2403.17935\] OmniVid: A Generative Framework for Universal Video Understanding](https://arxiv.org/abs/2403.17935) (CVPR)
- [ ] [\[2403.17936\] ConvoFusion: Multi-Modal Conversational Diffusion for Co-Speech Gesture Synthesis](https://arxiv.org/abs/2403.17936) (CVPR)
- [ ] [\[2403.17998\] Text Is MASS: Modeling as Stochastic Embedding for Text-Video Retrieval](https://arxiv.org/abs/2403.17998) (Rochester Institute of Technology, CVPR)
- [ ] [\[2403.18036\] Move as You Say, Interact as You Can: Language-guided Human Motion Generation with Scene Affordance](https://arxiv.org/abs/2403.18036) (CVPR)
- [ ] [\[2403.18040\] Global Point Cloud Registration Network for Large Transformations](https://arxiv.org/abs/2403.18040) (MPI)
- [ ] [\[2403.18063\] Heracles: A Hybrid SSM-Transformer Model for High-Resolution Image and Time-Series Analysis](https://arxiv.org/abs/2403.18063) (Microsoft)
- [ ] [\[2403.18080\] EgoPoseFormer: A Simple Baseline for Stereo Egocentric 3D Human Pose Estimation](https://arxiv.org/abs/2403.18080) (ECCV)
- [ ] [\[2403.18092\] OCAI: Improving Optical Flow Estimation by Occlusion and Consistency Aware Interpolation](https://arxiv.org/abs/2403.18092) (CVPR)
- [ ] [\[2403.18094\] A Personalized Video-Based Hand Taxonomy: Application for Individuals with Spinal Cord Injury](https://arxiv.org/abs/2403.18094) (University of Toronto)
- [ ] [\[2403.18114\] Segment Any Medical Model Extended](https://arxiv.org/abs/2403.18114) (JHU)
- [ ] [\[2403.18118\] EgoLifter: Open-world 3D Segmentation for Egocentric Perception](https://arxiv.org/abs/2403.18118) (University of Toronto, ECCV)
- [ ] [\[2403.18186\] Don't Look into the Dark: Latent Codes for Pluralistic Image Inpainting](https://arxiv.org/abs/2403.18186) (CVPR)
- [ ] [\[2403.18187\] LayoutFlow: Flow Matching for Layout Generation](https://arxiv.org/abs/2403.18187) (ECCV)
- [ ] [\[2403.18193\] Middle Fusion and Multi-Stage, Multi-Form Prompts for Robust RGB-T Tracking](https://arxiv.org/abs/2403.18193) (BIT)
- [ ] [\[2403.18201\] Few-shot Online Anomaly Detection and Segmentation](https://arxiv.org/abs/2403.18201) (XJTU)
- [ ] [\[2403.18211\] NeuroPictor: Refining fMRI-to-Image Reconstruction via Multi-individual Pretraining and Multi-level Modulation](https://arxiv.org/abs/2403.18211) (Fudan, ECCV)
- [ ] [\[2403.18241\] NeuSDFusion: A Spatial-Aware Generative Model for 3D Shape Completion, Reconstruction, and Generation](https://arxiv.org/abs/2403.18241) (ECCV)
- [ ] [\[2403.18260\] Toward Interactive Regional Understanding in Vision-Large Language Models](https://arxiv.org/abs/2403.18260) (AWS)
- [ ] [\[2403.18271\] Unleashing the Potential of SAM for Medical Adaptation via Hierarchical Decoding](https://arxiv.org/abs/2403.18271) (CVPR)
- [ ] [\[2403.18274\] DVLO: Deep Visual-LiDAR Odometry with Local-to-Global Feature Fusion and Bi-Directional Structure Alignment](https://arxiv.org/abs/2403.18274) (ECCV)
- [ ] [\[2403.18281\] AIR-HLoc: Adaptive Image Retrieval for Efficient Visual Localisation](https://arxiv.org/abs/2403.18281) (HKUST)
- [ ] [\[2403.18293\] Efficient Test-Time Adaptation of Vision-Language Models](https://arxiv.org/abs/2403.18293) (CVPR)
- [ ] [\[2403.18342\] Learning Inclusion Matching for Animation Paint Bucket Colorization](https://arxiv.org/abs/2403.18342) (CVPR)
- [ ] [\[2403.18356\] MonoHair: High-Fidelity Hair Modeling from a Monocular Video](https://arxiv.org/abs/2403.18356) (CVPR)
- [ ] [\[2403.18360\] Learning CNN on ViT: A Hybrid Model to Explicitly Class-specific Boundaries for Domain Adaptation](https://arxiv.org/abs/2403.18360) (CVPR)
- [ ] [\[2403.18383\] Generative Multi-modal Models are Good Class-Incremental Learners](https://arxiv.org/abs/2403.18383) (CVPR)
- [ ] [\[2403.18442\] Backpropagation-free Network for 3D Test-time Adaptation](https://arxiv.org/abs/2403.18442) (AWS, CVPR)
- [ ] [\[2403.18452\] SingularTrajectory: Universal Trajectory Predictor Using Diffusion Model](https://arxiv.org/abs/2403.18452) (CVPR)
- [ ] [\[2403.18454\] Scaling Vision-and-Language Navigation With Offline RL](https://arxiv.org/abs/2403.18454) (UCLA)
- [ ] [\[2403.18461\] DiffStyler: Diffusion-based Localized Image Style Transfer](https://arxiv.org/abs/2403.18461) (SJTU)
- [ ] [\[2403.18469\] Density-guided Translator Boosts Synthetic-to-Real Unsupervised Domain Adaptive Segmentation of 3D Point Clouds](https://arxiv.org/abs/2403.18469) (CVPR)
- [ ] [\[2403.18512\] ParCo: Part-Coordinating Text-to-Motion Synthesis](https://arxiv.org/abs/2403.18512) (Peking, ECCV)
- [ ] [\[2403.18548\] A Semi-supervised Nighttime Dehazing Baseline with Spatial-Frequency Aware and Realistic Brightness Constraint](https://arxiv.org/abs/2403.18548) (CVPR)
- [ ] [\[2403.18551\] Attention Calibration for Disentangled Text-to-Image Personalization](https://arxiv.org/abs/2403.18551) (CVPR)
- [ ] [\[2403.18554\] CosalPure: Learning Concept from Group Images for Robust Co-Saliency Detection](https://arxiv.org/abs/2403.18554) (CVPR)
- [ ] [\[2403.18708\] Dense Vision Transformer Compression with Few Samples](https://arxiv.org/abs/2403.18708) (CVPR)
- [ ] [\[2403.18714\] Bringing Textual Prompt to AI-Generated Image Quality Assessment](https://arxiv.org/abs/2403.18714) (Peking)
- [ ] [\[2403.18775\] ImageNet-D: Benchmarking Neural Network Robustness on Diffusion Synthetic Object](https://arxiv.org/abs/2403.18775) (KAIST, CVPR)
- [ ] [\[2403.18791\] Object Pose Estimation via the Aggregation of Diffusion Features](https://arxiv.org/abs/2403.18791) (CVPR)
- [ ] [\[2403.18795\] Gamba: Marry Gaussian Splatting with Mamba for single view 3D reconstruction](https://arxiv.org/abs/2403.18795) (NUS)
- [ ] [\[2403.18807\] ECoDepth: Effective Conditioning of Diffusion Models for Monocular Depth Estimation](https://arxiv.org/abs/2403.18807) (CVPR)
- [ ] [\[2403.18811\] Duolando: Follower GPT with Off-Policy Reinforcement Learning for Dance Accompaniment](https://arxiv.org/abs/2403.18811) (ICLR)
- [ ] [\[2403.18819\] Benchmarking Object Detectors with COCO: A New Path Forward](https://arxiv.org/abs/2403.18819) (University of Michigan)
- [ ] [\[2403.18820\] MetaCap: Meta-learning Priors from Multi-View Imagery for Sparse-view Human Performance Capture and Rendering](https://arxiv.org/abs/2403.18820) (EPFL)
- [ ] [\[2403.18922\] Lift3D: Zero-Shot Lifting of Any 2D Vision Model to 3D](https://arxiv.org/abs/2403.18922) (CVPR)
- [ ] [\[2403.19001\] Cross-domain Fiber Cluster Shape Analysis for Language Performance Cognitive Score Prediction](https://arxiv.org/abs/2403.19001) (Harvard)
- [ ] [\[2403.19022\] WALT3D: Generating Realistic Training Data from Time-Lapse Imagery for Reconstructing Dynamic Objects under Occlusion](https://arxiv.org/abs/2403.19022) (CVPR)
- [ ] [\[2403.19066\] Generative Quanta Color Imaging](https://arxiv.org/abs/2403.19066) (CVPR)
- [ ] [\[2403.19078\] MVEB: Self-Supervised Learning with Multi-View Entropy Bottleneck](https://arxiv.org/abs/2403.19078) (HKUST, TPAMI)
- [ ] [\[2403.19080\] MMCert: Provable Defense against Adversarial Attacks to Multi-modal Models](https://arxiv.org/abs/2403.19080) (ZJU, CVPR)
- [ ] [\[2403.19101\] AAPMT: AGI Assessment Through Prompt and Metric Transformer](https://arxiv.org/abs/2403.19101) (SJTU)
- [ ] [\[2403.19104\] CRKD: Enhanced Camera-Radar Object Detection with Cross-modality Knowledge Distillation](https://arxiv.org/abs/2403.19104) (CVPR)
- [ ] [\[2403.19124\] PoCo: A Self-Supervised Approach via Polar Transformation Based Progressive Contrastive Learning for Ophthalmic Disease Diagnosis](https://arxiv.org/abs/2403.19124) (ZJU)
- [ ] [\[2403.19128\] OmniParser: A Unified Framework for Text Spotting, Key Information Extraction and Table Recognition](https://arxiv.org/abs/2403.19128) (Alibaba, CVPR)
- [ ] [\[2403.19140\] QNCD: Quantization Noise Correction for Diffusion Models](https://arxiv.org/abs/2403.19140) (ZJU)
- [ ] [\[2403.19158\] Uncertainty-Aware Deep Video Compression with Ensembles](https://arxiv.org/abs/2403.19158) (JHU)
- [ ] [\[2403.19205\] From Activation to Initialization: Scaling Insights for Optimizing Neural Fields](https://arxiv.org/abs/2403.19205) (CVPR)
- [ ] [\[2403.19213\] Learning Multiple Representations with Inconsistency-Guided Detail Regularization for Mask-Guided Matting](https://arxiv.org/abs/2403.19213) (SJTU)
- [ ] [\[2403.19220\] GeoAuxNet: Towards Universal 3D Representation Learning for Multi-sensor Point Clouds](https://arxiv.org/abs/2403.19220) (Tsinghua, CVPR)
- [ ] [\[2403.19225\] Efficient and Effective Weakly-Supervised Action Segmentation via Action-Transition-Aware Boundary Alignment](https://arxiv.org/abs/2403.19225) (CVPR)
- [ ] [\[2403.19232\] AZ-NAS: Assembling Zero-Cost Proxies for Network Architecture Search](https://arxiv.org/abs/2403.19232) (CVPR)
- [ ] [\[2403.19235\] DreamSalon: A Staged Diffusion Framework for Preserving Identity-Context in Editable Face Generation](https://arxiv.org/abs/2403.19235) (ZJU)
- [ ] [\[2403.19238\] Taming Lookup Tables for Efficient Image Retouching](https://arxiv.org/abs/2403.19238) (Tsinghua, ECCV)
- [ ] [\[2403.19242\] RTracker: Recoverable Tracking via PN Tree Structured Memory](https://arxiv.org/abs/2403.19242) (HIT, CVPR)
- [ ] [\[2403.19278\] CAT: Exploiting Inter-Class Dynamics for Domain Adaptive Object Detection](https://arxiv.org/abs/2403.19278) (NUS, CVPR)
- [ ] [\[2403.19314\] Total-Decom: Decomposed 3D Scene Reconstruction with Minimal Interaction](https://arxiv.org/abs/2403.19314) (CVPR)
- [ ] [\[2403.19316\] Hypergraph-based Multi-View Action Recognition using Event Cameras](https://arxiv.org/abs/2403.19316) (Tsinghua, TPAMI)
- [ ] [\[2403.19319\] Mesh2NeRF: Direct Mesh Supervision for Neural Radiance Field Representation and Generation](https://arxiv.org/abs/2403.19319) (ECCV)
- [ ] [\[2403.19334\] Test-Time Domain Generalization for Face Anti-Spoofing](https://arxiv.org/abs/2403.19334) (SJTU, CVPR)
- [ ] [\[2403.19366\] Infrared Small Target Detection with Scale and Location Sensitivity](https://arxiv.org/abs/2403.19366) (BIT, CVPR)
- [ ] [\[2403.19412\] A Simple and Effective Point-based Network for Event Camera 6-DOFs Pose Relocalization](https://arxiv.org/abs/2403.19412) (HKUST(GZ), CVPR)
- [ ] [\[2403.19417\] OAKINK2: A Dataset of Bimanual Hands-Object Manipulation in Complex Task Completion](https://arxiv.org/abs/2403.19417) (CVPR)
- [ ] [\[2403.19473\] Benchmarking Implicit Neural Representation and Geometric Rendering in Real-Time RGB-D SLAM](https://arxiv.org/abs/2403.19473) (HKUST, CVPR)
- [ ] [\[2403.19490\] Jointly Training and Pruning CNNs via Learnable Agent Guidance and Alignment](https://arxiv.org/abs/2403.19490) (CVPR)
- [ ] [\[2403.19501\] RELI11D: A Comprehensive Multimodal Human Motion Dataset and Method](https://arxiv.org/abs/2403.19501) (CVPR)
- [ ] [\[2403.19517\] XScale-NVS: Cross-Scale Novel View Synthesis with Hash Featurized Manifold](https://arxiv.org/abs/2403.19517) (Tsinghua, CVPR)
- [ ] [\[2403.19527\] Instance-Adaptive and Geometric-Aware Keypoint Learning for Category-Level 6D Object Pose Estimation](https://arxiv.org/abs/2403.19527) (CVPR)
- [ ] [\[2403.19539\] De-confounded Data-free Knowledge Distillation for Handling Distribution Shifts](https://arxiv.org/abs/2403.19539) (CVPR)
- [ ] [\[2403.19580\] OV-Uni3DETR: Towards Unified Open-Vocabulary 3D Object Detection via Cycle-Modality Propagation](https://arxiv.org/abs/2403.19580) (Tsinghua, ECCV)
- [ ] [\[2403.19586\] TOGS: Gaussian Splatting with Temporal Opacity Offset for Real-Time 4D DSA Rendering](https://arxiv.org/abs/2403.19586) (HUST)
- [ ] [\[2403.19588\] DenseNets Reloaded: Paradigm Shift Beyond ResNets and ViTs](https://arxiv.org/abs/2403.19588) (ECCV)
- [ ] [\[2403.19611\] Nearest Neighbor Classification for Classical Image Upsampling](https://arxiv.org/abs/2403.19611) (Illinois)
- [ ] [\[2403.19615\] SA-GS: Scale-Adaptive Gaussian Splatting for Training-Free Anti-Aliasing](https://arxiv.org/abs/2403.19615) (Tongji)
- [ ] [\[2403.19651\] MagicLens: Self-Supervised Image Retrieval with Open-Ended Instructions](https://arxiv.org/abs/2403.19651) (ICML)
- [ ] [\[2403.19768\] Using Deep Learning to Increase Eye-Tracking Robustness, Accuracy, and Precision in Virtual Reality](https://arxiv.org/abs/2403.19768) (Rochester Institute of Technology)
- [ ] [\[2403.19780\] Mitigating Motion Blur in Neural Radiance Fields with Events and Frames](https://arxiv.org/abs/2403.19780) (CVPR)
- [ ] [\[2403.19811\] X-MIC: Cross-Modal Instance Conditioning for Egocentric Action Generalization](https://arxiv.org/abs/2403.19811) (CVPR)
- [ ] [\[2403.19838\] Multi-Frame, Lightweight & Efficient Vision-Language Models for Question Answering in Autonomous Driving](https://arxiv.org/abs/2403.19838) (UCSD)
- [ ] [\[2403.19866\] Is Synthetic Image Useful for Transfer Learning? An Investigation into Data Generation, Volume, and Utilization](https://arxiv.org/abs/2403.19866) (Yale, ICLR)
- [ ] [\[2403.19898\] Structure Matters: Tackling the Semantic Discrepancy in Diffusion Models for Image Inpainting](https://arxiv.org/abs/2403.19898) (CVPR)
- [ ] [\[2403.19902\] Heterogeneous Network Based Contrastive Learning Method for PolSAR Land Cover Classification](https://arxiv.org/abs/2403.19902) (Xidian)
- [ ] [\[2403.19904\] Fully Geometric Panoramic Localization](https://arxiv.org/abs/2403.19904) (CVPR)
- [ ] [\[2403.19924\] SceneTracker: Long-term Scene Flow Estimation Network](https://arxiv.org/abs/2403.19924) (NUDT)
- [ ] [\[2403.19944\] Binarized Low-light Raw Video Enhancement](https://arxiv.org/abs/2403.19944) (CVPR)
- [ ] [\[2403.19949\] FairCLIP: Harnessing Fairness in Vision-Language Learning](https://arxiv.org/abs/2403.19949) (NYU, CVPR)
- [ ] [\[2403.19963\] Efficient Modulation for Vision Networks](https://arxiv.org/abs/2403.19963) (ICLR)
- [ ] [\[2403.19964\] FairRAG: Fair Human Generation via Fair Retrieval Augmentation](https://arxiv.org/abs/2403.19964) (CVPR)
- [ ] [\[2403.19967\] Rewrite the Stars](https://arxiv.org/abs/2403.19967) (CVPR)
- [ ] [\[2403.19975\] Context-Aware Integration of Language and Visual References for Natural Language Tracking](https://arxiv.org/abs/2403.19975) (CVPR)
- [ ] [\[2403.19979\] Semantically-Shifted Incremental Adapter-Tuning is A Continual ViTransformer](https://arxiv.org/abs/2403.19979) (HUST, CVPR)
- [ ] [\[2403.20002\] Grounding and Enhancing Grid-based Models for Neural Fields](https://arxiv.org/abs/2403.20002) (CVPR)
- [ ] [\[2403.20012\] Colorful Cutout: Enhancing Image Data Augmentation with Curriculum Learning](https://arxiv.org/abs/2403.20012) (ICLR)
- [ ] [\[2403.20013\] DerainNeRF: 3D Scene Estimation with Adhesive Waterdrop Removal](https://arxiv.org/abs/2403.20013) (ZJU)
- [ ] [\[2403.20022\] Psychometry: An Omnifit Model for Image Reconstruction from Human Brain Activity](https://arxiv.org/abs/2403.20022) (CVPR)
- [ ] [\[2403.20026\] FSMR: A Feature Swapping Multi-modal Reasoning Approach with Joint Textual and Visual Clues](https://arxiv.org/abs/2403.20026) (Tsinghua)
- [ ] [\[2403.20031\] A Unified Framework for Human-centric Point Cloud Video Understanding](https://arxiv.org/abs/2403.20031) (CVPR)
- [ ] [\[2403.20034\] NeSLAM: Neural Implicit Mapping and Self-Supervised Feature Tracking With Depth Completion and Denoising](https://arxiv.org/abs/2403.20034) (SJTU)
- [ ] [\[2403.20078\] Negative Label Guided OOD Detection with Pretrained Vision-Language Models](https://arxiv.org/abs/2403.20078) (USyd, ICLR)
- [ ] [\[2403.20079\] SGD: Street View Synthesis with Gaussian Splatting and Diffusion Prior](https://arxiv.org/abs/2403.20079) (ETH)
- [ ] [\[2403.20126\] ECLIPSE: Efficient Continual Learning in Panoptic Segmentation with Visual Prompt Tuning](https://arxiv.org/abs/2403.20126) (KAIST, CVPR)
- [ ] [\[2403.20225\] MTMMC: A Large-Scale Real-World Multi-Modal Camera Tracking Benchmark](https://arxiv.org/abs/2403.20225) (CVPR)
- [ ] [\[2403.20236\] Long-Tailed Anomaly Detection with Learnable Class Names](https://arxiv.org/abs/2403.20236) (UCSD, CVPR)
- [ ] [\[2403.20249\] Relation Rectification in Diffusion Model](https://arxiv.org/abs/2403.20249) (NUS)
- [ ] [\[2403.20254\] Benchmarking the Robustness of Temporal Action Detection Models Against Temporal Corruptions](https://arxiv.org/abs/2403.20254) (CVPR)
- [ ] [\[2403.20271\] Draw-and-Understand: Leveraging Visual Prompts to Enable MLLMs to Comprehend What You Want](https://arxiv.org/abs/2403.20271) (Shanghai AI Lab)
- [ ] [\[2403.20317\] Convolutional Prompting meets Language Models for Continual Learning](https://arxiv.org/abs/2403.20317) (CVPR)
- [ ] [\[2403.20318\] SeaBird: Segmentation in Bird's View with Dice Loss Improves Monocular 3D Detection of Large Objects](https://arxiv.org/abs/2403.20318) (CVPR)
- [ ] [\[2403.20320\] MTLoRA: A Low-Rank Adaptation Approach for Efficient Multi-Task Learning](https://arxiv.org/abs/2403.20320) (CVPR)
- [ ] [\[2404.00086\] DVIS-DAQ: Improving Video Segmentation via Dynamic Anchor Queries](https://arxiv.org/abs/2404.00086) (WHU, ECCV)
- [ ] [\[2404.00098\] Sparse Views, Near Light: A Practical Paradigm for Uncalibrated Point-light Photometric Stereo](https://arxiv.org/abs/2404.00098) (CVPR)
- [ ] [\[2404.00130\] FISBe: A real-world benchmark dataset for instance segmentation of long-range thin filamentous structures](https://arxiv.org/abs/2404.00130) (CVPR)
- [ ] [\[2404.00149\] VSRD: Instance-Aware Volumetric Silhouette Rendering for Weakly Supervised 3D Object Detection](https://arxiv.org/abs/2404.00149) (CVPR)
- [ ] [\[2404.00168\] Multi-Level Neural Scene Graphs for Dynamic Urban Environments](https://arxiv.org/abs/2404.00168) (CVPR)
- [ ] [\[2404.00234\] Grid Diffusion Models for Text-to-Video Generation](https://arxiv.org/abs/2404.00234) (CVPR)
- [ ] [\[2404.00260\] Exploiting Self-Supervised Constraints in Image Super-Resolution](https://arxiv.org/abs/2404.00260) (HIT)
- [ ] [\[2404.00262\] Image-to-Image Matching via Foundation Models: A New Perspective for Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2404.00262) (CVPR)
- [ ] [\[2404.00269\] IPoD: Implicit Field Learning with Point Diffusion for Generalizable 3D Object Reconstruction from Single RGB-D Images](https://arxiv.org/abs/2404.00269) (CVPR)
- [ ] [\[2404.00292\] LAKE-RED: Camouflaged Images Generation by Latent Background Knowledge Retrieval-Augmented Diffusion](https://arxiv.org/abs/2404.00292) (Tsinghua, CVPR)
- [ ] [\[2404.00299\] HOI-M3:Capture Multiple Humans and Objects Interaction within Contextual Environment](https://arxiv.org/abs/2404.00299) (CVPR)
- [ ] [\[2404.00301\] Monocular Identity-Conditioned Facial Reflectance Reconstruction](https://arxiv.org/abs/2404.00301) (CVPR)
- [ ] [\[2404.00345\] MaGRITTe: Manipulative and Generative 3D Realization from Image, Topview and Text](https://arxiv.org/abs/2404.00345) (University of Tokyo)
- [ ] [\[2404.00349\] SGDFormer: One-stage Transformer-based Architecture for Cross-Spectral Stereo Image Guided Denoising](https://arxiv.org/abs/2404.00349) (ZJU)
- [ ] [\[2404.00351\] Rethinking Attention-Based Multiple Instance Learning for Whole-Slide Pathological Image Classification: An Instance Attribute Viewpoint](https://arxiv.org/abs/2404.00351) (HIT)
- [ ] [\[2404.00360\] Reusable Architecture Growth for Continual Stereo Matching](https://arxiv.org/abs/2404.00360) (CVPR)
- [ ] [\[2404.00362\] STBA: Towards Evaluating the Robustness of DNNs for Query-Limited Black-box Scenario](https://arxiv.org/abs/2404.00362) (Peking)
- [ ] [\[2404.00368\] Towards Variable and Coordinated Holistic Co-Speech Motion Generation](https://arxiv.org/abs/2404.00368) (MPI, CVPR)
- [ ] [\[2404.00380\] DHR: Dual Features-Driven Hierarchical Rebalancing in Inter- and Intra-Class Regions for Weakly-Supervised Semantic Segmentation](https://arxiv.org/abs/2404.00380) (University of Michigan)
- [ ] [\[2404.00385\] Constrained Layout Generation with Factor Graphs](https://arxiv.org/abs/2404.00385) (NUS, CVPR)
- [ ] [\[2404.00485\] DiffHuman: Probabilistic Photorealistic 3D Reconstruction of Humans](https://arxiv.org/abs/2404.00485) (CVPR)
- [ ] [\[2404.00504\] NYC-Indoor-VPR: A Long-Term Indoor Visual Place Recognition Dataset with Semi-Automatic Annotation](https://arxiv.org/abs/2404.00504) (NYU)
- [ ] [\[2404.00513\] Transformer based Pluralistic Image Completion with Reduced Information Loss](https://arxiv.org/abs/2404.00513) (USTC, TPAMI)
- [ ] [\[2404.00532\] LLMs are Good Action Recognizers](https://arxiv.org/abs/2404.00532) (NTU, CVPR)
- [ ] [\[2404.00546\] On the Estimation of Image-matching Uncertainty in Visual Place Recognition](https://arxiv.org/abs/2404.00546) (CVPR)
- [ ] [\[2404.00548\] Modeling State Shifting via Local-Global Distillation for Event-Frame Gaze Tracking](https://arxiv.org/abs/2404.00548) (Xidian)
- [ ] [\[2404.00562\] Text2HOI: Text-guided 3D Motion Generation for Hand-Object Interaction](https://arxiv.org/abs/2404.00562) (CVPR)
- [ ] [\[2404.00563\] Exploiting Inter-sample and Inter-feature Relations in Dataset Distillation](https://arxiv.org/abs/2404.00563) (CVPR)
- [ ] [\[2404.00588\] Memory-based Cross-modal Semantic Alignment Network for Radiology Report Generation](https://arxiv.org/abs/2404.00588) (ShanghaiTech)
- [ ] [\[2404.00593\] LAESI: Leaf Area Estimation with Synthetic Imagery](https://arxiv.org/abs/2404.00593) (TUM)
- [ ] [\[2404.00597\] Parameter and Data-Efficient Spectral StyleDCGAN](https://arxiv.org/abs/2404.00597) (ICLR)
- [ ] [\[2404.00636\] Learning to Generate Conditional Tri-plane for 3D-aware Expression Controllable Portrait Animation](https://arxiv.org/abs/2404.00636) (KAIST, ECCV)
- [ ] [\[2404.00653\] Dual DETRs for Multi-Label Temporal Action Detection](https://arxiv.org/abs/2404.00653) (NJU, CVPR)
- [ ] [\[2404.00658\] KTPFormer: Kinematics and Trajectory Prior Knowledge-Enhanced Transformer for 3D Human Pose Estimation](https://arxiv.org/abs/2404.00658) (PolyU, CVPR)
- [ ] [\[2404.00679\] Weak-to-Strong 3D Object Detection with X-Ray Distillation](https://arxiv.org/abs/2404.00679) (Computer Vision and Pattern Recognition)
- [ ] [\[2404.00680\] Learning to Rank Patches for Unbiased Image Redundancy Reduction](https://arxiv.org/abs/2404.00680) (Fudan, CVPR)
- [ ] [\[2404.00710\] Unknown Prompt, the only Lacuna: Unveiling CLIP's Potential for Open Domain Generalization](https://arxiv.org/abs/2404.00710) (CVPR)
- [ ] [\[2404.00724\] Absolute-Unified Multi-Class Anomaly Detection via Class-Agnostic Distribution Alignment](https://arxiv.org/abs/2404.00724) (BIT)
- [ ] [\[2404.00741\] Rethinking Interactive Image Segmentation with Low Latency, High Quality, and Diverse Prompts](https://arxiv.org/abs/2404.00741) (CVPR)
- [ ] [\[2404.00742\] Adapting to Length Shift: FlexiLength Network for Trajectory Prediction](https://arxiv.org/abs/2404.00742) (CVPR)
- [ ] [\[2404.00777\] Privacy-preserving Optics for Enhancing Protection in Face De-identification](https://arxiv.org/abs/2404.00777) (CVPR)
- [ ] [\[2404.00785\] Disentangling Hippocampal Shape Variations: A Study of Neurological Disorders Using Mesh Variational Autoencoder with Contrastive Learning](https://arxiv.org/abs/2404.00785) (University of Alberta)
- [ ] [\[2404.00801\] $R^2$-Tuning: Efficient Image-to-Video Transfer Learning for Video Temporal Grounding](https://arxiv.org/abs/2404.00801) (Harvard, ECCV)
- [ ] [\[2404.00815\] Towards Realistic Scene Generation with LiDAR Diffusion Models](https://arxiv.org/abs/2404.00815) (CMU, CVPR)
- [ ] [\[2404.00834\] Towards Robust Event-guided Low-Light Image Enhancement: A Large-Scale Real-World Event-Image Dataset and Novel Approach](https://arxiv.org/abs/2404.00834) (HKUST, CVPR)
- [ ] [\[2404.00847\] Collaborative Learning of Anomalies with Privacy (CLAP) for Unsupervised Video Anomaly Detection: A New Baseline](https://arxiv.org/abs/2404.00847) (CVPR)
- [ ] [\[2404.00849\] Generating Content for HDR Deghosting from Frequency View](https://arxiv.org/abs/2404.00849) (CVPR)
- [ ] [\[2404.00851\] Prompt Learning via Meta-Regularization](https://arxiv.org/abs/2404.00851) (CVPR)
- [ ] [\[2404.00874\] DiSR-NeRF: Diffusion-Guided View-Consistent Super-Resolution NeRF](https://arxiv.org/abs/2404.00874) (NUS)
- [ ] [\[2404.00875\] DPA-Net: Structured 3D Abstraction from Sparse Views via Differentiable Primitive Assembly](https://arxiv.org/abs/2404.00875) (ECCV)
- [ ] [\[2404.00876\] MGMap: Mask-Guided Learning for Online Vectorized HD Map Construction](https://arxiv.org/abs/2404.00876) (CVPR)
- [ ] [\[2404.00878\] TryOn-Adapter: Efficient Fine-Grained Clothing Identity Adaptation for High-Fidelity Virtual Try-On](https://arxiv.org/abs/2404.00878) (ZJU)
- [ ] [\[2404.00901\] Slightly Shift New Classes to Remember Old Classes for Video Class-Incremental Learning](https://arxiv.org/abs/2404.00901) (UESTC)
- [ ] [\[2404.00906\] From Pixels to Graphs: Open-Vocabulary Scene Graph Generation with Vision-Language Models](https://arxiv.org/abs/2404.00906) (CVPR)
- [ ] [\[2404.00909\] Learning by Correction: Efficient Tuning Task for Zero-Shot Generative Vision-Language Reasoning](https://arxiv.org/abs/2404.00909) (CVPR)
- [ ] [\[2404.00913\] LLaMA-Excitor: General Instruction Tuning via Indirect Feature Interaction](https://arxiv.org/abs/2404.00913) (Tsinghua, CVPR)
- [ ] [\[2404.00915\] Scalable 3D Registration via Truncated Entry-wise Absolute Residuals](https://arxiv.org/abs/2404.00915) (CUHK, CVPR)
- [ ] [\[2404.00922\] Towards Memorization-Free Diffusion Models](https://arxiv.org/abs/2404.00922) (CVPR)
- [ ] [\[2404.00924\] BadPart: Unified Black-box Adversarial Patch Attacks against Pixel-wise Regression Tasks](https://arxiv.org/abs/2404.00924) (ICML)
- [ ] [\[2404.00925\] LLMs are Good Sign Language Translators](https://arxiv.org/abs/2404.00925) (CVPR)
- [ ] [\[2404.00928\] Instance-Aware Group Quantization for Vision Transformers](https://arxiv.org/abs/2404.00928) (CVPR)
- [ ] [\[2404.00973\] VideoDistill: Language-aware Vision Distillation for Video Question Answering](https://arxiv.org/abs/2404.00973) (Tsinghua, CVPR)
- [ ] [\[2404.00974\] Improving Visual Recognition with Hyperbolical Visual Hierarchy Mapping](https://arxiv.org/abs/2404.00974) (CVPR)
- [ ] [\[2404.00989\] 360+x: A Panoptic Multi-modal Scene Understanding Dataset](https://arxiv.org/abs/2404.00989) (CVPR)
- [ ] [\[2404.00992\] SGCNeRF: Few-Shot Neural Rendering via Sparse Geometric Consistency Guidance](https://arxiv.org/abs/2404.00992) (Tsinghua)
- [ ] [\[2404.00995\] PosterLlama: Bridging Design Ability of Langauge Model to Contents-Aware Layout Generation](https://arxiv.org/abs/2404.00995) (ECCV)
- [ ] [\[2404.01013\] Teeth-SEG: An Efficient Instance Segmentation Framework for Orthodontic Treatment based on Anthropic Prior Knowledge](https://arxiv.org/abs/2404.01013) (Tsinghua, CVPR)
- [ ] [\[2404.01014\] Harnessing Large Language Models for Training-free Video Anomaly Detection](https://arxiv.org/abs/2404.01014) (CVPR)
- [ ] [\[2404.01050\] Drag Your Noise: Interactive Point-based Editing via Diffusion Semantic Propagation](https://arxiv.org/abs/2404.01050) (CVPR)
- [ ] [\[2404.01051\] Action Detection via an Image Diffusion Process](https://arxiv.org/abs/2404.01051) (CVPR)
- [ ] [\[2404.01053\] HAHA: Highly Articulated Gaussian Human Avatars with Textured Mesh Prior](https://arxiv.org/abs/2404.01053) (UCL)
- [ ] [\[2404.01065\] T-Mamba: A unified framework with Long-Range Dependency in dual-domain for 2D & 3D Tooth Segmentation](https://arxiv.org/abs/2404.01065) (HKU)
- [ ] [\[2404.01089\] Texture-Preserving Diffusion Models for High-Fidelity Virtual Try-On](https://arxiv.org/abs/2404.01089) (CVPR)
- [ ] [\[2404.01120\] Motion Blur Decomposition with Cross-shutter Guidance](https://arxiv.org/abs/2404.01120) (University of Tokyo, CVPR)
- [ ] [\[2404.01121\] CMT: Cross Modulation Transformer with Hybrid Loss for Pansharpening](https://arxiv.org/abs/2404.01121) (UESTC)
- [ ] [\[2404.01133\] CityGaussian: Real-time High-quality Large-Scale Scene Rendering with Gaussians](https://arxiv.org/abs/2404.01133) (ECCV)
- [ ] [\[2404.01143\] Condition-Aware Neural Network for Controlled Image Generation](https://arxiv.org/abs/2404.01143) (CVPR)
- [ ] [\[2404.01154\] Uncovering the Text Embedding in Text-to-Image Diffusion Models](https://arxiv.org/abs/2404.01154) (USTC)
- [ ] [\[2404.01156\] SyncMask: Synchronized Attentional Masking for Fashion-centric Vision-Language Pretraining](https://arxiv.org/abs/2404.01156) (CVPR)
- [ ] [\[2404.01174\] SpikeMba: Multi-Modal Spiking Saliency Mamba for Temporal Video Grounding](https://arxiv.org/abs/2404.01174) (Peking)
- [ ] [\[2404.01179\] BEM: Balanced and Entropy-based Mix for Long-Tailed Semi-Supervised Learning](https://arxiv.org/abs/2404.01179) (CVPR)
- [ ] [\[2404.01197\] Getting it Right: Improving Spatial Consistency in Text-to-Image Models](https://arxiv.org/abs/2404.01197) (ECCV)
- [ ] [\[2404.01203\] Video Interpolation with Diffusion Models](https://arxiv.org/abs/2404.01203) (Google, CVPR)
- [ ] [\[2404.01225\] SurMo: Surface-based 4D Motion Modeling for Dynamic Human Rendering](https://arxiv.org/abs/2404.01225) (CVPR)
- [ ] [\[2404.01241\] StructLDM: Structured Latent Diffusion for 3D Human Generation](https://arxiv.org/abs/2404.01241) (ECCV)
- [ ] [\[2404.01243\] A Unified and Interpretable Emotion Representation and Expression Generation](https://arxiv.org/abs/2404.01243) (ETH, CVPR)
- [ ] [\[2404.01260\] Bridging Remote Sensors with Multisensor Geospatial Foundation Models](https://arxiv.org/abs/2404.01260) (CVPR)
- [ ] [\[2404.01292\] Measuring Style Similarity in Diffusion Models](https://arxiv.org/abs/2404.01292) (UMD)
- [ ] [\[2404.01294\] CosmicMan: A Text-to-Image Foundation Model for Humans](https://arxiv.org/abs/2404.01294) (CVPR)
- [ ] [\[2404.01297\] Streaming Dense Video Captioning](https://arxiv.org/abs/2404.01297) (CVPR)
- [ ] [\[2404.01300\] NeRF-MAE: Masked AutoEncoders for Self-Supervised 3D Representation Learning for Neural Radiance Fields](https://arxiv.org/abs/2404.01300) (ECCV)
- [ ] [\[2404.01409\] OVFoodSeg: Elevating Open-Vocabulary Food Image Segmentation via Image-Informed Textual Representation](https://arxiv.org/abs/2404.01409) (CVPR)
- [ ] [\[2404.01415\] On the Faithfulness of Vision Transformer Explanations](https://arxiv.org/abs/2404.01415) (CMU, CVPR)
- [ ] [\[2404.01424\] DPMesh: Exploiting Diffusion Prior for Occluded Human Mesh Recovery](https://arxiv.org/abs/2404.01424) (CVPR)
- [ ] [\[2404.01440\] Neural Implicit Representation for Building Digital Twins of Unknown Articulated Objects](https://arxiv.org/abs/2404.01440) (CVPR)
- [ ] [\[2404.01491\] SUGAR: Pre-training 3D Visual Representations for Robotics](https://arxiv.org/abs/2404.01491) (CVPR)
- [ ] [\[2404.01492\] Modality Translation for Object Detection Adaptation Without Forgetting Prior Knowledge](https://arxiv.org/abs/2404.01492) (ECCV)
- [ ] [\[2404.01509\] Can Biases in ImageNet Models Explain Generalization?](https://arxiv.org/abs/2404.01509) (CVPR)
- [ ] [\[2404.01518\] Temporally Consistent Unbalanced Optimal Transport for Unsupervised Action Segmentation](https://arxiv.org/abs/2404.01518) (CVPR)
- [ ] [\[2404.01524\] On Train-Test Class Overlap and Detection for Image Retrieval](https://arxiv.org/abs/2404.01524) (CVPR)
- [ ] [\[2404.01543\] Efficient 3D Implicit Head Avatar with Mesh-anchored Hash Table Blendshapes](https://arxiv.org/abs/2404.01543) (CVPR)
- [ ] [\[2404.01568\] A Linear Time and Space Local Point Cloud Geometry Encoder via Vectorized Kernel Mixture (VecKM)](https://arxiv.org/abs/2404.01568) (UMD, ICML)
- [ ] [\[2404.01587\] TSCM: A Teacher-Student Model for Vision Place Recognition Using Cross-Metric Knowledge Distillation](https://arxiv.org/abs/2404.01587) (NUDT)
- [ ] [\[2404.01591\] Language Model Guided Interpretable Video Action Reasoning](https://arxiv.org/abs/2404.01591) (CVPR)
- [ ] [\[2404.01604\] WaveDH: Wavelet Sub-bands Guided ConvNet for Efficient Image Dehazing](https://arxiv.org/abs/2404.01604) (Xidian)
- [ ] [\[2404.01612\] Spin-UP: Spin Light for Natural Light Uncalibrated Photometric Stereo](https://arxiv.org/abs/2404.01612) (Peking, CVPR)
  
  - [ ] [\[2404.01628\] Learning Equi-angular Representations for Online Continual Learning](https://arxiv.org/abs/2404.01628) (CVPR)

- [ ] [\[2404.01636\] Learning to Control Camera Exposure via Reinforcement Learning](https://arxiv.org/abs/2404.01636) (CMU, CVPR)
- [ ] [\[2404.01654\] AI WALKUP: A Computer-Vision Approach to Quantifying MDS-UPDRS in Parkinson's Disease](https://arxiv.org/abs/2404.01654) (HUST)
- [ ] [\[2404.01656\] Supporting Mitosis Detection AI Training with Inter-Observer Eye-Gaze Consistencies](https://arxiv.org/abs/2404.01656) (UCLA)
- [ ] [\[2404.01673\] A Universal Knowledge Embedded Contrastive Learning Framework for Hyperspectral Image Classification](https://arxiv.org/abs/2404.01673) (WHU)
- [ ] [\[2404.01686\] JRDB-PanoTrack: An Open-world Panoptic Segmentation and Tracking Robotic Dataset in Crowded Human Environments](https://arxiv.org/abs/2404.01686) (CVPR)
- [ ] [\[2404.01690\] RefQSR: Reference-based Quantization for Image Super-Resolution Networks](https://arxiv.org/abs/2404.01690) (TIP)
- [ ] [\[2404.01692\] Beyond Image Super-Resolution for Image Recognition with Task-Driven Perceptual Loss](https://arxiv.org/abs/2404.01692) (CVPR)
- [ ] [\[2404.01703\] Boosting Visual Recognition in Real-world Degradations via Unsupervised Feature Enhancement Module with Deep Channel Prior](https://arxiv.org/abs/2404.01703) (Tsinghua)
- [ ] [\[2404.01725\] Disentangled Pre-training for Human-Object Interaction Detection](https://arxiv.org/abs/2404.01725) (CVPR)
- [ ] [\[2404.01743\] Atom-Level Optical Chemical Structure Recognition with Limited Supervision](https://arxiv.org/abs/2404.01743) (Computer Vision and Pattern Recognition)
- [ ] [\[2404.01751\] T-VSL: Text-Guided Visual Sound Source Localization in Mixtures](https://arxiv.org/abs/2404.01751) (CVPR)
- [ ] [\[2404.01775\] A noisy elephant in the room: Is your out-of-distribution detector robust to label noise?](https://arxiv.org/abs/2404.01775) (CVPR)
- [ ] [\[2404.01810\] GS2Mesh: Surface Reconstruction from Gaussian Splatting via Novel Stereo Views](https://arxiv.org/abs/2404.01810) (ECCV)
- [ ] [\[2404.01819\] Sparse Semi-DETR: Sparse Learnable Queries for Semi-Supervised Object Detection](https://arxiv.org/abs/2404.01819) (CVPR)
- [ ] [\[2404.01862\] Co-Speech Gesture Video Generation via Motion-Decoupled Diffusion Model](https://arxiv.org/abs/2404.01862) (Tsinghua, CVPR)
- [ ] [\[2404.01889\] RAVE: Residual Vector Embedding for CLIP-Guided Backlit Image Enhancement](https://arxiv.org/abs/2404.01889) (UCL)
- [ ] [\[2404.01892\] Minimize Quantization Output Error with Bias Compensation](https://arxiv.org/abs/2404.01892) (Nankai)
- [ ] [\[2404.01925\] Improving Bird's Eye View Semantic Segmentation by Task Decomposition](https://arxiv.org/abs/2404.01925) (CVPR)
- [ ] [\[2404.01933\] PREGO: online mistake detection in PRocedural EGOcentric videos](https://arxiv.org/abs/2404.01933) (CVPR)
- [ ] [\[2404.01941\] LPSNet: End-to-End Human Pose and Shape Estimation with Lensless Imaging](https://arxiv.org/abs/2404.01941) (NJU, CVPR)
- [ ] [\[2404.01943\] Lookahead Exploration with Neural Radiance Representation for Continuous Vision-Language Navigation](https://arxiv.org/abs/2404.01943) (CVPR)
- [ ] [\[2404.01945\] Event-assisted Low-Light Video Object Segmentation](https://arxiv.org/abs/2404.01945) (CVPR)
- [ ] [\[2404.01976\] Joint-Task Regularization for Partially Labeled Multi-Task Learning](https://arxiv.org/abs/2404.01976) (Harvard, CVPR)
- [ ] [\[2404.01998\] Specularity Factorization for Low-Light Enhancement](https://arxiv.org/abs/2404.01998) (CVPR)
- [ ] [\[2404.02041\] SelfPose3d: Self-Supervised Multi-Person Multi-View 3d Pose Estimation](https://arxiv.org/abs/2404.02041) (CVPR)
- [ ] [\[2404.02065\] Multi-Level Label Correction by Distilling Proximate Patterns for Semi-supervised Semantic Segmentation](https://arxiv.org/abs/2404.02065) (BU)
- [ ] [\[2404.02072\] EGTR: Extracting Graph from Transformer for Scene Graph Generation](https://arxiv.org/abs/2404.02072) (CVPR)
- [ ] [\[2404.02082\] WcDT: World-centric Diffusion Transformer for Traffic Scene Generation](https://arxiv.org/abs/2404.02082) (University of Toronto)
- [ ] [\[2404.02106\] Neural Ordinary Differential Equation based Sequential Image Registration for Dynamic Characterization](https://arxiv.org/abs/2404.02106) (CVPR)
- [ ] [\[2404.02117\] Pre-trained Vision and Language Transformers Are Few-Shot Incremental Learners](https://arxiv.org/abs/2404.02117) (CVPR)
- [ ] [\[2404.02132\] ViTamin: Designing Scalable Vision Models in the Vision-Language Era](https://arxiv.org/abs/2404.02132) (CVPR)
- [ ] [\[2404.02145\] Iterated Learning Improves Compositionality in Large Vision-Language Models](https://arxiv.org/abs/2404.02145) (University of Michigan, CVPR)
- [ ] [\[2404.02148\] Diffusion$^2$: Dynamic 3D Content Generation via Score Composition of Orthogonal Diffusion Models](https://arxiv.org/abs/2404.02148) (Fudan)
- [ ] [\[2404.02152\] GeneAvatar: Generic Expression-Aware Volumetric Head Avatar Editing from a Single Image](https://arxiv.org/abs/2404.02152) (CVPR)
- [ ] [\[2404.02155\] Alpha Invariance: On Inverse Scaling Between Distance and Volume Density in Neural Radiance Fields](https://arxiv.org/abs/2404.02155) (CVPR)
- [ ] [\[2404.02185\] NeRFCodec: Neural Feature Compression Meets Neural Radiance Fields for Memory-Efficient Scene Representation](https://arxiv.org/abs/2404.02185) (CVPR)
- [ ] [\[2404.02225\] CHOSEN: Contrastive Hypothesis Selection for Multi-View Depth Refinement](https://arxiv.org/abs/2404.02225) (Google)
- [ ] [\[2404.02227\] OOSTraj: Out-of-Sight Trajectory Prediction With Vision-Positioning Denoising](https://arxiv.org/abs/2404.02227) (CVPR)
- [ ] [\[2404.02233\] Visual Concept Connectome (VCC): Open World Concept Discovery and their Interlayer Connections in Deep Models](https://arxiv.org/abs/2404.02233) (CVPR)
- [ ] [\[2404.02241\] Linear Combination of Saved Checkpoints Makes Consistency and Diffusion Models Better](https://arxiv.org/abs/2404.02241) (Tsinghua)
- [ ] [\[2404.02242\] Towards Robust 3D Pose Transfer with Adversarial Learning](https://arxiv.org/abs/2404.02242) (Stanford, CVPR)
- [ ] [\[2404.02257\] SnAG: Scalable and Accurate Video Grounding](https://arxiv.org/abs/2404.02257) (CVPR)
- [ ] [\[2404.02370\] Enhancing Human-Computer Interaction in Chest X-ray Analysis using Vision and Language Model with Eye Gaze Patterns](https://arxiv.org/abs/2404.02370) (UCL)
- [ ] [\[2404.02415\] What Are We Measuring When We Evaluate Large Vision-Language Models? An Analysis of Latent Factors and Biases](https://arxiv.org/abs/2404.02415) (Salesforce)
- [ ] [\[2404.02460\] TSNet:A Two-stage Network for Image Dehazing with Multi-scale Fusion and Adaptive Learning](https://arxiv.org/abs/2404.02460) (Tianjin)
- [ ] [\[2404.02462\] A Unified Membership Inference Method for Visual Self-supervised Encoder via Part-aware Capability](https://arxiv.org/abs/2404.02462) (Peking)
- [ ] [\[2404.02544\] Semi-Supervised Unconstrained Head Pose Estimation in the Wild](https://arxiv.org/abs/2404.02544) (SJTU)
- [ ] [\[2404.02558\] Regional biases in image geolocation estimation: a case study with the SenseCity Africa dataset](https://arxiv.org/abs/2404.02558) (EPFL)
- [ ] [\[2404.02573\] Knowledge Distillation with Multi-granularity Mixture of Priors for Image Super-Resolution](https://arxiv.org/abs/2404.02573) (HKUST)
- [ ] [\[2404.02585\] Unsegment Anything by Simulating Deformation](https://arxiv.org/abs/2404.02585) (NUS, CVPR)
- [ ] [\[2404.02638\] SG-BEV: Satellite-Guided BEV Fusion for Cross-View Semantic Segmentation](https://arxiv.org/abs/2404.02638) (SenseTime, CVPR)
- [ ] [\[2404.02668\] RS-Mamba for Large Remote Sensing Image Dense Prediction](https://arxiv.org/abs/2404.02668) (NJU)
- [ ] [\[2404.02686\] Design2Cloth: 3D Cloth Generation from 2D Masks](https://arxiv.org/abs/2404.02686) (CVPR)
- [ ] [\[2404.02742\] LiDAR4D: Dynamic Neural Fields for Novel Space-time View LiDAR Synthesis](https://arxiv.org/abs/2404.02742) (CVPR)
- [ ] [\[2404.02755\] DIBS: Enhancing Dense Video Captioning with Unlabeled Videos via Pseudo Boundary Enrichment and Online Refinement](https://arxiv.org/abs/2404.02755) (USTC, CVPR)
- [ ] [\[2404.02759\] Unsupervised Occupancy Learning from Sparse Point Cloud](https://arxiv.org/abs/2404.02759) (CVPR)
- [ ] [\[2404.02788\] GenN2N: Generative NeRF2NeRF Translation](https://arxiv.org/abs/2404.02788) (CVPR)
- [ ] [\[2404.02790\] MULAN: A Multi Layer Annotated Dataset for Controllable Text-to-Image Generation](https://arxiv.org/abs/2404.02790) (CVPR)
- [ ] [\[2404.02830\] Enhancing Interpretability of Vertebrae Fracture Grading using Human-interpretable Prototypes](https://arxiv.org/abs/2404.02830) (TUM)
- [ ] [\[2404.02845\] Cross-Modal Conditioned Reconstruction for Language-guided Medical Image Segmentation](https://arxiv.org/abs/2404.02845) (Peking)
- [ ] [\[2404.02883\] On the Scalability of Diffusion-based Text-to-Image Generation](https://arxiv.org/abs/2404.02883) (CVPR)
- [ ] [\[2404.02900\] DeiT-LT Distillation Strikes Back for Vision Transformer Training on Long-Tailed Datasets](https://arxiv.org/abs/2404.02900) (CVPR)
- [ ] [\[2404.02903\] LidarDM: Generative LiDAR Simulation in a Generated World](https://arxiv.org/abs/2404.02903) (MIT)
- [ ] [\[2404.02905\] Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction](https://arxiv.org/abs/2404.02905) (Peking)
- [ ] [\[2404.02973\] Scaling Laws for Galaxy Images](https://arxiv.org/abs/2404.02973) (University of Toronto)
- [ ] [\[2404.03015\] DPFT: Dual Perspective Fusion Transformer for Camera-Radar-based Object Detection](https://arxiv.org/abs/2404.03015) (TUM)
- [ ] [\[2404.03042\] AWOL: Analysis WithOut synthesis using Language](https://arxiv.org/abs/2404.03042) (MPI)
- [ ] [\[2404.03138\] Discontinuity-preserving Normal Integration with Auxiliary Edges](https://arxiv.org/abs/2404.03138) (CVPR)
- [ ] [\[2404.03144\] Diverse and Tailored Image Generation for Zero-shot Multi-label Classification](https://arxiv.org/abs/2404.03144) (USyd)
- [ ] [\[2404.03159\] HandDiff: 3D Hand Pose Estimation with Diffusion on Image-Point Cloud](https://arxiv.org/abs/2404.03159) (Computer Vision and Pattern Recognition)
- [ ] [\[2404.03179\] UniAV: Unified Audio-Visual Perception for Multi-Task Video Event Localization](https://arxiv.org/abs/2404.03179) (HKU)
- [ ] [\[2404.03181\] MonoCD: Monocular 3D Object Detection with Complementary Depths](https://arxiv.org/abs/2404.03181) (CVPR)
- [ ] [\[2404.03183\] BodyMAP -- Jointly Predicting Body Mesh and 3D Applied Pressure Map for People in Bed](https://arxiv.org/abs/2404.03183) (NVIDIA, CVPR)
- [ ] [\[2404.03190\] Adaptive Discrete Disparity Volume for Self-supervised Monocular Depth Estimation](https://arxiv.org/abs/2404.03190) (BUPT)
- [ ] [\[2404.03202\] OmniGS: Fast Radiance Field Reconstruction using Omnidirectional Gaussian Splatting](https://arxiv.org/abs/2404.03202) (SYSU)
- [ ] [\[2404.03210\] HDR Imaging for Dynamic Scenes with Events](https://arxiv.org/abs/2404.03210) (Tsinghua)
- [ ] [\[2404.03242\] Would Deep Generative Models Amplify Bias in Future Models?](https://arxiv.org/abs/2404.03242) (CVPR)
- [ ] [\[2404.03248\] Learning Transferable Negative Prompts for Out-of-Distribution Detection](https://arxiv.org/abs/2404.03248) (CVPR)
- [ ] [\[2404.03296\] AdaBM: On-the-Fly Adaptive Bit Mapping for Image Super-Resolution](https://arxiv.org/abs/2404.03296) (CVPR)
- [ ] [\[2404.03327\] DI-Retinex: Digital-Imaging Retinex Theory for Low-Light Image Enhancement](https://arxiv.org/abs/2404.03327) (SYSU)
- [ ] [\[2404.03340\] Meta Invariance Defense Towards Generalizable Robustness to Unknown Adversarial Attacks](https://arxiv.org/abs/2404.03340) (Chongqing, TPAMI)
- [ ] [\[2404.03384\] LongVLM: Efficient Long Video Understanding via Large Language Models](https://arxiv.org/abs/2404.03384) (USTC, ECCV)
- [ ] [\[2404.03398\] Scaling Up Video Summarization Pretraining with Large Language Models](https://arxiv.org/abs/2404.03398) (CVPR)
- [ ] [\[2404.03446\] SP$^2$OT: Semantic-Regularized Progressive Partial Optimal Transport for Imbalanced Clustering](https://arxiv.org/abs/2404.03446) (ShanghaiTech)
- [ ] [\[2404.03451\] How Much Data are Enough? Investigating Dataset Requirements for Patch-Based Brain MRI Segmentation Tasks](https://arxiv.org/abs/2404.03451) (USyd)
- [ ] [\[2404.03477\] Towards Automated Movie Trailer Generation](https://arxiv.org/abs/2404.03477) (CVPR)
- [ ] [\[2404.03482\] AdaGlimpse: Active Visual Exploration with Arbitrary Glimpse Position and Scale](https://arxiv.org/abs/2404.03482) (ECCV)
- [ ] [\[2404.03507\] DQ-DETR: DETR with Dynamic Query for Tiny Object Detection](https://arxiv.org/abs/2404.03507) (ECCV)
- [ ] [\[2404.03518\] SDPose: Tokenized Pose Estimation via Circulation-Guide Self-Distillation](https://arxiv.org/abs/2404.03518) (CVPR)
- [ ] [\[2404.03566\] PointInfinity: Resolution-Invariant Point Diffusion Models](https://arxiv.org/abs/2404.03566) (CVPR)
- [ ] [\[2404.03575\] DreamScene: 3D Gaussian-based Text-to-3D Scene Generation via Formation Pattern Sampling](https://arxiv.org/abs/2404.03575) (USTC)
- [ ] [\[2404.03584\] Towards more realistic human motion prediction with attention to motion coordination](https://arxiv.org/abs/2404.03584) (BUPT)
- [ ] [\[2404.03613\] Per-Gaussian Embedding-Based Deformation for Deformable 3D Gaussian Splatting](https://arxiv.org/abs/2404.03613) (ECCV)
- [ ] [\[2404.03635\] WorDepth: Variational Language Prior for Monocular Depth Estimation](https://arxiv.org/abs/2404.03635) (UCLA)
- [ ] [\[2404.03645\] Decoupling Static and Hierarchical Motion Perception for Referring Video Segmentation](https://arxiv.org/abs/2404.03645) (CVPR)
- [ ] [\[2404.03650\] OpenNeRF: Open Set 3D Neural Scene Segmentation with Pixel-Wise Features and Rendered Novel Views](https://arxiv.org/abs/2404.03650) (ICLR)
- [ ] [\[2404.03652\] The More You See in 2D, the More You Perceive in 3D](https://arxiv.org/abs/2404.03652) (ZJU)
- [ ] [\[2404.03653\] CoMat: Aligning Text-to-Image Diffusion Model with Image-to-Text Concept Matching](https://arxiv.org/abs/2404.03653) (SenseTime)
- [ ] [\[2404.03658\] Know Your Neighbors: Improving Single-View Reconstruction via Spatial Vision-Language Reasoning](https://arxiv.org/abs/2404.03658) (CVPR)
- [ ] [\[2404.03673\] RL for Consistency Models: Faster Reward Guided Text-to-Image Generation](https://arxiv.org/abs/2404.03673) (Cornell)
- [ ] [\[2404.03736\] SC4D: Sparse-Controlled Video-to-4D Generation and Motion Transfer](https://arxiv.org/abs/2404.03736) (ECCV)
- [ ] [\[2404.03789\] Quantifying Uncertainty in Motion Prediction with Variational Bayesian Mixture](https://arxiv.org/abs/2404.03789) (CVPR)
- [ ] [\[2404.03831\] SleepVST: Sleep Staging from Near-Infrared Video Signals using Pre-Trained Transformers](https://arxiv.org/abs/2404.03831) (Oxford, CVPR)
- [ ] [\[2404.03898\] VoltaVision: A Transfer Learning model for electronic component classification](https://arxiv.org/abs/2404.03898) (ICLR)
- [ ] [\[2404.03913\] Concept Weaver: Enabling Multi-Concept Fusion in Text-to-Image Models](https://arxiv.org/abs/2404.03913) (CVPR)
- [ ] [\[2404.03924\] Learning Correlation Structures for Vision Transformers](https://arxiv.org/abs/2404.03924) (CVPR)
- [ ] [\[2404.03962\] RaSim: A Range-aware High-fidelity RGB-D Data Simulation Pipeline for Real-world Applications](https://arxiv.org/abs/2404.03962) (Tsinghua)
- [ ] [\[2404.03999\] Finsler-Laplace-Beltrami Operators with Application to Shape Analysis](https://arxiv.org/abs/2404.03999) (TUM)
- [ ] [\[2404.04037\] InstructHumans: Editing Animated 3D Human Textures with Instructions](https://arxiv.org/abs/2404.04037) (NUS)
- [ ] [\[2404.04050\] No Time to Train: Empowering Non-Parametric Networks for Few-shot 3D Scene Segmentation](https://arxiv.org/abs/2404.04050) (CVPR)
- [ ] [\[2404.04072\] Label Propagation for Zero-shot Classification with Vision-Language Models](https://arxiv.org/abs/2404.04072) (CVPR)
- [ ] [\[2404.04095\] Dynamic Prompt Optimizing for Text-to-Image Generation](https://arxiv.org/abs/2404.04095) (CVPR)
- [ ] [\[2404.04125\] No "Zero-Shot" Without Exponential Data: Pretraining Concept Frequency Determines Multimodal Model Performance](https://arxiv.org/abs/2404.04125) (ICLR)
- [ ] [\[2404.04231\] Image-Text Co-Decomposition for Text-Supervised Semantic Segmentation](https://arxiv.org/abs/2404.04231) (CVPR)
- [ ] [\[2404.04242\] Physical Property Understanding from Language-Embedded Feature Fields](https://arxiv.org/abs/2404.04242) (CVPR)
- [ ] [\[2404.04318\] Robust Depth Enhancement via Polarization Prompt Fusion Tuning](https://arxiv.org/abs/2404.04318) (CVPR)
- [ ] [\[2404.04319\] SpatialTracker: Tracking Any 2D Pixels in 3D Space](https://arxiv.org/abs/2404.04319) (CVPR)
- [ ] [\[2404.04346\] Koala: Key frame-conditioned long video-LLM](https://arxiv.org/abs/2404.04346) (CVPR)
- [ ] [\[2404.04363\] Idea-2-3D: Collaborative LMM Agents Enable 3D Model Generation from Interleaved Multimodal Inputs](https://arxiv.org/abs/2404.04363) (Tsinghua)
- [ ] [\[2404.04376\] ClickDiffusion: Harnessing LLMs for Interactive Precise Image Editing](https://arxiv.org/abs/2404.04376) (GIT)
- [ ] [\[2404.04394\] Analyzing Participants' Engagement during Online Meetings Using Unsupervised Remote Photoplethysmography with Behavioral Features](https://arxiv.org/abs/2404.04394) (ZJU)
- [ ] [\[2404.04434\] Robust Few-Shot Ensemble Learning with Focal Diversity-Based Pruning](https://arxiv.org/abs/2404.04434) (GIT)
- [ ] [\[2404.04458\] JRDB-Social: A Multifaceted Robotic Dataset for Understanding of Context and Dynamics of Human Interactions Within Social Groups](https://arxiv.org/abs/2404.04458) (CVPR)
- [ ] [\[2404.04465\] Aligning Diffusion Models by Optimizing Human Utility](https://arxiv.org/abs/2404.04465) (UCLA)
- [ ] [\[2404.04517\] Latent-based Diffusion Model for Long-tailed Recognition](https://arxiv.org/abs/2404.04517) (CVPR)
- [ ] [\[2404.04518\] MedIAnomaly: A comparative study of anomaly detection in medical images](https://arxiv.org/abs/2404.04518) (HKUST)
- [ ] [\[2404.04526\] DATENeRF: Depth-Aware Text-based Editing of NeRFs](https://arxiv.org/abs/2404.04526) (ECCV)
- [ ] [\[2404.04546\] A self-attention model for robust rigid slice-to-volume registration of functional MRI](https://arxiv.org/abs/2404.04546) (Harvard)
- [ ] [\[2404.04556\] Rethinking Self-training for Semi-supervised Landmark Detection: A Selection-free Approach](https://arxiv.org/abs/2404.04556) (HKUST)
- [ ] [\[2404.04561\] Co-Occ: Coupling Explicit Feature Fusion with Volume Rendering Regularization for Multi-Modal 3D Semantic Occupancy Prediction](https://arxiv.org/abs/2404.04561) (HKUST)
- [ ] [\[2404.04562\] Diffusion Time-step Curriculum for One Image to 3D Generation](https://arxiv.org/abs/2404.04562) (NTU, CVPR)
- [ ] [\[2404.04565\] SportsHHI: A Dataset for Human-Human Interaction Detection in Sports Videos](https://arxiv.org/abs/2404.04565) (CVPR)
- [ ] [\[2404.04624\] Bridging the Gap Between End-to-End and Two-Step Text Spotting](https://arxiv.org/abs/2404.04624) (CVPR)
- [ ] [\[2404.04627\] Self-Training Large Language Models for Improved Visual Program Synthesis With Visual Reinforcement](https://arxiv.org/abs/2404.04627) (CVPR)
- [ ] [\[2404.04647\] Structured Gradient-based Interpretations via Norm-Regularized Adversarial Training](https://arxiv.org/abs/2404.04647) (CVPR)
- [ ] [\[2404.04650\] InitNO: Boosting Text-to-Image Diffusion Models via Initial Noise Optimization](https://arxiv.org/abs/2404.04650) (CVPR)
- [ ] [\[2404.04665\] Adaptive Intra-Class Variation Contrastive Learning for Unsupervised Person Re-Identification](https://arxiv.org/abs/2404.04665) (BUPT)
- [ ] [\[2404.04673\] Neural-ABC: Neural Parametric Models for Articulated Body with Clothes](https://arxiv.org/abs/2404.04673) (USTC)
- [ ] [\[2404.04693\] OmniColor: A Global Camera Pose Optimization Approach of LiDAR-360Camera Fusion for Colorizing Point Clouds](https://arxiv.org/abs/2404.04693) (HKUST)
- [ ] [\[2404.04763\] GenEARL: A Training-Free Generative Framework for Multimodal Event Argument Role Labeling](https://arxiv.org/abs/2404.04763) (UCLA)
- [ ] [\[2404.04785\] Rethinking Diffusion Model for Multi-Contrast MRI Super-Resolution](https://arxiv.org/abs/2404.04785) (CVPR)
- [ ] [\[2404.04799\] Few-Shot Object Detection: Research Advances and Challenges](https://arxiv.org/abs/2404.04799) (HUST)
- [ ] [\[2404.04804\] Light the Night: A Multi-Condition Diffusion Framework for Unpaired Low-Light Enhancement in Autonomous Driving](https://arxiv.org/abs/2404.04804) (UCLA, CVPR)
- [ ] [\[2404.04808\] MemFlow: Optical Flow Estimation and Prediction with Memory](https://arxiv.org/abs/2404.04808) (CVPR)
- [ ] [\[2404.04819\] Joint Reconstruction of 3D Human and Object via Contact-Based Refinement Transformer](https://arxiv.org/abs/2404.04819) (Meta, CVPR)
- [ ] [\[2404.04823\] 3D Building Reconstruction from Monocular Remote Sensing Images with Multi-level Supervisions](https://arxiv.org/abs/2404.04823) (SYSU, CVPR)
- [ ] [\[2404.04828\] Strictly-ID-Preserved and Controllable Accessory Advertising Image Generation](https://arxiv.org/abs/2404.04828) (Tsinghua)
- [ ] [\[2404.04833\] ShoeModel: Learning to Wear on the User-specified Shoes via Diffusion Model](https://arxiv.org/abs/2404.04833) (Alibaba, ECCV)
- [ ] [\[2404.04876\] HiLo: Detailed and Robust 3D Clothed Human Reconstruction with High-and Low-Frequency Information of Parametric Models](https://arxiv.org/abs/2404.04876) (CVPR)
- [ ] [\[2404.04884\] LRNet: Change detection of high-resolution remote sensing imagery via strategy of localization-then-refinement](https://arxiv.org/abs/2404.04884) (WHU)
- [ ] [\[2404.04908\] Dual-Camera Smooth Zoom on Mobile Phones](https://arxiv.org/abs/2404.04908) (HIT)
- [ ] [\[2404.04933\] UniMD: Towards Unifying Moment Retrieval and Temporal Action Detection](https://arxiv.org/abs/2404.04933) (ECCV)
- [ ] [\[2404.04936\] Bootstrapping Chest CT Image Understanding by Distilling Knowledge from X-ray Expert Models](https://arxiv.org/abs/2404.04936) (CVPR)
- [ ] [\[2404.04946\] AnimateZoo: Zero-shot Video Generation of Cross-Species Animation via Subject Alignment](https://arxiv.org/abs/2404.04946) (Oxford)
- [ ] [\[2404.04953\] High-Discriminative Attribute Feature Learning for Generalized Zero-Shot Learning](https://arxiv.org/abs/2404.04953) (Xidian)
- [ ] [\[2404.04956\] Gaussian Shading: Provable Performance-Lossless Image Watermarking for Diffusion Models](https://arxiv.org/abs/2404.04956) (NUS, CVPR)
- [ ] [\[2404.04960\] PairAug: What Can Augmented Image-Text Pairs Do for Radiology?](https://arxiv.org/abs/2404.04960) (CVPR)
- [ ] [\[2404.04971\] FPL+: Filtered Pseudo Label-based Unsupervised Cross-Modality Adaptation for 3D Medical Image Segmentation](https://arxiv.org/abs/2404.04971) (UESTC)
- [ ] [\[2404.04996\] Fantastic Animals and Where to Find Them: Segment Any Marine Animal with Dual SAM](https://arxiv.org/abs/2404.04996) (CVPR)
- [ ] [\[2404.04998\] Weakly Supervised Deep Hyperspherical Quantization for Image Retrieval](https://arxiv.org/abs/2404.04998) (Tsinghua)
- [ ] [\[2404.05001\] Dual-Scale Transformer for Large-Scale Single-Pixel Imaging](https://arxiv.org/abs/2404.05001) (CVPR)
- [ ] [\[2404.05016\] Hyperbolic Learning with Synthetic Captions for Open-World Detection](https://arxiv.org/abs/2404.05016) (CVPR)
- [ ] [\[2404.05029\] LOGO: A Long-Form Video Dataset for Group Action Quality Assessment](https://arxiv.org/abs/2404.05029) (CVPR)
- [ ] [\[2404.05052\] Facial Affective Behavior Analysis with Instruction Tuning](https://arxiv.org/abs/2404.05052) (MIT)
- [ ] [\[2404.05069\] AirShot: Efficient Few-Shot Detection for Autonomous Exploration](https://arxiv.org/abs/2404.05069) (University of Edinburgh)
- [ ] [\[2404.05105\] VMambaMorph: a Multi-Modality Deformable Image Registration Framework based on Visual State Space Model with Cross-Scan Module](https://arxiv.org/abs/2404.05105) (Oxford)
- [ ] [\[2404.05111\] Class Similarity Transition: Decoupling Class Similarities and Imbalance from Generalized Few-shot Segmentation](https://arxiv.org/abs/2404.05111) (SYSU)
- [ ] [\[2404.05136\] Self-Supervised Multi-Object Tracking with Path Consistency](https://arxiv.org/abs/2404.05136) (CVPR)
- [ ] [\[2404.05145\] UniMix: Towards Domain Adaptive and Generalizable LiDAR Semantic Segmentation in Adverse Weather](https://arxiv.org/abs/2404.05145) (Tsinghua, CVPR)
- [ ] [\[2404.05163\] Semantic Flow: Learning Semantic Field of Dynamic Scenes from Monocular Videos](https://arxiv.org/abs/2404.05163) (XJTU, ICLR)
- [ ] [\[2404.05181\] Adaptive Learning for Multi-view Stereo Reconstruction](https://arxiv.org/abs/2404.05181) (Peking)
- [ ] [\[2404.05187\] LGSDF: Continual Global Learning of Signed Distance Fields Aided by Local Updating](https://arxiv.org/abs/2404.05187) (BIT)
- [ ] [\[2404.05206\] SoundingActions: Learning How Actions Sound from Narrated Egocentric Videos](https://arxiv.org/abs/2404.05206) (CVPR)
- [ ] [\[2404.05211\] Multi-level Graph Subspace Contrastive Learning for Hyperspectral Image Clustering](https://arxiv.org/abs/2404.05211) (NUDT)
- [ ] [\[2404.05212\] DiffCJK: Conditional Diffusion Model for High-Quality and Wide-coverage CJK Character Generation](https://arxiv.org/abs/2404.05212) (Google)
- [ ] [\[2404.05218\] Multi-agent Long-term 3D Human Pose Forecasting via Interaction-aware Trajectory Conditioning](https://arxiv.org/abs/2404.05218) (CVPR)
- [ ] [\[2404.05225\] LayoutLLM: Layout Instruction Tuning with Large Language Models for Document Understanding](https://arxiv.org/abs/2404.05225) (CVPR)
- [ ] [\[2404.05231\] PromptAD: Learning Prompts with only Normal Samples for Few-Shot Anomaly Detection](https://arxiv.org/abs/2404.05231) (CVPR)
- [ ] [\[2404.05238\] Allowing humans to interactively guide machines where to look does not always improve human-AI team's classification accuracy](https://arxiv.org/abs/2404.05238) (Princeton)
- [ ] [\[2404.05253\] CodeEnhance: A Codebook-Driven Approach for Low-Light Image Enhancement](https://arxiv.org/abs/2404.05253) (University of Alberta)
- [ ] [\[2404.05274\] Deep Optics for Video Snapshot Compressive Imaging](https://arxiv.org/abs/2404.05274) (ICCV)
- [ ] [\[2404.05300\] Texture Classification Network Integrating Adaptive Wavelet Transform](https://arxiv.org/abs/2404.05300) (Chongqing)
- [ ] [\[2404.05384\] Rethinking the Spatial Inconsistency in Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2404.05384) (CVPR)
- [ ] [\[2404.05393\] PAT: Pixel-wise Adaptive Training for Long-tailed Segmentation](https://arxiv.org/abs/2404.05393) (USyd)
- [ ] [\[2404.05426\] Test-Time Zero-Shot Temporal Action Localization](https://arxiv.org/abs/2404.05426) (CVPR)
- [ ] [\[2404.05465\] HAMMR: HierArchical MultiModal React agents for generic VQA](https://arxiv.org/abs/2404.05465) (Google)
- [ ] [\[2404.05490\] Two-Person Interaction Augmentation with Skeleton Priors](https://arxiv.org/abs/2404.05490) (UCL)
- [ ] [\[2404.05559\] TIM: A Time Interval Machine for Audio-Visual Action Recognition](https://arxiv.org/abs/2404.05559) (CVPR)
- [ ] [\[2404.05580\] Responsible Visual Editing](https://arxiv.org/abs/2404.05580) (PolyU)
- [ ] [\[2404.05583\] Towards More General Video-based Deepfake Detection through Facial Feature Guided Adaptation for Foundation Model](https://arxiv.org/abs/2404.05583) (Microsoft)
- [ ] [\[2404.05621\] MULTIFLOW: Shifting Towards Task-Agnostic Vision-Language Pruning](https://arxiv.org/abs/2404.05621) (CVPR)
- [ ] [\[2404.05626\] Learning a Category-level Object Pose Estimator without Pose Annotations](https://arxiv.org/abs/2404.05626) (XJTU)
- [ ] [\[2404.05657\] MLP Can Be A Good Transformer Learner](https://arxiv.org/abs/2404.05657) (MIT)
- [ ] [\[2404.05661\] Automatic Controllable Colorization via Imagination](https://arxiv.org/abs/2404.05661) (CVPR)
- [ ] [\[2404.05669\] NAF-DPM: A Nonlinear Activation-Free Diffusion Probabilistic Model for Document Enhancement](https://arxiv.org/abs/2404.05669) (Transactions on Pattern Analysis and Machine Intelligence)
- [ ] [\[2404.05673\] CoReS: Orchestrating the Dance of Reasoning and Segmentation](https://arxiv.org/abs/2404.05673) (ECCV)
- [ ] [\[2404.05675\] Normalizing Flows on the Product Space of SO(3) Manifolds for Probabilistic Human Pose Modeling](https://arxiv.org/abs/2404.05675) (MPI, CVPR)
- [ ] [\[2404.05680\] SphereHead: Stable 3D Full-head Synthesis with Spherical Tri-plane Representation](https://arxiv.org/abs/2404.05680) (ECCV)
- [ ] [\[2404.05687\] Retrieval-Augmented Open-Vocabulary Object Detection](https://arxiv.org/abs/2404.05687) (CVPR)
- [ ] [\[2404.05726\] MA-LMM: Memory-Augmented Large Multimodal Model for Long-Term Video Understanding](https://arxiv.org/abs/2404.05726) (CVPR)
- [ ] [\[2404.05814\] Towards Explainable Automated Neuroanatomy](https://arxiv.org/abs/2404.05814) (UCSD)
- [ ] [\[2404.05872\] TabConv: Low-Computation CNN Inference via Table Lookups](https://arxiv.org/abs/2404.05872) (UCLA)
- [ ] [\[2404.05980\] Tackling Structural Hallucination in Image Translation with Local Diffusion](https://arxiv.org/abs/2404.05980) (UCL)
- [ ] [\[2404.06012\] Diffusion-Based Point Cloud Super-Resolution for mmWave Radar Data](https://arxiv.org/abs/2404.06012) (NUDT)
- [ ] [\[2404.06044\] Object Dynamics Modeling with Hierarchical Point Cloud-based Representations](https://arxiv.org/abs/2404.06044) (CVPR)
- [ ] [\[2404.06050\] Incremental Joint Learning of Depth, Pose and Implicit Scene Representation on Monocular Camera in Large-scale Scenes](https://arxiv.org/abs/2404.06050) (SJTU)
- [ ] [\[2404.06065\] Unified Entropy Optimization for Open-Set Test-Time Adaptation](https://arxiv.org/abs/2404.06065) (CVPR)
- [ ] [\[2404.06091\] Hash3D: Training-free Acceleration for 3D Generation](https://arxiv.org/abs/2404.06091) (NUS)
- [ ] [\[2404.06119\] DreamView: Injecting View-specific Text Guidance into Text-to-3D Generation](https://arxiv.org/abs/2404.06119) (SYSU, ECCV)
- [ ] [\[2404.06139\] DiffHarmony: Latent Diffusion Model Meets Image Harmonization](https://arxiv.org/abs/2404.06139) (BUPT)
- [ ] [\[2404.06152\] HFNeRF: Learning Human Biomechanic Features with Neural Radiance Fields](https://arxiv.org/abs/2404.06152) (Inria)
- [ ] [\[2404.06155\] Efficient and Robust Point Cloud Registration via Heuristics-guided Parameter Search](https://arxiv.org/abs/2404.06155) (Transactions on Pattern Analysis and Machine Intelligence)
- [ ] [\[2404.06177\] Uncertainty-aware Evidential Fusion-based Learning for Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2404.06177) (Peking)
- [ ] [\[2404.06181\] EPL: Evidential Prototype Learning for Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2404.06181) (Peking)
- [ ] [\[2404.06194\] Exploring the Potential of Large Foundation Models for Open-Vocabulary HOI Detection](https://arxiv.org/abs/2404.06194) (Peking)
- [ ] [\[2404.06244\] Anchor-based Robust Finetuning of Vision-Language Models](https://arxiv.org/abs/2404.06244) (CVPR)
- [ ] [\[2404.06246\] GHNeRF: Learning Generalizable Human Features with Efficient Neural Radiance Fields](https://arxiv.org/abs/2404.06246) (Inria)
- [ ] [\[2404.06253\] From Barlow Twins to Triplet Training: Differentiating Dementia with Limited Data](https://arxiv.org/abs/2404.06253) (TUM)
- [ ] [\[2404.06256\] Label-Efficient 3D Object Detection For Road-Side Units](https://arxiv.org/abs/2404.06256) (Inria)
- [ ] [\[2404.06270\] 3D Geometry-aware Deformable Gaussian Splatting for Dynamic View Synthesis](https://arxiv.org/abs/2404.06270) (CVPR)
- [ ] [\[2404.06350\] Rolling Shutter Correction with Intermediate Distortion Flow Estimation](https://arxiv.org/abs/2404.06350) (CVPR)
- [ ] [\[2404.06351\] HPNet: Dynamic Trajectory Forecasting with Historical Prediction Attention](https://arxiv.org/abs/2404.06351) (CVPR)
- [ ] [\[2404.06369\] VISION2UI: A Real-World Dataset with Layout for Code Generation from UI Designs](https://arxiv.org/abs/2404.06369) (Peking)
- [ ] [\[2404.06443\] Multi-scale Dynamic and Hierarchical Relationship Modeling for Facial Action Units Recognition](https://arxiv.org/abs/2404.06443) (CVPR)
- [ ] [\[2404.06493\] Flying with Photons: Rendering Novel Views of Propagating Light](https://arxiv.org/abs/2404.06493) (University of Toronto, ECCV)
- [ ] [\[2404.06510\] Can Feedback Enhance Semantic Grounding in Large Vision-Language Models?](https://arxiv.org/abs/2404.06510) (University of Toronto)
- [ ] [\[2404.06511\] MoReVQA: Exploring Modular Reasoning Models for Video Question Answering](https://arxiv.org/abs/2404.06511) (CVPR)
- [ ] [\[2404.06512\] InternLM-XComposer2-4KHD: A Pioneering Large Vision-Language Model Handling Resolutions from 336 Pixels to 4K HD](https://arxiv.org/abs/2404.06512) (Shanghai AI Lab)
- [ ] [\[2404.06542\] Training-Free Open-Vocabulary Segmentation with Offline Diffusion-Augmented Prototype Generation](https://arxiv.org/abs/2404.06542) (CVPR)
- [ ] [\[2404.06665\] Deep Generative Data Assimilation in Multimodal Setting](https://arxiv.org/abs/2404.06665) (Columbia University, CVPR)
- [ ] [\[2404.06683\] Unsupervised Visible-Infrared ReID via Pseudo-label Correction and Modality-level Alignment](https://arxiv.org/abs/2404.06683) (HKUST(GZ))
- [ ] [\[2404.06692\] Perception-Oriented Video Frame Interpolation via Asymmetric Blending](https://arxiv.org/abs/2404.06692) (CVPR)
- [ ] [\[2404.06693\] Binomial Self-compensation for Motion Error in Dynamic 3D Scanning](https://arxiv.org/abs/2404.06693) (UESTC, ECCV)
- [ ] [\[2404.06741\] An Animation-based Augmentation Approach for Action Recognition from Discontinuous Video](https://arxiv.org/abs/2404.06741) (University of Tokyo)
- [ ] [\[2404.06773\] Adapting LLaMA Decoder to Vision Transformer](https://arxiv.org/abs/2404.06773) (HKU)
- [ ] [\[2404.06780\] Urban Architect: Steerable 3D Urban Scene Generation with Layout Prior](https://arxiv.org/abs/2404.06780) (CUHK)
- [ ] [\[2404.06842\] MoCha-Stereo: Motif Channel Attention Network for Stereo Matching](https://arxiv.org/abs/2404.06842) (CVPR)
- [ ] [\[2404.06851\] UDiFF: Generating Conditional Unsigned Distance Fields with Optimal Wavelet Diffusion](https://arxiv.org/abs/2404.06851) (Tsinghua, CVPR)
- [ ] [\[2404.06860\] Monocular 3D lane detection for Autonomous Driving: Recent Achievements, Challenges, and Outlooks](https://arxiv.org/abs/2404.06860) (HKUST)
- [ ] [\[2404.06865\] Fine color guidance in diffusion models and its application to image compression at extremely low bitrates](https://arxiv.org/abs/2404.06865) (TIP)
