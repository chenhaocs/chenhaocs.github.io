- [ ] [\[2404.06913\] Sparse Global Matching for Video Frame Interpolation with Large Motion](https://arxiv.org/abs/2404.06913) (NJU, CVPR)
- [ ] [\[2404.06918\] HRVDA: High-Resolution Visual Document Assistant](https://arxiv.org/abs/2404.06918) (USTC, CVPR)
- [ ] [\[2404.06936\] Efficient and Generic Point Model for Lossless Point Cloud Attribute Compression](https://arxiv.org/abs/2404.06936) (NJU)
- [ ] [\[2404.06971\] TrajPRed: Trajectory Prediction with Region-based Relation Learning](https://arxiv.org/abs/2404.06971) (GIT)
- [ ] [\[2404.07032\] An Evidential-enhanced Tri-Branch Consistency Learning Method for Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2404.07032) (Xidian)
- [ ] [\[2404.07106\] 3DMambaComplete: Exploring Structured State Space Model for Point Cloud Completion](https://arxiv.org/abs/2404.07106) (Fudan)
- [ ] [\[2404.07124\] Measuring proximity to standard planes during fetal brain ultrasound scanning](https://arxiv.org/abs/2404.07124) (UCL)
- [ ] [\[2404.07155\] Unified Language-driven Zero-shot Domain Adaptation](https://arxiv.org/abs/2404.07155) (HIT, CVPR)
- [ ] [\[2404.07178\] Move Anything with Layered Scene Diffusion](https://arxiv.org/abs/2404.07178) (CVPR)
- [ ] [\[2404.07202\] UMBRAE: Unified Multimodal Brain Decoding](https://arxiv.org/abs/2404.07202) (ECCV)
- [ ] [\[2404.07306\] AI-Guided Defect Detection Techniques to Model Single Crystal Diamond Growth](https://arxiv.org/abs/2404.07306) (Michigan State University)
- [ ] [\[2404.07336\] PEAVS: Perceptual Evaluation of Audio-Visual Synchrony Grounded in Viewers' Opinion Scores](https://arxiv.org/abs/2404.07336) (AWS)
- [ ] [\[2404.07347\] Gaze-Guided Graph Neural Network for Action Anticipation Conditioned on Intention](https://arxiv.org/abs/2404.07347) (TUM)
- [ ] [\[2404.07351\] A Transformer-Based Model for the Prediction of Human Gaze Behavior on Videos](https://arxiv.org/abs/2404.07351) (TUM)
- [ ] [\[2404.07389\] Object-Conditioned Energy-Based Attention Map Alignment in Text-to-Image Diffusion Models](https://arxiv.org/abs/2404.07389) (UCLA)
- [ ] [\[2404.07445\] Multi-view Aggregation Network for Dichotomous Image Segmentation](https://arxiv.org/abs/2404.07445) (CVPR)
- [ ] [\[2404.07474\] G-NeRF: Geometry-enhanced Novel View Synthesis from Single-View Images](https://arxiv.org/abs/2404.07474) (CVPR)
- [ ] [\[2404.07487\] Fine-Grained Side Information Guided Dual-Prompts for Zero-Shot Skeleton Action Recognition](https://arxiv.org/abs/2404.07487) (PolyU)
- [ ] [\[2404.07520\] PromptSync: Bridging Domain Gaps in Vision-Language Models through Class-Aware Prototype Alignment and Discrimination](https://arxiv.org/abs/2404.07520) (CVPR)
- [ ] [\[2404.07543\] Content-Adaptive Non-Local Convolution for Remote Sensing Pansharpening](https://arxiv.org/abs/2404.07543) (UESTC, CVPR)
- [ ] [\[2404.07545\] Stereo-LiDAR Depth Estimation with Deformable Propagation and Learned Disparity-Depth Conversion](https://arxiv.org/abs/2404.07545) (SJTU)
- [ ] [\[2404.07580\] Multi-rater Prompting for Ambiguous Medical Image Segmentation](https://arxiv.org/abs/2404.07580) (ZJU)
- [ ] [\[2404.07600\] Implicit and Explicit Language Guidance for Diffusion-based Visual Perception](https://arxiv.org/abs/2404.07600) (Chongqing)
- [ ] [\[2404.07603\] GLID: Pre-training a Generalist Encoder-Decoder Vision Model](https://arxiv.org/abs/2404.07603) (CVPR)
- [ ] [\[2404.07610\] Do You Remember? Dense Video Captioning with Cross-Modal Memory Retrieval](https://arxiv.org/abs/2404.07610) (CVPR)
- [ ] [\[2404.07626\] Homography Guided Temporal Fusion for Road Line and Marking Segmentation](https://arxiv.org/abs/2404.07626) (ICCV)
- [ ] [\[2404.07705\] ViM-UNet: Vision Mamba for Biomedical Segmentation](https://arxiv.org/abs/2404.07705) (University of Göttingen)
- [ ] [\[2404.07713\] Progressive Semantic-Guided Vision Transformer for Zero-Shot Learning](https://arxiv.org/abs/2404.07713) (CVPR)
- [ ] [\[2404.07739\] Exploiting Object-based and Segmentation-based Semantic Features for Deep Learning-based Indoor Scene Classification](https://arxiv.org/abs/2404.07739) (Transactions on Image Processing)
- [ ] [\[2404.07770\] Joint Conditional Diffusion Model for Image Restoration with Mixed Degradations](https://arxiv.org/abs/2404.07770) (BIT)
- [ ] [\[2404.07788\] AUG: A New Dataset and An Efficient Model for Aerial Image Urban Scene Graph Generation](https://arxiv.org/abs/2404.07788) (WHU)
- [ ] [\[2404.07794\] DGMamba: Domain Generalization via Generalized State Space Model](https://arxiv.org/abs/2404.07794) (ACMMM)
- [ ] [\[2404.07833\] Streamlined Photoacoustic Image Processing with Foundation Models: A Training-Free Solution](https://arxiv.org/abs/2404.07833) (Peking)
- [ ] [\[2404.07846\] TBSN: Transformer-Based Blind-Spot Network for Self-Supervised Image Denoising](https://arxiv.org/abs/2404.07846) (HIT)
- [ ] [\[2404.07850\] MindBridge: A Cross-Subject Brain Decoding Framework](https://arxiv.org/abs/2404.07850) (NUS, CVPR)
- [ ] [\[2404.07855\] Resolve Domain Conflicts for Generalizable Remote Physiological Measurement](https://arxiv.org/abs/2404.07855) (NJU, ACMMM)
- [ ] [\[2404.07932\] FusionMamba: Efficient Image Fusion with State Space Model](https://arxiv.org/abs/2404.07932) (UESTC)
- [ ] [\[2404.07949\] Taming Stable Diffusion for Text to 360{\deg} Panorama Image Generation](https://arxiv.org/abs/2404.07949) (CVPR)
- [ ] [\[2404.07950\] Reinforcement Learning with Generalizable Gaussian Splatting](https://arxiv.org/abs/2404.07950) (HKUST)
- [ ] [\[2404.07973\] Ferret-v2: An Improved Baseline for Referring and Grounding with Large Language Models](https://arxiv.org/abs/2404.07973) (Columbia University)
- [ ] [\[2404.07983\] Two Effects, One Trigger: On the Modality Gap, Object Bias, and Information Imbalance in Contrastive Vision-Language Representation Learning](https://arxiv.org/abs/2404.07983) (Bosch)
- [ ] [\[2404.07990\] OpenBias: Open-set Bias Detection in Text-to-Image Generative Models](https://arxiv.org/abs/2404.07990) (CVPR)
- [ ] [\[2404.07991\] GoMAvatar: Efficient Animatable Human Modeling from Monocular Video Using Gaussians-on-Mesh](https://arxiv.org/abs/2404.07991) (CVPR)
- [ ] [\[2404.07992\] GoMVS: Geometrically Consistent Cost Aggregation for Multi-View Stereo](https://arxiv.org/abs/2404.07992) (CVPR)
- [ ] [\[2404.08013\] Enhanced Cooperative Perception for Autonomous Vehicles Using Imperfect Communication](https://arxiv.org/abs/2404.08013) (MIT)
- [ ] [\[2404.08017\] AI-Guided Feature Segmentation Techniques to Model Features from Single Crystal Diamond Growth](https://arxiv.org/abs/2404.08017) (Michigan State University)
- [ ] [\[2404.08027\] SurvMamba: State Space Model with Multi-grained Multi-modal Interaction for Survival Prediction](https://arxiv.org/abs/2404.08027) (Xiamen)
- [ ] [\[2404.08031\] Latent Guard: a Safety Framework for Text-to-image Generation](https://arxiv.org/abs/2404.08031) (ECCV)
- [ ] [\[2404.08081\] Real-Time Detection and Analysis of Vehicles and Pedestrians using Deep Learning](https://arxiv.org/abs/2404.08081) (University of Alberta)
- [ ] [\[2404.08111\] S3Editor: A Sparse Semantic-Disentangled Self-Training Framework for Face Video Editing](https://arxiv.org/abs/2404.08111) (NUS)
- [ ] [\[2404.08195\] Tackling Ambiguity from Perspective of Uncertainty Inference and Affinity Diversification for Weakly Supervised Semantic Segmentation](https://arxiv.org/abs/2404.08195) (Fudan)
- [ ] [\[2404.08197\] Scaling (Down) CLIP: A Comprehensive Analysis of Data, Architecture, and Training Strategies](https://arxiv.org/abs/2404.08197) (Google)
- [ ] [\[2404.08237\] IFViT: Interpretable Fixed-Length Representation for Fingerprint Matching via Vision Transformer](https://arxiv.org/abs/2404.08237) (HKU)
- [ ] [\[2404.08292\] AdaContour: Adaptive Contour Descriptor with Hierarchical Representation](https://arxiv.org/abs/2404.08292) (Microsoft)
- [ ] [\[2404.08353\] TDANet: Target-Directed Attention Network For Object-Goal Visual Navigation With Zero-Shot Ability](https://arxiv.org/abs/2404.08353) (Peking)
- [ ] [\[2404.08419\] Direct May Not Be the Best: An Incremental Evolution View of Pose Generation](https://arxiv.org/abs/2404.08419) (Peking)
- [ ] [\[2404.08449\] OccGaussian: 3D Gaussian Splatting for Occluded Human Rendering](https://arxiv.org/abs/2404.08449) (Tsinghua)
- [ ] [\[2404.08452\] MoE-FFD: Mixture of Experts for Generalized and Parameter-Efficient Face Forgery Detection](https://arxiv.org/abs/2404.08452) (NTU)
- [ ] [\[2404.08489\] SpectralMamba: Efficient Mamba for Hyperspectral Image Classification](https://arxiv.org/abs/2404.08489) (Inria)
- [ ] [\[2404.08506\] LaSagnA: Language-based Segmentation Assistant for Complex Queries](https://arxiv.org/abs/2404.08506) (Tsinghua)
- [ ] [\[2404.08514\] NIR-Assisted Image Denoising: A Selective Fusion Approach and A Real-World Benchmark Dataset](https://arxiv.org/abs/2404.08514) (HIT)
- [ ] [\[2404.08531\] Text Prompt with Normality Guidance for Weakly Supervised Video Anomaly Detection](https://arxiv.org/abs/2404.08531) (CVPR)
- [ ] [\[2404.08540\] On the Robustness of Language Guidance for Low-Level Vision Tasks: Findings from Depth Estimation](https://arxiv.org/abs/2404.08540) (CVPR)
- [ ] [\[2404.08544\] Analyzing Decades-Long Environmental Changes in Namibia Using Archival Aerial Photography and Deep Learning](https://arxiv.org/abs/2404.08544) (Microsoft)
- [ ] [\[2404.08603\] Training-free Boost for Open-Vocabulary Object Detection with Confidence Aggregation](https://arxiv.org/abs/2404.08603) (ZJU)
- [ ] [\[2404.08636\] Probing the 3D Awareness of Visual Foundation Models](https://arxiv.org/abs/2404.08636) (CVPR)
- [ ] [\[2404.08639\] COCONut: Modernizing COCO Segmentation](https://arxiv.org/abs/2404.08639) (CVPR)
- [ ] [\[2404.08640\] EventEgo3D: 3D Human Motion Capture from Egocentric Event Streams](https://arxiv.org/abs/2404.08640) (CVPR)
- [ ] [\[2404.08921\] PNeRV: Enhancing Spatial Consistency via Pyramidal Neural Representation for Videos](https://arxiv.org/abs/2404.08921) (NJU)
- [ ] [\[2404.08926\] Diffusion Models Meet Remote Sensing: Principles, Methods, and Perspectives](https://arxiv.org/abs/2404.08926) (Xidian)
- [ ] [\[2404.08958\] AMU-Tuning: Effective Logit Bias for CLIP-based Few-shot Learning](https://arxiv.org/abs/2404.08958) (CVPR)
- [ ] [\[2404.08964\] Understanding Multimodal Deep Neural Networks: A Concept Selection View](https://arxiv.org/abs/2404.08964) (Tsinghua)
- [ ] [\[2404.08966\] LoopGaussian: Creating 3D Cinemagraph with Multi-view Images via Eulerian Motion Field](https://arxiv.org/abs/2404.08966) (ZJU)
- [ ] [\[2404.08968\] MCPNet: An Interpretable Classifier via Multi-Level Concept Prototypes](https://arxiv.org/abs/2404.08968) (NVIDIA, CVPR)
- [ ] [\[2404.09011\] PracticalDG: Perturbation Distillation on Vision-Language Models for Hybrid Domain Generalization](https://arxiv.org/abs/2404.09011) (BUPT, CVPR)
- [ ] [\[2404.09051\] Rethinking Iterative Stereo Matching from Diffusion Bridge Model Perspective](https://arxiv.org/abs/2404.09051) (TIP)
- [ ] [\[2404.09115\] GCC: Generative Calibration Clustering](https://arxiv.org/abs/2404.09115) (Google)
- [ ] [\[2404.09158\] StreakNet-Arch: An Anti-scattering Network-based Architecture for Underwater Carrier LiDAR-Radar Imaging](https://arxiv.org/abs/2404.09158) (NWPU)
- [ ] [\[2404.09172\] LoopAnimate: Loopable Salient Object Animation](https://arxiv.org/abs/2404.09172) (ZJU)
- [ ] [\[2404.09178\] HANet: A Hierarchical Attention Network for Change Detection With Bitemporal Very-High-Resolution Remote Sensing Images](https://arxiv.org/abs/2404.09178) (WHU)
- [ ] [\[2404.09179\] Change Guiding Network: Incorporating Change Prior to Guide Change Detection in Remote Sensing Imagery](https://arxiv.org/abs/2404.09179) (WHU)
- [ ] [\[2404.09216\] DetCLIPv3: Towards Versatile Generative Open-vocabulary Object Detection](https://arxiv.org/abs/2404.09216) (HKUST, CVPR)
- [ ] [\[2404.09263\] Task-Driven Exploration: Decoupling and Inter-Task Feedback for Joint Moment Retrieval and Highlight Detection](https://arxiv.org/abs/2404.09263) (XJTU)
- [ ] [\[2404.09290\] RoofDiffusion: Constructing Roofs from Severely Corrupted Point Data via Diffusion](https://arxiv.org/abs/2404.09290) (Meta)
- [ ] [\[2404.09292\] Bridging Data Islands: Geographic Heterogeneity-Aware Federated Learning for Collaborative Remote Sensing Semantic Segmentation](https://arxiv.org/abs/2404.09292) (WHU)
- [ ] [\[2404.09293\] A Novel State Space Model with Local Enhancement and State Sharing for Image Fusion](https://arxiv.org/abs/2404.09293) (UESTC)
- [ ] [\[2404.09342\] Face-voice Association in Multilingual Environments (FAME) Challenge 2024 Evaluation Plan](https://arxiv.org/abs/2404.09342) (ACM Multimedia)
- [ ] [\[2404.09359\] Evaluation Framework for Feedback Generation Methods in Skeletal Movement Assessment](https://arxiv.org/abs/2404.09359) (ECCV)
- [ ] [\[2404.09426\] ViFu: Multiple 360$^\circ$ Objects Reconstruction with Clean Background via Visible Part Fusion](https://arxiv.org/abs/2404.09426) (University of Tokyo)
- [ ] [\[2404.09447\] kNN-CLIP: Retrieval Enables Training-Free Segmentation on Continually Expanding Large Vocabularies](https://arxiv.org/abs/2404.09447) (Oxford)
- [ ] [\[2404.09451\] Contrastive Mean-Shift Learning for Generalized Category Discovery](https://arxiv.org/abs/2404.09451) (CVPR)
- [ ] [\[2404.09454\] Utility-Fairness Trade-Offs and How to Find Them](https://arxiv.org/abs/2404.09454) (Computer Vision and Pattern Recognition)
- [ ] [\[2404.09465\] PhyScene: Physically Interactable 3D Scene Synthesis for Embodied AI](https://arxiv.org/abs/2404.09465) (CVPR)
- [ ] [\[2404.09472\] Q2A: Querying Implicit Fully Continuous Feature Pyramid to Align Features for Medical Image Segmentation](https://arxiv.org/abs/2404.09472) (Tsinghua)
- [ ] [\[2404.09474\] TCCT-Net: Two-Stream Network Architecture for Fast and Efficient Engagement Estimation via Behavioral Feature Signals](https://arxiv.org/abs/2404.09474) (ZJU)
- [ ] [\[2404.09476\] FreqMamba: Viewing Mamba from a Frequency Perspective for Image Deraining](https://arxiv.org/abs/2404.09476) (USTC)
- [ ] [\[2404.09490\] Leveraging Temporal Contextualization for Video Action Recognition](https://arxiv.org/abs/2404.09490) (ECCV)
- [ ] [\[2404.09496\] Towards Collaborative Autonomous Driving: Simulation Platform and End-to-End System](https://arxiv.org/abs/2404.09496) (SJTU)
- [ ] [\[2404.09498\] FusionMamba: Dynamic Feature Enhancement for Multimodal Image Fusion with Mamba](https://arxiv.org/abs/2404.09498) (PolyU)
- [ ] [\[2404.09502\] SparseOcc: Rethinking Sparse Latent Representation for Vision-Based Semantic Occupancy Prediction](https://arxiv.org/abs/2404.09502) (CVPR)
- [ ] [\[2404.09504\] Learning Tracking Representations from Single Point Annotations](https://arxiv.org/abs/2404.09504) (CVPR)
- [ ] [\[2404.09509\] Fuse after Align: Improving Face-Voice Association Learning via Multimodal Encoder](https://arxiv.org/abs/2404.09509) (CMU)
- [ ] [\[2404.09530\] RanLayNet: A Dataset for Document Layout Detection used for Domain Adaptation and Generalization](https://arxiv.org/abs/2404.09530) (ACMMM)
- [ ] [\[2404.09531\] Oblique-MERF: Revisiting and Improving MERF for Oblique Photography](https://arxiv.org/abs/2404.09531) (USTC)
- [ ] [\[2404.09586\] Mitigating the Curse of Dimensionality for Certified Robustness via Dual Randomized Smoothing](https://arxiv.org/abs/2404.09586) (ICLR)
- [ ] [\[2404.09624\] AesExpert: Towards Multi-modality Foundation Model for Image Aesthetics Perception](https://arxiv.org/abs/2404.09624) (Xidian, ACMMM)
- [ ] [\[2404.09632\] Bridging Vision and Language Spaces with Assignment Prediction](https://arxiv.org/abs/2404.09632) (ICLR)
- [ ] [\[2404.09640\] CREST: Cross-modal Resonance through Evidential Deep Learning for Enhanced Zero-Shot Learning](https://arxiv.org/abs/2404.09640) (ACMMM)
- [ ] [\[2404.09654\] Do LLMs Understand Visual Anomalies? Uncovering LLM's Capabilities in Zero-shot Anomaly Detection](https://arxiv.org/abs/2404.09654) (BIT)
- [ ] [\[2404.09690\] Harnessing GPT-4V(ision) for Insurance: A Preliminary Exploration](https://arxiv.org/abs/2404.09690) (Fudan)
- [ ] [\[2404.09736\] FSRT: Facial Scene Representation Transformer for Face Reenactment from Factorized Appearance, Head-pose, and Facial Expression Features](https://arxiv.org/abs/2404.09736) (CVPR)
- [ ] [\[2404.09819\] 3D Face Tracking from 2D Video through Iterative Dense UV to Image Flow](https://arxiv.org/abs/2404.09819) (CVPR)
- [ ] [\[2404.09833\] Video2Game: Real-time, Interactive, Realistic and Browser-Compatible Environment from a Single Video](https://arxiv.org/abs/2404.09833) (CVPR)
- [ ] [\[2404.09842\] STMixer: A One-Stage Sparse Action Detector](https://arxiv.org/abs/2404.09842) (CVPR)
- [ ] [\[2404.09846\] A Diffusion-based Data Generator for Training Object Recognition Models in Ultra-Range Distance](https://arxiv.org/abs/2404.09846) (Tel Aviv)
- [ ] [\[2404.09857\] Empowering Embodied Visual Tracking with Visual Foundation Models and Offline RL](https://arxiv.org/abs/2404.09857) (ECCV)
- [ ] [\[2404.09870\] Table tennis ball spin estimation with an event camera](https://arxiv.org/abs/2404.09870) (University of Tübingen)
- [ ] [\[2404.09884\] Map-Relative Pose Regression for Visual Re-Localization](https://arxiv.org/abs/2404.09884) (CVPR)
- [ ] [\[2404.09942\] Knowledge-enhanced Visual-Language Pretraining for Computational Pathology](https://arxiv.org/abs/2404.09942) (Shanghai AI Lab)
- [ ] [\[2404.09976\] Diffscaler: Enhancing the Generative Prowess of Diffusion Transformers](https://arxiv.org/abs/2404.09976) (Stanford)
- [ ] [\[2404.09977\] MaxFusion: Plug&Play Multi-Modal Generation in Text-to-Image Diffusion Models](https://arxiv.org/abs/2404.09977) (Stanford)
- [ ] [\[2404.09993\] No More Ambiguity in 360{\deg} Room Layout via Bi-Layout Estimation](https://arxiv.org/abs/2404.09993) (CVPR)
- [ ] [\[2404.10096\] Vision Augmentation Prediction Autoencoder with Attention Design (VAPAAD)](https://arxiv.org/abs/2404.10096) (Columbia University)
- [ ] [\[2404.10166\] Self-Supervised Learning Featuring Small-Scale Image Dataset for Treatable Retinal Diseases Classification](https://arxiv.org/abs/2404.10166) (BU)
- [ ] [\[2404.10177\] Consistent Diffusion Meets Tweedie: Training Exact Ambient Diffusion Models with Noisy Data](https://arxiv.org/abs/2404.10177) (UT Austin, ICML)
- [ ] [\[2404.10193\] Consistency and Uncertainty: Identifying Unreliable Responses From Black-Box Vision-Language Models for Selective Visual Question Answering](https://arxiv.org/abs/2404.10193) (CVPR)
- [ ] [\[2404.10227\] MS-MANO: Enabling Hand Pose Tracking with Biomechanical Constraints](https://arxiv.org/abs/2404.10227) (CVPR)
- [ ] [\[2404.10242\] Masked Autoencoders for Microscopy are Scalable Learners of Cellular Biology](https://arxiv.org/abs/2404.10242) (CVPR)
- [ ] [\[2404.10267\] OneActor: Consistent Character Generation via Cluster-Conditioned Guidance](https://arxiv.org/abs/2404.10267) (XJTU)
- [ ] [\[2404.10279\] EucliDreamer: Fast and High-Quality Texturing for 3D Models with Depth-Conditioned Stable Diffusion](https://arxiv.org/abs/2404.10279) (Columbia University)
- [ ] [\[2404.10292\] From Data Deluge to Data Curation: A Filtering-WoRA Paradigm for Efficient Text-based Person Search](https://arxiv.org/abs/2404.10292) (BIT)
- [ ] [\[2404.10322\] Domain-Rectifying Adapter for Cross-Domain Few-Shot Segmentation](https://arxiv.org/abs/2404.10322) (HIT, CVPR)
- [ ] [\[2404.10342\] Referring Flexible Image Restoration](https://arxiv.org/abs/2404.10342) (HKUST(GZ))
- [ ] [\[2404.10343\] The Ninth NTIRE 2024 Efficient Super-Resolution Challenge Report](https://arxiv.org/abs/2404.10343) (ETH)
- [ ] [\[2404.10407\] Comprehensive Survey of Model Compression and Speed up for Vision Transformers](https://arxiv.org/abs/2404.10407) (Berkeley)
- [ ] [\[2404.10411\] Camera clustering for scalable stream-based active distillation](https://arxiv.org/abs/2404.10411) (Imperial)
- [ ] [\[2404.10438\] The Unreasonable Effectiveness of Pre-Trained Features for Camera Pose Refinement](https://arxiv.org/abs/2404.10438) (CVPR)
- [ ] [\[2404.10484\] AbsGS: Recovering Fine Details for 3D Gaussian Splatting](https://arxiv.org/abs/2404.10484) (NUDT)
- [ ] [\[2404.10499\] Robust Noisy Label Learning via Two-Stream Sample Distillation](https://arxiv.org/abs/2404.10499) (XJTU)
- [ ] [\[2404.10501\] Self-Supervised Visual Preference Alignment](https://arxiv.org/abs/2404.10501) (NJU)
- [ ] [\[2404.10527\] SPVLoc: Semantic Panoramic Viewport Matching for 6D Camera Localization in Unseen Environments](https://arxiv.org/abs/2404.10527) (ECCV)
- [ ] [\[2404.10571\] CMU-Flownet: Exploring Point Cloud Scene Flow Estimation in Occluded Scenario](https://arxiv.org/abs/2404.10571) (Xiamen)
- [ ] [\[2404.10603\] Enhancing 3D Fidelity of Text-to-3D using Cross-View Correspondences](https://arxiv.org/abs/2404.10603) (CVPR)
- [ ] [\[2404.10626\] Exploring selective image matching methods for zero-shot and few-sample unsupervised domain adaptation of urban canopy prediction](https://arxiv.org/abs/2404.10626) (Alan Turing Institute)
- [ ] [\[2404.10667\] VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time](https://arxiv.org/abs/2404.10667) (Microsoft)
- [ ] [\[2404.10681\] StyleCity: Large-Scale 3D Urban Scenes Stylization](https://arxiv.org/abs/2404.10681) (ECCV)
- [ ] [\[2404.10688\] Efficient Conditional Diffusion Model with Probability Flow Sampling for Image Super-resolution](https://arxiv.org/abs/2404.10688) (Tsinghua)
- [ ] [\[2404.10716\] MOWA: Multiple-in-One Image Warping Model](https://arxiv.org/abs/2404.10716) (NTU)
- [ ] [\[2404.10760\] Learning Feature Inversion for Multi-class Anomaly Detection under General-purpose COCO-AD Benchmark](https://arxiv.org/abs/2404.10760) (ZJU)
- [ ] [\[2404.10765\] RefFusion: Reference Adapted Diffusion Models for 3D Scene Inpainting](https://arxiv.org/abs/2404.10765) (NVIDIA)
- [ ] [\[2404.10838\] Dynamic Self-adaptive Multiscale Distillation from Pre-trained Multimodal Large Model for Efficient Cross-modal Representation Learning](https://arxiv.org/abs/2404.10838) (BUPT)
- [ ] [\[2404.10880\] HumMUSS: Human Motion Understanding using State Space Models](https://arxiv.org/abs/2404.10880) (CVPR)
- [ ] [\[2404.10966\] Domain-Specific Block Selection and Paired-View Pseudo-Labeling for Online Test-Time Adaptation](https://arxiv.org/abs/2404.10966) (CVPR)
- [ ] [\[2404.10980\] Hyper Evidential Deep Learning to Quantify Composite Classification Uncertainty](https://arxiv.org/abs/2404.10980) (ICLR)
- [ ] [\[2404.10989\] FairSSD: Understanding Bias in Synthetic Speech Detectors](https://arxiv.org/abs/2404.10989) (CVPR)
- [ ] [\[2404.11016\] MaeFuse: Transferring Omni Features with Pretrained Masked Autoencoders for Infrared and Visible Image Fusion via Guided Training](https://arxiv.org/abs/2404.11016) (HIT)
- [ ] [\[2404.11031\] TaCOS: Task-Specific Camera Optimization with Simulation](https://arxiv.org/abs/2404.11031) (USyd)
- [ ] [\[2404.11070\] Sky-GVIO: an enhanced GNSS/INS/Vision navigation with FCN-based sky-segmentation in urban canyon](https://arxiv.org/abs/2404.11070) (WHU)
- [ ] [\[2404.11100\] Synthesizing Realistic Data for Table Recognition](https://arxiv.org/abs/2404.11100) (HUST)
- [ ] [\[2404.11111\] CorrNet+: Sign Language Recognition and Translation via Spatial-Temporal Correlation](https://arxiv.org/abs/2404.11111) (Tianjin)
- [ ] [\[2404.11120\] TiNO-Edit: Timestep and Noise Optimization for Robust Diffusion-Based Image Editing](https://arxiv.org/abs/2404.11120) (CVPR)
- [ ] [\[2404.11129\] Fact :Teaching MLLMs with Faithful, Concise and Transferable Rationales](https://arxiv.org/abs/2404.11129) (ZJU)
- [ ] [\[2404.11139\] GeoReF: Geometric Alignment Across Shape Variation for Category-level Object Pose Refinement](https://arxiv.org/abs/2404.11139) (HKU, Computer Vision and Pattern Recognition)
- [ ] [\[2404.11156\] Learning SO(3)-Invariant Semantic Correspondence via Local Shape Transform](https://arxiv.org/abs/2404.11156) (CVPR)
- [ ] [\[2404.11161\] Pre-processing matters: A segment search method for WSI classification](https://arxiv.org/abs/2404.11161) (MBZUAI)
- [ ] [\[2404.11202\] GhostNetV3: Exploring the Training Strategies for Compact Models](https://arxiv.org/abs/2404.11202) (BIT)
- [ ] [\[2404.11207\] Exploring the Transferability of Visual Prompting for Multimodal Large Language Models](https://arxiv.org/abs/2404.11207) (CVPR)
- [ ] [\[2404.11265\] The Victim and The Beneficiary: Exploiting a Poisoned Model to Train a Clean Model on Poisoned Data](https://arxiv.org/abs/2404.11265) (ICCV)
- [ ] [\[2404.11266\] Criteria for Uncertainty-based Corner Cases Detection in Instance Segmentation](https://arxiv.org/abs/2404.11266) (Bosch)
- [ ] [\[2404.11291\] Closely Interactive Human Reconstruction with Proxemics and Physics-Guided Adaption](https://arxiv.org/abs/2404.11291) (CVPR)
- [ ] [\[2404.11317\] Improving Composed Image Retrieval via Contrastive Learning with Scaling Positives and Negatives](https://arxiv.org/abs/2404.11317) (ACMMM)
- [ ] [\[2404.11355\] Consisaug: A Consistency-based Augmentation for Polyp Detection in Endoscopy Image Analysis](https://arxiv.org/abs/2404.11355) (SJTU)
- [ ] [\[2404.11357\] Detector Collapse: Physical-World Backdooring Object Detection to Catastrophic Overload or Blindness in Autonomous Driving](https://arxiv.org/abs/2404.11357) (MIT)
- [ ] [\[2404.11375\] Text-controlled Motion Mamba: Text-Instructed Temporal Grounding of Human Motion](https://arxiv.org/abs/2404.11375) (Peking)
- [ ] [\[2404.11419\] SLAIM: Robust Dense Neural SLAM for Online Tracking and Mapping](https://arxiv.org/abs/2404.11419) (GIT)
- [ ] [\[2404.11426\] SPAMming Labels: Efficient Annotations for the Trackers of Tomorrow](https://arxiv.org/abs/2404.11426) (ECCV)
- [ ] [\[2404.11492\] arcjetCV: an open-source software to analyze material ablation](https://arxiv.org/abs/2404.11492) (NASA)
- [ ] [\[2404.11537\] SSDiff: Spatial-spectral Integrated Diffusion Model for Remote Sensing Pansharpening](https://arxiv.org/abs/2404.11537) (UESTC)
- [ ] [\[2404.11590\] A Subspace-Constrained Tyler's Estimator and its Applications to Structure from Motion](https://arxiv.org/abs/2404.11590) (CVPR)
- [ ] [\[2404.11605\] VG4D: Vision-Language Model Goes 4D Video Recognition](https://arxiv.org/abs/2404.11605) (SYSU)
- [ ] [\[2404.11614\] Dynamic Typography: Bringing Text to Life via Video Diffusion Prior](https://arxiv.org/abs/2404.11614) (HKUST)
- [ ] [\[2404.11615\] Factorized Diffusion: Perceptual Illusions by Noise Decomposition](https://arxiv.org/abs/2404.11615) (University of Michigan)
- [ ] [\[2404.11669\] Factorized Motion Fields for Fast Sparse Input Dynamic View Synthesis](https://arxiv.org/abs/2404.11669) (SIGGRAPH)
- [ ] [\[2404.11732\] Visual Prompting for Generalized Few-shot Segmentation: A Multi-scale Approach](https://arxiv.org/abs/2404.11732) (CVPR)
- [ ] [\[2404.11778\] CU-Mamba: Selective State Space Models with Channel Learning for Image Restoration](https://arxiv.org/abs/2404.11778) (Stanford)
- [ ] [\[2404.11798\] Establishing a Baseline for Gaze-driven Authentication Performance in VR: A Breadth-First Investigation on a Very Large Dataset](https://arxiv.org/abs/2404.11798) (Meta)
- [ ] [\[2404.11864\] Progressive Multi-modal Conditional Prompt Tuning](https://arxiv.org/abs/2404.11864) (USTC)
- [ ] [\[2404.11871\] Group-On: Boosting One-Shot Segmentation with Supportive Query](https://arxiv.org/abs/2404.11871) (ZJU)
- [ ] [\[2404.11884\] Seeing Motion at Nighttime with an Event Camera](https://arxiv.org/abs/2404.11884) (BIT, CVPR)
- [ ] [\[2404.11895\] FreeDiff: Progressive Frequency Truncation for Image Editing with Diffusion Models](https://arxiv.org/abs/2404.11895) (Xidian, ECCV)
- [ ] [\[2404.11903\] Simultaneous Detection and Interaction Reasoning for Object-Centric Action Recognition](https://arxiv.org/abs/2404.11903) (NUS)
- [ ] [\[2404.11957\] The devil is in the object boundary: towards annotation-free instance segmentation using Foundation Models](https://arxiv.org/abs/2404.11957) (ICLR)
- [ ] [\[2404.11958\] Not All Voxels Are Equal: Hardness-Aware Semantic Scene Completion with Self-Distillation](https://arxiv.org/abs/2404.11958) (CVPR)
- [ ] [\[2404.11979\] MTGA: Multi-view Temporal Granularity aligned Aggregation for Event-based Lip-reading](https://arxiv.org/abs/2404.11979) (WHU)
- [ ] [\[2404.11998\] Curriculum Point Prompting for Weakly-Supervised Referring Image Segmentation](https://arxiv.org/abs/2404.11998) (CVPR)
- [ ] [\[2404.12104\] Ethical-Lens: Curbing Malicious Usages of Open-Source Text-to-Image Models](https://arxiv.org/abs/2404.12104) (NYU)
- [ ] [\[2404.12142\] SDIP: Self-Reinforcement Deep Image Prior Framework for Image Processing](https://arxiv.org/abs/2404.12142) (NYU)
- [ ] [\[2404.12168\] Real-World Efficient Blind Motion Deblurring via Blur Pixel Discretization](https://arxiv.org/abs/2404.12168) (CVPR)
- [ ] [\[2404.12235\] Beyond Average: Individualized Visual Scanpath Prediction](https://arxiv.org/abs/2404.12235) (CVPR)
- [ ] [\[2404.12322\] Generalizable Face Landmarking Guided by Conditional Face Warping](https://arxiv.org/abs/2404.12322) (CVPR)
- [ ] [\[2404.12352\] Point-In-Context: Understanding Point Cloud via In-Context Learning](https://arxiv.org/abs/2404.12352) (SYSU)
- [ ] [\[2404.12368\] Gradient-Regularized Out-of-Distribution Detection](https://arxiv.org/abs/2404.12368) (ECCV)
- [ ] [\[2404.12372\] MedThink: Explaining Medical Visual Question Answering via Multimodal Decision-Making Rationale](https://arxiv.org/abs/2404.12372) (ZJU)
- [ ] [\[2404.12383\] G-HOP: Generative Hand-Object Prior for Interaction Reconstruction and Grasp Synthesis](https://arxiv.org/abs/2404.12383) (CVPR)
- [ ] [\[2404.12386\] SOHES: Self-supervised Open-world Hierarchical Entity Segmentation](https://arxiv.org/abs/2404.12386) (ICLR)
- [ ] [\[2404.12390\] BLINK: Multimodal Large Language Models Can See but Not Perceive](https://arxiv.org/abs/2404.12390) (UW, ECCV)
- [ ] [\[2404.12391\] On the Content Bias in Fr\'echet Video Distance](https://arxiv.org/abs/2404.12391) (CVPR)
- [ ] [\[2404.12407\] TV100: A TV Series Dataset that Pre-Trained CLIP Has Not Seen](https://arxiv.org/abs/2404.12407) (NJU)
- [ ] [\[2404.12467\] Towards Multi-modal Transformers in Federated Learning](https://arxiv.org/abs/2404.12467) (ECCV)
- [ ] [\[2404.12524\] DoughNet: A Visual Predictive Model for Topological Manipulation of Deformable Objects](https://arxiv.org/abs/2404.12524) (Columbia University)
- [ ] [\[2404.12538\] TrACT: A Training Dynamics Aware Contrastive Learning Framework for Long-tail Trajectory Prediction](https://arxiv.org/abs/2404.12538) (University of Toronto)
- [ ] [\[2404.12678\] Exploring Interactive Semantic Alignment for Efficient HOI Detection with Vision-language Model](https://arxiv.org/abs/2404.12678) (SJTU)
- [ ] [\[2404.12693\] Improving Chinese Character Representation with Formation Tree](https://arxiv.org/abs/2404.12693) (Xiamen)
- [ ] [\[2404.12720\] PDF-MVQA: A Dataset for Multimodal Information Retrieval in PDF-based Visual Question Answering](https://arxiv.org/abs/2404.12720) (USyd)
- [ ] [\[2404.12734\] DLoRA-TrOCR: Mixed Text Mode Optical Character Recognition Based On Transformer](https://arxiv.org/abs/2404.12734) (WHU)
- [ ] [\[2404.12768\] MixLight: Borrowing the Best of both Spherical Harmonics and Gaussian Models](https://arxiv.org/abs/2404.12768) (BIT)
- [ ] [\[2404.12782\] Sentiment-oriented Transformer-based Variational Autoencoder Network for Live Video Commenting](https://arxiv.org/abs/2404.12782) (USTC)
- [ ] [\[2404.12794\] MambaMOS: LiDAR-based 3D Moving Object Segmentation with Motion-aware State Space Model](https://arxiv.org/abs/2404.12794) (ZJU, ACMMM)
- [ ] [\[2404.12804\] Linearly-evolved Transformer for Pan-sharpening](https://arxiv.org/abs/2404.12804) (USTC)
- [ ] [\[2404.12856\] Language-Driven Active Learning for Diverse Open-Set 3D Object Detection](https://arxiv.org/abs/2404.12856) (UCSD)
- [ ] [\[2404.12886\] MCM: Multi-condition Motion Synthesis Framework](https://arxiv.org/abs/2404.12886) (ZJU)
- [ ] [\[2404.12887\] 3D Multi-frame Fusion for Video Stabilization](https://arxiv.org/abs/2404.12887) (CVPR)
- [ ] [\[2404.12920\] Zero-Shot Medical Phrase Grounding with Off-the-shelf Diffusion Models](https://arxiv.org/abs/2404.12920) (University of Edinburgh)
- [ ] [\[2404.12966\] Eyes Can Deceive: Benchmarking Counterfactual Reasoning Abilities of Multi-modal Large Language Models](https://arxiv.org/abs/2404.12966) (Fudan)
- [ ] [\[2404.13039\] LaPA: Latent Prompt Assist Model For Medical Visual Question Answering](https://arxiv.org/abs/2404.13039) (USyd)
- [ ] [\[2404.13159\] Equivariant Imaging for Self-supervised Hyperspectral Image Inpainting](https://arxiv.org/abs/2404.13159) (University of Edinburgh)
- [ ] [\[2404.13282\] Wills Aligner: A Robust Multi-Subject Brain Representation Learner](https://arxiv.org/abs/2404.13282) (Tongji)
- [ ] [\[2404.13299\] PCQA: A Strong Baseline for AIGC Quality Assessment Based on Prompt Condition](https://arxiv.org/abs/2404.13299) (Tongji)
- [ ] [\[2404.13306\] FakeBench: Probing Explainable Fake Image Detection via Large Multimodal Models](https://arxiv.org/abs/2404.13306) (NTU)
- [ ] [\[2404.13320\] Pixel is a Barrier: Diffusion Models Are More Adversarially Robust Than We Think](https://arxiv.org/abs/2404.13320) (GIT)
- [ ] [\[2404.13342\] Hyperspectral Anomaly Detection with Self-Supervised Anomaly Prior](https://arxiv.org/abs/2404.13342) (Xidian)
- [ ] [\[2404.13353\] Generating Daylight-driven Architectural Design via Diffusion Models](https://arxiv.org/abs/2404.13353) (Tsinghua)
- [ ] [\[2404.13400\] HiVG: Hierarchical Multimodal Fine-grained Modulation for Visual Grounding](https://arxiv.org/abs/2404.13400) (ACMMM)
- [ ] [\[2404.13408\] AMMUNet: Multi-Scale Attention Map Merging for Remote Sensing Image Segmentation](https://arxiv.org/abs/2404.13408) (WHU)
- [ ] [\[2404.13420\] NeurCADRecon: Neural Representation for Reconstructing CAD Surfaces by Enforcing Zero Gaussian Curvature](https://arxiv.org/abs/2404.13420) (SIGGRAPH)
- [ ] [\[2404.13434\] Nested-TNT: Hierarchical Vision Transformers with Multi-Scale Feature Processing](https://arxiv.org/abs/2404.13434) (NTU)
- [ ] [\[2404.13449\] SiNC+: Adaptive Camera-Based Vitals with Unsupervised Learning of Periodic Signals](https://arxiv.org/abs/2404.13449) (CVPR)
- [ ] [\[2404.13541\] Generalizable Novel-View Synthesis using a Stereo Camera](https://arxiv.org/abs/2404.13541) (CVPR)
- [ ] [\[2404.13558\] LASER: Tuning-Free LLM-Driven Attention Control for Efficient Text-conditioned Image-to-Animation](https://arxiv.org/abs/2404.13558) (ZJU)
- [ ] [\[2404.13565\] Exploring Diverse Methods in Visual Question Answering](https://arxiv.org/abs/2404.13565) (University of Michigan)
- [ ] [\[2404.13573\] Exploring AIGC Video Quality: A Focus on Visual Harmony, Video-Text Consistency and Domain Distribution Gap](https://arxiv.org/abs/2404.13573) (Peking)
- [ ] [\[2404.13576\] I2CANSAY:Inter-Class Analogical Augmentation and Intra-Class Significance Analysis for Non-Exemplar Online Task-Free Continual Learning](https://arxiv.org/abs/2404.13576) (XJTU)
- [ ] [\[2404.13605\] Turb-Seg-Res: A Segment-then-Restore Pipeline for Dynamic Videos with Atmospheric Turbulence](https://arxiv.org/abs/2404.13605) (CVPR)
- [ ] [\[2404.13648\] Data-independent Module-aware Pruning for Hierarchical Vision Transformers](https://arxiv.org/abs/2404.13648) (ICLR)
- [ ] [\[2404.13657\] MLP: Motion Label Prior for Temporal Sentence Localization in Untrimmed 3D Human Motions](https://arxiv.org/abs/2404.13657) (Peking)
- [ ] [\[2404.13671\] FiLo: Zero-Shot Anomaly Detection by Fine-Grained Description and High-Quality Localization](https://arxiv.org/abs/2404.13671) (ACMMM)
- [ ] [\[2404.13692\] A sustainable development perspective on urban-scale roof greening priorities and benefits](https://arxiv.org/abs/2404.13692) (PolyU)
- [ ] [\[2404.13791\] Universal Fingerprint Generation: Controllable Diffusion Model with Multimodal Conditions](https://arxiv.org/abs/2404.13791) (Michigan State University)
- [ ] [\[2404.13798\] Enforcing Conditional Independence for Fair Representation Learning and Causal Image Generation](https://arxiv.org/abs/2404.13798) (Stanford)
- [ ] [\[2404.13807\] FaceFolds: Meshed Radiance Manifolds for Efficient Volumetric Rendering of Dynamic Faces](https://arxiv.org/abs/2404.13807) (MIT)
- [ ] [\[2404.13816\] Neural Radiance Field in Autonomous Driving: A Survey](https://arxiv.org/abs/2404.13816) (Tsinghua)
- [ ] [\[2404.13830\] A Comprehensive Survey and Taxonomy on Point Cloud Registration Based on Deep Learning](https://arxiv.org/abs/2404.13830) (HUST)
- [ ] [\[2404.13838\] C2F-SemiCD: A Coarse-to-Fine Semi-Supervised Change Detection Method Based on Consistency Regularization in High-Resolution Remote Sensing Images](https://arxiv.org/abs/2404.13838) (WHU)
- [ ] [\[2404.13842\] On Support Relations Inference and Scene Hierarchy Graph Construction from Point Cloud in Clustered Environments](https://arxiv.org/abs/2404.13842) (Fudan)
- [ ] [\[2404.13859\] Unveiling and Mitigating Generalized Biases of DNNs through the Intrinsic Dimensions of Perceptual Manifolds](https://arxiv.org/abs/2404.13859) (Xidian, TPAMI)
- [ ] [\[2404.13862\] PGAHum: Prior-Guided Geometry and Appearance Learning for High-Fidelity Animatable Human Reconstruction](https://arxiv.org/abs/2404.13862) (NTU)
- [ ] [\[2404.13880\] Regional Style and Color Transfer](https://arxiv.org/abs/2404.13880) (Columbia University, ICCV)
- [ ] [\[2404.13896\] CT-NeRF: Incremental Optimizing Neural Radiance Field and Poses with Complex Trajectory](https://arxiv.org/abs/2404.13896) (ZJU)
- [ ] [\[2404.13911\] GlobalBuildingMap -- Unveiling the Mystery of Global Buildings](https://arxiv.org/abs/2404.13911) (TUM)
- [ ] [\[2404.13953\] 360VOTS: Visual Object Tracking and Segmentation in Omnidirectional Videos](https://arxiv.org/abs/2404.13953) (HKUST)
- [ ] [\[2404.13984\] RHanDS: Refining Malformed Hands for Generated Images with Decoupled Structure and Style Guidance](https://arxiv.org/abs/2404.13984) (Alibaba)
- [ ] [\[2404.13992\] Dynamic Proxy Domain Generalizes the Crowd Localization by Better Binary Segmentation](https://arxiv.org/abs/2404.13992) (NWPU)
- [ ] [\[2404.14007\] Infusion: Preventing Customized Text-to-Image Diffusion from Overfitting](https://arxiv.org/abs/2404.14007) (SJTU)
- [ ] [\[2404.14025\] DHRNet: A Dual-Path Hierarchical Relation Network for Multi-Person Pose Estimation](https://arxiv.org/abs/2404.14025) (BUPT)
- [ ] [\[2404.14037\] GaussianTalker: Speaker-specific Talking Head Synthesis via 3D Gaussian Splatting](https://arxiv.org/abs/2404.14037) (Alibaba, ACMMM)
- [ ] [\[2404.14040\] Surgical-DeSAM: Decoupling SAM for Instrument Segmentation in Robotic Surgery](https://arxiv.org/abs/2404.14040) (UCL)
- [ ] [\[2404.14042\] CloudFort: Enhancing Robustness of 3D Point Cloud Classification Against Backdoor Attacks via Spatial Partitioning and Ensemble Prediction](https://arxiv.org/abs/2404.14042) (CUHK)
- [ ] [\[2404.14044\] HashPoint: Accelerated Point Searching and Sampling for Neural Rendering](https://arxiv.org/abs/2404.14044) (CVPR)
- [ ] [\[2404.14055\] RingID: Rethinking Tree-Ring Watermarking for Enhanced Multi-Key Identification](https://arxiv.org/abs/2404.14055) (NUS)
- [ ] [\[2404.14109\] CKD: Contrastive Knowledge Distillation from A Sample-wise Perspective](https://arxiv.org/abs/2404.14109) (Tianjin)
- [ ] [\[2404.14162\] FLDM-VTON: Faithful Latent Diffusion Model for Virtual Try-on](https://arxiv.org/abs/2404.14162) (Fudan)
- [ ] [\[2404.14177\] Face2Face: Label-driven Facial Retouching Restoration](https://arxiv.org/abs/2404.14177) (Peking)
- [ ] [\[2404.14198\] BCFPL: Binary classification ConvNet based Fast Parking space recognition with Low resolution image](https://arxiv.org/abs/2404.14198) (Tianjin)
- [ ] [\[2404.14233\] Detecting and Mitigating Hallucination in Large Vision Language Models via Fine-Grained AI Feedback](https://arxiv.org/abs/2404.14233) (ZJU)
- [ ] [\[2404.14241\] UrbanCross: Enhancing Satellite Image-Text Retrieval with Cross-Domain Adaptation](https://arxiv.org/abs/2404.14241) (NWPU)
- [ ] [\[2404.14309\] Towards Better Adversarial Purification via Adversarial Denoising Diffusion Training](https://arxiv.org/abs/2404.14309) (SYSU)
- [ ] [\[2404.14329\] X-Ray: A Sequential 3D Representation For Generation](https://arxiv.org/abs/2404.14329) (NUS)
- [ ] [\[2404.14349\] Automatic Discovery of Visual Circuits](https://arxiv.org/abs/2404.14349) (MIT)
- [ ] [\[2404.14351\] Scene Coordinate Reconstruction: Posing of Image Collections via Incremental Learning of a Relocalizer](https://arxiv.org/abs/2404.14351) (ECCV)
- [ ] [\[2404.14368\] Graphic Design with Large Multimodal Model](https://arxiv.org/abs/2404.14368) (Nankai)
- [ ] [\[2404.14409\] CrossScore: Towards Multi-View Image Evaluation and Scoring](https://arxiv.org/abs/2404.14409) (ECCV)
- [ ] [\[2404.14412\] AutoAD III: The Prequel -- Back to the Pixels](https://arxiv.org/abs/2404.14412) (CVPR)
- [ ] [\[2404.14435\] FreSeg: Frenet-Frame-based Part Segmentation for 3D Curvilinear Structures](https://arxiv.org/abs/2404.14435) (Harvard)
- [ ] [\[2404.14441\] Optimizing Contrail Detection: A Deep Learning Approach with EfficientNet-b4 Encoding](https://arxiv.org/abs/2404.14441) (Columbia University)
- [ ] [\[2404.14471\] Narrative Action Evaluation with Prompt-Guided Multimodal Interaction](https://arxiv.org/abs/2404.14471) (CVPR)
- [ ] [\[2404.14542\] UVEB: A Large-scale Benchmark and Baseline Towards Real-World Underwater Video Enhancement](https://arxiv.org/abs/2404.14542) (CVPR)
- [ ] [\[2404.14560\] Adaptive Local Binary Pattern: A Novel Feature Descriptor for Enhanced Analysis of Kidney Abnormalities in CT Scan Images using ensemble based Machine Learning Approach](https://arxiv.org/abs/2404.14560) (University of Alberta)
- [ ] [\[2404.14568\] UVMap-ID: A Controllable and Personalized UV Map Generative Model](https://arxiv.org/abs/2404.14568) (ACMMM)
- [ ] [\[2404.14606\] Cross-Task Multi-Branch Vision Transformer for Facial Expression and Mask Wearing Classification](https://arxiv.org/abs/2404.14606) (CMU)
- [ ] [\[2404.14634\] UPose3D: Uncertainty-Aware 3D Human Pose Estimation with Cross-View and Temporal Cues](https://arxiv.org/abs/2404.14634) (ECCV)
- [ ] [\[2404.14676\] DreamPBR: Text-driven Generation of High-resolution SVBRDF with Multi-modal Guidance](https://arxiv.org/abs/2404.14676) (Tsinghua)
- [ ] [\[2404.14678\] 3DBench: A Scalable 3D Benchmark and Instruction-Tuning Dataset](https://arxiv.org/abs/2404.14678) (Shanghai AI Lab)
- [ ] [\[2404.14704\] Unsupervised Domain Adaptation Architecture Search with Self-Training for Land Cover Mapping](https://arxiv.org/abs/2404.14704) (University of Tokyo)
- [ ] [\[2404.14709\] SC-HVPPNet: Spatial and Channel Hybrid-Attention Video Post-Processing Network with CNN and Transformer](https://arxiv.org/abs/2404.14709) (HIT)
- [ ] [\[2404.14715\] FINEMATCH: Aspect-based Fine-grained Image and Text Mismatch Detection and Correction](https://arxiv.org/abs/2404.14715) (ECCV)
- [ ] [\[2404.14808\] Visual-Augmented Dynamic Semantic Prototype for Generative Zero-Shot Learning](https://arxiv.org/abs/2404.14808) (HUST)
- [ ] [\[2404.14852\] Ultrasound Nodule Segmentation Using Asymmetric Learning with Simple Clinical Annotation](https://arxiv.org/abs/2404.14852) (XJTU)
- [ ] [\[2404.14906\] Driver Activity Classification Using Generalizable Representations from Vision-Language Models](https://arxiv.org/abs/2404.14906) (UCSD)
- [ ] [\[2404.14908\] Mining Supervision for Dynamic Regions in Self-Supervised Monocular Depth Estimation](https://arxiv.org/abs/2404.14908) (NVIDIA, CVPR)
- [ ] [\[2404.14949\] Multi-Modal Prompt Learning on Blind Image Quality Assessment](https://arxiv.org/abs/2404.14949) (Xiamen)
- [ ] [\[2404.14952\] Leveraging Speech for Gesture Detection in Multimodal Communication](https://arxiv.org/abs/2404.14952) (UVA.NL)
- [ ] [\[2404.14966\] Mamba3D: Enhancing Local Features for 3D Point Cloud Analysis via State Space Model](https://arxiv.org/abs/2404.14966) (HUST, ACMMM)
- [ ] [\[2404.15033\] IPAD: Industrial Process Anomaly Detection Dataset](https://arxiv.org/abs/2404.15033) (SJTU)
- [ ] [\[2404.15081\] Perturbing Attention Gives You More Bang for the Buck: Subtle Imaging Perturbations That Efficiently Fool Customized Diffusion Models](https://arxiv.org/abs/2404.15081) (CVPR)
- [ ] [\[2404.15127\] MedDr: Diagnosis-Guided Bootstrapping for Large-Scale Medical Vision-Language Learning](https://arxiv.org/abs/2404.15127) (HKUST)
- [ ] [\[2404.15141\] CutDiffusion: A Simple, Fast, Cheap, and Strong Diffusion Extrapolation Method](https://arxiv.org/abs/2404.15141) (Xiamen)
- [ ] [\[2404.15174\] Fourier-enhanced Implicit Neural Fusion Network for Multispectral and Hyperspectral Image Fusion](https://arxiv.org/abs/2404.15174) (UESTC)
- [ ] [\[2404.15228\] Re-Thinking Inverse Graphics With Large Language Models](https://arxiv.org/abs/2404.15228) (MPI)
- [ ] [\[2404.15254\] UniMERNet: A Universal Network for Real-World Mathematical Expression Recognition](https://arxiv.org/abs/2404.15254) (Shanghai AI Lab)
- [ ] [\[2404.15263\] Multi-Session SLAM with Differentiable Wide-Baseline Pose Optimization](https://arxiv.org/abs/2404.15263) (Princeton, CVPR)
- [ ] [\[2404.15264\] TalkingGaussian: Structure-Persistent 3D Talking Head Synthesis via Gaussian Splatting](https://arxiv.org/abs/2404.15264) (ECCV)
- [ ] [\[2404.15272\] CT-GLIP: 3D Grounded Language-Image Pretraining with CT Scans and Radiology Reports for Full-Body Scenarios](https://arxiv.org/abs/2404.15272) (Alibaba)
- [ ] [\[2404.15276\] SMPLer: Taming Transformers for Monocular 3D Human Shape and Pose Estimation](https://arxiv.org/abs/2404.15276) (TPAMI)
- [ ] [\[2404.15436\] Iterative Cluster Harvesting for Wafer Map Defect Patterns](https://arxiv.org/abs/2404.15436) (Bosch)
- [ ] [\[2404.15449\] ID-Aligner: Enhancing Identity-Preserving Text-to-Image Generation with Reward Feedback Learning](https://arxiv.org/abs/2404.15449) (SYSU)
- [ ] [\[2404.15506\] Metric3D v2: A Versatile Monocular Geometric Foundation Model for Zero-shot Metric Depth and Surface Normal Estimation](https://arxiv.org/abs/2404.15506) (HKU, TPAMI)
- [ ] [\[2404.15580\] MiM: Mask in Mask Self-Supervised Pre-Training for 3D Medical Image Analysis](https://arxiv.org/abs/2404.15580) (HKUST)
- [ ] [\[2404.15592\] ImplicitAVE: An Open-Source Dataset and Multimodal LLMs Benchmark for Implicit Attribute Value Extraction](https://arxiv.org/abs/2404.15592) (CMU)
- [ ] [\[2404.15638\] PriorNet: A Novel Lightweight Network with Multidimensional Interactive Attention for Efficient Image Dehazing](https://arxiv.org/abs/2404.15638) (USTC)
- [ ] [\[2404.15655\] Multi-Modal Proxy Learning Towards Personalized Visual Multiple Clustering](https://arxiv.org/abs/2404.15655) (Alibaba, CVPR)
- [ ] [\[2404.15672\] Representing Part-Whole Hierarchies in Foundation Models by Learning Localizability, Composability, and Decomposability from Anatomy via Self-Supervision](https://arxiv.org/abs/2404.15672) (CVPR)
- [ ] [\[2404.15677\] CharacterFactory: Sampling Consistent Characters with GANs for Diffusion Models](https://arxiv.org/abs/2404.15677) (Tianjin)
- [ ] [\[2404.15700\] MAS-SAM: Segment Any Marine Animal with Aggregated Features](https://arxiv.org/abs/2404.15700) (CMU)
- [ ] [\[2404.15707\] ESR-NeRF: Emissive Source Reconstruction Using LDR Multi-view Images](https://arxiv.org/abs/2404.15707) (CVPR)
- [ ] [\[2404.15719\] HDBN: A Novel Hybrid Dual-branch Network for Robust Skeleton-based Action Recognition](https://arxiv.org/abs/2404.15719) (Peking)
- [ ] [\[2404.15721\] SPARO: Selective Attention for Robust and Compositional Transformer Encodings for Vision](https://arxiv.org/abs/2404.15721) (University of Montreal)
- [ ] [\[2404.15734\] ODMixer: Fine-grained Spatial-temporal MLP for Metro Origin-Destination Prediction](https://arxiv.org/abs/2404.15734) (SYSU)
- [ ] [\[2404.15770\] ChEX: Interactive Localization and Region Description in Chest X-rays](https://arxiv.org/abs/2404.15770) (ECCV)
- [ ] [\[2404.15771\] DVF: Advancing Robust and Accurate Fine-Grained Image Retrieval with Retrieval Guidelines](https://arxiv.org/abs/2404.15771) (NJU)
- [ ] [\[2404.15789\] MotionMaster: Training-free Camera Motion Transfer For Video Generation](https://arxiv.org/abs/2404.15789) (HIT)
- [ ] [\[2404.15802\] Raformer: Redundancy-Aware Transformer for Video Wire Inpainting](https://arxiv.org/abs/2404.15802) (Tianjin)
- [ ] [\[2404.15879\] Revisiting Out-of-Distribution Detection in LiDAR-based 3D Object Detection](https://arxiv.org/abs/2404.15879) (Bosch)
- [ ] [\[2404.15882\] Unexplored Faces of Robustness and Out-of-Distribution: Covariate Shifts in Environment and Sensor Domains](https://arxiv.org/abs/2404.15882) (CVPR)
- [ ] [\[2404.15889\] Sketch2Human: Deep Human Generation with Disentangled Geometry and Appearance Control](https://arxiv.org/abs/2404.15889) (HKUST)
- [ ] [\[2404.15891\] OMEGAS: Object Mesh Extraction from Large Scenes Guided by Gaussian Segmentation](https://arxiv.org/abs/2404.15891) (BUPT)
- [ ] [\[2404.15956\] A Survey on Visual Mamba](https://arxiv.org/abs/2404.15956) (USTC)
- [ ] [\[2404.16006\] MMT-Bench: A Comprehensive Multimodal Benchmark for Evaluating Large Vision-Language Models Towards Multitask AGI](https://arxiv.org/abs/2404.16006) (Shanghai AI Lab)
- [ ] [\[2404.16030\] MoDE: CLIP Data Experts via Clustering](https://arxiv.org/abs/2404.16030) (CVPR)
- [ ] [\[2404.16033\] Cantor: Inspiring Multimodal Chain-of-Thought of MLLM](https://arxiv.org/abs/2404.16033) (Xiamen)
- [ ] [\[2404.16035\] MaGGIe: Masked Guided Gradual Human Instance Matting](https://arxiv.org/abs/2404.16035) (CVPR)
- [ ] [\[2404.16123\] FairDeDup: Detecting and Mitigating Vision-Language Fairness Disparities in Semantic Dataset Deduplication](https://arxiv.org/abs/2404.16123) (CVPR)
- [ ] [\[2404.16222\] Step Differences in Instructional Video](https://arxiv.org/abs/2404.16222) (CVPR)
- [ ] [\[2404.16304\] BezierFormer: A Unified Architecture for 2D and 3D Lane Detection](https://arxiv.org/abs/2404.16304) (UW)
- [ ] [\[2404.16306\] TI2V-Zero: Zero-Shot Image Conditioning for Text-to-Video Diffusion Models](https://arxiv.org/abs/2404.16306) (CVPR)
- [ ] [\[2404.16339\] Training-Free Unsupervised Prompt for Vision-Language Models](https://arxiv.org/abs/2404.16339) (USyd)
- [ ] [\[2404.16348\] Dual Expert Distillation Network for Generalized Zero-Shot Learning](https://arxiv.org/abs/2404.16348) (PolyU)
- [ ] [\[2404.16386\] Promoting CNNs with Cross-Architecture Knowledge Distillation for Efficient Monocular Depth Estimation](https://arxiv.org/abs/2404.16386) (ZJU)
- [ ] [\[2404.16416\] Learning Discriminative Spatio-temporal Representations for Semi-supervised Action Recognition](https://arxiv.org/abs/2404.16416) (XJTU)
- [ ] [\[2404.16422\] Robust Fine-tuning for Pre-trained 3D Point Cloud Models](https://arxiv.org/abs/2404.16422) (Fudan)
- [ ] [\[2404.16423\] Neural Assembler: Learning to Generate Fine-Grained Robotic Assembly Instructions from Multi-View Images](https://arxiv.org/abs/2404.16423) (Peking)
- [ ] [\[2404.16451\] Latent Modulated Function for Computational Optimal Continuous Image Representation](https://arxiv.org/abs/2404.16451) (SYSU)
- [ ] [\[2404.16452\] PAD: Patch-Agnostic Defense against Adversarial Patch Attacks](https://arxiv.org/abs/2404.16452) (SYSU, CVPR)
- [ ] [\[2404.16456\] Correlation-Decoupled Knowledge Distillation for Multimodal Sentiment Analysis with Incomplete Modalities](https://arxiv.org/abs/2404.16456) (Fudan, CVPR)
- [ ] [\[2404.16474\] DiffSeg: A Segmentation Model for Skin Lesions Based on Diffusion Difference](https://arxiv.org/abs/2404.16474) (Chongqing)
- [ ] [\[2404.16493\] Commonsense Prototype for Outdoor Unsupervised 3D Object Detection](https://arxiv.org/abs/2404.16493) (CVPR)
- [ ] [\[2404.16501\] 360SFUDA++: Towards Source-free UDA for Panoramic Segmentation by Learning Reliable Category Prototypes](https://arxiv.org/abs/2404.16501) (HKUST)
- [ ] [\[2404.16552\] Efficient Solution of Point-Line Absolute Pose](https://arxiv.org/abs/2404.16552) (CVPR)
- [ ] [\[2404.16557\] Energy-Latency Manipulation of Multi-modal Large Language Models via Verbose Samples](https://arxiv.org/abs/2404.16557) (Tsinghua)
- [ ] [\[2404.16571\] MonoPCC: Photometric-invariant Cycle Constraint for Monocular Depth Estimation of Endoscopic Images](https://arxiv.org/abs/2404.16571) (HUST)
- [ ] [\[2404.16573\] Multi-Scale Representations by Varying Window Attention for Semantic Segmentation](https://arxiv.org/abs/2404.16573) (ICLR)
- [ ] [\[2404.16609\] SFMViT: SlowFast Meet ViT in Chaotic World](https://arxiv.org/abs/2404.16609) (Peking)
- [ ] [\[2404.16622\] DAVE -- A Detect-and-Verify Paradigm for Low-Shot Counting](https://arxiv.org/abs/2404.16622) (CVPR)
- [ ] [\[2404.16635\] TinyChart: Efficient Chart Understanding with Visual Token Merging and Program-of-Thoughts Learning](https://arxiv.org/abs/2404.16635) (Alibaba)
- [ ] [\[2404.16670\] EmoVIT: Revolutionizing Emotion Insights with Visual Instruction Tuning](https://arxiv.org/abs/2404.16670) (CVPR)
- [ ] [\[2404.16752\] TokenHMR: Advancing Human Mesh Recovery with a Tokenized Pose Representation](https://arxiv.org/abs/2404.16752) (CVPR)
- [ ] [\[2404.16781\] Registration by Regression (RbR): a framework for interpretable and flexible atlas registration](https://arxiv.org/abs/2404.16781) (Harvard)
- [ ] [\[2404.16821\] How Far Are We to GPT-4V? Closing the Gap to Commercial Multimodal Models with Open-Source Suites](https://arxiv.org/abs/2404.16821) (Shanghai AI Lab)
- [ ] [\[2404.16824\] V2A-Mark: Versatile Deep Visual-Audio Watermarking for Manipulation Localization and Copyright Protection](https://arxiv.org/abs/2404.16824) (ACMMM)
- [ ] [\[2404.16825\] ResVR: Joint Rescaling and Viewport Rendering of Omnidirectional Images](https://arxiv.org/abs/2404.16825) (Peking)
- [ ] [\[2404.16828\] Made to Order: Discovering monotonic temporal changes via self-supervised video ordering](https://arxiv.org/abs/2404.16828) (ECCV)
- [ ] [\[2404.16882\] ThermoPore: Predicting Part Porosity Based on Thermal Images Using Deep Learning](https://arxiv.org/abs/2404.16882) (CMU)
- [ ] [\[2404.16885\] Adapting an Artificial Intelligence Sexually Transmitted Diseases Symptom Checker Tool for Mpox Detection: The HeHealth Experience](https://arxiv.org/abs/2404.16885) (NUS)
- [ ] [\[2404.16944\] Constellation Dataset: Benchmarking High-Altitude Object Detection for an Urban Intersection](https://arxiv.org/abs/2404.16944) (Columbia University)
- [ ] [\[2404.17033\] Auto-Generating Weak Labels for Real & Synthetic Data to Improve Label-Scarce Medical Image Segmentation](https://arxiv.org/abs/2404.17033) (Stanford)
- [ ] [\[2404.17092\] Defending Spiking Neural Networks against Adversarial Attacks through Image Purification](https://arxiv.org/abs/2404.17092) (USTC)
- [ ] [\[2404.17100\] Open-Set Video-based Facial Expression Recognition with Human Expression-sensitive Prompting](https://arxiv.org/abs/2404.17100) (ACMMM)
- [ ] [\[2404.17105\] Synthesizing Iris Images using Generative Adversarial Networks: Survey and Comparative Analysis](https://arxiv.org/abs/2404.17105) (Michigan State University)
- [ ] [\[2404.17159\] Phase-aggregated Dual-branch Network for Efficient Fingerprint Dense Registration](https://arxiv.org/abs/2404.17159) (Tsinghua)
- [ ] [\[2404.17173\] Exploring Beyond Logits: Hierarchical Dynamic Labeling Based on Embeddings for Semi-Supervised Classification](https://arxiv.org/abs/2404.17173) (Xidian)
- [ ] [\[2404.17184\] Low-Rank Knowledge Decomposition for Medical Foundation Models](https://arxiv.org/abs/2404.17184) (CVPR)
- [ ] [\[2404.17186\] MCSDNet: Mesoscale Convective System Detection Network via Multi-scale Spatiotemporal Information](https://arxiv.org/abs/2404.17186) (HIT)
- [ ] [\[2404.17202\] Self-supervised visual learning in the low-data regime: a comparative evaluation](https://arxiv.org/abs/2404.17202) (UVA.NL)
- [ ] [\[2404.17230\] ObjectAdd: Adding Objects into Image via a Training-Free Diffusion Modification Fashion](https://arxiv.org/abs/2404.17230) (Xiamen)
- [ ] [\[2404.17273\] 3SHNet: Boosting Image-Sentence Retrieval via Visual Semantic-Spatial Self-Highlighting](https://arxiv.org/abs/2404.17273) (ZJU)
- [ ] [\[2404.17275\] Adversarial Reweighting with $\alpha$-Power Maximization for Domain Adaptation](https://arxiv.org/abs/2404.17275) (XJTU)
- [ ] [\[2404.17310\] Image Copy-Move Forgery Detection via Deep PatchMatch and Pairwise Ranking Learning](https://arxiv.org/abs/2404.17310) (BU)
- [ ] [\[2404.17340\] Masked Two-channel Decoupling Framework for Incomplete Multi-view Weak Multi-label Learning](https://arxiv.org/abs/2404.17340) (NIPS)
- [ ] [\[2404.17433\] PromptCIR: Blind Compressed Image Restoration with Prompt Learning](https://arxiv.org/abs/2404.17433) (USTC)
- [ ] [\[2404.17486\] TextGaze: Gaze-Controllable Face Generation with Natural Language](https://arxiv.org/abs/2404.17486) (ACMMM)
- [ ] [\[2404.17503\] Inhomogeneous illumination image enhancement under ex-tremely low visibility condition](https://arxiv.org/abs/2404.17503) (SYSU)
- [ ] [\[2404.17507\] HYPE: Hyperbolic Entailment Filtering for Underspecified Images and Texts](https://arxiv.org/abs/2404.17507) (ECCV)
- [ ] [\[2404.17528\] Geometry-aware Reconstruction and Fusion-refined Rendering for Generalizable Neural Radiance Fields](https://arxiv.org/abs/2404.17528) (CVPR)
- [ ] [\[2404.17569\] MaPa: Text-driven Photorealistic Material Painting for 3D Shapes](https://arxiv.org/abs/2404.17569) (SIGGRAPH)
- [ ] [\[2404.17610\] Regression of Dense Distortion Field from a Single Fingerprint Image](https://arxiv.org/abs/2404.17610) (Tsinghua)
- [ ] [\[2404.17747\] MMA-UNet: A Multi-Modal Asymmetric UNet Architecture for Infrared and Visible Image Fusion](https://arxiv.org/abs/2404.17747) (HKUST)
- [ ] [\[2404.17762\] Large Multi-modality Model Assisted AI-Generated Image Quality Assessment](https://arxiv.org/abs/2404.17762) (SJTU, ACMMM)
- [ ] [\[2404.17765\] RFL-CDNet: Towards Accurate Change Detection via Richer Feature Learning](https://arxiv.org/abs/2404.17765) (WHU)
- [ ] [\[2404.17774\] High-quality Surface Reconstruction using Gaussian Surfels](https://arxiv.org/abs/2404.17774) (ZJU)
- [ ] [\[2404.17825\] ODCR: Orthogonal Decoupling Contrastive Regularization for Unpaired Image Dehazing](https://arxiv.org/abs/2404.17825) (CVPR)
- [ ] [\[2404.17837\] Hybrid 3D Human Pose Estimation with Monocular Video and Sparse IMUs](https://arxiv.org/abs/2404.17837) (SJTU)
- [ ] [\[2404.17883\] Underwater Variable Zoom: Depth-Guided Perception Network for Underwater Image Enhancement](https://arxiv.org/abs/2404.17883) (BU)
- [ ] [\[2404.17929\] Spatio-Temporal Side Tuning Pre-trained Foundation Models for Video-based Pedestrian Attribute Recognition](https://arxiv.org/abs/2404.17929) (Peking)
- [ ] [\[2404.18060\] Prompt Customization for Continual Learning](https://arxiv.org/abs/2404.18060) (HIT, ACMMM)
- [ ] [\[2404.18062\] Compressed Image Captioning using CNN-based Encoder-Decoder Framework](https://arxiv.org/abs/2404.18062) (University of Alberta)
- [ ] [\[2404.18065\] Grounded Compositional and Diverse Text-to-3D with Pretrained Multi-View Diffusion Model](https://arxiv.org/abs/2404.18065) (AWS)
- [ ] [\[2404.18106\] Semi-supervised Text-based Person Search](https://arxiv.org/abs/2404.18106) (WHU)
- [ ] [\[2404.18109\] Finding Beautiful and Happy Images for Mental Health and Well-being Applications](https://arxiv.org/abs/2404.18109) (Imperial)
- [ ] [\[2404.18114\] Deep Boosting Learning: A Brand-new Cooperative Approach for Image-Text Matching](https://arxiv.org/abs/2404.18114) (TIP)
- [ ] [\[2404.18150\] RadSimReal: Bridging the Gap Between Synthetic and Real Data in Radar Object Detection With Simulation](https://arxiv.org/abs/2404.18150) (CVPR)
- [ ] [\[2404.18155\] ShapeMoir\'e: Channel-Wise Shape-Guided Network for Image Demoir\'eing](https://arxiv.org/abs/2404.18155) (NUS)
- [ ] [\[2404.18203\] LMM-PCQA: Assisting Point Cloud Quality Assessment with LMM](https://arxiv.org/abs/2404.18203) (SJTU)
- [ ] [\[2404.18213\] S$^2$Mamba: A Spatial-spectral State Space Model for Hyperspectral Image Classification](https://arxiv.org/abs/2404.18213) (Xidian)
- [ ] [\[2404.18260\] Align, Minimize and Diversify: A Source-Free Unsupervised Domain Adaptation Method for Handwritten Text Recognition](https://arxiv.org/abs/2404.18260) (ECCV)
- [ ] [\[2404.18316\] Position: Do Not Explain Vision Models Without Context](https://arxiv.org/abs/2404.18316) (ICML)
- [ ] [\[2404.18352\] Post-hoc and manifold explanations analysis of facial expression data based on deep learning](https://arxiv.org/abs/2404.18352) (Nankai)
- [ ] [\[2404.18394\] Reconstructing Satellites in 3D from Amateur Telescope Images](https://arxiv.org/abs/2404.18394) (Peking)
- [ ] [\[2404.18399\] Semantic Line Combination Detector](https://arxiv.org/abs/2404.18399) (CVPR)
- [ ] [\[2404.18401\] Spectral-Spatial Mamba for Hyperspectral Image Classification](https://arxiv.org/abs/2404.18401) (HIT)
- [ ] [\[2404.18409\] PKU-AIGIQA-4K: A Perceptual Quality Assessment Database for Both Text-to-Image and Image-to-Image AI-Generated Images](https://arxiv.org/abs/2404.18409) (Peking)
- [ ] [\[2404.18419\] Research on Intelligent Aided Diagnosis System of Medical Image Based on Computer Deep Learning](https://arxiv.org/abs/2404.18419) (CMU)
- [ ] [\[2404.18448\] MFP: Making Full Use of Probability Maps for Interactive Image Segmentation](https://arxiv.org/abs/2404.18448) (CVPR)
- [ ] [\[2404.18454\] 3D Gaussian Splatting with Deferred Reflection](https://arxiv.org/abs/2404.18454) (ZJU)
- [ ] [\[2404.18620\] FlexiFilm: Long Video Generation with Flexible Conditions](https://arxiv.org/abs/2404.18620) (ZJU)
- [ ] [\[2404.18630\] 4D-DRESS: A 4D Dataset of Real-world Human Clothing with Semantic Annotations](https://arxiv.org/abs/2404.18630) (CVPR)
- [ ] [\[2404.18648\] Uncertainty-boosted Robust Video Activity Anticipation](https://arxiv.org/abs/2404.18648) (HIT)
- [ ] [\[2404.18695\] Dual-Modal Prompting for Sketch-Based Image Retrieval](https://arxiv.org/abs/2404.18695) (NWPU)
- [ ] [\[2404.18758\] Transitive Vision-Language Prompt Learning for Domain Generalization](https://arxiv.org/abs/2404.18758) (Xiamen)
- [ ] [\[2404.18772\] Saliency Suppressed, Semantics Surfaced: Visual Transformations in Neural Networks and the Brain](https://arxiv.org/abs/2404.18772) (UVA.NL)
- [ ] [\[2404.18861\] Visual Mamba: A Survey and New Outlooks](https://arxiv.org/abs/2404.18861) (WHU)
- [ ] [\[2404.18873\] OpenStreetView-5M: The Many Roads to Global Visual Geolocation](https://arxiv.org/abs/2404.18873) (CVPR)
- [ ] [\[2404.18876\] A Multilevel Strategy to Improve People Tracking in a Real-World Scenario](https://arxiv.org/abs/2404.18876) (ICCV)
- [ ] [\[2404.18928\] Stylus: Automatic Adapter Selection for Diffusion Models](https://arxiv.org/abs/2404.18928) (Berkeley)
- [ ] [\[2404.18929\] DGE: Direct Gaussian 3D Editing by Consistent Multi-view Editing](https://arxiv.org/abs/2404.18929) (ECCV)
- [ ] [\[2404.18930\] Hallucination of Multimodal Large Language Models: A Survey](https://arxiv.org/abs/2404.18930) (AWS)
- [ ] [\[2404.18962\] An Aggregation-Free Federated Learning for Tackling Data Heterogeneity](https://arxiv.org/abs/2404.18962) (CVPR)
- [ ] [\[2404.19031\] Machine Unlearning for Document Classification](https://arxiv.org/abs/2404.19031) (Nankai)
- [ ] [\[2404.19040\] GSTalker: Real-time Audio-Driven Talking Face Generation via Deformable Gaussian Splatting](https://arxiv.org/abs/2404.19040) (SJTU)
- [ ] [\[2404.19108\] Real-Time Convolutional Neural Network-Based Star Detection and Centroiding Method for CubeSat Star Tracker](https://arxiv.org/abs/2404.19108) (Illinois)
- [ ] [\[2404.19134\] Evaluating Deep Clustering Algorithms on Non-Categorical 3D CAD Models](https://arxiv.org/abs/2404.19134) (NYU)
- [ ] [\[2404.19174\] XFeat: Accelerated Features for Lightweight Image Matching](https://arxiv.org/abs/2404.19174) (Google, CVPR)
- [ ] [\[2404.19204\] NeRF-Insert: 3D Local Editing with Multimodal Control Signals](https://arxiv.org/abs/2404.19204) (UCLA)
- [ ] [\[2404.19227\] Espresso: Robust Concept Filtering in Text-to-Image Models](https://arxiv.org/abs/2404.19227) (ZJU)
- [ ] [\[2404.19248\] Transition Rate Scheduling for Quantization-Aware Training](https://arxiv.org/abs/2404.19248) (TPAMI)
- [ ] [\[2404.19250\] Enhancing Intrinsic Features for Debiasing via Investigating Class-Discerning Common Attributes in Bias-Contrastive Pair](https://arxiv.org/abs/2404.19250) (CVPR)
- [ ] [\[2404.19277\] Bridge to Non-Barrier Communication: Gloss-Prompted Fine-grained Cued Speech Gesture Generation with Diffusion Model](https://arxiv.org/abs/2404.19277) (HKUST(GZ))
- [ ] [\[2404.19286\] Soft Prompt Generation for Domain Generalization](https://arxiv.org/abs/2404.19286) (XJTU, ECCV)
- [ ] [\[2404.19287\] Revisiting the Adversarial Robustness of Vision Language Models: a Multimodal Perspective](https://arxiv.org/abs/2404.19287) (XJTU)
- [ ] [\[2404.19289\] On Improving the Algorithm-, Model-, and Data- Efficiency of Self-Supervised Learning](https://arxiv.org/abs/2404.19289) (NJU)
- [ ] [\[2404.19299\] Robust Pedestrian Detection via Constructing Versatile Pedestrian Knowledge Bank](https://arxiv.org/abs/2404.19299) (KAIST)
- [ ] [\[2404.19326\] LVOS: A Benchmark for Large-scale Long-term Video Object Segmentation](https://arxiv.org/abs/2404.19326) (Fudan)
- [ ] [\[2404.19334\] Multi-Scale Heterogeneity-Aware Hypergraph Representation for Histopathology Whole Slide Images](https://arxiv.org/abs/2404.19334) (Fudan)
- [ ] [\[2404.19379\] SemanticFormer: Holistic and Semantic Traffic Scene Representation for Trajectory Prediction using Knowledge Graphs](https://arxiv.org/abs/2404.19379) (Bosch)
- [ ] [\[2404.19384\] Pseudo Label Refinery for Unsupervised Domain Adaptation on Cross-dataset 3D Object Detection](https://arxiv.org/abs/2404.19384) (CVPR)
- [ ] [\[2404.19394\] CLIP-Mamba: CLIP Pretrained Mamba Models with OOD and Hessian Evaluation](https://arxiv.org/abs/2404.19394) (Tongji)
- [ ] [\[2404.19401\] UniFS: Universal Few-shot Instance Perception with Point Representations](https://arxiv.org/abs/2404.19401) (HKU, ECCV)
- [ ] [\[2404.19417\] Physical Backdoor: Towards Temperature-based Backdoor Attacks in the Physical World](https://arxiv.org/abs/2404.19417) (ZJU, CVPR)
- [ ] [\[2404.19444\] AnomalyXFusion: Multi-modal Anomaly Synthesis with Diffusion](https://arxiv.org/abs/2404.19444) (Xiamen)
- [ ] [\[2404.19475\] TwinDiffusion: Enhancing Coherence and Efficiency in Panoramic Image Generation with Diffusion Models](https://arxiv.org/abs/2404.19475) (ZJU)
- [ ] [\[2404.19527\] Revealing the Two Sides of Data Augmentation: An Asymmetric Distillation-based Win-Win Solution for Open-Set Recognition](https://arxiv.org/abs/2404.19527) (HIT)
- [ ] [\[2404.19531\] MoST: Multi-modality Scene Tokenization for Motion Prediction](https://arxiv.org/abs/2404.19531) (CVPR)
- [ ] [\[2404.19541\] Ultra Inertial Poser: Scalable Motion Capture and Tracking from Sparse Inertial Sensors and Ultra-Wideband Ranging](https://arxiv.org/abs/2404.19541) (SIGGRAPH)
- [ ] [\[2404.19615\] SemiPL: A Semi-supervised Method for Event Sound Source Localization](https://arxiv.org/abs/2404.19615) (Peking)
- [ ] [\[2404.19644\] MetaCoCo: A New Few-Shot Classification Benchmark with Spurious Correlation](https://arxiv.org/abs/2404.19644) (Peking, ICLR)
- [ ] [\[2404.19696\] Naturally Supervised 3D Visual Grounding with Language-Regularized Concept Learners](https://arxiv.org/abs/2404.19696) (CVPR)
- [ ] [\[2404.19706\] RTG-SLAM: Real-time 3D Reconstruction at Scale using Gaussian Splatting](https://arxiv.org/abs/2404.19706) (ZJU, SIGGRAPH)
- [ ] [\[2404.19752\] Visual Fact Checker: Enabling High-Fidelity Detailed Caption Generation](https://arxiv.org/abs/2404.19752) (CVPR)
- [ ] [\[2405.00117\] Training a high-performance retinal foundation model with half-the-data and 400 times less compute](https://arxiv.org/abs/2405.00117) (University of Edinburgh)
- [ ] [\[2405.00181\] Uncovering What, Why and How: A Comprehensive Benchmark for Causation Understanding of Video Anomaly](https://arxiv.org/abs/2405.00181) (CVPR)
- [ ] [\[2405.00244\] Towards Real-World HDR Video Reconstruction: A Large-Scale Benchmark Dataset and A Two-Stage Alignment Network](https://arxiv.org/abs/2405.00244) (CVPR)
- [ ] [\[2405.00250\] SemVecNet: Generalizable Vector Map Generation for Arbitrary Sensor Configurations](https://arxiv.org/abs/2405.00250) (UCSD)
- [ ] [\[2405.00256\] ASAM: Boosting Segment Anything Model with Adversarial Tuning](https://arxiv.org/abs/2405.00256) (CVPR)
- [ ] [\[2405.00293\] MoPEFT: A Mixture-of-PEFTs for the Segment Anything Model](https://arxiv.org/abs/2405.00293) (Rochester Institute of Technology)
- [ ] [\[2405.00354\] CrossMatch: Enhance Semi-Supervised Medical Image Segmentation with Perturbation Strategies and Knowledge Distillation](https://arxiv.org/abs/2405.00354) (Nankai)
- [ ] [\[2405.00378\] Adaptive Bidirectional Displacement for Semi-Supervised Medical Image Segmentation](https://arxiv.org/abs/2405.00378) (CVPR)
- [ ] [\[2405.00431\] Detail-Enhancing Framework for Reference-Based Image Super-Resolution](https://arxiv.org/abs/2405.00431) (ShanghaiTech)
- [ ] [\[2405.00448\] MMTryon: Multi-Modal Multi-Reference Control for High-Quality Fashion Generation](https://arxiv.org/abs/2405.00448) (SYSU)
- [ ] [\[2405.00452\] Predictive Accuracy-Based Active Learning for Medical Image Segmentation](https://arxiv.org/abs/2405.00452) (USTC)
- [ ] [\[2405.00479\] Enhanced Visual Question Answering: A Comparative Analysis and Textual Feature Extraction Via Convolutions](https://arxiv.org/abs/2405.00479) (Tongji)
- [ ] [\[2405.00485\] The Pyramid of Captions](https://arxiv.org/abs/2405.00485) (HKUST)
- [ ] [\[2405.00514\] Get Your Embedding Space in Order: Domain-Adaptive Regression for Forest Monitoring](https://arxiv.org/abs/2405.00514) (University of Copenhagen)
- [ ] [\[2405.00574\] EALD-MLLM: Emotion Analysis in Long-sequential and De-identity videos with Multi-modal Large Language Model](https://arxiv.org/abs/2405.00574) (Tianjin)
- [ ] [\[2405.00587\] GraCo: Granularity-Controllable Interactive Segmentation](https://arxiv.org/abs/2405.00587) (Peking, CVPR)
- [ ] [\[2405.00676\] Spectrally Pruned Gaussian Fields with Neural Compensation](https://arxiv.org/abs/2405.00676) (Imperial)
- [ ] [\[2405.00740\] Modeling Caption Diversity in Contrastive Vision-Language Pretraining](https://arxiv.org/abs/2405.00740) (ICML)
- [ ] [\[2405.00749\] More is Better: Deep Domain Adaptation with Multiple Sources](https://arxiv.org/abs/2405.00749) (Peking)
- [ ] [\[2405.00760\] Deep Reward Supervisions for Tuning Text-to-Image Diffusion Models](https://arxiv.org/abs/2405.00760) (CUHK)
- [ ] [\[2405.00900\] LidaRF: Delving into Lidar for Neural Radiance Field on Street Scenes](https://arxiv.org/abs/2405.00900) (CVPR)
- [ ] [\[2405.00906\] LOTUS: Improving Transformer Efficiency with Sparsity Pruning and Data Lottery Tickets](https://arxiv.org/abs/2405.00906) (GIT)
- [ ] [\[2405.00915\] EchoScene: Indoor Scene Generation via Information Echo over Scene Graph Diffusion](https://arxiv.org/abs/2405.00915) (TUM)
- [ ] [\[2405.00954\] X-Oscar: A Progressive Framework for High-quality Text-guided 3D Animatable Avatar Generation](https://arxiv.org/abs/2405.00954) (Xiamen, ICML)
- [ ] [\[2405.00962\] FITA: Fine-grained Image-Text Aligner for Radiology Report Generation](https://arxiv.org/abs/2405.00962) (HKUST)
- [ ] [\[2405.01002\] Spider: A Unified Framework for Context-dependent Concept Segmentation](https://arxiv.org/abs/2405.01002) (ICML)
- [ ] [\[2405.01008\] On Mechanistic Knowledge Localization in Text-to-Image Generative Models](https://arxiv.org/abs/2405.01008) (UMD, ICML)
- [ ] [\[2405.01065\] MFDS-Net: Multi-Scale Feature Depth-Supervised Network for Remote Sensing Change Detection with Global Semantic and Detail Information](https://arxiv.org/abs/2405.01065) (BU)
- [ ] [\[2405.01126\] Detecting and clustering swallow events in esophageal long-term high-resolution manometry](https://arxiv.org/abs/2405.01126) (TUM)
- [ ] [\[2405.01130\] Automated Virtual Product Placement and Assessment in Images using Diffusion Models](https://arxiv.org/abs/2405.01130) (AWS)
- [ ] [\[2405.01170\] GroupedMixer: An Entropy Model with Group-wise Token-Mixers for Learned Image Compression](https://arxiv.org/abs/2405.01170) (Peking)
- [ ] [\[2405.01326\] Multi-modal Learnable Queries for Image Aesthetics Assessment](https://arxiv.org/abs/2405.01326) (Alibaba)
- [ ] [\[2405.01356\] Improving Subject-Driven Image Synthesis with Subject-Agnostic Guidance](https://arxiv.org/abs/2405.01356) (CVPR)
- [ ] [\[2405.01373\] ATOM: Attention Mixer for Efficient Dataset Distillation](https://arxiv.org/abs/2405.01373) (CVPR)
- [ ] [\[2405.01439\] Improving Domain Generalization on Gaze Estimation via Branch-out Auxiliary Regularization](https://arxiv.org/abs/2405.01439) (BU)
- [ ] [\[2405.01461\] SATO: Stable Text-to-Motion Framework](https://arxiv.org/abs/2405.01461) (Tongji)
- [ ] [\[2405.01469\] Advancing human-centric AI for robust X-ray analysis through holistic self-supervised learning](https://arxiv.org/abs/2405.01469) (Meta)
- [ ] [\[2405.01496\] LocInv: Localization-aware Inversion for Text-Guided Image Editing](https://arxiv.org/abs/2405.01496) (Nankai)
- [ ] [\[2405.01533\] OmniDrive: A Holistic LLM-Agent Framework for Autonomous Driving with 3D Perception, Reasoning and Planning](https://arxiv.org/abs/2405.01533) (NVIDIA)
- [ ] [\[2405.01538\] Multi-Space Alignments Towards Universal LiDAR Segmentation](https://arxiv.org/abs/2405.01538) (CVPR)
- [ ] [\[2405.01688\] Adapting Self-Supervised Learning for Computational Pathology](https://arxiv.org/abs/2405.01688) (Microsoft)
- [ ] [\[2405.01885\] Enhancing Micro Gesture Recognition for Emotion Understanding via Context-aware Visual-Text Contrastive Learning](https://arxiv.org/abs/2405.01885) (Tianjin)
- [ ] [\[2405.01920\] Lightweight Change Detection in Heterogeneous Remote Sensing Images with Online All-Integer Pruning Training](https://arxiv.org/abs/2405.01920) (Tsinghua)
- [ ] [\[2405.01926\] Auto-Encoding Morph-Tokens for Multimodal LLM](https://arxiv.org/abs/2405.01926) (ZJU, ICML)
- [ ] [\[2405.02005\] HoloGS: Instant Depth-based 3D Gaussian Splatting with Microsoft HoloLens 2](https://arxiv.org/abs/2405.02005) (ISPRS)
- [ ] [\[2405.02008\] DiffMap: Enhancing Map Segmentation with Map Prior Using Diffusion Model](https://arxiv.org/abs/2405.02008) (Tsinghua)
- [ ] [\[2405.02023\] IFNet: Deep Imaging and Focusing for Handheld SAR with Millimeter-wave Signals](https://arxiv.org/abs/2405.02023) (USTC)
- [ ] [\[2405.02061\] Towards general deep-learning-based tree instance segmentation models](https://arxiv.org/abs/2405.02061) (University of Göttingen)
- [ ] [\[2405.02068\] Advancing Pre-trained Teacher: Towards Robust Feature Discrepancy for Anomaly Detection](https://arxiv.org/abs/2405.02068) (XJTU)
- [ ] [\[2405.02077\] MVP-Shot: Multi-Velocity Progressive-Alignment Framework for Few-Shot Action Recognition](https://arxiv.org/abs/2405.02077) (NJU)
- [ ] [\[2405.02171\] Self-Supervised Learning for Real-World Super-Resolution from Dual and Multiple Zoomed Observations](https://arxiv.org/abs/2405.02171) (HIT, ECCV)
- [ ] [\[2405.02218\] Multispectral Fine-Grained Classification of Blackgrass in Wheat and Barley Crops](https://arxiv.org/abs/2405.02218) (Oxford)
- [ ] [\[2405.02288\] Prospective Role of Foundation Models in Advancing Autonomous Vehicles](https://arxiv.org/abs/2405.02288) (Tongji)
- [ ] [\[2405.02296\] M\"obius Transform for Mitigating Perspective Distortions in Representation Learning](https://arxiv.org/abs/2405.02296) (ECCV)
- [ ] [\[2405.02317\] Long-term Human Participation Assessment In Collaborative Learning Environments Using Dynamic Scene Analysis](https://arxiv.org/abs/2405.02317) (UT Austin)
- [ ] [\[2405.02363\] LLM as Dataset Analyst: Subpopulation Structure Discovery with Large Language Model](https://arxiv.org/abs/2405.02363) (Peking, ECCV)
- [ ] [\[2405.02386\] Rip-NeRF: Anti-aliasing Radiance Fields with Ripmap-Encoded Platonic Solids](https://arxiv.org/abs/2405.02386) (BIT, SIGGRAPH)
- [ ] [\[2405.02538\] AdaFPP: Adapt-Focused Bi-Propagating Prototype Learning for Panoramic Activity Recognition](https://arxiv.org/abs/2405.02538) (NJU)
- [ ] [\[2405.02564\] Leveraging the Human Ventral Visual Stream to Improve Neural Network Robustness](https://arxiv.org/abs/2405.02564) (Illinois)
- [ ] [\[2405.02581\] Stationary Representations: Optimally Approximating Compatibility and Implications for Improved Model Replacements](https://arxiv.org/abs/2405.02581) (CVPR)
- [ ] [\[2405.02591\] Better YOLO with Attention-Augmented Network and Enhanced Generalization Performance for Safety Helmet Detection](https://arxiv.org/abs/2405.02591) (HKUST(GZ))
- [ ] [\[2405.02608\] UnSAMFlow: Unsupervised Optical Flow Guided by Segment Anything Model](https://arxiv.org/abs/2405.02608) (CVPR)
- [ ] [\[2405.02676\] Hand-Object Interaction Controller (HOIC): Deep Reinforcement Learning for Reconstructing Interactions with Physics](https://arxiv.org/abs/2405.02676) (Tsinghua, SIGGRAPH)
- [ ] [\[2405.02686\] Boosting 3D Neuron Segmentation with 2D Vision Transformer Pre-trained on Natural Images](https://arxiv.org/abs/2405.02686) (USyd)
- [ ] [\[2405.02730\] U-DiTs: Downsample Tokens in U-Shaped Diffusion Transformers](https://arxiv.org/abs/2405.02730) (Peking)
- [ ] [\[2405.02771\] MMEarth: Exploring Multi-Modal Pretext Tasks For Geospatial Representation Learning](https://arxiv.org/abs/2405.02771) (University of Copenhagen, ECCV)
- [ ] [\[2405.02781\] Instantaneous Perception of Moving Objects in 3D](https://arxiv.org/abs/2405.02781) (CVPR)
- [ ] [\[2405.02785\] Fused attention mechanism-based ore sorting network](https://arxiv.org/abs/2405.02785) (BU)
- [ ] [\[2405.02791\] Efficient Text-driven Motion Generation via Latent Consistency Training](https://arxiv.org/abs/2405.02791) (Tongji)
- [ ] [\[2405.02797\] Adapting to Distribution Shift by Visual Domain Prompt Generation](https://arxiv.org/abs/2405.02797) (University of Toronto, ICLR)
- [ ] [\[2405.02824\] Adaptive Guidance Learning for Camouflaged Object Detection](https://arxiv.org/abs/2405.02824) (NJU)
- [ ] [\[2405.02832\] Fast One-Stage Unsupervised Domain Adaptive Person Search](https://arxiv.org/abs/2405.02832) (BU)
- [ ] [\[2405.02834\] Scene-Adaptive Person Search via Bilateral Modulations](https://arxiv.org/abs/2405.02834) (BU)
- [ ] [\[2405.02843\] Residual-Conditioned Optimal Transport: Towards Structure-Preserving Unpaired and Paired Image Restoration](https://arxiv.org/abs/2405.02843) (XJTU, ICML)
- [ ] [\[2405.02844\] SMCD: High Realism Motion Style Transfer via Mamba-based Diffusion](https://arxiv.org/abs/2405.02844) (Fudan)
- [ ] [\[2405.02859\] MVIP-NeRF: Multi-view 3D Inpainting on NeRF Scenes via Diffusion Prior](https://arxiv.org/abs/2405.02859) (NTU)
- [ ] [\[2405.02880\] Blending Distributed NeRFs with Tri-stage Robust Pose Optimization](https://arxiv.org/abs/2405.02880) (Tsinghua)
- [ ] [\[2405.02911\] Multimodal Sense-Informed Prediction of 3D Human Motions](https://arxiv.org/abs/2405.02911) (ZJU)
- [ ] [\[2405.02918\] MERIT: Multi-view Evidential learning for Reliable and Interpretable liver fibrosis sTaging](https://arxiv.org/abs/2405.02918) (Peking)
- [ ] [\[2405.02941\] Boundary-aware Decoupled Flow Networks for Realistic Extreme Rescaling](https://arxiv.org/abs/2405.02941) (Tsinghua)
- [ ] [\[2405.02944\] Imaging Signal Recovery Using Neural Network Priors Under Uncertain Forward Model Parameters](https://arxiv.org/abs/2405.02944) (CVPR)
- [ ] [\[2405.02945\] Invertible Residual Rescaling Models](https://arxiv.org/abs/2405.02945) (HIT)
- [ ] [\[2405.02951\] iSEARLE: Improving Textual Inversion for Zero-Shot Composed Image Retrieval](https://arxiv.org/abs/2405.02951) (ICCV)
- [ ] [\[2405.02954\] Source-Free Domain Adaptation Guided by Vision and Vision-Language Pre-Training](https://arxiv.org/abs/2405.02954) (ICCV)
- [ ] [\[2405.02982\] Paintings and Drawings Aesthetics Assessment with Rich Attributes for Various Artistic Categories](https://arxiv.org/abs/2405.02982) (USTC)
- [ ] [\[2405.03091\] Research on Image Recognition Technology Based on Multimodal Deep Learning](https://arxiv.org/abs/2405.03091) (NYU)
- [ ] [\[2405.03109\] Intra-task Mutual Attention based Vision Transformer for Few-Shot Learning](https://arxiv.org/abs/2405.03109) (HUST)
- [ ] [\[2405.03121\] AniTalker: Animate Vivid and Diverse Talking Faces through Identity-Decoupled Facial Motion Encoding](https://arxiv.org/abs/2405.03121) (SJTU)
- [ ] [\[2405.03144\] PTQ4SAM: Post-Training Quantization for Segment Anything](https://arxiv.org/abs/2405.03144) (CVPR)
- [ ] [\[2405.03197\] StyleSeg V2: Towards Robust One-shot Segmentation of Brain Tissue via Optimization-free Registration Error Perception](https://arxiv.org/abs/2405.03197) (HUST)
- [ ] [\[2405.03202\] Hierarchical Space-Time Attention for Micro-Expression Recognition](https://arxiv.org/abs/2405.03202) (USTC)
- [ ] [\[2405.03218\] Elevator, Escalator or Neither? Classifying Pedestrian Conveyor State Using Inertial Navigation System](https://arxiv.org/abs/2405.03218) (HKUST)
- [ ] [\[2405.03221\] Spatial and Surface Correspondence Field for Interaction Transfer](https://arxiv.org/abs/2405.03221) (SIGGRAPH)
- [ ] [\[2405.03243\] Mind the Gap Between Synthetic and Real: Utilizing Transfer Learning to Probe the Boundaries of Stable Diffusion Generated Data](https://arxiv.org/abs/2405.03243) (Bosch)
- [ ] [\[2405.03280\] Animate Your Thoughts: Decoupled Reconstruction of Dynamic Natural Vision from Slow Brain Activity](https://arxiv.org/abs/2405.03280) (BUPT)
- [ ] [\[2405.03333\] Light-VQA+: A Video Quality Assessment Model for Exposure Correction with Vision-Language Guidance](https://arxiv.org/abs/2405.03333) (SJTU)
- [ ] [\[2405.03351\] Modality Prompts for Arbitrary Modality Salient Object Detection](https://arxiv.org/abs/2405.03351) (Xidian)
- [ ] [\[2405.03352\] Salient Object Detection From Arbitrary Modalities](https://arxiv.org/abs/2405.03352) (Xidian)
- [ ] [\[2405.03373\] Knowledge-aware Text-Image Retrieval for Remote Sensing Images](https://arxiv.org/abs/2405.03373) (EPFL)
- [ ] [\[2405.03388\] 3D LiDAR Mapping in Dynamic Environments Using a 4D Implicit Neural Representation](https://arxiv.org/abs/2405.03388) (CVPR)
- [ ] [\[2405.03485\] LGTM: Local-to-Global Text-Driven Human Motion Diffusion Model](https://arxiv.org/abs/2405.03485) (SIGGRAPH)
- [ ] [\[2405.03546\] CCDM: Continuous Conditional Diffusion Models for Image Generation](https://arxiv.org/abs/2405.03546) (ZJU)
- [ ] [\[2405.03659\] A Construct-Optimize Approach to Sparse View Synthesis without Camera Pose](https://arxiv.org/abs/2405.03659) (UCSD)
- [ ] [\[2405.03662\] Diffeomorphic Template Registration for Atmospheric Turbulence Mitigation](https://arxiv.org/abs/2405.03662) (UCLA)
- [ ] [\[2405.03685\] Language-Image Models with 3D Understanding](https://arxiv.org/abs/2405.03685) (UT Austin)
- [ ] [\[2405.03689\] Pose Priors from Language Models](https://arxiv.org/abs/2405.03689) (Google)
- [ ] [\[2405.03702\] Leafy Spurge Dataset: Real-world Weed Classification Within Aerial Drone Imagery](https://arxiv.org/abs/2405.03702) (CMU)
- [ ] [\[2405.03722\] Class-relevant Patch Embedding Selection for Few-Shot Image Classification](https://arxiv.org/abs/2405.03722) (HUST)
- [ ] [\[2405.03882\] Trio-ViT: Post-Training Quantization and Acceleration for Softmax-Free Efficient Vision Transformer](https://arxiv.org/abs/2405.03882) (SYSU)
- [ ] [\[2405.03894\] MVDiff: Scalable and Flexible Multi-View Diffusion for 3D Object Reconstruction from Single-View](https://arxiv.org/abs/2405.03894) (Oxford)
- [ ] [\[2405.03959\] Joint Identity Verification and Pose Alignment for Partial Fingerprints](https://arxiv.org/abs/2405.03959) (Tsinghua)
- [ ] [\[2405.03971\] Unified End-to-End V2X Cooperative Autonomous Driving](https://arxiv.org/abs/2405.03971) (Tsinghua)
- [ ] [\[2405.03995\] Deep Event-based Object Detection in Autonomous Driving: A Survey](https://arxiv.org/abs/2405.03995) (NUDT)
- [ ] [\[2405.04009\] Structured Click Control in Transformer-based Interactive Segmentation](https://arxiv.org/abs/2405.04009) (NIPS)
- [ ] [\[2405.04044\] DMOFC: Discrimination Metric-Optimized Feature Compression](https://arxiv.org/abs/2405.04044) (USTC)
- [ ] [\[2405.04100\] ESP: Extro-Spective Prediction for Long-term Behavior Reasoning in Emergency Scenarios](https://arxiv.org/abs/2405.04100) (ShanghaiTech)
- [ ] [\[2405.04121\] ELiTe: Efficient Image-to-LiDAR Knowledge Transfer for Semantic Segmentation](https://arxiv.org/abs/2405.04121) (Fudan)
- [ ] [\[2405.04133\] Exposing AI-generated Videos: A Benchmark Dataset and a Local-and-Global Temporal Defect Based Detection Method](https://arxiv.org/abs/2405.04133) (CMU)
- [ ] [\[2405.04164\] Sign2GPT: Leveraging Large Language Models for Gloss-Free Sign Language Translation](https://arxiv.org/abs/2405.04164) (Meta, ICLR)
- [ ] [\[2405.04167\] Bridging the Synthetic-to-Authentic Gap: Distortion-Guided Unsupervised Domain Adaptation for Blind Image Quality Assessment](https://arxiv.org/abs/2405.04167) (Xidian, CVPR)
- [ ] [\[2405.04175\] Topicwise Separable Sentence Retrieval for Medical Report Generation](https://arxiv.org/abs/2405.04175) (Tianjin)
- [ ] [\[2405.04189\] Artificial Intelligence-powered fossil shark tooth identification: Unleashing the potential of Convolutional Neural Networks](https://arxiv.org/abs/2405.04189) (Cambridge)
- [ ] [\[2405.04233\] Vidu: a Highly Consistent, Dynamic and Skilled Text-to-Video Generator with Diffusion Models](https://arxiv.org/abs/2405.04233) (Tsinghua)
- [ ] [\[2405.04309\] Non-rigid Structure-from-Motion: Temporally-smooth Procrustean Alignment and Spatially-variant Deformation Modeling](https://arxiv.org/abs/2405.04309) (NWPU, CVPR)
- [ ] [\[2405.04312\] Inf-DiT: Upsampling Any-Resolution Image with Memory-Efficient Diffusion Transformer](https://arxiv.org/abs/2405.04312) (Tsinghua)
- [ ] [\[2405.04345\] Novel View Synthesis with Neural Radiance Fields for Industrial Robot Applications](https://arxiv.org/abs/2405.04345) (ISPRS)
- [ ] [\[2405.04356\] Diffusion-driven GAN Inversion for Multi-Modal Face Image Generation](https://arxiv.org/abs/2405.04356) (CVPR)
- [ ] [\[2405.04370\] Diff-IP2D: Diffusion-Based Hand-Object Interaction Prediction on Egocentric Videos](https://arxiv.org/abs/2405.04370) (SJTU)
- [ ] [\[2405.04377\] Choose What You Need: Disentangled Representation Learning for Scene Text Recognition, Removal and Editing](https://arxiv.org/abs/2405.04377) (CVPR)
- [ ] [\[2405.04390\] DriveWorld: 4D Pre-trained Scene Understanding via World Models for Autonomous Driving](https://arxiv.org/abs/2405.04390) (Peking, CVPR)
- [ ] [\[2405.04404\] Vision Mamba: A Comprehensive Survey and Taxonomy](https://arxiv.org/abs/2405.04404) (Chongqing)
- [ ] [\[2405.04408\] DocRes: A Generalist Model Toward Unifying Document Image Restoration Tasks](https://arxiv.org/abs/2405.04408) (CVPR)
- [ ] [\[2405.04416\] DistGrid: Scalable Scene Reconstruction with Distributed Multi-resolution Hash Grid](https://arxiv.org/abs/2405.04416) (NUDT, SIGGRAPH)
- [ ] [\[2405.04496\] Edit-Your-Motion: Space-Time Diffusion Decoupling Learning for Video Motion Editing](https://arxiv.org/abs/2405.04496) (Xidian)
- [ ] [\[2405.04534\] Tactile-Augmented Radiance Fields](https://arxiv.org/abs/2405.04534) (CVPR)
- [ ] [\[2405.04537\] An intuitive multi-frequency feature representation for SO(3)-equivariant networks](https://arxiv.org/abs/2405.04537) (ICLR)
- [ ] [\[2405.04549\] ClothPPO: A Proximal Policy Optimization Enhancing Framework for Robotic Cloth Manipulation with Observation-Aligned Action Spaces](https://arxiv.org/abs/2405.04549) (HKUST)
- [ ] [\[2405.04589\] A Novel Wide-Area Multiobject Detection System with High-Probability Region Searching](https://arxiv.org/abs/2405.04589) (Chongqing)
- [ ] [\[2405.04662\] Radar Fields: Frequency-Space Neural Scene Representations for FMCW Radar](https://arxiv.org/abs/2405.04662) (SIGGRAPH)
- [ ] [\[2405.04682\] TALC: Time-Aligned Captions for Multi-Scene Text-to-Video Generation](https://arxiv.org/abs/2405.04682) (UCLA)
- [ ] [\[2405.04741\] All in One Framework for Multimodal Re-identification in the Wild](https://arxiv.org/abs/2405.04741) (WHU, CVPR)
- [ ] [\[2405.04771\] Exploring Vision Transformers for 3D Human Motion-Language Models with Motion Patches](https://arxiv.org/abs/2405.04771) (CVPR)
- [ ] [\[2405.04788\] SemiCD-VL: Visual-Language Model Guidance Makes Better Semi-supervised Change Detector](https://arxiv.org/abs/2405.04788) (XJTU)
- [ ] [\[2405.04800\] DeepDamageNet: A two-step deep-learning model for multi-disaster building damage segmentation and classification using satellite imagery](https://arxiv.org/abs/2405.04800) (Stanford)
- [ ] [\[2405.04858\] Pedestrian Attribute Recognition as Label-balanced Multi-label Learning](https://arxiv.org/abs/2405.04858) (ICML)
- [ ] [\[2405.04883\] FreeBind: Free Lunch in Unified Multimodal Space via Knowledge Fusion](https://arxiv.org/abs/2405.04883) (ZJU, ICML)
- [ ] [\[2405.04918\] Delve into Base-Novel Confusion: Redundancy Exploration for Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2405.04918) (BU)
- [ ] [\[2405.04940\] Harnessing the Power of MLLMs for Transferable Text-to-Image Person ReID](https://arxiv.org/abs/2405.04940) (CVPR)
- [ ] [\[2405.04950\] VisionGraph: Leveraging Large Multimodal Models for Graph Theory Problems in Visual Context](https://arxiv.org/abs/2405.04950) (HIT, ICML)
- [ ] [\[2405.04953\] Supervised Anomaly Detection for Complex Industrial Images](https://arxiv.org/abs/2405.04953) (CVPR)
- [ ] [\[2405.04964\] Frequency-Assisted Mamba for Remote Sensing Image Super-Resolution](https://arxiv.org/abs/2405.04964) (WHU)
- [ ] [\[2405.05001\] HMANet: Hybrid Multi-Axis Aggregation Network for Image Super-Resolution](https://arxiv.org/abs/2405.05001) (HIT)
- [ ] [\[2405.05027\] StyleMamba : State Space Model for Efficient Text-driven Image Style Transfer](https://arxiv.org/abs/2405.05027) (Imperial)
- [ ] [\[2405.05130\] Multi-scale Bottleneck Transformer for Weakly Supervised Multimodal Violence Detection](https://arxiv.org/abs/2405.05130) (ZJU)
- [ ] [\[2405.05164\] ProbRadarM3F: mmWave Radar based Human Skeletal Pose Estimation with Probability Map Guided Multi-Format Feature Fusion](https://arxiv.org/abs/2405.05164) (USyd)
- [ ] [\[2405.05216\] FinePOSE: Fine-Grained Prompt-Driven 3D Human Pose Estimation via Diffusion Models](https://arxiv.org/abs/2405.05216) (Peking, CVPR)
- [ ] [\[2405.05237\] EVA-X: A Foundation Model for General Chest X-ray Analysis with Self-supervised Learning](https://arxiv.org/abs/2405.05237) (HUST)
- [ ] [\[2405.05252\] Attention-Driven Training-Free Efficiency Enhancement of Diffusion Models](https://arxiv.org/abs/2405.05252) (CVPR)
- [ ] [\[2405.05256\] THRONE: An Object-based Hallucination Benchmark for the Free-form Generations of Large Vision-Language Models](https://arxiv.org/abs/2405.05256) (Oxford, CVPR)
- [ ] [\[2405.05258\] Multi-Modal Data-Efficient 3D Scene Understanding for Autonomous Driving](https://arxiv.org/abs/2405.05258) (NTU)
- [ ] [\[2405.05259\] OpenESS: Event-based Semantic Scene Understanding with Open Vocabularies](https://arxiv.org/abs/2405.05259) (CVPR)
- [ ] [\[2405.05260\] Financial Table Extraction in Image Documents](https://arxiv.org/abs/2405.05260) (NVIDIA)
- [ ] [\[2405.05354\] Transfer-LMR: Heavy-Tail Driving Behavior Recognition in Diverse Traffic Scenarios](https://arxiv.org/abs/2405.05354) (UT Austin)
- [ ] [\[2405.05422\] EarthMatch: Iterative Coregistration for Fine-grained Localization of Astronaut Photography](https://arxiv.org/abs/2405.05422) (CVPR)
- [ ] [\[2405.05502\] Towards Accurate and Robust Architectures via Neural Architecture Search](https://arxiv.org/abs/2405.05502) (CVPR)
- [ ] [\[2405.05523\] Prompt When the Animal is: Temporal Animal Behavior Grounding with Positional Recovery Training](https://arxiv.org/abs/2405.05523) (Peking)
- [ ] [\[2405.05573\] Poisoning-based Backdoor Attacks for Arbitrary Target Label with Positive Triggers](https://arxiv.org/abs/2405.05573) (HKU)
- [ ] [\[2405.05587\] Navigate Beyond Shortcuts: Debiased Learning through the Lens of Neural Collapse](https://arxiv.org/abs/2405.05587) (CVPR)
- [ ] [\[2405.05605\] Minimal Perspective Autocalibration](https://arxiv.org/abs/2405.05605) (CVPR)
- [ ] [\[2405.05613\] Robust Pseudo-label Learning with Neighbor Relation for Unsupervised Visible-Infrared Person Re-Identification](https://arxiv.org/abs/2405.05613) (Xiamen)
- [ ] [\[2405.05615\] Memory-Space Visual Prompting for Efficient Vision-Language Fine-Tuning](https://arxiv.org/abs/2405.05615) (Peking, ICML)
- [ ] [\[2405.05636\] SwapTalk: Audio-Driven Talking Face Generation with One-Shot Customization in Latent Space](https://arxiv.org/abs/2405.05636) (Peking)
- [ ] [\[2405.05663\] RPBG: Towards Robust Neural Point-based Graphics in the Wild](https://arxiv.org/abs/2405.05663) (ECCV)
- [ ] [\[2405.05691\] StableMoFusion: Towards Robust and Efficient Diffusion-based Motion Generation Framework](https://arxiv.org/abs/2405.05691) (BUPT)
- [ ] [\[2405.05714\] Estimating Noisy Class Posterior with Part-level Labels for Noisy Label Learning](https://arxiv.org/abs/2405.05714) (XJTU, CVPR)
- [ ] [\[2405.05768\] FastScene: Text-Driven Fast 3D Indoor Scene Generation via Panoramic Gaussian Splatting](https://arxiv.org/abs/2405.05768) (SYSU)
- [ ] [\[2405.05769\] Exploring Text-Guided Single Image Editing for Remote Sensing Images](https://arxiv.org/abs/2405.05769) (IS CAS)
- [ ] [\[2405.05803\] Boosting Multimodal Large Language Models with Visual Tokens Withdrawal for Rapid Inference](https://arxiv.org/abs/2405.05803) (Xiamen)
- [ ] [\[2405.05806\] MasterWeaver: Taming Editability and Face Identity for Personalized Text-to-Image Generation](https://arxiv.org/abs/2405.05806) (ECCV)
- [ ] [\[2405.05967\] Distilling Diffusion Models into Conditional GANs](https://arxiv.org/abs/2405.05967) (ECCV)
- [ ] [\[2405.06088\] A Mixture of Experts Approach to 3D Human Motion Prediction](https://arxiv.org/abs/2405.06088) (GIT)
- [ ] [\[2405.06201\] PhysMLE: Generalizable and Priors-Inclusive Multi-task Remote Physiological Measurement](https://arxiv.org/abs/2405.06201) (HKUST)
- [ ] [\[2405.06216\] Event-based Structure-from-Orbit](https://arxiv.org/abs/2405.06216) (Stanford, CVPR)
- [ ] [\[2405.06217\] DARA: Domain- and Relation-aware Adapters Make Parameter-efficient Tuning for Visual Grounding](https://arxiv.org/abs/2405.06217) (NUDT)
- [ ] [\[2405.06228\] Context-Guided Spatial Feature Reconstruction for Efficient Semantic Segmentation](https://arxiv.org/abs/2405.06228) (ECCV)
- [ ] [\[2405.06264\] Selective Focus: Investigating Semantics Sensitivity in Post-training Quantization for Lane Detection](https://arxiv.org/abs/2405.06264) (ShanghaiTech)
- [ ] [\[2405.06323\] Open Access Battle Damage Detection via Pixel-Wise T-Test on Sentinel-1 Imagery](https://arxiv.org/abs/2405.06323) (UCL)
- [ ] [\[2405.06389\] Continual Novel Class Discovery via Feature Enhancement and Adaptation](https://arxiv.org/abs/2405.06389) (XJTU)
- [ ] [\[2405.06535\] Controllable Image Generation With Composed Parallel Token Prediction](https://arxiv.org/abs/2405.06535) (NIPS)
- [ ] [\[2405.06536\] Mesh Denoising Transformer](https://arxiv.org/abs/2405.06536) (Tsinghua)
- [ ] [\[2405.06598\] A Lightweight Transformer for Remote Sensing Image Change Captioning](https://arxiv.org/abs/2405.06598) (XJTU)
- [ ] [\[2405.06600\] Multi-Object Tracking in the Dark](https://arxiv.org/abs/2405.06600) (CVPR)
- [ ] [\[2405.06782\] GraphRelate3D: Context-Dependent 3D Object Detection with Inter-Object Relationship Graphs](https://arxiv.org/abs/2405.06782) (TUM)
- [ ] [\[2405.06828\] G-FARS: Gradient-Field-based Auto-Regressive Sampling for 3D Part Grouping](https://arxiv.org/abs/2405.06828) (Imperial, CVPR)
- [ ] [\[2405.06849\] GreedyViG: Dynamic Axial Graph Construction for Efficient Vision GNNs](https://arxiv.org/abs/2405.06849) (CVPR)
- [ ] [\[2405.06872\] eCAR: edge-assisted Collaborative Augmented Reality Framework](https://arxiv.org/abs/2405.06872) (KAIST)
- [ ] [\[2405.06887\] FineParser: A Fine-grained Spatio-temporal Action Parser for Human-centric Action Quality Assessment](https://arxiv.org/abs/2405.06887) (Peking, CVPR)
- [ ] [\[2405.06903\] UniGarmentManip: A Unified Framework for Category-Level Garment Manipulation via Dense Visual Correspondence](https://arxiv.org/abs/2405.06903) (CVPR)
- [ ] [\[2405.06914\] Non-confusing Generation of Customized Concepts in Diffusion Models](https://arxiv.org/abs/2405.06914) (ZJU)
- [ ] [\[2405.06918\] Super-Resolving Blurry Images with Events](https://arxiv.org/abs/2405.06918) (WHU)
- [ ] [\[2405.06944\] Learning Monocular Depth from Focus with Event Focal Stack](https://arxiv.org/abs/2405.06944) (WHU)
- [ ] [\[2405.07027\] TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization](https://arxiv.org/abs/2405.07027) (NUDT)
- [ ] [\[2405.07047\] Unsupervised Density Neural Representation for CT Metal Artifact Reduction](https://arxiv.org/abs/2405.07047) (ShanghaiTech)
- [ ] [\[2405.07178\] Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction](https://arxiv.org/abs/2405.07178) (Berkeley)
- [ ] [\[2405.07194\] Differentiable Model Scaling using Differentiable Topk](https://arxiv.org/abs/2405.07194) (Shanghai AI Lab, ICML)
- [ ] [\[2405.07201\] Building a Strong Pre-Training Baseline for Universal 3D Large-Scale Perception](https://arxiv.org/abs/2405.07201) (Xiamen, CVPR)
- [ ] [\[2405.07284\] Zero Shot Context-Based Object Segmentation using SLIP (SAM+CLIP)](https://arxiv.org/abs/2405.07284) (NYU)
- [ ] [\[2405.07319\] LayGA: Layered Gaussian Avatars for Animatable Clothing Transfer](https://arxiv.org/abs/2405.07319) (Tsinghua, SIGGRAPH)
- [ ] [\[2405.07364\] BoQ: A Place is Worth a Bag of Learnable Queries](https://arxiv.org/abs/2405.07364) (CVPR)
- [ ] [\[2405.07411\] MoVL:Exploring Fusion Strategies for the Domain-Adaptive Application of Pretrained Models in Medical Imaging Tasks](https://arxiv.org/abs/2405.07411) (BUPT)
- [ ] [\[2405.07444\] Motion Keyframe Interpolation for Any Human Skeleton via Temporally Consistent Point Cloud Sampling and Reconstruction](https://arxiv.org/abs/2405.07444) (USyd)
- [ ] [\[2405.07451\] CLIP-Powered TASS: Target-Aware Single-Stream Network for Audio-Visual Question Answering](https://arxiv.org/abs/2405.07451) (BUPT)
- [ ] [\[2405.07481\] Text Grouping Adapter: Adapting Pre-trained Text Detector for Layout Analysis](https://arxiv.org/abs/2405.07481) (XJTU, CVPR)
- [ ] [\[2405.07655\] Quality-aware Selective Fusion Network for V-D-T Salient Object Detection](https://arxiv.org/abs/2405.07655) (TIP)
- [ ] [\[2405.07801\] Deep Learning-Based Object Pose Estimation: A Comprehensive Survey](https://arxiv.org/abs/2405.07801) (Tsinghua)
- [ ] [\[2405.07857\] Synergistic Integration of Coordinate Network and Tensorial Feature for Improving Neural Radiance Fields from Sparse Inputs](https://arxiv.org/abs/2405.07857) (KAIST, ICML)
- [ ] [\[2405.07919\] Exploring the Low-Pass Filtering Behavior in Image Super-Resolution](https://arxiv.org/abs/2405.07919) (UESTC, ICML)
- [ ] [\[2405.07933\] Authentic Hand Avatar from a Phone Scan via Universal Hand Model](https://arxiv.org/abs/2405.07933) (CVPR)
- [ ] [\[2405.07966\] OverlapMamba: Novel Shift State Space Model for LiDAR-based Place Recognition](https://arxiv.org/abs/2405.07966) (NUDT)
- [ ] [\[2405.07988\] A Generalist Learner for Multifaceted Medical Image Interpretation](https://arxiv.org/abs/2405.07988) (Harvard)
- [ ] [\[2405.07992\] MambaOut: Do We Really Need Mamba for Vision?](https://arxiv.org/abs/2405.07992) (NUS)
