- [ ] [\[2410.09704\] EchoPrime: A Multi-Video View-Informed Vision-Language Model for Comprehensive Echocardiography Interpretation](https://arxiv.org/abs/2410.09704) (Stanford)
- [ ] [\[2410.09714\] AM-SAM: Automated Prompting and Mask Calibration for Segment Anything Model](https://arxiv.org/abs/2410.09714) (UCSD)
- [ ] [\[2410.09732\] LOKI: A Comprehensive Synthetic Data Detection Benchmark using Large Multimodal Models](https://arxiv.org/abs/2410.09732) (SYSU)
- [ ] [\[2410.09733\] MMCOMPOSITION: Revisiting the Compositionality of Pre-trained Vision-Language Models](https://arxiv.org/abs/2410.09733) (Microsoft)
- [ ] [\[2410.09747\] t-READi: Transformer-Powered Robust and Efficient Multimodal Inference for Autonomous Driving](https://arxiv.org/abs/2410.09747) (SUSTech)
- [ ] [\[2410.09749\] EMWaveNet: Physically Explainable Neural Network Based on Microwave Propagation for SAR Target Recognition](https://arxiv.org/abs/2410.09749) (Fudan)
- [ ] [\[2410.09776\] ECIS-VQG: Generation of Entity-centric Information-seeking Questions from Videos](https://arxiv.org/abs/2410.09776) (Microsoft)
- [ ] [\[2410.09797\] Task Adaptive Feature Distribution Based Network for Few-shot Fine-grained Target Classification](https://arxiv.org/abs/2410.09797) (XJTU)
- [ ] [\[2410.09802\] EBDM: Exemplar-guided Image Translation with Brownian-bridge Diffusion Models](https://arxiv.org/abs/2410.09802) (ECCV)
- [ ] [\[2410.09818\] TopOC: Topological Deep Learning for Ovarian and Breast Cancer Diagnosis](https://arxiv.org/abs/2410.09818) (Harvard)
- [ ] [\[2410.09834\] Towards Defining an Efficient and Expandable File Format for AI-Generated Contents](https://arxiv.org/abs/2410.09834) (USTC)
- [ ] [\[2410.09855\] Text4Seg: Reimagining Image Segmentation as Text Generation](https://arxiv.org/abs/2410.09855) (NTU)
- [ ] [\[2410.09864\] AuthFace: Towards Authentic Blind Face Restoration with Face-oriented Generative Diffusion Prior](https://arxiv.org/abs/2410.09864) (HKUST)
- [ ] [\[2410.09873\] Training-Free Adaptive Diffusion with Bounded Difference Approximation Strategy](https://arxiv.org/abs/2410.09873) (Shanghai AI Lab, NIPS)
- [ ] [\[2410.09890\] Large-Scale 3D Medical Image Pre-training with Geometric Context Priors](https://arxiv.org/abs/2410.09890) (HKUST, CVPR)
- [ ] [\[2410.09909\] UnSeg: One Universal Unlearnable Example Generator is Enough against All Image Segmentation](https://arxiv.org/abs/2410.09909) (NIPS)
- [ ] [\[2410.09911\] Combining Generative and Geometry Priors for Wide-Angle Portrait Correction](https://arxiv.org/abs/2410.09911) (ECCV)
- [ ] [\[2410.09962\] LongHalQA: Long-Context Hallucination Evaluation for MultiModal Large Language Models](https://arxiv.org/abs/2410.09962) (NTU)
- [ ] [\[2410.09979\] Facial Width-to-Height Ratio Does Not Predict Self-Reported Behavioral Tendencies](https://arxiv.org/abs/2410.09979) (Stanford)
- [ ] [\[2410.10012\] NARAIM: Native Aspect Ratio Autoregressive Image Models](https://arxiv.org/abs/2410.10012) (UVA.NL, NIPS)
- [ ] [\[2410.10053\] DINTR: Tracking via Diffusion-based Interpolation](https://arxiv.org/abs/2410.10053) (NIPS)
- [ ] [\[2410.10084\] PointNet with KAN versus PointNet with MLP for 3D Classification and Segmentation of Point Sets](https://arxiv.org/abs/2410.10084) (Stanford)
- [ ] [\[2410.10121\] Interaction-Guided Two-Branch Image Dehazing Network](https://arxiv.org/abs/2410.10121) (HKUST)
- [ ] [\[2410.10133\] TextCtrl: Diffusion-based Scene Text Editing with Prior Guidance Control](https://arxiv.org/abs/2410.10133) (Nankai)
- [ ] [\[2410.10168\] First Creating Backgrounds Then Rendering Texts: A New Paradigm for Visual Text Blending](https://arxiv.org/abs/2410.10168) (Nankai)
- [ ] [\[2410.10207\] MagicEraser: Erasing Any Objects via Semantics-Aware Control](https://arxiv.org/abs/2410.10207) (ECCV)
- [ ] [\[2410.10227\] KNN Transformer with Pyramid Prompts for Few-Shot Learning](https://arxiv.org/abs/2410.10227) (ACMMM)
- [ ] [\[2410.10238\] ForgeryGPT: Multimodal Large Language Model For Explainable Image Forgery Detection and Localization](https://arxiv.org/abs/2410.10238) (USTC)
- [ ] [\[2410.10260\] Slide-based Graph Collaborative Training for Histopathology Whole Slide Image Analysis](https://arxiv.org/abs/2410.10260) (USTC)
- [ ] [\[2410.10287\] Manifold-Aware Local Feature Modeling for Semi-Supervised Medical Image Segmentation](https://arxiv.org/abs/2410.10287) (NUS)
- [ ] [\[2410.10295\] A Consistency-Aware Spot-Guided Transformer for Versatile and Hierarchical Point Cloud Registration](https://arxiv.org/abs/2410.10295) (NIPS)
- [ ] [\[2410.10308\] LG-CAV: Train Any Concept Activation Vector with Language Guidance](https://arxiv.org/abs/2410.10308) (Alibaba)
- [ ] [\[2410.10316\] GlobalMamba: Global Image Serialization for Vision Mamba](https://arxiv.org/abs/2410.10316) (Tsinghua)
- [ ] [\[2410.10356\] FasterDiT: Towards Faster Diffusion Transformers Training without Architecture Modification](https://arxiv.org/abs/2410.10356) (HUST, NIPS)
- [ ] [\[2410.10366\] Affinity-Graph-Guided Contractive Learning for Pretext-Free Medical Image Segmentation with Minimal Annotation](https://arxiv.org/abs/2410.10366) (Oxford)
- [ ] [\[2410.10382\] V2M: Visual 2-Dimensional Mamba for Image Representation Learning](https://arxiv.org/abs/2410.10382) (Tsinghua)
- [ ] [\[2410.10389\] Reverse Refinement Network for Narrow Rural Road Detection in High-Resolution Satellite Imagery](https://arxiv.org/abs/2410.10389) (WHU)
- [ ] [\[2410.10399\] Parameterize Structure with Differentiable Template for 3D Shape Generation](https://arxiv.org/abs/2410.10399) (HKU)
- [ ] [\[2410.10429\] DOME: Taming Diffusion Model into High-Fidelity Controllable Occupancy World Model](https://arxiv.org/abs/2410.10429) (UCAS)
- [ ] [\[2410.10442\] Domain-Conditioned Transformer for Fully Test-time Adaptation](https://arxiv.org/abs/2410.10442) (SUSTech)
- [ ] [\[2410.10497\] Continual Learning Improves Zero-Shot Action Recognition](https://arxiv.org/abs/2410.10497) (University of Edinburgh)
- [ ] [\[2410.10573\] Queryable Prototype Multiple Instance Learning with Vision-Language Models for Incremental Whole Slide Image Classification](https://arxiv.org/abs/2410.10573) (UESTC)
- [ ] [\[2410.10587\] TopoFR: A Closer Look at Topology Alignment on Face Recognition](https://arxiv.org/abs/2410.10587) (ZJU, NIPS)
- [ ] [\[2410.10589\] MoTE: Reconciling Generalization with Specialization for Visual-Language to Video Knowledge Transfer](https://arxiv.org/abs/2410.10589) (NIPS)
- [ ] [\[2410.10659\] PCF-Lift: Panoptic Lifting by Probabilistic Contrastive Fusion](https://arxiv.org/abs/2410.10659) (ECCV)
- [ ] [\[2410.10663\] Cross-Modal Few-Shot Learning: a Generative Transfer Learning Framework](https://arxiv.org/abs/2410.10663) (WHU)
- [ ] [\[2410.10696\] TALK-Act: Enhance Textural-Awareness for 2D Speaking Avatar Reenactment with Diffusion Model](https://arxiv.org/abs/2410.10696) (SIGGRAPH)
- [ ] [\[2410.10710\] Ensemble of ConvNeXt V2 and MaxViT for Long-Tailed CXR Classification with View-Based Aggregation](https://arxiv.org/abs/2410.10710) (University of Tokyo)
- [ ] [\[2410.10733\] Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models](https://arxiv.org/abs/2410.10733) (NVIDIA)
- [ ] [\[2410.10751\] DragEntity: Trajectory Guided Video Generation using Entity and Positional Relationships](https://arxiv.org/abs/2410.10751) (ICT CAS, ACMMM)
- [ ] [\[2410.10777\] UniMatch V2: Pushing the Limit of Semi-Supervised Semantic Segmentation](https://arxiv.org/abs/2410.10777) (HKU)
- [ ] [\[2410.10826\] High-Fidelity 3D Lung CT Synthesis in ARDS Swine Models Using Score-Based 3D Residual Diffusion Models](https://arxiv.org/abs/2410.10826) (Harvard)
- [ ] [\[2410.11118\] MoonMetaSync: Lunar Image Registration Analysis](https://arxiv.org/abs/2410.11118) (Rochester Institute of Technology)
- [ ] [\[2410.11125\] UAV3D: A Large-scale 3D Perception Benchmark for Unmanned Aerial Vehicles](https://arxiv.org/abs/2410.11125) (NIPS)
- [ ] [\[2410.11187\] Multiview Scene Graph](https://arxiv.org/abs/2410.11187) (NIPS)
- [ ] [\[2410.11208\] DreamSteerer: Enhancing Source Image Conditioned Editability using Personalized Diffusion Models](https://arxiv.org/abs/2410.11208) (NIPS)
- [ ] [\[2410.11215\] A CLIP-Powered Framework for Robust and Generalizable Data Selection](https://arxiv.org/abs/2410.11215) (NJU)
- [ ] [\[2410.11228\] TEOcc: Radar-camera Multi-modal Occupancy Prediction via Temporal Enhancement](https://arxiv.org/abs/2410.11228) (Peking)
- [ ] [\[2410.11241\] Learning Diffusion Model from Noisy Measurement using Principled Expectation-Maximization Method](https://arxiv.org/abs/2410.11241) (Peking)
- [ ] [\[2410.11301\] Open World Object Detection: A Survey](https://arxiv.org/abs/2410.11301) (NTU)
- [ ] [\[2410.11302\] Have the VLMs Lost Confidence? A Study of Sycophancy in VLMs](https://arxiv.org/abs/2410.11302) (Fudan)
- [ ] [\[2410.11358\] SeaDATE: Remedy Dual-Attention Transformer with Semantic Alignment via Contrast Learning for Multimodal Object Detection](https://arxiv.org/abs/2410.11358) (Xidian)
- [ ] [\[2410.11363\] Visual-Geometric Collaborative Guidance for Affordance Learning](https://arxiv.org/abs/2410.11363) (USTC)
- [ ] [\[2410.11374\] Augmentation-Driven Metric for Balancing Preservation and Modification in Text-Guided Image Editing](https://arxiv.org/abs/2410.11374) (KAIST)
- [ ] [\[2410.11404\] MoChat: Joints-Grouped Spatio-Temporal Grounding LLM for Multi-Turn Motion Comprehension and Description](https://arxiv.org/abs/2410.11404) (BU)
- [ ] [\[2410.11419\] GS^3: Efficient Relighting with Triple Gaussian Splatting](https://arxiv.org/abs/2410.11419) (ZJU, SIGGRAPH)
- [ ] [\[2410.11505\] LoGS: Visual Localization via Gaussian Splatting with Fewer Training Images](https://arxiv.org/abs/2410.11505) (ZJU)
- [ ] [\[2410.11506\] Spatio-Temporal Distortion Aware Omnidirectional Video Super-Resolution](https://arxiv.org/abs/2410.11506) (UCAS)
- [ ] [\[2410.11509\] Dual-Teacher Ensemble Models with Double-Copy-Paste for 3D Semi-Supervised Medical Image Segmentation](https://arxiv.org/abs/2410.11509) (NJU)
- [ ] [\[2410.11528\] Hairmony: Fairness-aware hairstyle classification](https://arxiv.org/abs/2410.11528) (Microsoft)
- [ ] [\[2410.11560\] PSVMA+: Exploring Multi-granularity Semantic-visual Adaption for Generalized Zero-shot Learning](https://arxiv.org/abs/2410.11560) (TPAMI)
- [ ] [\[2410.11586\] Breaking Modality Gap in RGBT Tracking: Coupled Knowledge Distillation](https://arxiv.org/abs/2410.11586) (ACMMM)
- [ ] [\[2410.11623\] VidEgoThink: Assessing Egocentric Video Understanding Capabilities for Embodied AI](https://arxiv.org/abs/2410.11623) (Tsinghua)
- [ ] [\[2410.11639\] Efficient and Effective Universal Adversarial Attack against Vision-Language Pre-training Models](https://arxiv.org/abs/2410.11639) (HUST)
- [ ] [\[2410.11646\] Feature-guided score diffusion for sampling conditional densities](https://arxiv.org/abs/2410.11646) (NYU)
- [ ] [\[2410.11650\] ED-ViT: Splitting Vision Transformer for Distributed Inference on Edge Devices](https://arxiv.org/abs/2410.11650) (NUS)
- [ ] [\[2410.11666\] Degradation Oriented and Regularized Network for Blind Depth Super-Resolution](https://arxiv.org/abs/2410.11666) (NJU)
- [ ] [\[2410.11670\] Leveraging Structure Knowledge and Deep Models for the Detection of Abnormal Handwritten Text](https://arxiv.org/abs/2410.11670) (USTC)
- [ ] [\[2410.11686\] A Survey of Low-shot Vision-Language Model Adaptation via Representer Theorem](https://arxiv.org/abs/2410.11686) (IA CAS)
- [ ] [\[2410.11722\] RClicks: Realistic Click Simulation for Benchmarking Interactive Segmentation](https://arxiv.org/abs/2410.11722) (NIPS)
- [ ] [\[2410.11761\] SlideChat: A Large Vision-Language Assistant for Whole-Slide Pathology Image Understanding](https://arxiv.org/abs/2410.11761) (Stanford)
- [ ] [\[2410.11815\] SGEdit: Bridging LLM with Text2Image Generative Model for Scene Graph-based Image Editing](https://arxiv.org/abs/2410.11815) (SIGGRAPH)
- [ ] [\[2410.11817\] Improving Long-Text Alignment for Text-to-Image Diffusion Models](https://arxiv.org/abs/2410.11817) (HKU)
- [ ] [\[2410.11828\] Analysis and Benchmarking of Extending Blind Face Image Restoration to Videos](https://arxiv.org/abs/2410.11828) (HKU, TIP)
- [ ] [\[2410.11831\] CoTracker3: Simpler and Better Point Tracking by Pseudo-Labelling Real Videos](https://arxiv.org/abs/2410.11831) (Oxford)
- [ ] [\[2410.11842\] MoH: Multi-Head Attention as Mixture-of-Head Attention](https://arxiv.org/abs/2410.11842) (Peking)
- [ ] [\[2410.11878\] Neural Metamorphosis](https://arxiv.org/abs/2410.11878) (NUS, ECCV)
- [ ] [\[2410.11934\] Dual-frame Fluid Motion Estimation with Test-time Optimization and Zero-divergence Loss](https://arxiv.org/abs/2410.11934) (UCAS, NIPS)
- [ ] [\[2410.12053\] SOE: SO(3)-Equivariant 3D MRI Encoding](https://arxiv.org/abs/2410.12053) (Stanford)
- [ ] [\[2410.12158\] SAM-Guided Masked Token Prediction for 3D Scene Understanding](https://arxiv.org/abs/2410.12158) (NIPS)
- [ ] [\[2410.12183\] TransAgent: Transfer Vision-Language Foundation Models with Heterogeneous Agent Collaboration](https://arxiv.org/abs/2410.12183) (NIPS)
- [ ] [\[2410.12269\] LoD-Loc: Aerial Visual Localization using LoD 3D Map with Neural Wireframe Alignment](https://arxiv.org/abs/2410.12269) (NUDT, NIPS)
- [ ] [\[2410.12332\] MC-Bench: A Benchmark for Multi-Context Visual Grounding in the Era of MLLMs](https://arxiv.org/abs/2410.12332) (ZJU)
- [ ] [\[2410.12337\] ARIC: An Activity Recognition Dataset in Classroom Surveillance Images](https://arxiv.org/abs/2410.12337) (UESTC)
- [ ] [\[2410.12369\] Context-Infused Visual Grounding for Art](https://arxiv.org/abs/2410.12369) (UVA.NL)
- [ ] [\[2410.12372\] GAN Based Top-Down View Synthesis in Reinforcement Learning Environments](https://arxiv.org/abs/2410.12372) (UMD)
- [ ] [\[2410.12379\] Stylistic Multi-Task Analysis of Ukiyo-e Woodblock Prints](https://arxiv.org/abs/2410.12379) (UVA.NL)
- [ ] [\[2410.12394\] Real-time Stereo-based 3D Object Detection for Streaming Perception](https://arxiv.org/abs/2410.12394) (SYSU, NIPS)
- [ ] [\[2410.12474\] Mind the Gap Between Prototypes and Images in Cross-domain Finetuning](https://arxiv.org/abs/2410.12474) (USyd)
- [ ] [\[2410.12490\] Stabilize the Latent Space for Image Autoregressive Modeling: A Unified Perspective](https://arxiv.org/abs/2410.12490) (USTC, NIPS)
- [ ] [\[2410.12501\] DH-VTON: Deep Text-Driven Virtual Try-On via Hybrid Attention Learning](https://arxiv.org/abs/2410.12501) (BIT)
- [ ] [\[2410.12524\] MambaPainter: Neural Stroke-Based Rendering in a Single Step](https://arxiv.org/abs/2410.12524) (SIGGRAPH)
- [ ] [\[2410.12564\] FTII-Bench: A Comprehensive Multimodal Benchmark for Flow Text with Image Insertion](https://arxiv.org/abs/2410.12564) (SJTU)
- [ ] [\[2410.12591\] Rethinking Visual Counterfactual Explanations Through Region Constraint](https://arxiv.org/abs/2410.12591) (UW)
- [ ] [\[2410.12595\] CMAL: A Novel Cross-Modal Associative Learning Framework for Vision-Language Pre-Training](https://arxiv.org/abs/2410.12595) (HUST)
- [ ] [\[2410.12692\] Machine learning approach to brain tumor detection and classification](https://arxiv.org/abs/2410.12692) (MIT)
- [ ] [\[2410.12696\] AdaptiveDrag: Semantic-Driven Dragging on Diffusion-Based Image Editing](https://arxiv.org/abs/2410.12696) (Alibaba)
- [ ] [\[2410.12700\] Embedding an Ethical Mind: Aligning Text-to-Image Synthesis via Lightweight Value Optimization](https://arxiv.org/abs/2410.12700) (Tsinghua, ACMMM)
- [ ] [\[2410.12763\] Gravity-aligned Rotation Averaging with Circular Regression](https://arxiv.org/abs/2410.12763) (ECCV)
- [ ] [\[2410.12790\] Dual Prototype Evolving for Test-Time Generalization of Vision-Language Models](https://arxiv.org/abs/2410.12790) (NIPS)
- [ ] [\[2410.12816\] Rethinking Misalignment in Vision-Language Model Adaptation from a Causal Perspective](https://arxiv.org/abs/2410.12816) (NIPS)
- [ ] [\[2410.12928\] DreamCraft3D++: Efficient Hierarchical 3D Generation with Multi-Plane Reconstruction Model](https://arxiv.org/abs/2410.12928) (Tsinghua)
- [ ] [\[2410.13016\] Interpreting and Analyzing CLIP's Zero-Shot Image Classification via Mutual Knowledge](https://arxiv.org/abs/2410.13016) (NIPS)
- [ ] [\[2410.13027\] Geometric Trajectory Diffusion Models](https://arxiv.org/abs/2410.13027) (Stanford, NIPS)
- [ ] [\[2410.13094\] Task Consistent Prototype Learning for Incremental Few-shot Semantic Segmentation](https://arxiv.org/abs/2410.13094) (UTS)
- [ ] [\[2410.13122\] Boosting Imperceptibility of Stable Diffusion-based Adversarial Examples Generation with Momentum](https://arxiv.org/abs/2410.13122) (GIT)
- [ ] [\[2410.13242\] Fundus to Fluorescein Angiography Video Generation as a Retinal Generative Foundation Model](https://arxiv.org/abs/2410.13242) (PolyU)
- [ ] [\[2410.13311\] Enhancing Dataset Distillation via Label Inconsistency Elimination and Learning Pattern Refinement](https://arxiv.org/abs/2410.13311) (NTU, ECCV)
- [ ] [\[2410.13360\] Remember, Retrieve and Generate: Understanding Infinite Visual Concepts as Your Personalized Assistant](https://arxiv.org/abs/2410.13360) (CUHK)
- [ ] [\[2410.13370\] MagicTailor: Component-Controllable Personalization in Text-to-Image Diffusion Models](https://arxiv.org/abs/2410.13370) (CUHK)
- [ ] [\[2410.13437\] Temporal-Enhanced Multimodal Transformer for Referring Multi-Object Tracking and Segmentation](https://arxiv.org/abs/2410.13437) (NUDT)
- [ ] [\[2410.13486\] SemSim: Revisiting Weak-to-Strong Consistency from a Semantic Similarity Perspective for Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2410.13486) (ZJU)
- [ ] [\[2410.13500\] SAda-Net: A Self-Supervised Adaptive Stereo Estimation CNN For Remote Sensing Image Data](https://arxiv.org/abs/2410.13500) (DLR)
- [ ] [\[2410.13523\] Can Medical Vision-Language Pre-training Succeed with Purely Synthetic Data?](https://arxiv.org/abs/2410.13523) (Imperial)
- [ ] [\[2410.13530\] L3DG: Latent 3D Gaussian Diffusion](https://arxiv.org/abs/2410.13530) (SIGGRAPH)
- [ ] [\[2410.13532\] RemoteDet-Mamba: A Hybrid Mamba-CNN Network for Multi-modal Object Detection in Remote Sensing Images](https://arxiv.org/abs/2410.13532) (BUPT)
- [ ] [\[2410.13571\] DriveDreamer4D: World Models Are Effective Data Machines for 4D Driving Scene Representation](https://arxiv.org/abs/2410.13571) (IA CAS)
- [ ] [\[2410.13585\] Pseudo Dataset Generation for Out-of-Domain Multi-Camera View Recommendation](https://arxiv.org/abs/2410.13585) (Illinois)
- [ ] [\[2410.13598\] Let Me Finish My Sentence: Video Temporal Grounding with Holistic Text Understanding](https://arxiv.org/abs/2410.13598) (KAIST, ACMMM)
- [ ] [\[2410.13607\] DN-4DGS: Denoised Deformable Network with Temporal-Spatial Aggregation for Dynamic Scene Rendering](https://arxiv.org/abs/2410.13607) (NIPS)
- [ ] [\[2410.13613\] MEGA: Memory-Efficient 4D Gaussian Splatting for Dynamic Scenes](https://arxiv.org/abs/2410.13613) (NYU)
- [ ] [\[2410.13618\] LoLDU: Low-Rank Adaptation via Lower-Diag-Upper Decomposition for Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2410.13618) (UESTC)
- [ ] [\[2410.13685\] Label-free prediction of fluorescence markers in bovine satellite cells using deep learning](https://arxiv.org/abs/2410.13685) (Michigan State University)
- [ ] [\[2410.13726\] DAWN: Dynamic Frame Avatar with Non-autoregressive Diffusion Framework for Talking Head Video Generation](https://arxiv.org/abs/2410.13726) (USTC)
- [ ] [\[2410.13786\] Emphasizing Semantic Consistency of Salient Posture for Speech-Driven Gesture Generation](https://arxiv.org/abs/2410.13786) (SJTU)
- [ ] [\[2410.13823\] Deep Generative Models Unveil Patterns in Medical Images Through Vision-Language Conditioning](https://arxiv.org/abs/2410.13823) (Imperial)
- [ ] [\[2410.13824\] Harnessing Webpage UIs for Text-Rich Visual Understanding](https://arxiv.org/abs/2410.13824) (CUHK)
- [ ] [\[2410.13832\] VidPanos: Generative Panoramic Videos from Casual Panning Videos](https://arxiv.org/abs/2410.13832) (SIGGRAPH)
- [ ] [\[2410.13924\] ARKit LabelMaker: A New Scale for Indoor 3D Scene Understanding](https://arxiv.org/abs/2410.13924) (ETH)
- [ ] [\[2410.13989\] Reproducibility study of "LICO: Explainable Models with Language-Image Consistency"](https://arxiv.org/abs/2410.13989) (UVA.NL)
- [ ] [\[2410.14138\] ProReason: Multi-Modal Proactive Reasoning with Decoupled Eyesight and Wisdom](https://arxiv.org/abs/2410.14138) (XJTU)
- [ ] [\[2410.14143\] Preview-based Category Contrastive Learning for Knowledge Distillation](https://arxiv.org/abs/2410.14143) (Peking)
- [ ] [\[2410.14169\] DaRePlane: Direction-aware Representations for Dynamic Scene Reconstruction](https://arxiv.org/abs/2410.14169) (Vanderbilt University)
- [ ] [\[2410.14189\] Neural Signed Distance Function Inference through Splatting 3D Gaussians Pulled on Zero-Level Set](https://arxiv.org/abs/2410.14189) (Tsinghua, NIPS)
- [ ] [\[2410.14195\] Rethinking Transformer for Long Contextual Histopathology Whole Slide Image Analysis](https://arxiv.org/abs/2410.14195) (NIPS)
- [ ] [\[2410.14210\] Shape Transformation Driven by Active Contour for Class-Imbalanced Semi-Supervised Medical Image Segmentation](https://arxiv.org/abs/2410.14210) (WHU)
- [ ] [\[2410.14214\] MambaSCI: Efficient Mamba-UNet for Quad-Bayer Patterned Video Snapshot Compressive Imaging](https://arxiv.org/abs/2410.14214) (NIPS)
- [ ] [\[2410.14238\] Storyboard guided Alignment for Fine-grained Video Action Recognition](https://arxiv.org/abs/2410.14238) (BIT)
- [ ] [\[2410.14324\] HiCo: Hierarchical Controllable Diffusion Model for Layout-to-image Generation](https://arxiv.org/abs/2410.14324) (NIPS)
- [ ] [\[2410.14340\] Zero-shot Action Localization via the Confidence of Large Vision-Language Models](https://arxiv.org/abs/2410.14340) (Stanford)
- [ ] [\[2410.14379\] AnomalyNCD: Towards Novel Anomaly Class Discovery in Industrial Scenarios](https://arxiv.org/abs/2410.14379) (HUST)
- [ ] [\[2410.14398\] Dynamic Negative Guidance of Diffusion Models](https://arxiv.org/abs/2410.14398) (ICLR)
- [ ] [\[2410.14429\] FashionR2R: Texture-preserving Rendered-to-Real Image Translation with Diffusion Models](https://arxiv.org/abs/2410.14429) (NIPS)
- [ ] [\[2410.14445\] Toward Generalizing Visual Brain Decoding to Unseen Subjects](https://arxiv.org/abs/2410.14445) (PolyU)
- [ ] [\[2410.14633\] Swiss Army Knife: Synergizing Biases in Knowledge from Vision Foundation Models for Multi-Task Learning](https://arxiv.org/abs/2410.14633) (SJTU)
- [ ] [\[2410.14669\] NaturalBench: Evaluating Vision-Language Models on Natural Adversarial Samples](https://arxiv.org/abs/2410.14669) (NIPS)
- [ ] [\[2410.14672\] BiGR: Harnessing Binary Latent Codes for Image Generation and Improved Visual Representation Capabilities](https://arxiv.org/abs/2410.14672) (HKU)
- [ ] [\[2410.14705\] Optimizing Parking Space Classification: Distilling Ensembles into Lightweight Classifiers](https://arxiv.org/abs/2410.14705) (ICML)
- [ ] [\[2410.14770\] A Survey on Computational Solutions for Reconstructing Complete Objects by Reassembling Their Fractured Parts](https://arxiv.org/abs/2410.14770) (UT Austin)
- [ ] [\[2410.14980\] DCDepth: Progressive Monocular Depth Estimation in Discrete Cosine Domain](https://arxiv.org/abs/2410.14980) (NIPS)
- [ ] [\[2410.15007\] DiffuseST: Unleashing the Capability of the Diffusion Model for Style Transfer](https://arxiv.org/abs/2410.15007) (ACMMM)
- [ ] [\[2410.15015\] MambaSOD: Dual Mamba-Driven Cross-Modal Fusion Network for RGB-D Salient Object Detection](https://arxiv.org/abs/2410.15015) (Chongqing)
- [ ] [\[2410.15038\] A General-Purpose Multimodal Foundation Model for Dermatology](https://arxiv.org/abs/2410.15038) (Queensland)
- [ ] [\[2410.15229\] Deep Learning-based Detection of Bacterial Swarm Motion Using a Single Image](https://arxiv.org/abs/2410.15229) (UCLA)
- [ ] [\[2410.15266\] GSSF: Generalized Structural Sparse Function for Deep Cross-modal Metric Learning](https://arxiv.org/abs/2410.15266) (HKUST, TIP)
- [ ] [\[2410.15279\] ContextDet: Temporal Action Detection with Adaptive Context Aggregation](https://arxiv.org/abs/2410.15279) (Rochester Institute of Technology)
- [ ] [\[2410.15312\] Synergistic Dual Spatial-aware Generation of Image-to-Text and Text-to-Image](https://arxiv.org/abs/2410.15312) (Tianjin)
- [ ] [\[2410.15364\] Scene Graph Generation with Role-Playing Large Language Models](https://arxiv.org/abs/2410.15364) (NIPS)
- [ ] [\[2410.15385\] LoRA-IR: Taming Low-Rank Experts for Efficient All-in-One Image Restoration](https://arxiv.org/abs/2410.15385) (IA CAS)
- [ ] [\[2410.15403\] MMCS: A Multimodal Medical Diagnosis System Integrating Image Analysis and Knowledge-based Departmental Consultation](https://arxiv.org/abs/2410.15403) (Xidian)
- [ ] [\[2410.15430\] BoostAdapter: Improving Vision-Language Test-Time Adaptation via Regional Bootstrapping](https://arxiv.org/abs/2410.15430) (NIPS)
- [ ] [\[2410.15432\] MedDiff-FM: A Diffusion-based Foundation Model for Versatile Medical Image Applications](https://arxiv.org/abs/2410.15432) (SenseTime)
- [ ] [\[2410.15446\] Concept Complement Bottleneck Model for Interpretable Medical Image Diagnosis](https://arxiv.org/abs/2410.15446) (HKUST)
- [ ] [\[2410.15475\] Generalized Multimodal Fusion via Poisson-Nernst-Planck Equation](https://arxiv.org/abs/2410.15475) (NIPS)
- [ ] [\[2410.15581\] Multimodal Learning for Embryo Viability Prediction in Clinical IVF](https://arxiv.org/abs/2410.15581) (Harvard)
- [ ] [\[2410.15584\] Deep Learning and Machine Learning -- Object Detection and Semantic Segmentation: From Theory to Applications](https://arxiv.org/abs/2410.15584) (GIT)
- [ ] [\[2410.15615\] Joint Top-Down and Bottom-Up Frameworks for 3D Visual Grounding](https://arxiv.org/abs/2410.15615) (Peking)
- [ ] [\[2410.15629\] Fully Explicit Dynamic Gaussian Splatting](https://arxiv.org/abs/2410.15629) (NIPS)
- [ ] [\[2410.15674\] TALoS: Enhancing Semantic Scene Completion via Test-time Adaptation on the Line of Sight](https://arxiv.org/abs/2410.15674) (KAIST, NIPS)
- [ ] [\[2410.15682\] RANSAC Back to SOTA: A Two-stage Consensus Filtering for Real-time 3D Registration](https://arxiv.org/abs/2410.15682) (WHU)
- [ ] [\[2410.15689\] Enhancing SNN-based Spatio-Temporal Learning: A Benchmark Dataset and Cross-Modality Attention Model](https://arxiv.org/abs/2410.15689) (ZJU)
- [ ] [\[2410.15701\] Students Rather Than Experts: A New AI For Education Pipeline To Model More Human-Like And Personalised Early Adolescences](https://arxiv.org/abs/2410.15701) (NTU)
- [ ] [\[2410.15728\] Object-Centric Temporal Consistency via Conditional Autoregressive Inductive Biases](https://arxiv.org/abs/2410.15728) (University of Tokyo)
- [ ] [\[2410.15732\] ViMoE: An Empirical Study of Designing Vision Mixture-of-Experts](https://arxiv.org/abs/2410.15732) (UCAS)
- [ ] [\[2410.15760\] DeepIcon: A Hierarchical Network for Layer-wise Icon Vectorization](https://arxiv.org/abs/2410.15760) (USyd)
- [ ] [\[2410.15780\] An Efficient System for Automatic Map Storytelling -- A Case Study on Historical Maps](https://arxiv.org/abs/2410.15780) (ETH)
- [ ] [\[2410.15814\] Kaninfradet3D:A Road-side Camera-LiDAR Fusion 3D Perception Model based on Nonlinear Feature Extraction and Intrinsic Correlation](https://arxiv.org/abs/2410.15814) (HKUST(GZ))
- [ ] [\[2410.15919\] Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?](https://arxiv.org/abs/2410.15919) (A*STAR,, NIPS)
- [ ] [\[2410.15926\] Mitigating Object Hallucination via Concentric Causal Attention](https://arxiv.org/abs/2410.15926) (NIPS)
- [ ] [\[2410.15941\] MBPU: A Plug-and-Play State Space Model for Point Cloud Upsamping with Fast Point Rendering](https://arxiv.org/abs/2410.15941) (Fudan)
- [ ] [\[2410.15971\] Zero-Shot Scene Reconstruction from Single Images with Deep Prior Assembly](https://arxiv.org/abs/2410.15971) (Tsinghua, NIPS)
- [ ] [\[2410.15981\] Visual Representation Learning Guided By Multi-modal Prior Knowledge](https://arxiv.org/abs/2410.15981) (Bosch)
- [ ] [\[2410.16020\] START: A Generalized State Space Model with Saliency-Driven Token-Aware Transformation](https://arxiv.org/abs/2410.16020) (NJU, NIPS)
- [ ] [\[2410.16037\] Improving the Multi-label Atomic Activity Recognition by Robust Visual Feature and Advanced Attention @ ROAD++ Atomic Activity Recognition 2024](https://arxiv.org/abs/2410.16037) (Xidian)
- [ ] [\[2410.16057\] Label Filling via Mixed Supervision for Medical Image Segmentation from Noisy Annotations](https://arxiv.org/abs/2410.16057) (SJTU)
- [ ] [\[2410.16095\] LMHaze: Intensity-aware Image Dehazing with a Large-scale Multi-intensity Real Haze Dataset](https://arxiv.org/abs/2410.16095) (BIT)
- [ ] [\[2410.16162\] Sparkle: Mastering Basic Spatial Capabilities in Vision Language Models Elicits Generalization to Composite Spatial Reasoning](https://arxiv.org/abs/2410.16162) (HKU)
- [ ] [\[2410.16166\] Beyond Filtering: Adaptive Image-Text Quality Enhancement for MLLM Pretraining](https://arxiv.org/abs/2410.16166) (IA CAS)
- [ ] [\[2410.16177\] A Framework for Evaluating Predictive Models Using Synthetic Image Covariates and Longitudinal Data](https://arxiv.org/abs/2410.16177) (Cambridge)
- [ ] [\[2410.16255\] Revisiting Deep Feature Reconstruction for Logical and Structural Industrial Anomaly Detection](https://arxiv.org/abs/2410.16255) (MBZUAI)
- [ ] [\[2410.16257\] Elucidating the design space of language models for image generation](https://arxiv.org/abs/2410.16257) (HKUST)
- [ ] [\[2410.16266\] 3DGS-Enhancer: Enhancing Unbounded 3D Gaussian Splatting with View-consistent 2D Diffusion Priors](https://arxiv.org/abs/2410.16266) (NIPS)
- [ ] [\[2410.16267\] xGen-MM-Vid (BLIP-3-Video): You Only Need 32 Tokens to Represent a Video Even in VLMs](https://arxiv.org/abs/2410.16267) (Salesforce)
- [ ] [\[2410.16602\] Foundation Models for Remote Sensing and Earth Observation: A Survey](https://arxiv.org/abs/2410.16602) (NTU)
- [ ] [\[2410.16707\] DI-MaskDINO: A Joint Object Detection and Instance Segmentation Model](https://arxiv.org/abs/2410.16707) (Chongqing, NIPS)
- [ ] [\[2410.16719\] Progressive Compositionality In Text-to-Image Generative Models](https://arxiv.org/abs/2410.16719) (MIT)
- [ ] [\[2410.16732\] Polyp-E: Benchmarking the Robustness of Deep Segmentation Models via Polyp Editing](https://arxiv.org/abs/2410.16732) (BUPT)
- [ ] [\[2410.16794\] One-Step Diffusion Distillation through Score Implicit Matching](https://arxiv.org/abs/2410.16794) (Peking, NIPS)
- [ ] [\[2410.16892\] VistaDream: Sampling multiview consistent images for single-view scene reconstruction](https://arxiv.org/abs/2410.16892) (HKUST)
- [ ] [\[2410.16910\] Hierarchical Clustering for Conditional Diffusion in Image Generation](https://arxiv.org/abs/2410.16910) (ETH, ICLR)
- [ ] [\[2410.16942\] DiP-GO: A Diffusion Pruner via Few-step Gradient Optimization](https://arxiv.org/abs/2410.16942) (Tsinghua)
- [ ] [\[2410.16995\] E-3DGS: Gaussian Splatting with Exposure and Motion Events](https://arxiv.org/abs/2410.16995) (ZJU)
- [ ] [\[2410.16999\] AGSENet: A Robust Road Ponding Detection Method for Proactive Traffic Safety](https://arxiv.org/abs/2410.16999) (SYSU)
- [ ] [\[2410.17001\] Joint Point Cloud Upsampling and Cleaning with Octree-based CNNs](https://arxiv.org/abs/2410.17001) (Peking)
- [ ] [\[2410.17136\] AlphaChimp: Tracking and Behavior Recognition of Chimpanzees](https://arxiv.org/abs/2410.17136) (Peking)
- [ ] [\[2410.17144\] YOLO-TS: Real-Time Traffic Sign Detection with Enhanced Accuracy Using Optimized Receptive Fields and Anchor-Free Fusion](https://arxiv.org/abs/2410.17144) (SYSU)
- [ ] [\[2410.17207\] EPContrast: Effective Point-level Contrastive Learning for Large-scale Point Cloud Understanding](https://arxiv.org/abs/2410.17207) (Peking)
- [ ] [\[2410.17331\] Offline Evaluation of Set-Based Text-to-Image Generation](https://arxiv.org/abs/2410.17331) (Google)
- [ ] [\[2410.17393\] Denoise-I2W: Mapping Images to Denoising Words for Accurate Zero-Shot Composed Image Retrieval](https://arxiv.org/abs/2410.17393) (BIT)
- [ ] [\[2410.17434\] LongVU: Spatiotemporal Adaptive Compression for Long Video-Language Understanding](https://arxiv.org/abs/2410.17434) (Meta)
- [ ] [\[2410.17489\] Unsupervised Domain Adaptation for Action Recognition via Self-Ensembling and Conditional Embedding Alignment](https://arxiv.org/abs/2410.17489) (AWS)
- [ ] [\[2410.17521\] Diffusion Priors for Variational Likelihood Estimation and Image Denoising](https://arxiv.org/abs/2410.17521) (HUST, NIPS)
- [ ] [\[2410.17534\] OVT-B: A New Large-Scale Benchmark for Open-Vocabulary Multi-Object Tracking](https://arxiv.org/abs/2410.17534) (ZJU, NIPS)
- [ ] [\[2410.17594\] How to Continually Adapt Text-to-Image Diffusion Models for Flexible Customization?](https://arxiv.org/abs/2410.17594) (NIPS)
- [ ] [\[2410.17606\] Towards Effective Data-Free Knowledge Distillation via Diverse Diffusion Augmentation](https://arxiv.org/abs/2410.17606) (UESTC)
- [ ] [\[2410.17637\] MIA-DPO: Multi-Image Augmented Direct Preference Optimization For Large Vision-Language Models](https://arxiv.org/abs/2410.17637) (SJTU)
- [ ] [\[2410.17642\] Surgical Scene Segmentation by Transformer With Asymmetric Feature Enhancement](https://arxiv.org/abs/2410.17642) (SJTU)
- [ ] [\[2410.17734\] YOLO-Vehicle-Pro: A Cloud-Edge Collaborative Framework for Object Detection in Autonomous Driving under Adverse Weather Conditions](https://arxiv.org/abs/2410.17734) (USTC)
- [ ] [\[2410.17752\] AdaDiffSR: Adaptive Region-aware Dynamic Acceleration Diffusion Model for Real-World Image Super-Resolution](https://arxiv.org/abs/2410.17752) (XJTU, ECCV)
- [ ] [\[2410.17802\] GenUDC: High Quality 3D Mesh Generation with Unsigned Dual Contouring Representation](https://arxiv.org/abs/2410.17802) (SUSTech, ACMMM)
- [ ] [\[2410.17809\] An Intelligent Agentic System for Complex Image Restoration Problems](https://arxiv.org/abs/2410.17809) (Shanghai AI Lab)
- [ ] [\[2410.17810\] EntityCLIP: Entity-Centric Image-Text Matching via Multimodal Attentive Contrastive Learning](https://arxiv.org/abs/2410.17810) (XJTU)
- [ ] [\[2410.17822\] DREB-Net: Dual-stream Restoration Embedding Blur-feature Fusion Network for High-mobility UAV Object Detection](https://arxiv.org/abs/2410.17822) (TUM)
- [ ] [\[2410.17832\] Exploiting Text-Image Latent Spaces for the Description of Visual Concepts](https://arxiv.org/abs/2410.17832) (DLR)
- [ ] [\[2410.17839\] Few-shot NeRF by Adaptive Rendering Loss Regularization](https://arxiv.org/abs/2410.17839) (ECCV)
- [ ] [\[2410.17918\] Addressing Asynchronicity in Clinical Multimodal Fusion via Individualized Chest X-ray Generation](https://arxiv.org/abs/2410.17918) (BU, NIPS)
- [ ] [\[2410.17920\] Gaze-Assisted Medical Image Segmentation](https://arxiv.org/abs/2410.17920) (University of Copenhagen)
- [ ] [\[2410.18195\] Personalized Instance-based Navigation Toward User-Specific Objects in Realistic Environments](https://arxiv.org/abs/2410.18195) (NIPS)
- [ ] [\[2410.18355\] Real-time 3D-aware Portrait Video Relighting](https://arxiv.org/abs/2410.18355) (ICT CAS, CVPR)
- [ ] [\[2410.18387\] Interpretable Bilingual Multimodal Large Language Model for Diverse Biomedical Tasks](https://arxiv.org/abs/2410.18387) (HKUST)
- [ ] [\[2410.18398\] You Only Look Around: Learning Illumination Invariant Feature for Low-light Object Detection](https://arxiv.org/abs/2410.18398) (UESTC, NIPS)
- [ ] [\[2410.18408\] Scale Propagation Network for Generalizable Depth Completion](https://arxiv.org/abs/2410.18408) (XJTU, TPAMI)
- [ ] [\[2410.18410\] FreCaS: Efficient Higher-Resolution Image Generation via Frequency-aware Cascaded Sampling](https://arxiv.org/abs/2410.18410) (PolyU)
- [ ] [\[2410.18490\] Synth4Seg -- Learning Defect Data Synthesis for Defect Segmentation using Bi-level Optimization](https://arxiv.org/abs/2410.18490) (GIT)
- [ ] [\[2410.18539\] Interpretable Representation Learning from Videos using Nonlinear Priors](https://arxiv.org/abs/2410.18539) (Oxford)
- [ ] [\[2410.18615\] FairQueue: Rethinking Prompt Learning for Fair Text-to-Image Generation](https://arxiv.org/abs/2410.18615) (NIPS)
- [ ] [\[2410.18630\] A Cranial-Feature-Based Registration Scheme for Robotic Micromanipulation Using a Microscopic Stereo Camera System](https://arxiv.org/abs/2410.18630) (University of Tokyo)
- [ ] [\[2410.18695\] PESFormer: Boosting Macro- and Micro-expression Spotting with Direct Timestamp Encoding](https://arxiv.org/abs/2410.18695) (UESTC)
- [ ] [\[2410.18715\] ChatSearch: a Dataset and a Generative Retrieval Model for General Conversational Image Retrieval](https://arxiv.org/abs/2410.18715) (IA CAS)
- [ ] [\[2410.18756\] Schedule Your Edit: A Simple yet Effective Diffusion Noise Schedule for Image Editing](https://arxiv.org/abs/2410.18756) (NIPS)
- [ ] [\[2410.18775\] Robust Watermarking Using Generative Priors Against Image Editing: From Benchmarking to Advances](https://arxiv.org/abs/2410.18775) (NTU)
- [ ] [\[2410.18804\] Fast constrained sampling in pre-trained diffusion models](https://arxiv.org/abs/2410.18804) (Microsoft)
- [ ] [\[2410.18809\] Learning Global Object-Centric Representations via Disentangled Slot Attention](https://arxiv.org/abs/2410.18809) (Fudan)
- [ ] [\[2410.18822\] Binocular-Guided 3D Gaussian Splatting with View Consistency for Sparse View Synthesis](https://arxiv.org/abs/2410.18822) (Tsinghua, NIPS)
- [ ] [\[2410.18881\] Diff-Instruct++: Training One-step Text-to-image Generator Model to Align with Human Preferences](https://arxiv.org/abs/2410.18881) (Peking)
- [ ] [\[2410.18962\] Where Am I and What Will I See: An Auto-Regressive Model for Spatial Localization and View Prediction](https://arxiv.org/abs/2410.18962) (SJTU)
- [ ] [\[2410.18979\] PixelGaussian: Generalizable 3D Gaussian Reconstruction from Arbitrary Views](https://arxiv.org/abs/2410.18979) (Tsinghua)
- [ ] [\[2410.19213\] Prototypical Hash Encoding for On-the-Fly Fine-Grained Category Discovery](https://arxiv.org/abs/2410.19213) (NIPS)
- [ ] [\[2410.19239\] Prompting Continual Person Search](https://arxiv.org/abs/2410.19239) (ACMMM)
- [ ] [\[2410.19294\] Enhancing Zero-Shot Vision Models by Label-Free Prompt Distribution Learning and Bias Correcting](https://arxiv.org/abs/2410.19294) (USTC, NIPS)
- [ ] [\[2410.19310\] Flow Generator Matching](https://arxiv.org/abs/2410.19310) (ZJU)
- [ ] [\[2410.19324\] Simpler Diffusion (SiD2): 1.5 FID on ImageNet512 with pixel-space diffusion](https://arxiv.org/abs/2410.19324) (Google)
- [ ] [\[2410.19424\] Paint Bucket Colorization Using Anime Character Color Design Sheets](https://arxiv.org/abs/2410.19424) (NTU)
- [ ] [\[2410.19483\] Content-Aware Radiance Fields: Aligning Model Complexity with Scene Intricacy Through Learned Bitwidth Quantization](https://arxiv.org/abs/2410.19483) (ECCV)
- [ ] [\[2410.19486\] x-RAGE: eXtended Reality -- Action & Gesture Events Dataset](https://arxiv.org/abs/2410.19486) (Meta)
- [ ] [\[2410.19573\] FastPCI: Motion-Structure Guided Fast Point Cloud Frame Interpolation](https://arxiv.org/abs/2410.19573) (Nankai, ECCV)
- [ ] [\[2410.19590\] MonoDGP: Monocular 3D Object Detection with Decoupled-Query and Geometry-Error Priors](https://arxiv.org/abs/2410.19590) (Tsinghua)
- [ ] [\[2410.19604\] Microplastic Identification Using AI-Driven Image Segmentation and GAN-Generated Ecological Context](https://arxiv.org/abs/2410.19604) (Stanford)
- [ ] [\[2410.19635\] Frozen-DETR: Enhancing DETR with Image Understanding from Frozen Foundation Models](https://arxiv.org/abs/2410.19635) (SYSU, NIPS)
- [ ] [\[2410.19657\] DiffGS: Functional Gaussian Splatting Diffusion](https://arxiv.org/abs/2410.19657) (Tsinghua, NIPS)
- [ ] [\[2410.19680\] Inferring Neural Signed Distance Functions by Overfitting on Single Noisy Point Clouds through Finetuning Data-Driven based Priors](https://arxiv.org/abs/2410.19680) (Tsinghua)
- [ ] [\[2410.19759\] PINNing Cerebral Blood Flow: Analysis of Perfusion MRI in Infants using Physics-Informed Neural Networks](https://arxiv.org/abs/2410.19759) (Imperial)
- [ ] [\[2410.19766\] Large Model for Small Data: Foundation Model for Cross-Modal RF Human Activity Recognition](https://arxiv.org/abs/2410.19766) (NTU)
- [ ] [\[2410.19786\] Resolution Enhancement of Under-sampled Photoacoustic Microscopy Images using Implicit Neural Representations](https://arxiv.org/abs/2410.19786) (ShanghaiTech)
- [ ] [\[2410.19796\] Feature Clipping for Uncertainty Calibration](https://arxiv.org/abs/2410.19796) (USyd)
- [ ] [\[2410.19816\] DivShift: Exploring Domain-Specific Distribution Shift in Volunteer-Collected Biodiversity Datasets](https://arxiv.org/abs/2410.19816) (Berkeley)
- [ ] [\[2410.19831\] GL-NeRF: Gauss-Laguerre Quadrature Enables Training-Free NeRF Acceleration](https://arxiv.org/abs/2410.19831) (NIPS)
- [ ] [\[2410.19836\] Upsampling DINOv2 features for unsupervised vision tasks and weakly supervised materials segmentation](https://arxiv.org/abs/2410.19836) (Imperial)
- [ ] [\[2410.19896\] FLAASH: Flow-Attention Adaptive Semantic Hierarchical Fusion for Multi-Modal Tobacco Content Analysis](https://arxiv.org/abs/2410.19896) (CMU)
- [ ] [\[2410.19932\] Tracking and triangulating firefly flashes in field recordings](https://arxiv.org/abs/2410.19932) (Cornell)
- [ ] [\[2410.20030\] SCube: Instant Large-Scale Scene Reconstruction using VoxSplats](https://arxiv.org/abs/2410.20030) (NIPS)
- [ ] [\[2410.20047\] ResAD: A Simple Framework for Class Generalizable Anomaly Detection](https://arxiv.org/abs/2410.20047) (NIPS)
- [ ] [\[2410.20055\] 3D Distance-color-coded Assessment of PCI Stent Apposition via Deep-learning-based Three-dimensional Multi-object Segmentation](https://arxiv.org/abs/2410.20055) (UESTC)
- [ ] [\[2410.20079\] SFTrack: A Robust Scale and Motion Adaptive Algorithm for Tracking Small and Fast Moving Objects](https://arxiv.org/abs/2410.20079) (Sungkyunkwan University)
- [ ] [\[2410.20084\] UniVST: A Unified Framework for Training-free Localized Video Style Transfer](https://arxiv.org/abs/2410.20084) (Xiamen)
- [ ] [\[2410.20097\] Generative Adversarial Patches for Physical Attacks on Cross-Modal Pedestrian Re-Identification](https://arxiv.org/abs/2410.20097) (Xidian)
- [ ] [\[2410.20126\] Semantic Feature Decomposition based Semantic Communication System of Images with Large-scale Visual Generation Models](https://arxiv.org/abs/2410.20126) (BUPT)
- [ ] [\[2410.20149\] AdaNeg: Adaptive Negative Proxy Guided OOD Detection with Vision-Language Models](https://arxiv.org/abs/2410.20149) (PolyU, NIPS)
- [ ] [\[2410.20155\] Human-Object Interaction Detection Collaborated with Large Relation-driven Diffusion Models](https://arxiv.org/abs/2410.20155) (NIPS)
- [ ] [\[2410.20158\] Your Image is Secretly the Last Frame of a Pseudo Video](https://arxiv.org/abs/2410.20158) (Imperial)
- [ ] [\[2410.20252\] Adaptive Video Understanding Agent: Enhancing efficiency with dynamic frame sampling and feedback-driven reasoning](https://arxiv.org/abs/2410.20252) (Illinois)
- [ ] [\[2410.20294\] Harmony4D: A Video Dataset for In-The-Wild Close Human Interactions](https://arxiv.org/abs/2410.20294) (NIPS)
- [ ] [\[2410.20346\] Historical Test-time Prompt Tuning for Vision Foundation Models](https://arxiv.org/abs/2410.20346) (NIPS)
- [ ] [\[2410.20349\] Idempotent Unsupervised Representation Learning for Skeleton-Based Action Recognition](https://arxiv.org/abs/2410.20349) (ECCV)
- [ ] [\[2410.20371\] Open-Vocabulary Object Detection via Language Hierarchy](https://arxiv.org/abs/2410.20371) (NIPS)
- [ ] [\[2410.20389\] Lodge++: High-quality and Long Dance Generation with Vivid Choreography Patterns](https://arxiv.org/abs/2410.20389) (Tsinghua)
- [ ] [\[2410.20395\] Depth Attention for Robust RGB Tracking](https://arxiv.org/abs/2410.20395) (MBZUAI)
- [ ] [\[2410.20406\] Point-PRC: A Prompt Learning Based Regulation Framework for Generalizable Point Cloud Analysis](https://arxiv.org/abs/2410.20406) (NIPS)
- [ ] [\[2410.20421\] NT-VOT211: A Large-Scale Benchmark for Night-time Visual Object Tracking](https://arxiv.org/abs/2410.20421) (MBZUAI)
- [ ] [\[2410.20451\] BlinkVision: A Benchmark for Optical Flow, Scene Flow and Point Tracking Estimation using RGB Frames and Events](https://arxiv.org/abs/2410.20451) (ECCV)
- [ ] [\[2410.20508\] Referring Human Pose and Mask Estimation in the Wild](https://arxiv.org/abs/2410.20508) (NIPS)
- [ ] [\[2410.20519\] Fractal and Turbulent Feature Extraction and NFT Label Generation for Pollock Style Migration Paintings Based on VGG19](https://arxiv.org/abs/2410.20519) (HIT)
- [ ] [\[2410.20535\] Asynchronous Perception Machine For Efficient Test-Time-Training](https://arxiv.org/abs/2410.20535) (NIPS)
- [ ] [\[2410.20552\] SympCam: Remote Optical Measurement of Sympathetic Arousal](https://arxiv.org/abs/2410.20552) (UW)
- [ ] [\[2410.20593\] Normal-GS: 3D Gaussian Splatting with Normal-Involved Rendering](https://arxiv.org/abs/2410.20593) (NIPS)
- [ ] [\[2410.20716\] Physics-Free Spectrally Multiplexed Photometric Stereo under Unknown Spectral Composition](https://arxiv.org/abs/2410.20716) (ECCV)
- [ ] [\[2410.20717\] Face-MLLM: A Large Face Perception Model](https://arxiv.org/abs/2410.20717) (ICT CAS)
- [ ] [\[2410.20723\] CompGS: Unleashing 2D Compositionality for Compositional Text-to-3D via Dynamically Optimizing 3D Gaussians](https://arxiv.org/abs/2410.20723) (HKU)
- [ ] [\[2410.20752\] Bidirectional Recurrence for Cardiac Motion Tracking with Gaussian Process Latent Coding](https://arxiv.org/abs/2410.20752) (NIPS)
- [ ] [\[2410.20790\] SparseTem: Boosting the Efficiency of CNN-Based Video Encoders by Exploiting Temporal Continuity](https://arxiv.org/abs/2410.20790) (Berkeley)
- [ ] [\[2410.20807\] Long-Tailed Out-of-Distribution Detection via Normalized Outlier Distribution Adaptation](https://arxiv.org/abs/2410.20807) (NIPS)
- [ ] [\[2410.20815\] Grid4D: 4D Decomposed Hash Encoding for High-fidelity Dynamic Gaussian Splatting](https://arxiv.org/abs/2410.20815) (NJU, NIPS)
- [ ] [\[2410.20823\] Novel Object Synthesis via Adaptive Text-Image Harmony](https://arxiv.org/abs/2410.20823) (Nankai, NIPS)
- [ ] [\[2410.20855\] ByteNet: Rethinking Multimedia File Fragment Classification through Visual Perspectives](https://arxiv.org/abs/2410.20855) (NTU)
- [ ] [\[2410.20882\] The unrealized potential of agroforestry for an emissions-intensive agricultural commodity](https://arxiv.org/abs/2410.20882) (Queensland)
- [ ] [\[2410.20898\] Diff-Instruct*: Towards Human-Preferred One-step Text-to-image Generative Models](https://arxiv.org/abs/2410.20898) (Peking)
- [ ] [\[2410.20971\] BlueSuffix: Reinforced Blue Teaming for Vision-Language Models Against Jailbreak Attacks](https://arxiv.org/abs/2410.20971) (Fudan)
- [ ] [\[2410.21042\] Improving Visual Prompt Tuning by Gaussian Neighborhood Minimization for Long-Tailed Visual Recognition](https://arxiv.org/abs/2410.21042) (Xiamen, NIPS)
- [ ] [\[2410.21175\] Deep Learning-Based Fatigue Cracks Detection in Bridge Girders using Feature Pyramid Networks](https://arxiv.org/abs/2410.21175) (ZJU)
- [ ] [\[2410.21299\] TV-3DG: Mastering Text-to-3D Customized Generation with Visual Prompt](https://arxiv.org/abs/2410.21299) (HIT)
- [ ] [\[2410.21300\] Contrastive Learning with Auxiliary User Detection for Identifying Activities](https://arxiv.org/abs/2410.21300) (ICML)
- [ ] [\[2410.21308\] A Robust Anchor-based Method for Multi-Camera Pedestrian Localization](https://arxiv.org/abs/2410.21308) (SJTU)
- [ ] [\[2410.21318\] Multi-path Exploration and Feedback Adjustment for Text-to-Image Person Retrieval](https://arxiv.org/abs/2410.21318) (UCAS)
- [ ] [\[2410.21361\] Domain Adaptation with a Single Vision-Language Embedding](https://arxiv.org/abs/2410.21361) (Inria)
- [ ] [\[2410.21411\] SocialGPT: Prompting LLMs for Social Relation Reasoning via Greedy Segment Optimization](https://arxiv.org/abs/2410.21411) (NIPS)
- [ ] [\[2410.21494\] Towards Multi-dimensional Explanation Alignment for Medical Classification](https://arxiv.org/abs/2410.21494) (NIPS)
- [ ] [\[2410.21535\] ECMamba: Consolidating Selective State Space Model with Retinex Guidance for Efficient Multiple Exposure Correction](https://arxiv.org/abs/2410.21535) (SJTU, NIPS)
- [ ] [\[2410.21560\] Going Beyond H&E and Oncology: How Do Histopathology Foundation Models Perform for Multi-stain IHC and Immunology?](https://arxiv.org/abs/2410.21560) (QMUL)
- [ ] [\[2410.21615\] NYC-Event-VPR: A Large-Scale High-Resolution Event-Based Visual Place Recognition Dataset in Dense Urban Environments](https://arxiv.org/abs/2410.21615) (NYU)
- [ ] [\[2410.21643\] Neural Experts: Mixture of Experts for Implicit Neural Representations](https://arxiv.org/abs/2410.21643) (NIPS)
- [ ] [\[2410.21667\] Revisiting Multi-Granularity Representation via Group Contrastive Learning for Unsupervised Vehicle Re-identification](https://arxiv.org/abs/2410.21667) (SJTU)
- [ ] [\[2410.21705\] AdaptGCD: Multi-Expert Adapter Tuning for Generalized Category Discovery](https://arxiv.org/abs/2410.21705) (Nankai)
- [ ] [\[2410.21708\] Unsupervised Modality Adaptation with Text-to-Image Diffusion Models for Semantic Segmentation](https://arxiv.org/abs/2410.21708) (NIPS)
- [ ] [\[2410.21743\] EI-Nexus: Towards Unmediated and Flexible Inter-Modality Local Feature Extraction and Matching for Event-Image Data](https://arxiv.org/abs/2410.21743) (ZJU)
- [ ] [\[2410.21758\] DOFS: A Real-world 3D Deformable Object Dataset with Full Spatial Information for Dynamics Model Learning](https://arxiv.org/abs/2410.21758) (CUHK)
- [ ] [\[2410.21802\] Text-Guided Attention is All You Need for Zero-Shot Robustness in Vision-Language Models](https://arxiv.org/abs/2410.21802) (IA CAS, NIPS)
- [ ] [\[2410.21842\] Diffusion as Reasoning: Enhancing Object Goal Navigation with LLM-Biased Diffusion Model](https://arxiv.org/abs/2410.21842) (HIT)
- [ ] [\[2410.21857\] Micro-Structures Graph-Based Point Cloud Registration for Balancing Efficiency and Accuracy](https://arxiv.org/abs/2410.21857) (WHU)
- [ ] [\[2410.21872\] Advancing Efficient Brain Tumor Multi-Class Classification -- New Insights from the Vision Mamba Model in Transfer Learning](https://arxiv.org/abs/2410.21872) (Columbia University)
- [ ] [\[2410.21966\] PrefPaint: Aligning Image Inpainting Diffusion Model with Human Preference](https://arxiv.org/abs/2410.21966) (Yale)
- [ ] [\[2410.21969\] BenchX: A Unified Benchmark Framework for Medical Vision-Language Pretraining on Chest X-Rays](https://arxiv.org/abs/2410.21969) (NIPS)
- [ ] [\[2410.21982\] A Survey on RGB, 3D, and Multimodal Approaches for Unsupervised Industrial Anomaly Detection](https://arxiv.org/abs/2410.21982) (Fudan)
- [ ] [\[2410.22099\] TractShapeNet: Efficient Multi-Shape Learning with 3D Tractography Point Clouds](https://arxiv.org/abs/2410.22099) (Harvard)
- [ ] [\[2410.22135\] Lightweight Frequency Masker for Cross-Domain Few-Shot Semantic Segmentation](https://arxiv.org/abs/2410.22135) (NIPS)
- [ ] [\[2410.22149\] Capacity Control is an Effective Memorization Mitigation Mechanism in Text-Conditional Diffusion Models](https://arxiv.org/abs/2410.22149) (University of Edinburgh)
- [ ] [\[2410.22187\] Active Learning for Vision-Language Models](https://arxiv.org/abs/2410.22187) (JHU)
- [ ] [\[2410.22217\] Towards Unifying Understanding and Generation in the Era of Vision Foundation Models: A Survey from the Autoregression Perspective](https://arxiv.org/abs/2410.22217) (Peking)
- [ ] [\[2410.22280\] Active Event Alignment for Monocular Distance Estimation](https://arxiv.org/abs/2410.22280) (Inria)
- [ ] [\[2410.22288\] Motion Graph Unleashed: A Novel Approach to Video Prediction](https://arxiv.org/abs/2410.22288) (Oxford, NIPS)
- [ ] [\[2410.22306\] Multi-Object 3D Grounding with Dynamic Modules and Language-Informed Spatial Attention](https://arxiv.org/abs/2410.22306) (NIPS)
- [ ] [\[2410.22312\] Effective Guidance for Model Attention with Simple Yes-no Annotations](https://arxiv.org/abs/2410.22312) (GIT)
- [ ] [\[2410.22313\] Senna: Bridging Large Vision-Language Models and End-to-End Autonomous Driving](https://arxiv.org/abs/2410.22313) (HUST)
- [ ] [\[2410.22317\] Multi-Class Textual-Inversion Secretly Yields a Semantic-Agnostic Classifier](https://arxiv.org/abs/2410.22317) (Nankai)
- [ ] [\[2410.22456\] Image2Struct: Benchmarking Structure Extraction for Vision-Language Models](https://arxiv.org/abs/2410.22456) (NIPS)
- [ ] [\[2410.22461\] Unified Domain Generalization and Adaptation for Multi-View 3D Object Detection](https://arxiv.org/abs/2410.22461) (NIPS)
- [ ] [\[2410.22655\] FlowDCN: Exploring DCN-like Architectures for Fast Image Generation with Arbitrary Resolution](https://arxiv.org/abs/2410.22655) (NIPS)
- [ ] [\[2410.22705\] Geometry Cloak: Preventing TGS-based 3D Reconstruction from Copyrighted Images](https://arxiv.org/abs/2410.22705) (BU, NIPS)
- [ ] [\[2410.22709\] FilterViT and DropoutViT: Lightweight Vision Transformer Models for Efficient Attention Mechanisms](https://arxiv.org/abs/2410.22709) (UESTC)
- [ ] [\[2410.22710\] LoFLAT: Local Feature Matching using Focused Linear Attention Transformer](https://arxiv.org/abs/2410.22710) (NWPU)
- [ ] [\[2410.22715\] SCRREAM : SCan, Register, REnder And Map:A Framework for Annotating Accurate and Dense 3D Indoor Scenes with a Benchmark](https://arxiv.org/abs/2410.22715) (TUM)
- [ ] [\[2410.22771\] FuseAnyPart: Diffusion-Driven Facial Parts Swapping via Multiple Reference Images](https://arxiv.org/abs/2410.22771) (SJTU, NIPS)
- [ ] [\[2410.22777\] Bregman implementation of Meyer's $G-$norm for cartoon + textures decomposition](https://arxiv.org/abs/2410.22777) (UCLA)
- [ ] [\[2410.22817\] Epipolar-Free 3D Gaussian Splatting for Generalizable Novel View Synthesis](https://arxiv.org/abs/2410.22817) (NIPS)
- [ ] [\[2410.22865\] Prune and Repaint: Content-Aware Image Retargeting for any Ratio](https://arxiv.org/abs/2410.22865) (Alibaba, NIPS)
- [ ] [\[2410.22888\] Effective and Efficient Adversarial Detection for Vision-Language Models via A Single Vector](https://arxiv.org/abs/2410.22888) (NUS)
- [ ] [\[2410.22899\] Wormhole Loss for Partial Shape Matching](https://arxiv.org/abs/2410.22899) (NIPS)
- [ ] [\[2410.22939\] AdaptiveISP: Learning an Adaptive Image Signal Processor for Object Detection](https://arxiv.org/abs/2410.22939) (Peking, NIPS)
- [ ] [\[2410.22995\] VisAidMath: Benchmarking Visual-Aided Mathematical Reasoning](https://arxiv.org/abs/2410.22995) (Alibaba)
- [ ] [\[2410.23072\] CNN Explainability with Multivector Tucker Saliency Maps for Self-Supervised Models](https://arxiv.org/abs/2410.23072) (Inria)
- [ ] [\[2410.23091\] CausalDiff: Causality-Inspired Disentanglement via Diffusion Model for Adversarial Defense](https://arxiv.org/abs/2410.23091) (ICT CAS, NIPS)
- [ ] [\[2410.23105\] Automated Image-Based Identification and Consistent Classification of Fire Patterns with Quantitative Shape Analysis and Spatial Location Identification](https://arxiv.org/abs/2410.23105) (CMU)
- [ ] [\[2410.23107\] Decoupling Semantic Similarity from Spatial Alignment for Neural Networks](https://arxiv.org/abs/2410.23107) (NIPS)
- [ ] [\[2410.23114\] Unified Triplet-Level Hallucination Evaluation for Large Vision-Language Models](https://arxiv.org/abs/2410.23114) (HKUST)
- [ ] [\[2410.23159\] Fourier Amplitude and Correlation Loss: Beyond Using L2 Loss for Skillful Precipitation Nowcasting](https://arxiv.org/abs/2410.23159) (HKUST, NIPS)
- [ ] [\[2410.23219\] DiaMond: Dementia Diagnosis with Multi-Modal Vision Transformers Using MRI and PET](https://arxiv.org/abs/2410.23219) (TUM)
- [ ] [\[2410.23231\] LGU-SLAM: Learnable Gaussian Uncertainty Matching with Deformable Correlation Sampling for Deep Visual SLAM](https://arxiv.org/abs/2410.23231) (UESTC)
- [ ] [\[2410.23278\] OpenSatMap: A Fine-grained High-resolution Satellite Dataset for Large-scale Map Construction](https://arxiv.org/abs/2410.23278) (NIPS)
- [ ] [\[2410.23287\] ReferEverything: Towards Segmenting Everything We Can Speak of in Videos](https://arxiv.org/abs/2410.23287) (Illinois)
- [ ] [\[2410.23317\] VL-Cache: Sparsity and Modality-Aware KV Cache Compression for Vision-Language Model Inference Acceleration](https://arxiv.org/abs/2410.23317) (UCLA)
- [ ] [\[2410.23332\] MoLE: Enhancing Human-centric Text-to-image Diffusion via Mixture of Low-rank Experts](https://arxiv.org/abs/2410.23332) (Peking, NIPS)
- [ ] [\[2410.23370\] Multilingual Vision-Language Pre-training for the Remote Sensing Domain](https://arxiv.org/abs/2410.23370) (EPFL)
- [ ] [\[2410.23522\] LBurst: Learning-Based Robotic Burst Feature Extraction for 3D Reconstruction in Low Light](https://arxiv.org/abs/2410.23522) (USyd)
- [ ] [\[2410.23603\] Using Multimodal Deep Neural Networks to Disentangle Language from Visual Aesthetics](https://arxiv.org/abs/2410.23603) (Harvard)
- [ ] [\[2410.23608\] Context-Aware Token Selection and Packing for Enhanced Vision Transformer](https://arxiv.org/abs/2410.23608) (Cornell)
- [ ] [\[2410.23629\] Posture-Informed Muscular Force Learning for Robust Hand Pressure Estimation](https://arxiv.org/abs/2410.23629) (NIPS)
- [ ] [\[2410.23641\] Recovering Complete Actions for Cross-dataset Skeleton Action Recognition](https://arxiv.org/abs/2410.23641) (Tsinghua, NIPS)
- [ ] [\[2410.23663\] DIP: Diffusion Learning of Inconsistency Pattern for General DeepFake Detection](https://arxiv.org/abs/2410.23663) (SYSU)
- [ ] [\[2410.23676\] Web-Scale Visual Entity Recognition: An LLM-Driven Data Approach](https://arxiv.org/abs/2410.23676) (NIPS)
- [ ] [\[2410.23758\] Reverse Attitude Statistics Based Star Map Identification Method](https://arxiv.org/abs/2410.23758) (BIT)
- [ ] [\[2410.23767\] Open-Set 3D object detection in LiDAR data as an Out-of-Distribution problem](https://arxiv.org/abs/2410.23767) (PSL University)
- [ ] [\[2410.23775\] In-Context LoRA for Diffusion Transformers](https://arxiv.org/abs/2410.23775) (ZJU)
- [ ] [\[2410.23780\] Driving by the Rules: A Benchmark for Integrating Traffic Sign Regulations into Vectorized HD Map](https://arxiv.org/abs/2410.23780) (XJTU)
- [ ] [\[2410.23782\] Video Token Merging for Long-form Video Understanding](https://arxiv.org/abs/2410.23782) (AWS, NIPS)
- [ ] [\[2410.23788\] EDT: An Efficient Diffusion Transformer Framework Inspired by Human-like Sketching](https://arxiv.org/abs/2410.23788) (NIPS)
- [ ] [\[2410.23836\] Stereo-Talker: Audio-driven 3D Human Synthesis with Prior-Guided Mixture-of-Experts](https://arxiv.org/abs/2410.23836) (Tsinghua)
- [ ] [\[2410.23854\] Airway Labeling Meets Clinical Applications: Reflecting Topology Consistency and Outliers via Learnable Attentions](https://arxiv.org/abs/2410.23854) (SJTU)
- [ ] [\[2410.23891\] AllClear: A Comprehensive Dataset and Benchmark for Cloud Removal in Satellite Imagery](https://arxiv.org/abs/2410.23891) (NIPS)
- [ ] [\[2410.23904\] EZ-HOI: VLM Adaptation via Guided Prompt Learning for Zero-Shot HOI Detection](https://arxiv.org/abs/2410.23904) (NIPS)
- [ ] [\[2410.23905\] Text-DiFuse: An Interactive Multi-Modal Image Fusion Framework based on Text-modulated Diffusion Model](https://arxiv.org/abs/2410.23905) (WHU, NIPS)
- [ ] [\[2410.23910\] Uncertainty Estimation for 3D Object Detection via Evidential Learning](https://arxiv.org/abs/2410.23910) (EPFL)
- [ ] [\[2410.23946\] MV-CC: Mask Enhanced Video Model for Remote Sensing Change Caption](https://arxiv.org/abs/2410.23946) (XJTU)
- [ ] [\[2410.23962\] Image Synthesis with Class-Aware Semantic Diffusion Models for Surgical Scene Segmentation](https://arxiv.org/abs/2410.23962) (Imperial)
- [ ] [\[2410.24001\] ImOV3D: Learning Open-Vocabulary Point Clouds 3D Object Detection from Only 2D Images](https://arxiv.org/abs/2410.24001) (NIPS)
- [ ] [\[2410.24010\] Re-assembling the past: The RePAIR dataset and benchmark for real world 2D and 3D puzzle solving](https://arxiv.org/abs/2410.24010) (NIPS)
- [ ] [\[2410.24037\] TPC: Test-time Procrustes Calibration for Diffusion-based Human Image Animation](https://arxiv.org/abs/2410.24037) (NIPS)
- [ ] [\[2410.24075\] Identifying Spatio-Temporal Drivers of Extreme Events](https://arxiv.org/abs/2410.24075) (NIPS)
- [ ] [\[2410.24116\] AIDOVECL: AI-generated Dataset of Outpainted Vehicles for Eye-level Classification and Localization](https://arxiv.org/abs/2410.24116) (Illinois)
- [ ] [\[2410.24148\] Exploring Vision Language Models for Facial Attribute Recognition: Emotion, Race, Gender, and Age](https://arxiv.org/abs/2410.24148) (NYU)
- [ ] [\[2410.24203\] DiffPano: Scalable and Consistent Text to Panorama Generation with Spherical Epipolar-Aware Diffusion](https://arxiv.org/abs/2410.24203) (Tongji, NIPS)
- [ ] [\[2410.24219\] Enhancing Motion in Text-to-Video Generation with Decomposed Encoding and Conditioning](https://arxiv.org/abs/2410.24219) (SUSTech, NIPS)
- [ ] [\[2410.24223\] URAvatar: Universal Relightable Gaussian Codec Avatars](https://arxiv.org/abs/2410.24223) (Meta, SIGGRAPH)
- [ ] [\[2411.00078\] How Good Are We? Evaluating Cell AI Foundation Models in Kidney Pathology with Human-in-the-Loop Enrichment](https://arxiv.org/abs/2411.00078) (Vanderbilt University)
- [ ] [\[2411.00144\] Self-Ensembling Gaussian Splatting for Few-shot Novel View Synthesis](https://arxiv.org/abs/2411.00144) (EPFL)
- [ ] [\[2411.00158\] Using Deep Neural Networks to Quantify Parking Dwell Time](https://arxiv.org/abs/2411.00158) (ICML)
- [ ] [\[2411.00210\] Scale-Aware Recognition in Satellite Images under Resource Constraint](https://arxiv.org/abs/2411.00210) (Cornell)
- [ ] [\[2411.00225\] Fashion-VDM: Video Diffusion Model for Virtual Try-On](https://arxiv.org/abs/2411.00225) (SIGGRAPH)
- [ ] [\[2411.00274\] Adaptive Residual Transformation for Enhanced Feature-Based OOD Detection in SAR Imagery](https://arxiv.org/abs/2411.00274) (POSTECH)
- [ ] [\[2411.00304\] Unified Generative and Discriminative Training for Multi-modal Large Language Models](https://arxiv.org/abs/2411.00304) (NUS)
- [ ] [\[2411.00355\] TextDestroyer: A Training- and Annotation-Free Diffusion Method for Destroying Anomal Text from Images](https://arxiv.org/abs/2411.00355) (Xiamen)
- [ ] [\[2411.00394\] Right this way: Can VLMs Guide Us to See More to Answer Questions?](https://arxiv.org/abs/2411.00394) (NIPS)
- [ ] [\[2411.00399\] StyleTex: Style Image-Guided Texture Generation for 3D Models](https://arxiv.org/abs/2411.00399) (ZJU, SIGGRAPH)
- [ ] [\[2411.00402\] Improving Viewpoint-Independent Object-Centric Representations through Active Viewpoint Selection](https://arxiv.org/abs/2411.00402) (Fudan)
- [ ] [\[2411.00448\] ConceptFactory: Facilitate 3D Object Knowledge Annotation with Object Conceptualization](https://arxiv.org/abs/2411.00448) (NIPS)
- [ ] [\[2411.00462\] Target-Guided Adversarial Point Cloud Transformer Towards Recognition Against Real-world Corruptions](https://arxiv.org/abs/2411.00462) (NIPS)
- [ ] [\[2411.00543\] 3D Equivariant Pose Regression via Direct Wigner-D Harmonics Prediction](https://arxiv.org/abs/2411.00543) (NIPS)
- [ ] [\[2411.00552\] Tracking one-in-a-million: Large-scale benchmark for microbial single-cell tracking with experiment-aware robustness metrics](https://arxiv.org/abs/2411.00552) (ECCV)
- [ ] [\[2411.00553\] Is Multiple Object Tracking a Matter of Specialization?](https://arxiv.org/abs/2411.00553) (NIPS)
- [ ] [\[2411.00600\] On Deep Learning for Geometric and Semantic Scene Understanding Using On-Vehicle 3D LiDAR](https://arxiv.org/abs/2411.00600) (ECCV)
- [ ] [\[2411.00623\] Dual Low-Rank Adaptation for Continual Learning with Pre-Trained Models](https://arxiv.org/abs/2411.00623) (UT Austin)
- [ ] [\[2411.00632\] PCoTTA: Continual Test-Time Adaptation for Multi-Task Point Cloud Understanding](https://arxiv.org/abs/2411.00632) (SJTU, NIPS)
- [ ] [\[2411.00715\] B-cosification: Transforming Deep Neural Networks to be Inherently Interpretable](https://arxiv.org/abs/2411.00715) (NIPS)
- [ ] [\[2411.00769\] GameGen-X: Interactive Open-world Game Video Generation](https://arxiv.org/abs/2411.00769) (USTC)
- [ ] [\[2411.00826\] Uncertainty Quantification via H\"older Divergence for Multi-View Representation Learning](https://arxiv.org/abs/2411.00826) (BU)
- [ ] [\[2411.00827\] IDEATOR: Jailbreaking VLMs Using VLMs](https://arxiv.org/abs/2411.00827) (Fudan)
- [ ] [\[2411.00836\] DynaMath: A Dynamic Visual Benchmark for Evaluating Mathematical Reasoning Robustness of Vision Language Models](https://arxiv.org/abs/2411.00836) (Berkeley)
- [ ] [\[2411.00881\] Technical Report for SoccerNet Challenge 2022 -- Replay Grounding Task](https://arxiv.org/abs/2411.00881) (BUPT)
- [ ] [\[2411.00883\] Technical Report for ActivityNet Challenge 2022 -- Temporal Action Localization](https://arxiv.org/abs/2411.00883) (ZJU)
- [ ] [\[2411.01122\] OnlineTAS: An Online Baseline for Temporal Action Segmentation](https://arxiv.org/abs/2411.01122) (NIPS)
- [ ] [\[2411.01171\] Fast and Memory-Efficient Video Diffusion Using Streamlined Inference](https://arxiv.org/abs/2411.01171) (NIPS)
- [ ] [\[2411.01179\] Hollowed Net for On-Device Personalization of Text-to-Image Diffusion Models](https://arxiv.org/abs/2411.01179) (NIPS)
- [ ] [\[2411.01208\] MultiPull: Detailing Signed Distance Functions by Pulling Multi-Level Queries at Multi-Step](https://arxiv.org/abs/2411.01208) (Tsinghua, NIPS)
- [ ] [\[2411.01225\] RLE: A Unified Perspective of Data Augmentation for Cross-Spectral Re-identification](https://arxiv.org/abs/2411.01225) (Xiamen, NIPS)
- [ ] [\[2411.01327\] Visual Fourier Prompt Tuning](https://arxiv.org/abs/2411.01327) (NIPS)
- [ ] [\[2411.01348\] Optimizing Violence Detection in Video Classification Accuracy through 3D Convolutional Neural Networks](https://arxiv.org/abs/2411.01348) (Harvard)
- [ ] [\[2411.01351\] Guided Synthesis of Labeled Brain MRI Data Using Latent Diffusion Models for Segmentation of Enlarged Ventricles](https://arxiv.org/abs/2411.01351) (University of Copenhagen)
- [ ] [\[2411.01432\] Meta-Exploiting Frequency Prior for Cross-Domain Few-Shot Learning](https://arxiv.org/abs/2411.01432) (NWPU)
- [ ] [\[2411.01443\] Activating Self-Attention for Multi-Scene Absolute Pose Regression](https://arxiv.org/abs/2411.01443) (Sungkyunkwan University, NIPS)
- [ ] [\[2411.01455\] HiMemFormer: Hierarchical Memory-Aware Transformer for Multi-Agent Action Anticipation](https://arxiv.org/abs/2411.01455) (Illinois)
- [ ] [\[2411.01472\] Adaptive Domain Learning for Cross-domain Image Denoising](https://arxiv.org/abs/2411.01472) (NIPS)
- [ ] [\[2411.01492\] EEE-Bench: A Comprehensive Multimodal Electrical And Electronics Engineering Benchmark](https://arxiv.org/abs/2411.01492) (University of Tokyo)
- [ ] [\[2411.01494\] Finding NeMo: Negative-mined Mosaic Augmentation for Referring Image Segmentation](https://arxiv.org/abs/2411.01494) (ECCV)
- [ ] [\[2411.01505\] Object segmentation from common fate: Motion energy processing enables human-like zero-shot generalization to random dot stimuli](https://arxiv.org/abs/2411.01505) (NIPS)
- [ ] [\[2411.01542\] FactorizePhys: Matrix Factorization for Multidimensional Attention in Remote Physiological Sensing](https://arxiv.org/abs/2411.01542) (NIPS)
- [ ] [\[2411.01564\] ParseCaps: An Interpretable Parsing Capsule Network for Medical Image Diagnosis](https://arxiv.org/abs/2411.01564) (HIT)
- [ ] [\[2411.01584\] One for All: Multi-Domain Joint Training for Point Cloud Based 3D Object Detection](https://arxiv.org/abs/2411.01584) (HKU, NIPS)
- [ ] [\[2411.01593\] High-Fidelity Virtual Try-on with Large-Scale Unpaired Learning](https://arxiv.org/abs/2411.01593) (ETH)
- [ ] [\[2411.01595\] RS-MoE: Mixture of Experts for Remote Sensing Image Captioning and Visual Question Answering](https://arxiv.org/abs/2411.01595) (WHU)
- [ ] [\[2411.01597\] OSAD: Open-Set Aircraft Detection in SAR Images](https://arxiv.org/abs/2411.01597) (Fudan)
- [ ] [\[2411.01602\] DreamPolish: Domain Score Distillation With Progressive Geometry Generation](https://arxiv.org/abs/2411.01602) (Tsinghua)
- [ ] [\[2411.01624\] PreCM: The Padding-based Rotation Equivariant Convolution Mode for Semantic Segmentation](https://arxiv.org/abs/2411.01624) (TIP)
- [ ] [\[2411.01739\] Not Just Object, But State: Compositional Incremental Learning without Forgetting](https://arxiv.org/abs/2411.01739) (IA CAS, NIPS)
- [ ] [\[2411.01777\] Learning predictable and robust neural representations by straightening image sequences](https://arxiv.org/abs/2411.01777) (NIPS)
- [ ] [\[2411.01800\] Expanding Sparse Tuning for Low Memory Usage](https://arxiv.org/abs/2411.01800) (Tsinghua, NIPS)
- [ ] [\[2411.01801\] Bootstrapping Top-down Information for Self-modulating Slot Attention](https://arxiv.org/abs/2411.01801) (NIPS)
- [ ] [\[2411.01822\] Distribution alignment based transfer fusion frameworks on quantum devices for seeking quantum advantages](https://arxiv.org/abs/2411.01822) (CUHK)
- [ ] [\[2411.01846\] KptLLM: Unveiling the Power of Large Language Model for Keypoint Comprehension](https://arxiv.org/abs/2411.01846) (NIPS)
- [ ] [\[2411.01870\] Mining and Transferring Feature-Geometry Coherence for Unsupervised Point Cloud Registration](https://arxiv.org/abs/2411.01870) (NTU, NIPS)
- [ ] [\[2411.01948\] Learning Where to Edit Vision Transformers](https://arxiv.org/abs/2411.01948) (ZJU)
- [ ] [\[2411.01981\] Typicalness-Aware Learning for Failure Detection](https://arxiv.org/abs/2411.01981) (HIT, NIPS)
- [ ] [\[2411.02057\] Exploiting Unlabeled Data with Multiple Expert Teachers for Open Vocabulary Aerial Object Detection and Its Orientation Adaptation](https://arxiv.org/abs/2411.02057) (SJTU)
- [ ] [\[2411.02136\] Advanced computer vision for extracting georeferenced vehicle trajectories from drone imagery](https://arxiv.org/abs/2411.02136) (KAIST)
- [ ] [\[2411.02149\] Improving Domain Generalization in Self-supervised Monocular Depth Estimation via Stabilized Adversarial Training](https://arxiv.org/abs/2411.02149) (ECCV)
- [ ] [\[2411.02181\] Detect an Object At Once without Fine-tuning](https://arxiv.org/abs/2411.02181) (Tianjin)
- [ ] [\[2411.02220\] SIRA: Scalable Inter-frame Relation and Association for Radar Perception](https://arxiv.org/abs/2411.02220) (CVPR)
- [ ] [\[2411.02229\] FewViewGS: Gaussian Splatting with Few View Matching and Multi-stage Training](https://arxiv.org/abs/2411.02229) (UVA.NL, NIPS)
- [ ] [\[2411.02256\] Unified Speech Recognition: A Single Model for Auditory, Visual, and Audiovisual Inputs](https://arxiv.org/abs/2411.02256) (Meta, NIPS)
- [ ] [\[2411.02372\] Learning General-Purpose Biomedical Volume Representations using Randomized Synthesis](https://arxiv.org/abs/2411.02372) (MIT)
- [ ] [\[2411.02395\] Training-free Regional Prompting for Diffusion Transformers](https://arxiv.org/abs/2411.02395) (Peking)
- [ ] [\[2411.02397\] Adaptive Caching for Faster Video Generation with Diffusion Transformers](https://arxiv.org/abs/2411.02397) (Meta)
- [ ] [\[2411.02537\] INQUIRE: A Natural World Text-to-Image Retrieval Benchmark](https://arxiv.org/abs/2411.02537) (NIPS)
- [ ] [\[2411.02545\] TripletCLIP: Improving Compositional Reasoning of CLIP via Synthetic Vision-Language Negatives](https://arxiv.org/abs/2411.02545) (NIPS)
- [ ] [\[2411.02588\] TileTracker: Tracking Based Vector HD Mapping using Top-Down Road Images](https://arxiv.org/abs/2411.02588) (NVIDIA)
- [ ] [\[2411.02624\] Enhancing Indoor Mobility with Connected Sensor Nodes: A Real-Time, Delay-Aware Cooperative Perception Approach](https://arxiv.org/abs/2411.02624) (University of Alberta)
- [ ] [\[2411.02669\] Semantic-Aligned Adversarial Evolution Triangle for High-Transferability Vision-Language Attack](https://arxiv.org/abs/2411.02669) (NTU)
- [ ] [\[2411.02712\] V-DPO: Mitigating Hallucination in Large Vision Language Models via Vision-Guided Direct Preference Optimization](https://arxiv.org/abs/2411.02712) (NUS)
- [ ] [\[2411.02733\] DDFAV: Remote Sensing Large Vision Language Models Dataset and Evaluation Benchmark](https://arxiv.org/abs/2411.02733) (SJTU)
- [ ] [\[2411.02747\] Efficient Feature Aggregation and Scale-Aware Regression for Monocular 3D Object Detection](https://arxiv.org/abs/2411.02747) (Tsinghua)
- [ ] [\[2411.02779\] Advancing Recycling Efficiency: A Comparative Analysis of Deep Learning Models in Waste Classification](https://arxiv.org/abs/2411.02779) (BIT)
- [ ] [\[2411.02840\] Test-Time Dynamic Image Fusion](https://arxiv.org/abs/2411.02840) (NIPS)
- [ ] [\[2411.02858\] OLAF: A Plug-and-Play Framework for Enhanced Multi-object Multi-part Scene Parsing](https://arxiv.org/abs/2411.02858) (EPFL, ECCV)
- [ ] [\[2411.02860\] Continual Audio-Visual Sound Separation](https://arxiv.org/abs/2411.02860) (NIPS)
- [ ] [\[2411.02889\] Turbulence stabilization](https://arxiv.org/abs/2411.02889) (UCLA)
- [ ] [\[2411.02890\] Fried deconvolution](https://arxiv.org/abs/2411.02890) (UCLA)
- [ ] [\[2411.02902\] Membership Inference Attacks against Large Vision-Language Models](https://arxiv.org/abs/2411.02902) (UCLA, NIPS)
- [ ] [\[2411.02920\] Domain Expansion and Boundary Growth for Open-Set Single-Source Domain Generalization](https://arxiv.org/abs/2411.02920) (Fudan)
- [ ] [\[2411.02974\] Region-Guided Attack on the Segment Anything Model (SAM)](https://arxiv.org/abs/2411.02974) (NJU)
- [ ] [\[2411.03033\] Rethinking Decoders for Transformer-based Semantic Segmentation: Compression is All You Need](https://arxiv.org/abs/2411.03033) (NIPS)
- [ ] [\[2411.03041\] Judge Like a Real Doctor: Dual Teacher Sample Consistency Framework for Semi-supervised Medical Image Classification](https://arxiv.org/abs/2411.03041) (SYSU)
- [ ] [\[2411.03053\] Gradient-Guided Conditional Diffusion Models for Private Image Reconstruction: Analyzing Adversarial Impacts of Differential Privacy and Denoising](https://arxiv.org/abs/2411.03053) (MIT)
- [ ] [\[2411.03169\] Pre-trained Visual Dynamics Representations for Efficient Policy Learning](https://arxiv.org/abs/2411.03169) (Peking, ECCV)
- [ ] [\[2411.03177\] On Improved Conditioning Mechanisms and Pre-training Strategies for Diffusion Models](https://arxiv.org/abs/2411.03177) (NIPS)
- [ ] [\[2411.03312\] Inference Optimal VLMs Need Only One Visual Token but Larger Models](https://arxiv.org/abs/2411.03312) (Bosch)
- [ ] [\[2411.03313\] Classification Done Right for Vision-Language Pre-Training](https://arxiv.org/abs/2411.03313) (NIPS)
- [ ] [\[2411.03359\] Self-Calibrated Tuning of Vision-Language Models for Out-of-Distribution Detection](https://arxiv.org/abs/2411.03359) (SJTU, NIPS)
- [ ] [\[2411.03405\] Fine-Grained Spatial and Verbal Losses for 3D Visual Grounding](https://arxiv.org/abs/2411.03405) (ETH)
- [ ] [\[2411.03561\] Estimating Ego-Body Pose from Doubly Sparse Egocentric Video Data](https://arxiv.org/abs/2411.03561) (NIPS)
- [ ] [\[2411.03637\] Structure Consistent Gaussian Splatting with Matching Prior for Few-shot Novel View Synthesis](https://arxiv.org/abs/2411.03637) (Peking, NIPS)
- [ ] [\[2411.03670\] Touchstone Benchmark: Are We on the Right Way for Evaluating AI Algorithms for Medical Segmentation?](https://arxiv.org/abs/2411.03670) (NIPS)
- [ ] [\[2411.03672\] Towards 3D Semantic Scene Completion for Autonomous Driving: A Meta-Learning Framework Empowered by Deformable Large-Kernel Attention and Mamba Model](https://arxiv.org/abs/2411.03672) (KAIST)
- [ ] [\[2411.03695\] AMNCutter: Affinity-Attention-Guided Multi-View Normalized Cutter for Unsupervised Surgical Instrument Segmentation](https://arxiv.org/abs/2411.03695) (USyd)
- [ ] [\[2411.03696\] OccLoff: Learning Optimized Feature Fusion for 3D Occupancy Prediction](https://arxiv.org/abs/2411.03696) (WHU)
- [ ] [\[2411.03725\] PX2Tooth: Reconstructing the 3D Point Cloud Teeth from a Single Panoramic X-ray](https://arxiv.org/abs/2411.03725) (ZJU)
- [ ] [\[2411.03728\] Efficient Fourier Filtering Network with Contrastive Learning for UAV-based Unaligned Bi-modal Salient Object Detection](https://arxiv.org/abs/2411.03728) (NTU)
- [ ] [\[2411.03729\] Relation Learning and Aggregate-attention for Multi-person Motion Prediction](https://arxiv.org/abs/2411.03729) (BUPT)
- [ ] [\[2411.03819\] SA3DIP: Segment Any 3D Instance with Potential 3D Priors](https://arxiv.org/abs/2411.03819) (Xidian)
- [ ] [\[2411.03829\] Generalize or Detect? Towards Robust Semantic Segmentation Under Multiple Distribution Shifts](https://arxiv.org/abs/2411.03829) (EPFL, NIPS)
- [ ] [\[2411.03862\] ROBIN: Robust and Invisible Watermarks for Diffusion Models with Adversarial Optimization](https://arxiv.org/abs/2411.03862) (NIPS)
- [ ] [\[2411.03959\] Energy Score-based Pseudo-Label Filtering and Adaptive Loss for Imbalanced Semi-supervised SAR target recognition](https://arxiv.org/abs/2411.03959) (Chongqing)
- [ ] [\[2411.04077\] H-POPE: Hierarchical Polling-based Probing Evaluation of Hallucinations in Large Vision-Language Models](https://arxiv.org/abs/2411.04077) (MPI)
- [ ] [\[2411.04097\] RaVL: Discovering and Mitigating Spurious Correlations in Fine-Tuned Vision-Language Models](https://arxiv.org/abs/2411.04097) (Stanford, NIPS)
- [ ] [\[2411.04151\] UnityGraph: Unified Learning of Spatio-temporal features for Multi-person Motion Prediction](https://arxiv.org/abs/2411.04151) (BUPT)
- [ ] [\[2411.04168\] DiMSUM: Diffusion Mamba -- A Scalable and Unified Spatial-Frequency Method for Image Generation](https://arxiv.org/abs/2411.04168) (Cornell, NIPS)
- [ ] [\[2411.04357\] MegaPortrait: Revisiting Diffusion Control for High-fidelity Portrait Generation](https://arxiv.org/abs/2411.04357) (ETH)
- [ ] [\[2411.04399\] ProGraph: Temporally-alignable Probability Guided Graph Topological Modeling for 3D Human Reconstruction](https://arxiv.org/abs/2411.04399) (ZJU)
- [ ] [\[2411.04406\] Image Understanding Makes for A Good Tokenizer for Image Generation](https://arxiv.org/abs/2411.04406) (NIPS)
- [ ] [\[2411.04571\] DomainGallery: Few-shot Domain-driven Image Generation by Attribute-centric Finetuning](https://arxiv.org/abs/2411.04571) (NIPS)
- [ ] [\[2411.04607\] Cross- and Intra-image Prototypical Learning for Multi-label Disease Diagnosis and Interpretation](https://arxiv.org/abs/2411.04607) (Cornell)
- [ ] [\[2411.04646\] DanceFusion: A Spatio-Temporal Skeleton Diffusion Transformer for Audio-Driven Dance Motion Reconstruction](https://arxiv.org/abs/2411.04646) (Tsinghua)
- [ ] [\[2411.04693\] Reciprocal Point Learning Network with Large Electromagnetic Kernel for SAR Open-Set Recognition](https://arxiv.org/abs/2411.04693) (Fudan)
- [ ] [\[2411.04709\] TIP-I2V: A Million-Scale Real Text and Image Prompt Dataset for Image-to-Video Generation](https://arxiv.org/abs/2411.04709) (ZJU)
- [ ] [\[2411.04711\] Progressive Multi-Level Alignments for Semi-Supervised Domain Adaptation SAR Target Recognition Using Simulated Data](https://arxiv.org/abs/2411.04711) (Chongqing)
- [ ] [\[2411.04712\] SEE-DPO: Self Entropy Enhanced Direct Preference Optimization](https://arxiv.org/abs/2411.04712) (Illinois)
- [ ] [\[2411.04713\] Multi-Reward as Condition for Instruction-based Image Editing](https://arxiv.org/abs/2411.04713) (IS CAS)
- [ ] [\[2411.04873\] Boosting Latent Diffusion with Perceptual Objectives](https://arxiv.org/abs/2411.04873) (Meta)
- [ ] [\[2411.04923\] VideoGLaMM: A Large Multimodal Model for Pixel-Level Visual Grounding in Videos](https://arxiv.org/abs/2411.04923) (MBZUAI)
- [ ] [\[2411.04924\] MVSplat360: Feed-Forward 360 Scene Synthesis from Sparse Views](https://arxiv.org/abs/2411.04924) (NIPS)
- [ ] [\[2411.04928\] DimensionX: Create Any 3D and 4D Scenes from a Single Image with Controllable Video Diffusion](https://arxiv.org/abs/2411.04928) (HKUST)
- [ ] [\[2411.04954\] CAD-MLLM: Unifying Multimodality-Conditioned CAD Generation With MLLM](https://arxiv.org/abs/2411.04954) (HKU)
- [ ] [\[2411.04963\] VAIR: Visuo-Acoustic Implicit Representations for Low-Cost, Multi-Modal Transparent Surface Reconstruction in Indoor Scenes](https://arxiv.org/abs/2411.04963) (University of Michigan)
- [ ] [\[2411.04967\] AsCAN: Asymmetric Convolution-Attention Networks for Efficient Recognition and Generation](https://arxiv.org/abs/2411.04967) (NIPS)
- [ ] [\[2411.04984\] Planar Reflection-Aware Neural Radiance Fields](https://arxiv.org/abs/2411.04984) (Meta)
- [ ] [\[2411.04997\] LLM2CLIP: Powerful Language Model Unlock Richer Visual Representation](https://arxiv.org/abs/2411.04997) (Microsoft)
- [ ] [\[2411.04998\] HourVideo: 1-Hour Video-Language Understanding](https://arxiv.org/abs/2411.04998) (NIPS)
- [ ] [\[2411.05001\] Analyzing The Language of Visual Tokens](https://arxiv.org/abs/2411.05001) (University of Tokyo)
- [ ] [\[2411.05005\] Diff-2-in-1: Bridging Generation and Dense Perception with Diffusion Models](https://arxiv.org/abs/2411.05005) (Tsinghua)
- [ ] [\[2411.05006\] ProEdit: Simple Progression is All You Need for High-Quality 3D Scene Editing](https://arxiv.org/abs/2411.05006) (NIPS)
- [ ] [\[2401.00057\] Generalization properties of contrastive world models](https://arxiv.org/abs/2401.00057) (CMU)
- [ ] [\[2401.00135\] Deep Radon Prior: A Fully Unsupervised Framework for Sparse-View CT Reconstruction](https://arxiv.org/abs/2401.00135) (Tsinghua)
- [ ] [\[2401.00148\] TPatch: A Triggered Physical Adversarial Patch](https://arxiv.org/abs/2401.00148) (ZJU)
- [ ] [\[2401.00391\] SAFE-SIM: Safety-Critical Closed-Loop Traffic Simulation with Diffusion-Controllable Adversaries](https://arxiv.org/abs/2401.00391) (ECCV)
- [ ] [\[2401.00763\] New Job, New Gender? Measuring the Social Bias in Image Generation Models](https://arxiv.org/abs/2401.00763) (ACMMM)
- [ ] [\[2401.00859\] Federated Multi-View Synthesizing for Metaverse](https://arxiv.org/abs/2401.00859) (QMUL)
- [ ] [\[2401.00873\] A Bayesian Unification of Self-Supervised Clustering and Energy-Based Models](https://arxiv.org/abs/2401.00873) (KU Leuven)
- [ ] [\[2401.00877\] Improving the Stability and Efficiency of Diffusion Models for Content Consistent Super-Resolution](https://arxiv.org/abs/2401.00877) (PolyU)
- [ ] [\[2401.00894\] Balanced Multi-modal Federated Learning via Cross-Modal Infiltration](https://arxiv.org/abs/2401.00894) (PolyU)
- [ ] [\[2401.01383\] Predicting Infant Brain Connectivity with Federated Multi-Trajectory GNNs using Scarce Data](https://arxiv.org/abs/2401.01383) (Imperial)
- [ ] [\[2401.01496\] From Pixel to Slide image: Polarization Modality-based Pathological Diagnosis Using Representation Learning](https://arxiv.org/abs/2401.01496) (Tsinghua)
- [ ] [\[2401.02020\] Spikformer V2: Join the High Accuracy Club on ImageNet with an SNN Ticket](https://arxiv.org/abs/2401.02020) (Peking)
- [ ] [\[2401.02147\] Exploring Boundary of GPT-4V on Marine Analysis: A Preliminary Case Study](https://arxiv.org/abs/2401.02147) (HKUST)
- [ ] [\[2401.02329\] Exploring Vacant Classes in Label-Skewed Federated Learning](https://arxiv.org/abs/2401.02329) (USTC)
- [ ] [\[2401.02437\] Randomly Weighted Neuromodulation in Neural Networks Facilitates Learning of Manifolds Common Across Tasks](https://arxiv.org/abs/2401.02437) (NIPS)
- [ ] [\[2401.02539\] Robot-Assisted Deep Venous Thrombosis Ultrasound Examination using Virtual Fixture](https://arxiv.org/abs/2401.02539) (TUM)
- [ ] [\[2401.02695\] VoroNav: Voronoi-based Zero-shot Object Navigation with Large Language Model](https://arxiv.org/abs/2401.02695) (Peking)
- [ ] [\[2401.02961\] A Surrogate-Assisted Extended Generative Adversarial Network for Parameter Optimization in Free-Form Metasurface Design](https://arxiv.org/abs/2401.02961) (A*STAR,)
- [ ] [\[2401.02995\] CANAMRF: An Attention-Based Model for Multimodal Depression Detection](https://arxiv.org/abs/2401.02995) (USTC)
- [ ] [\[2401.03002\] Prompt-driven Latent Domain Generalization for Medical Image Classification](https://arxiv.org/abs/2401.03002) (Queensland)
- [ ] [\[2401.03060\] Super-resolution multi-contrast unbiased eye atlases with deep probabilistic refinement](https://arxiv.org/abs/2401.03060) (Vanderbilt University)
- [ ] [\[2401.03170\] Preserving Silent Features for Domain Generalization](https://arxiv.org/abs/2401.03170) (Tsinghua)
- [ ] [\[2401.03250\] Interpersonal Relationship Analysis with Dyadic EEG Signals via Learning Spatial-Temporal Patterns](https://arxiv.org/abs/2401.03250) (IS CAS)
- [ ] [\[2401.03411\] GRAM: Global Reasoning for Multi-Page VQA](https://arxiv.org/abs/2401.03411) (AWS)
- [ ] [\[2401.03621\] Machine Learning Applications in Traumatic Brain Injury: A Spotlight on Mild TBI](https://arxiv.org/abs/2401.03621) (Queensland)
- [ ] [\[2401.03664\] Dual-Channel Reliable Breast Ultrasound Image Classification Based on Explainable Attribution and Uncertainty Quantification](https://arxiv.org/abs/2401.03664) (Tsinghua)
- [ ] [\[2401.03695\] A Large-Scale Empirical Study on Improving the Fairness of Image Classification Models](https://arxiv.org/abs/2401.03695) (Tianjin)
- [ ] [\[2401.03885\] Hyperspectral Image Denoising via Spatial-Spectral Recurrent Transformer](https://arxiv.org/abs/2401.03885) (ZJU)
- [ ] [\[2401.04244\] Spatio-Temporal Turbulence Mitigation: A Translational Perspective](https://arxiv.org/abs/2401.04244) (CVPR)
- [ ] [\[2401.04377\] Towards Real-World Aerial Vision Guidance with Categorical 6D Pose Tracker](https://arxiv.org/abs/2401.04377) (NTU)
- [ ] [\[2401.04570\] An Automatic Cascaded Model for Hemorrhagic Stroke Segmentation and Hemorrhagic Volume Estimation](https://arxiv.org/abs/2401.04570) (BUPT)
- [ ] [\[2401.04747\] DiffSHEG: A Diffusion-Based Approach for Real-Time Speech-driven Holistic 3D Expression and Gesture Generation](https://arxiv.org/abs/2401.04747) (CVPR)
- [ ] [\[2401.05314\] ANIM-400K: A Large-Scale Dataset for Automated End-To-End Dubbing of Video](https://arxiv.org/abs/2401.05314) (Berkeley)
- [ ] [\[2401.05827\] Hallucination Benchmark in Medical Visual Question Answering](https://arxiv.org/abs/2401.05827) (ICLR)
- [ ] [\[2401.06000\] Body-Area Capacitive or Electric Field Sensing for Human Activity Recognition and Human-Computer Interaction: A Comprehensive Survey](https://arxiv.org/abs/2401.06000) (ETH)
- [ ] [\[2401.06005\] How does the primate brain combine generative and discriminative computations in vision?](https://arxiv.org/abs/2401.06005) (Columbia University)
- [ ] [\[2401.06148\] Artificial Intelligence for Digital and Computational Pathology](https://arxiv.org/abs/2401.06148) (Harvard)
- [ ] [\[2401.06349\] ADAPT: Alzheimer Diagnosis through Adaptive Profiling Transformers](https://arxiv.org/abs/2401.06349) (Illinois)
- [ ] [\[2401.06499\] Fully Automated Tumor Segmentation for Brain MRI data using Multiplanner UNet](https://arxiv.org/abs/2401.06499) (University of Copenhagen)
- [ ] [\[2401.06780\] HA-HI: Synergising fMRI and DTI through Hierarchical Alignments and Hierarchical Interactions for Mild Cognitive Impairment Diagnosis](https://arxiv.org/abs/2401.06780) (HIT)
- [ ] [\[2401.06893\] Local Gamma Augmentation for Ischemic Stroke Lesion Segmentation on MRI](https://arxiv.org/abs/2401.06893) (University of Copenhagen)
- [ ] [\[2401.07205\] Crafter: Facial Feature Crafting against Inversion-based Identity Theft on Deep Models](https://arxiv.org/abs/2401.07205) (HKUST)
- [ ] [\[2401.07487\] Robo-ABC: Affordance Generalization Beyond Categories via Semantic Correspondence for Robot Manipulation](https://arxiv.org/abs/2401.07487) (Tsinghua)
- [ ] [\[2401.07782\] Exploring Masked Autoencoders for Sensor-Agnostic Image Retrieval in Remote Sensing](https://arxiv.org/abs/2401.07782) (EPFL)
- [ ] [\[2401.07856\] Information hiding cameras: optical concealment of object information into ordinary images](https://arxiv.org/abs/2401.07856) (UCLA)
- [ ] [\[2401.07957\] Machine Perceptual Quality: Evaluating the Impact of Severe Lossy Compression on Audio and Image Models](https://arxiv.org/abs/2401.07957) (UT Austin)
- [ ] [\[2401.07990\] How does self-supervised pretraining improve robustness against noisy labels across various medical image classification datasets?](https://arxiv.org/abs/2401.07990) (Rochester Institute of Technology)
- [ ] [\[2401.08567\] Connect, Collapse, Corrupt: Learning Cross-Modal Tasks with Uni-Modal Data](https://arxiv.org/abs/2401.08567) (ICLR)
- [ ] [\[2401.08695\] Enabling Collaborative Clinical Diagnosis of Infectious Keratitis by Integrating Expert Knowledge and Interpretable Data-driven Intelligence](https://arxiv.org/abs/2401.08695) (ZJU)
- [ ] [\[2401.08732\] Bayes Conditional Distribution Estimation for Knowledge Distillation Based on Conditional Mutual Information](https://arxiv.org/abs/2401.08732) (ICLR)
- [ ] [\[2401.08920\] Idempotence and Perceptual Image Compression](https://arxiv.org/abs/2401.08920) (NYU, ICLR)
- [ ] [\[2401.08923\] Subwavelength Imaging using a Solid-Immersion Diffractive Optical Processor](https://arxiv.org/abs/2401.08923) (UCLA)
- [ ] [\[2401.09019\] Change Detection Between Optical Remote Sensing Imagery and Map Data via Segment Anything Model (SAM)](https://arxiv.org/abs/2401.09019) (University of Tokyo)
- [ ] [\[2401.09140\] Relative Pose for Nonrigid Multi-Perspective Cameras: The Static Case](https://arxiv.org/abs/2401.09140) (ShanghaiTech)
- [ ] [\[2401.09424\] Precipitation Prediction Using an Ensemble of Lightweight Learners](https://arxiv.org/abs/2401.09424) (Alibaba)
- [ ] [\[2401.09466\] Self Supervised Vision for Climate Downscaling](https://arxiv.org/abs/2401.09466) (KAIST)
- [ ] [\[2401.09802\] Efficient Training for Multilingual Visual Speech Recognition: Pre-training with Discretized Visual Speech Representation](https://arxiv.org/abs/2401.09802) (KAIST, ACMMM)
- [ ] [\[2401.09939\] ICGNet: A Unified Approach for Instance-Centric Grasping](https://arxiv.org/abs/2401.09939) (ETH)
  
  - [ ] [\[2401.10191\] Divide and not forget: Ensemble of selectively trained experts in Continual Learning](https://arxiv.org/abs/2401.10191) (ICLR)

- [ ] [\[2401.10474\] LDReg: Local Dimensionality Regularized Self-Supervised Learning](https://arxiv.org/abs/2401.10474) (ICLR)
- [ ] [\[2401.10637\] Towards Universal Unsupervised Anomaly Detection in Medical Imaging](https://arxiv.org/abs/2401.10637) (TUM)
- [ ] [\[2401.10709\] Dense 3D Reconstruction Through Lidar: A Comparative Study on Ex-vivo Porcine Tissue](https://arxiv.org/abs/2401.10709) (MPI)
- [ ] [\[2401.11143\] Density Adaptive Attention is All You Need: Robust Parameter-Efficient Fine-Tuning Across Multiple Modalities](https://arxiv.org/abs/2401.11143) (CMU)
- [ ] [\[2401.11439\] General Flow as Foundation Affordance for Scalable Robot Learning](https://arxiv.org/abs/2401.11439) (Tsinghua)
- [ ] [\[2401.11671\] RTA-Former: Reverse Transformer Attention for Polyp Segmentation](https://arxiv.org/abs/2401.11671) (JHU)
- [ ] [\[2401.11856\] MOSformer: Momentum encoder-based inter-slice fusion transformer for medical image segmentation](https://arxiv.org/abs/2401.11856) (IA CAS)
- [ ] [\[2401.11943\] Benchmarking Large Multimodal Models against Common Corruptions](https://arxiv.org/abs/2401.11943) (Illinois)
- [ ] [\[2401.11944\] CMMMU: A Chinese Massive Multi-discipline Multimodal Understanding Benchmark](https://arxiv.org/abs/2401.11944) (HKUST)
- [ ] [\[2401.12133\] VRMN-bD: A Multi-modal Natural Behavior Dataset of Immersive Human Fear Responses in VR Stand-up Interactive Games](https://arxiv.org/abs/2401.12133) (Tsinghua)
- [ ] [\[2401.12275\] Multi-Agent Dynamic Relational Reasoning for Social Robot Navigation](https://arxiv.org/abs/2401.12275) (Berkeley)
- [ ] [\[2401.12438\] Secure Federated Learning Approaches to Diagnosing COVID-19](https://arxiv.org/abs/2401.12438) (Illinois)
- [ ] [\[2401.12587\] An Efficient Implicit Neural Representation Image Codec Based on Mixed Autoregressive Model for Low-Complexity Decoding](https://arxiv.org/abs/2401.12587) (Tsinghua)
- [ ] [\[2401.12689\] Energy-based Automated Model Evaluation](https://arxiv.org/abs/2401.12689) (ICLR)
- [ ] [\[2401.12888\] Data-Centric Evolution in Autonomous Driving: A Comprehensive Survey of Big Data System, Data Mining, and Closed-Loop Technologies](https://arxiv.org/abs/2401.12888) (USyd)
- [ ] [\[2401.12915\] Red Teaming Visual Language Models](https://arxiv.org/abs/2401.12915) (HKU)
- [ ] [\[2401.12938\] Neural deformation fields for template-based reconstruction of cortical surfaces from MRI](https://arxiv.org/abs/2401.12938) (TUM)
  
  - [x] [\[2401.13650\] Tyche: Stochastic In-Context Learning for Medical Image Segmentation](https://arxiv.org/abs/2401.13650) (MIT)

- [ ] [\[2401.13782\] Position: AI/ML Influencers Have a Place in the Academic Process](https://arxiv.org/abs/2401.13782) (ICML)
- [ ] [\[2401.13853\] Dataset and Benchmark: Novel Sensors for Autonomous Vehicle Perception](https://arxiv.org/abs/2401.13853) (University of Michigan)
- [ ] [\[2401.13959\] Conditional Neural Video Coding with Spatial-Temporal Super-Resolution](https://arxiv.org/abs/2401.13959) (USTC)
- [ ] [\[2401.14007\] Semantic Ensemble Loss and Latent Refinement for High-Fidelity Neural Image Compression](https://arxiv.org/abs/2401.14007) (HIT)
