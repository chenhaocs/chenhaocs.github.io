- [ ] [\[2409.07797\] Quaternion Nuclear Norm minus Frobenius Norm Minimization for color image reconstruction](https://arxiv.org/abs/2409.07797) (CUHK)
- [ ] [\[2409.07825\] A Comprehensive Survey on Deep Multimodal Learning with Missing Modality](https://arxiv.org/abs/2409.07825) (MBZUAI)
- [ ] [\[2409.07843\] Real-time Multi-view Omnidirectional Depth Estimation System for Robots and Autonomous Driving on Real Scenes](https://arxiv.org/abs/2409.07843) (NJU)
- [ ] [\[2409.07896\] Microscopic-Mamba: Revealing the Secrets of Microscopic Images with Just 4M Parameters](https://arxiv.org/abs/2409.07896) (NUDT)
- [ ] [\[2409.07904\] FACT: Feature Adaptive Continual-learning Tracker for Multiple Object Tracking](https://arxiv.org/abs/2409.07904) (NTU)
- [ ] [\[2409.07913\] UGAD: Universal Generative AI Detector utilizing Frequency Fingerprints](https://arxiv.org/abs/2409.07913) (Sungkyunkwan University)
- [ ] [\[2409.07931\] Task-Augmented Cross-View Imputation Network for Partial Multi-View Incomplete Multi-Label Classification](https://arxiv.org/abs/2409.07931) (PolyU)
- [ ] [\[2409.07960\] Do Vision Foundation Models Enhance Domain Generalization in Medical Image Segmentation?](https://arxiv.org/abs/2409.07960) (ETH)
- [ ] [\[2409.07961\] Estimating Atmospheric Variables from Digital Typhoon Satellite Images via Conditional Denoising Diffusion Models](https://arxiv.org/abs/2409.07961) (Cambridge)
- [ ] [\[2409.07966\] ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE](https://arxiv.org/abs/2409.07966) (SIGGRAPH)
- [ ] [\[2409.07972\] Deep Height Decoupling for Precise Vision-based 3D Occupancy Prediction](https://arxiv.org/abs/2409.07972) (Nankai)
- [ ] [\[2409.07984\] SPARK: Self-supervised Personalized Real-time Monocular Face Capture](https://arxiv.org/abs/2409.07984) (SIGGRAPH)
- [ ] [\[2409.08056\] Expansive Supervision for Neural Radiance Field](https://arxiv.org/abs/2409.08056) (Tsinghua)
- [ ] [\[2409.08083\] SimMAT: Exploring Transferability from Vision Foundation Models to Any Image Modality](https://arxiv.org/abs/2409.08083) (IA CAS)
- [ ] [\[2409.08091\] EZIGen: Enhancing zero-shot subject-driven image generation with precise subject encoding and decoupled guidance](https://arxiv.org/abs/2409.08091) (Xidian)
- [ ] [\[2409.08102\] Bayesian Self-Training for Semi-Supervised 3D Segmentation](https://arxiv.org/abs/2409.08102) (ECCV)
- [ ] [\[2409.08156\] MagicStyle: Portrait Stylization Based on Reference Image](https://arxiv.org/abs/2409.08156) (Tongji)
- [ ] [\[2409.08171\] Low-Cost Tree Crown Dieback Estimation Using Deep Learning-Based Segmentation](https://arxiv.org/abs/2409.08171) (Cambridge)
- [ ] [\[2409.08202\] What Makes a Maze Look Like a Maze?](https://arxiv.org/abs/2409.08202) (Stanford)
- [ ] [\[2409.08207\] VI3DRM:Towards meticulous 3D Reconstruction from Sparse Views via Photo-Realistic Novel View Synthesis](https://arxiv.org/abs/2409.08207) (Fudan)
- [ ] [\[2409.08251\] Dynamic Prompting of Frozen Text-to-Image Diffusion Models for Panoptic Narrative Grounding](https://arxiv.org/abs/2409.08251) (ACMMM)
- [ ] [\[2409.08258\] Improving Virtual Try-On with Garment-focused Diffusion Models](https://arxiv.org/abs/2409.08258) (USTC, ECCV)
- [ ] [\[2409.08260\] Improving Text-guided Object Inpainting with Semantic Pre-inpainting](https://arxiv.org/abs/2409.08260) (Fudan, ECCV)
- [ ] [\[2409.08270\] FlashSplat: 2D to 3D Gaussian Splatting Segmentation Solved Optimally](https://arxiv.org/abs/2409.08270) (NUS, ECCV)
- [ ] [\[2409.08277\] Depth on Demand: Streaming Dense Depth from a Low Frame Rate Active Sensor](https://arxiv.org/abs/2409.08277) (ECCV)
- [ ] [\[2409.08278\] DreamHOI: Subject-Driven Generation of 3D Human-Object Interactions with Diffusion Priors](https://arxiv.org/abs/2409.08278) (CMU)
- [ ] [\[2409.08443\] CF-PRNet: Coarse-to-Fine Prototype Refining Network for Point Cloud Completion and Reconstruction](https://arxiv.org/abs/2409.08443) (ECCV)
- [ ] [\[2409.08444\] Towards Unified Facial Action Unit Recognition Framework by Large Language Models](https://arxiv.org/abs/2409.08444) (UCAS)
- [ ] [\[2409.08468\] Generalization Boosted Adapter for Open-Vocabulary Segmentation](https://arxiv.org/abs/2409.08468) (IA CAS)
- [ ] [\[2409.08501\] PSTNet: Enhanced Polyp Segmentation with Multi-scale Alignment and Frequency Domain Integration](https://arxiv.org/abs/2409.08501) (BUPT)
- [ ] [\[2409.08513\] Mamba-YOLO-World: Marrying YOLO-World with Mamba for Open-Vocabulary Detection](https://arxiv.org/abs/2409.08513) (Fudan)
- [ ] [\[2409.08518\] Anytime Continual Learning for Open Vocabulary Classification](https://arxiv.org/abs/2409.08518) (ECCV)
- [ ] [\[2409.08557\] DICS: Find Domain-Invariant and Class-Specific Features for Out-of-Distribution Generalization](https://arxiv.org/abs/2409.08557) (ZJU)
- [ ] [\[2409.08562\] CSS: Overcoming Pose and Scene Challenges in Crowd-Sourced 3D Gaussian Splatting](https://arxiv.org/abs/2409.08562) (ICT CAS)
- [ ] [\[2409.08572\] DiffFAS: Face Anti-Spoofing via Generative Diffusion Models](https://arxiv.org/abs/2409.08572) (Tianjin, ECCV)
- [ ] [\[2409.08585\] Optimizing 4D Lookup Table for Low-light Video Enhancement via Wavelet Priori](https://arxiv.org/abs/2409.08585) (CUHK)
- [ ] [\[2409.08598\] Knowledge-Enhanced Facial Expression Recognition with Emotional-to-Neutral Transformation](https://arxiv.org/abs/2409.08598) (Xidian)
- [ ] [\[2409.08669\] AdR-Gaussian: Accelerating Gaussian Splatting with Adaptive Radius](https://arxiv.org/abs/2409.08669) (SJTU, SIGGRAPH)
- [ ] [\[2409.08744\] Uncertainty and Generalizability in Foundation Models for Earth Observation](https://arxiv.org/abs/2409.08744) (Oxford)
- [ ] [\[2409.08831\] Breaking reCAPTCHAv2](https://arxiv.org/abs/2409.08831) (ETH)
- [ ] [\[2409.08857\] InstantDrag: Improving Interactivity in Drag-based Image Editing](https://arxiv.org/abs/2409.08857) (SIGGRAPH)
- [ ] [\[2409.08887\] Visual Language Tracking with Multi-modal Interaction: A Robust Benchmark](https://arxiv.org/abs/2409.08887) (IA CAS)
- [ ] [\[2409.09149\] Adaptive Multi-Modal Control of Digital Human Hand Synthesis Using a Region-Aware Cycle Loss](https://arxiv.org/abs/2409.09149) (QMUL)
- [ ] [\[2409.09269\] Guiding Vision-Language Model Selection for Visual Question-Answering Across Tasks, Domains, and Knowledge Types](https://arxiv.org/abs/2409.09269) (GIT)
- [ ] [\[2409.09286\] SAM-OCTA2: Layer Sequence OCTA Segmentation with Fine-tuned Segment Anything Model 2](https://arxiv.org/abs/2409.09286) (Chongqing)
- [ ] [\[2409.09292\] StyleTalk++: A Unified Framework for Controlling the Speaking Styles of Talking Heads](https://arxiv.org/abs/2409.09292) (Queensland, TPAMI)
- [ ] [\[2409.09293\] Associate Everything Detected: Facilitating Tracking-by-Detection to the Unknown](https://arxiv.org/abs/2409.09293) (UESTC)
- [ ] [\[2409.09312\] Registration between Point Cloud Streams and Sequential Bounding Boxes via Gradient Descent](https://arxiv.org/abs/2409.09312) (ShanghaiTech)
- [ ] [\[2409.09313\] Tensor-Based Synchronization and the Low-Rankness of the Block Trifocal Tensor](https://arxiv.org/abs/2409.09313) (UT Austin)
- [ ] [\[2409.09348\] QTG-VQA: Question-Type-Guided Architectural for VideoQA Systems](https://arxiv.org/abs/2409.09348) (SYSU)
- [ ] [\[2409.09360\] LACOSTE: Exploiting stereo and temporal contexts for surgical instrument segmentation](https://arxiv.org/abs/2409.09360) (USTC)
- [ ] [\[2409.09366\] MHAD: Multimodal Home Activity Dataset with Multi-Angle Videos and Synchronized Physiological Signals](https://arxiv.org/abs/2409.09366) (HUST)
- [ ] [\[2409.09369\] Interpretable Vision-Language Survival Analysis with Ordinal Inductive Bias for Computational Pathology](https://arxiv.org/abs/2409.09369) (UESTC)
- [ ] [\[2409.09497\] Multi-Scale Grouped Prototypes for Interpretable Semantic Segmentation](https://arxiv.org/abs/2409.09497) (Inria)
- [ ] [\[2409.09605\] DreamMover: Leveraging the Prior of Diffusion Models for Image Interpolation with Large Motion](https://arxiv.org/abs/2409.09605) (ECCV)
- [ ] [\[2409.09610\] TextureDiffusion: Target Prompt Disentangled Editing for Various Texture Transfer](https://arxiv.org/abs/2409.09610) (Tsinghua)
- [ ] [\[2409.09628\] Can Large Language Models Grasp Event Signals? Exploring Pure Zero-Shot Event-based Recognition](https://arxiv.org/abs/2409.09628) (BU)
- [ ] [\[2409.09649\] SparX: A Sparse Cross-Layer Connection Mechanism for Hierarchical Vision Mamba and Transformer Networks](https://arxiv.org/abs/2409.09649) (HKU)
- [ ] [\[2409.09673\] SITSMamba for Crop Classification based on Satellite Image Time Series](https://arxiv.org/abs/2409.09673) (WHU)
- [ ] [\[2409.09708\] ELSA: Exploiting Layer-wise N:M Sparsity for Vision Transformer Acceleration](https://arxiv.org/abs/2409.09708) (UT Austin)
- [ ] [\[2409.09714\] Pre-Training for 3D Hand Pose Estimation with Contrastive Learning on Large-Scale Hand Images in the Wild](https://arxiv.org/abs/2409.09714) (ECCV)
- [ ] [\[2409.09724\] MFCLIP: Multi-modal Fine-grained CLIP for Generalizable Diffusion Face Forgery Detection](https://arxiv.org/abs/2409.09724) (BU)
- [ ] [\[2409.09740\] VGG-Tex: A Vivid Geometry-Guided Facial Texture Estimation Model for High Fidelity Monocular 3D Face Reconstruction](https://arxiv.org/abs/2409.09740) (Tsinghua)
- [ ] [\[2409.09748\] Explore the Hallucination on Low-level Perception for MLLMs](https://arxiv.org/abs/2409.09748) (SJTU)
- [ ] [\[2409.09754\] Towards Single-Lens Controllable Depth-of-Field Imaging via All-in-Focus Aberration Correction and Monocular Depth Estimation](https://arxiv.org/abs/2409.09754) (ZJU)
- [ ] [\[2409.09756\] MesonGS: Post-training Compression of 3D Gaussians via Efficient Attribute Transformation](https://arxiv.org/abs/2409.09756) (ECCV)
- [ ] [\[2409.09766\] Automated Lesion Segmentation in Whole-Body PET/CT in a multitracer setting](https://arxiv.org/abs/2409.09766) (SJTU)
- [ ] [\[2409.09784\] Enhancing Lesion Segmentation in PET/CT Imaging with Deep Learning and Advanced Data Preprocessing Techniques](https://arxiv.org/abs/2409.09784) (SJTU)
- [ ] [\[2409.09788\] Reasoning Paths with Reference Objects Elicit Quantitative Spatial Reasoning in Large Vision-Language Models](https://arxiv.org/abs/2409.09788) (University of Toronto)
- [ ] [\[2409.09832\] Template-based Multi-Domain Face Recognition](https://arxiv.org/abs/2409.09832) (UMD)
- [ ] [\[2409.09907\] Rapid Adaptation of Earth Observation Foundation Models for Segmentation](https://arxiv.org/abs/2409.09907) (Oxford)
- [ ] [\[2409.09953\] Uncertainty-Guided Appearance-Motion Association Network for Out-of-Distribution Action Detection](https://arxiv.org/abs/2409.09953) (NTU)
- [ ] [\[2409.09969\] 2S-ODIS: Two-Stage Omni-Directional Image Synthesis by Geometric Distortion Correction](https://arxiv.org/abs/2409.09969) (ECCV)
- [ ] [\[2409.10063\] GlobalMapNet: An Online Framework for Vectorized Global HD Map Construction](https://arxiv.org/abs/2409.10063) (Fudan)
- [ ] [\[2409.10071\] Towards Physically-Realizable Adversarial Attacks in Embodied Vision Navigation](https://arxiv.org/abs/2409.10071) (BUPT)
- [ ] [\[2409.10094\] DDoS: Diffusion Distribution Similarity for Out-of-Distribution Detection](https://arxiv.org/abs/2409.10094) (KU Leuven)
- [ ] [\[2409.10180\] RealDiff: Real-world 3D Shape Completion using Self-Supervised Diffusion Models](https://arxiv.org/abs/2409.10180) (UVA.NL)
- [ ] [\[2409.10197\] Fit and Prune: Fast and Training-free Visual Token Pruning for Multi-modal Large Language Models](https://arxiv.org/abs/2409.10197) (Xiamen)
- [ ] [\[2409.10247\] SOLVR: Submap Oriented LiDAR-Visual Re-Localisation](https://arxiv.org/abs/2409.10247) (TUM)
- [ ] [\[2409.10422\] Learning Semi-Supervised Medical Image Segmentation from Spatial Registration](https://arxiv.org/abs/2409.10422) (Imperial)
- [ ] [\[2409.10473\] MacDiff: Unified Skeleton Modeling with Masked Conditional Diffusion](https://arxiv.org/abs/2409.10473) (Peking, ECCV)
- [ ] [\[2409.10476\] SimInversion: A Simple Framework for Inversion-Based Text-to-Image Editing](https://arxiv.org/abs/2409.10476) (UW)
- [ ] [\[2409.10535\] Learning Co-Speech Gesture Representations in Dialogue through Contrastive Learning: An Intrinsic Evaluation](https://arxiv.org/abs/2409.10535) (UVA.NL)
- [ ] [\[2409.10716\] Online Learning via Memory: Retrieval-Augmented Detector Adaptation](https://arxiv.org/abs/2409.10716) (Microsoft)
- [ ] [\[2409.10901\] TrajSSL: Trajectory-Enhanced Semi-Supervised 3D Object Detection](https://arxiv.org/abs/2409.10901) (Berkeley)
- [ ] [\[2409.10917\] AMEGO: Active Memory from long EGOcentric videos](https://arxiv.org/abs/2409.10917) (ECCV)
- [ ] [\[2409.10925\] HGSLoc: 3DGS-based Heuristic Camera Pose Refinement](https://arxiv.org/abs/2409.10925) (NUDT)
- [ ] [\[2409.10956\] Versatile Incremental Learning: Towards Class and Domain-Agnostic Incremental Learning](https://arxiv.org/abs/2409.10956) (ECCV)
- [ ] [\[2409.11018\] Unleashing the Potential of Mamba: Boosting a LiDAR 3D Sparse Detector by Using Cross-Model Knowledge Distillation](https://arxiv.org/abs/2409.11018) (USyd)
- [ ] [\[2409.11211\] SplatFields: Neural Gaussian Splats for Sparse 3D and 4D Reconstruction](https://arxiv.org/abs/2409.11211) (ECCV)
- [ ] [\[2409.11234\] STCMOT: Spatio-Temporal Cohesion Learning for UAV-Based Multiple Object Tracking](https://arxiv.org/abs/2409.11234) (UCAS)
- [ ] [\[2409.11235\] SLAck: Semantic, Location, and Appearance Aware Open-Vocabulary Tracking](https://arxiv.org/abs/2409.11235) (ECCV)
- [ ] [\[2409.11307\] GS-Net: Generalizable Plug-and-Play 3D Gaussian Splatting Module](https://arxiv.org/abs/2409.11307) (Tsinghua)
- [ ] [\[2409.11315\] fMRI-3D: A Comprehensive Dataset for Enhancing fMRI-based 3D Reconstruction](https://arxiv.org/abs/2409.11315) (Fudan, ECCV)
- [ ] [\[2409.11356\] RenderWorld: World Model with Self-Supervised 3D Label](https://arxiv.org/abs/2409.11356) (ShanghaiTech)
- [ ] [\[2409.11367\] OSV: One Step is Enough for High-Quality Image to Video Generation](https://arxiv.org/abs/2409.11367) (HKUST)
- [ ] [\[2409.11624\] Multimodal Generalized Category Discovery](https://arxiv.org/abs/2409.11624) (CMU)
- [ ] [\[2409.11642\] DAF-Net: A Dual-Branch Feature Decomposition Fusion Network with Domain Adaptive for Infrared and Visible Image Fusion](https://arxiv.org/abs/2409.11642) (UESTC)
- [ ] [\[2409.11656\] VL-Reader: Vision and Language Reconstructor is an Effective Scene Text Recognizer](https://arxiv.org/abs/2409.11656) (HUST)
- [ ] [\[2409.11661\] Bridging Domain Gap for Flight-Ready Spaceborne Vision](https://arxiv.org/abs/2409.11661) (Stanford)
- [ ] [\[2409.11664\] Agent Aggregator with Mask Denoise Mechanism for Histopathology Whole Slide Image Analysis](https://arxiv.org/abs/2409.11664) (Tsinghua)
- [ ] [\[2409.11682\] SRIF: Semantic Shape Registration Empowered by Diffusion-based Image Morphing and Flow Estimation](https://arxiv.org/abs/2409.11682) (Tsinghua, SIGGRAPH)
- [ ] [\[2409.11718\] Free-VSC: Free Semantics from Visual Foundation Models for Unsupervised Video Semantic Compression](https://arxiv.org/abs/2409.11718) (ECCV)
- [ ] [\[2409.11734\] InverseMeetInsert: Robust Real Image Editing via Geometric Accumulation Inversion in Guided Diffusion Models](https://arxiv.org/abs/2409.11734) (UT Austin)
- [ ] [\[2409.11750\] Neural Encoding for Image Recall: Human-Like Memory](https://arxiv.org/abs/2409.11750) (Berkeley)
- [ ] [\[2409.11785\] Distilling Channels for Efficient Deep Tracking](https://arxiv.org/abs/2409.11785) (USyd, TIP)
- [ ] [\[2409.11786\] Efficient Low-Resolution Face Recognition via Bridge Distillation](https://arxiv.org/abs/2409.11786) (TIP)
- [ ] [\[2409.11869\] SpheriGait: Enriching Spatial Representation via Spherical Projection for LiDAR-based Gait Recognition](https://arxiv.org/abs/2409.11869) (BIT)
- [ ] [\[2409.11923\] Agglomerative Token Clustering](https://arxiv.org/abs/2409.11923) (ECCV)
- [ ] [\[2409.11937\] Differentiable Collision-Supervised Tooth Arrangement Network with a Decoupling Perspective](https://arxiv.org/abs/2409.11937) (Tsinghua)
- [ ] [\[2409.11951\] GaussianHeads: End-to-End Learning of Drivable Gaussian Head Avatars from Coarse-to-fine Representations](https://arxiv.org/abs/2409.11951) (MPI, SIGGRAPH)
- [ ] [\[2409.11953\] Tracking Any Point with Frame-Event Fusion Network at High Frame Rate](https://arxiv.org/abs/2409.11953) (NUDT)
- [ ] [\[2409.11969\] Unveiling the Black Box: Independent Functional Module Evaluation for Bird's-Eye-View Perception Model](https://arxiv.org/abs/2409.11969) (Tsinghua)
- [ ] [\[2409.12011\] Mixture of Prompt Learning for Vision Language Models](https://arxiv.org/abs/2409.12011) (Tsinghua)
- [ ] [\[2409.12034\] Multi-Sensor Deep Learning for Glacier Mapping](https://arxiv.org/abs/2409.12034) (DLR)
- [ ] [\[2409.12108\] SPRMamba: Surgical Phase Recognition for Endoscopic Submucosal Dissection with Mamba](https://arxiv.org/abs/2409.12108) (SJTU)
- [ ] [\[2409.12140\] MoRAG -- Multi-Fusion Retrieval Augmented Generation for Human Motion](https://arxiv.org/abs/2409.12140) (UCSD)
- [ ] [\[2409.12162\] Precise Forecasting of Sky Images Using Spatial Warping](https://arxiv.org/abs/2409.12162) (CMU)
- [ ] [\[2409.12189\] Massively Multi-Person 3D Human Motion Forecasting with Scene Context](https://arxiv.org/abs/2409.12189) (University of GÃ¶ttingen)
- [ ] [\[2409.12193\] Vista3D: Unravel the 3D Darkside of a Single Image](https://arxiv.org/abs/2409.12193) (NUS, ECCV)
- [ ] [\[2409.12385\] Look Through Masks: Towards Masked Face Recognition with De-Occlusion Distillation](https://arxiv.org/abs/2409.12385) (ACMMM)
- [ ] [\[2409.12448\] Infrared Small Target Detection in Satellite Videos: A New Dataset and A Novel Recurrent Feature Refinement Framework](https://arxiv.org/abs/2409.12448) (NUDT)
- [ ] [\[2409.12470\] HSIGene: A Foundation Model For Hyperspectral Image Generation](https://arxiv.org/abs/2409.12470) (XJTU)
- [ ] [\[2409.12499\] End-to-end Open-vocabulary Video Visual Relationship Detection using Multi-modal Prompting](https://arxiv.org/abs/2409.12499) (BIT)
- [ ] [\[2409.12507\] Towards Low-latency Event-based Visual Recognition with Hybrid Step-wise Distillation Spiking Neural Networks](https://arxiv.org/abs/2409.12507) (Peking)
- [ ] [\[2409.12522\] Prompting Segment Anything Model with Domain-Adaptive Prototype for Generalizable Medical Image Segmentation](https://arxiv.org/abs/2409.12522) (WHU)
- [ ] [\[2409.12612\] Enhancing Perception of Key Changes in Remote Sensing Image Change Captioning](https://arxiv.org/abs/2409.12612) (WHU)
- [ ] [\[2409.12661\] Manifold Sampling for Differentiable Uncertainty in Radiance Fields](https://arxiv.org/abs/2409.12661) (SIGGRAPH)
- [ ] [\[2409.12680\] Exploiting Minority Pseudo-Labels for Semi-Supervised Semantic Segmentation in Autonomous Driving](https://arxiv.org/abs/2409.12680) (BU)
- [ ] [\[2409.12705\] Generation and Editing of Mandrill Faces: Application to Sex Editing and Assessment](https://arxiv.org/abs/2409.12705) (CNRS)
- [ ] [\[2409.12724\] PVContext: Hybrid Context Model for Point Cloud Compression](https://arxiv.org/abs/2409.12724) (HIT)
- [ ] [\[2409.12753\] DrivingForward: Feed-forward 3D Gaussian Splatting for Driving Scene Reconstruction from Flexible Surround-view Input](https://arxiv.org/abs/2409.12753) (SJTU)
- [ ] [\[2409.12778\] EventDance++: Language-guided Unsupervised Source-free Cross-modal Adaptation for Event-based Object Recognition](https://arxiv.org/abs/2409.12778) (HKUST)
- [ ] [\[2409.12952\] The Gaussian Discriminant Variational Autoencoder (GdVAE): A Self-Explainable Model with Counterfactual Explanations](https://arxiv.org/abs/2409.12952) (ECCV)
- [ ] [\[2409.12960\] LVCD: Reference-based Lineart Video Colorization with Diffusion Models](https://arxiv.org/abs/2409.12960) (SIGGRAPH)
- [ ] [\[2409.12973\] The Era of Foundation Models in Medical Imaging is Approaching : A Scoping Review of the Clinical Value of Large-Scale Generative AI Applications in Radiology](https://arxiv.org/abs/2409.12973) (KAIST)
- [ ] [\[2409.12980\] A New People-Object Interaction Dataset and NVS Benchmarks](https://arxiv.org/abs/2409.12980) (SJTU)
- [ ] [\[2409.13037\] DNI: Dilutional Noise Initialization for Diffusion Video Editing](https://arxiv.org/abs/2409.13037) (ECCV)
- [ ] [\[2409.13106\] UL-VIO: Ultra-lightweight Visual-Inertial Odometry with Noise Robust Test-time Adaptation](https://arxiv.org/abs/2409.13106) (Columbia University)
- [ ] [\[2409.13148\] UniTabNet: Bridging Vision and Language Models for Enhanced Table Structure Recognition](https://arxiv.org/abs/2409.13148) (USTC)
- [ ] [\[2409.13158\] High-Fidelity Mask-free Neural Surface Reconstruction for Virtual Reality](https://arxiv.org/abs/2409.13158) (University of Alberta)
- [ ] [\[2409.13162\] Towards Zero-shot Point Cloud Anomaly Detection: A Multi-View Projection Framework](https://arxiv.org/abs/2409.13162) (HUST)
- [ ] [\[2409.13173\] Bilateral Sharpness-Aware Minimization for Flatter Minima](https://arxiv.org/abs/2409.13173) (UCAS)
- [ ] [\[2409.13174\] Manipulation Facing Threats: Evaluating Physical Vulnerabilities in End-to-End Vision Language Action Models](https://arxiv.org/abs/2409.13174) (HKUST(GZ))
- [ ] [\[2409.13275\] Adaptive Margin Global Classifier for Exemplar-Free Class-Incremental Learning](https://arxiv.org/abs/2409.13275) (SYSU)
- [ ] [\[2409.13325\] Towards Semi-supervised Dual-modal Semantic Segmentation](https://arxiv.org/abs/2409.13325) (IA CAS)
- [ ] [\[2409.13345\] A Novel Adaptive Fine-Tuning Algorithm for Multimodal Models: Self-Optimizing Classification and Selection of High-Quality Datasets in Remote Sensing](https://arxiv.org/abs/2409.13345) (Xidian)
- [ ] [\[2409.13346\] Imagine yourself: Tuning-Free Personalized Image Generation](https://arxiv.org/abs/2409.13346) (Meta)
- [ ] [\[2409.13349\] ID-Guard: A Universal Framework for Combating Facial Manipulation via Breaking Identification](https://arxiv.org/abs/2409.13349) (SYSU)
- [ ] [\[2409.13392\] Elite-EvGS: Learning Event-based 3D Gaussian Splatting by Distilling Event-to-Video Priors](https://arxiv.org/abs/2409.13392) (HKUST(GZ))
- [ ] [\[2409.13402\] Validation & Exploration of Multimodal Deep-Learning Camera-Lidar Calibration models](https://arxiv.org/abs/2409.13402) (Michigan State University)
- [ ] [\[2409.13418\] Occupancy-Based Dual Contouring](https://arxiv.org/abs/2409.13418) (KAIST, SIGGRAPH)
- [ ] [\[2409.13430\] CVT-Occ: Cost Volume Temporal Fusion for 3D Occupancy Prediction](https://arxiv.org/abs/2409.13430) (Tsinghua, ECCV)
- [ ] [\[2409.13431\] Leveraging Text Localization for Scene Text Removal via Text-aware Masked Image Modeling](https://arxiv.org/abs/2409.13431) (USTC, ECCV)
- [ ] [\[2409.13464\] Robust Salient Object Detection on Compressed Images Using Convolutional Neural Networks](https://arxiv.org/abs/2409.13464) (Peking)
- [ ] [\[2409.13496\] DAP-LED: Learning Degradation-Aware Priors with CLIP for Joint Low-light Enhancement and Deblurring](https://arxiv.org/abs/2409.13496) (HKUST(GZ))
- [ ] [\[2409.13535\] Formula-Supervised Visual-Geometric Pre-training](https://arxiv.org/abs/2409.13535) (ECCV)
- [ ] [\[2409.13540\] FullAnno: A Data Engine for Enhancing Image Comprehension of MLLMs](https://arxiv.org/abs/2409.13540) (HKU)
- [ ] [\[2409.13557\] Trustworthy Hate Speech Detection Through Visual Augmentation](https://arxiv.org/abs/2409.13557) (A*STAR,)
- [ ] [\[2409.13591\] Portrait Video Editing Empowered by Multimodal Generative Priors](https://arxiv.org/abs/2409.13591) (USTC, SIGGRAPH)
- [ ] [\[2409.13609\] MaPPER: Multimodal Prior-guided Parameter Efficient Tuning for Referring Expression Comprehension](https://arxiv.org/abs/2409.13609) (NUDT)
- [ ] [\[2409.13648\] V^3: Viewing Volumetric Videos on Mobiles via Streamable 2D Dynamic Gaussians](https://arxiv.org/abs/2409.13648) (ShanghaiTech)
- [ ] [\[2409.13689\] Temporally Aligned Audio for Video with Autoregression](https://arxiv.org/abs/2409.13689) (Oxford)
- [ ] [\[2409.13690\] Colorful Diffuse Intrinsic Image Decomposition in the Wild](https://arxiv.org/abs/2409.13690) (SIGGRAPH)
- [ ] [\[2409.13803\] Intrinsic Single-Image HDR Reconstruction](https://arxiv.org/abs/2409.13803) (ECCV)
- [ ] [\[2409.13846\] Multi-Modality Conditioned Variational U-Net for Field-of-View Extension in Brain Diffusion MRI](https://arxiv.org/abs/2409.13846) (Vanderbilt University)
- [ ] [\[2409.13887\] Brain-Cognition Fingerprinting via Graph-GCCA with Contrastive Learning](https://arxiv.org/abs/2409.13887) (Cornell)
- [ ] [\[2409.13941\] TalkMosaic: Interactive PhotoMosaic with Multi-modal LLM Q&A Interactions](https://arxiv.org/abs/2409.13941) (MIT)
- [ ] [\[2409.13951\] Deep learning for fast segmentation and critical dimension metrology & characterization enabling AR/VR design and fabrication](https://arxiv.org/abs/2409.13951) (Meta)
- [ ] [\[2409.13971\] Monocular Event-Inertial Odometry with Adaptive decay-based Time Surface and Polarity-aware Tracking](https://arxiv.org/abs/2409.13971) (ZJU)
- [ ] [\[2409.13976\] Detecting Inpainted Video with Frequency Domain Insights](https://arxiv.org/abs/2409.13976) (UESTC)
- [ ] [\[2409.13977\] Improving 3D Semi-supervised Learning by Effectively Utilizing All Unlabelled Data](https://arxiv.org/abs/2409.13977) (ECCV)
- [ ] [\[2409.13983\] Enhanced Semantic Segmentation for Large-Scale and Imbalanced Point Clouds](https://arxiv.org/abs/2409.13983) (XJTU)
- [ ] [\[2409.13987\] Holistic and Historical Instance Comparison for Cervical Cell Detection](https://arxiv.org/abs/2409.13987) (HKUST)
- [ ] [\[2409.13988\] GAInS: Gradient Anomaly-aware Biomedical Instance Segmentation](https://arxiv.org/abs/2409.13988) (HKUST)
- [ ] [\[2409.13999\] Multiple-Exit Tuning: Towards Inference-Efficient Adaptation for Vision Transformer](https://arxiv.org/abs/2409.13999) (Tsinghua)
- [ ] [\[2409.14019\] MOSE: Monocular Semantic Reconstruction Using NeRF-Lifted Noisy Priors](https://arxiv.org/abs/2409.14019) (NUDT)
- [ ] [\[2409.14021\] BrainDreamer: Reasoning-Coherent and Controllable Image Generation from EEG Brain Signals via Language Guidance](https://arxiv.org/abs/2409.14021) (HKUST(GZ))
- [ ] [\[2409.14101\] PoseAugment: Generative Human Pose Data Augmentation with Physical Plausibility for IMU-based Motion Capture](https://arxiv.org/abs/2409.14101) (Tsinghua, ECCV)
- [ ] [\[2409.14103\] ExFMan: Rendering 3D Dynamic Humans with Hybrid Monocular Blurry Frames and Events](https://arxiv.org/abs/2409.14103) (HKUST(GZ))
- [ ] [\[2409.14149\] JVID: Joint Video-Image Diffusion for Visual-Quality and Temporal-Consistency in Video Generation](https://arxiv.org/abs/2409.14149) (Imperial)
- [ ] [\[2409.14163\] PromptTA: Prompt-driven Text Adapter for Source-free Domain Generalization](https://arxiv.org/abs/2409.14163) (XJTU)
- [ ] [\[2409.14170\] LFP: Efficient and Accurate End-to-End Lane-Level Planning via Camera-LiDAR Fusion](https://arxiv.org/abs/2409.14170) (USTC)
- [ ] [\[2409.14201\] LATTE: Improving Latex Recognition for Tables and Formulae with Iterative Refinement](https://arxiv.org/abs/2409.14201) (Illinois)
- [ ] [\[2409.14220\] Masks and Boxes: Combining the Best of Both Worlds for Multi-Object Tracking](https://arxiv.org/abs/2409.14220) (Inria)
- [ ] [\[2409.14273\] Lidar Panoptic Segmentation in an Open World](https://arxiv.org/abs/2409.14273) (CMU)
- [ ] [\[2409.14289\] Deep Learning Technology for Face Forgery Detection: A Survey](https://arxiv.org/abs/2409.14289) (IA CAS)
- [ ] [\[2409.14316\] MVPGS: Excavating Multi-view Priors for Gaussian Splatting from Sparse Input Views](https://arxiv.org/abs/2409.14316) (Peking, ECCV)
- [ ] [\[2409.14319\] Scene-Text Grounding for Text-Based Video Question Answering](https://arxiv.org/abs/2409.14319) (USTC)
- [ ] [\[2409.14331\] PISR: Polarimetric Neural Implicit Surface Reconstruction for Textureless and Specular Objects](https://arxiv.org/abs/2409.14331) (ECCV)
- [ ] [\[2409.14340\] Self-Supervised Audio-Visual Soundscape Stylization](https://arxiv.org/abs/2409.14340) (ECCV)
- [ ] [\[2409.14343\] Memory Matching is not Enough: Jointly Improving Memory Matching and Decoding for Video Object Segmentation](https://arxiv.org/abs/2409.14343) (UCAS)
- [ ] [\[2409.14379\] GroupDiff: Diffusion-based Group Portrait Editing](https://arxiv.org/abs/2409.14379) (ECCV)
- [ ] [\[2409.14385\] Prior Knowledge Distillation Network for Face Super-Resolution](https://arxiv.org/abs/2409.14385) (USTC)
- [ ] [\[2409.14444\] Fake It till You Make It: Curricular Dynamic Forgery Augmentations towards General Deepfake Detection](https://arxiv.org/abs/2409.14444) (SYSU, ECCV)
- [ ] [\[2409.14474\] SynBench: A Synthetic Benchmark for Non-rigid 3D Point Cloud Registration](https://arxiv.org/abs/2409.14474) (Harvard)
- [ ] [\[2409.14483\] One Model for Two Tasks: Cooperatively Recognizing and Recovering Low-Resolution Scene Text Images by Iterative Mutual Guidance](https://arxiv.org/abs/2409.14483) (Fudan)
- [ ] [\[2409.14485\] Video-XL: Extra-Long Vision Language Model for Hour-Scale Video Understanding](https://arxiv.org/abs/2409.14485) (SJTU)
- [ ] [\[2409.14538\] Towards Model-Agnostic Dataset Condensation by Heterogeneous Models](https://arxiv.org/abs/2409.14538) (ECCV)
- [ ] [\[2409.14553\] GlamTry: Advancing Virtual Try-On for High-End Accessories](https://arxiv.org/abs/2409.14553) (Stanford)
- [ ] [\[2409.14627\] SOS: Segment Object System for Open-World Instance Segmentation With Object Priors](https://arxiv.org/abs/2409.14627) (ECCV)
- [ ] [\[2409.14679\] Quantifying Context Bias in Domain Adaptation for Object Detection](https://arxiv.org/abs/2409.14679) (University of Michigan)
- [ ] [\[2409.14704\] VLEU: a Method for Automatic Evaluation for Generalizability of Text-to-Image Models](https://arxiv.org/abs/2409.14704) (CUHK)
- [ ] [\[2409.14713\] Phantom of Latent for Large Language and Vision Models](https://arxiv.org/abs/2409.14713) (KAIST)
- [ ] [\[2409.14741\] Less yet robust: crucial region selection for scene recognition](https://arxiv.org/abs/2409.14741) (IS CAS)
- [ ] [\[2409.14747\] Distribution-Level Feature Distancing for Machine Unlearning: Towards a Better Trade-off Between Model Utility and Forgetting](https://arxiv.org/abs/2409.14747) (POSTECH)
- [ ] [\[2409.14750\] FineCops-Ref: A new Dataset and Task for Fine-Grained Compositional Referring Expression Comprehension](https://arxiv.org/abs/2409.14750) (UESTC)
- [ ] [\[2409.14759\] VLM's Eye Examination: Instruct and Inspect Visual Competency of Vision Language Models](https://arxiv.org/abs/2409.14759) (POSTECH)
- [ ] [\[2409.14766\] Robust and Flexible Omnidirectional Depth Estimation with Multiple 360{\deg} Cameras](https://arxiv.org/abs/2409.14766) (NJU)
- [ ] [\[2409.14774\] CFVNet: An End-to-End Cancelable Finger Vein Network for Recognition](https://arxiv.org/abs/2409.14774) (HKUST)
- [ ] [\[2409.14847\] Revisiting Video Quality Assessment from the Perspective of Generalization](https://arxiv.org/abs/2409.14847) (WHU)
- [ ] [\[2409.14925\] DanceCamAnimator: Keyframe-Based Controllable 3D Dance Camera Synthesis](https://arxiv.org/abs/2409.14925) (Tsinghua, ACMMM)
- [ ] [\[2409.14935\] Deep Cost Ray Fusion for Sparse Depth Video Completion](https://arxiv.org/abs/2409.14935) (ECCV)
- [ ] [\[2409.14983\] Dynamic Integration of Task-Specific Adapters for Class Incremental Learning](https://arxiv.org/abs/2409.14983) (XJTU)
- [ ] [\[2409.14984\] SocialCircle+: Learning the Angle-based Conditioned Interaction Representation for Pedestrian Trajectory Prediction](https://arxiv.org/abs/2409.14984) (HUST)
- [ ] [\[2409.15006\] Generalizing monocular colonoscopy image depth estimation by uncertainty-based global and local fusion network](https://arxiv.org/abs/2409.15006) (SJTU)
- [ ] [\[2409.15028\] Region Mixup](https://arxiv.org/abs/2409.15028) (ICLR)
- [ ] [\[2409.15054\] FisheyeDepth: A Real Scale Self-Supervised Depth Estimation Model for Fisheye Camera](https://arxiv.org/abs/2409.15054) (HKUST)
- [ ] [\[2409.15077\] TSCLIP: Robust CLIP Fine-Tuning for Worldwide Cross-Regional Traffic Sign Recognition](https://arxiv.org/abs/2409.15077) (HKUST)
- [ ] [\[2409.15092\] M2OST: Many-to-one Regression for Predicting Spatial Transcriptomics from Digital Pathology Images](https://arxiv.org/abs/2409.15092) (ZJU)
- [ ] [\[2409.15107\] The BRAVO Semantic Segmentation Challenge Results in UNCV2024](https://arxiv.org/abs/2409.15107) (ECCV)
- [ ] [\[2409.15132\] FusionRF: High-Fidelity Satellite Neural Radiance Fields from Multispectral and Panchromatic Acquisitions](https://arxiv.org/abs/2409.15132) (JHU)
- [ ] [\[2409.15179\] MIMAFace: Face Animation via Motion-Identity Modulated Appearance Feature Learning](https://arxiv.org/abs/2409.15179) (ZJU)
- [ ] [\[2409.15190\] Interpretability-Guided Test-Time Adversarial Defense](https://arxiv.org/abs/2409.15190) (ECCV)
- [ ] [\[2409.15196\] HOTVCOM: Generating Buzzworthy Comments for Videos](https://arxiv.org/abs/2409.15196) (SUSTech)
- [ ] [\[2409.15284\] The NGT200 Dataset: Geometric Multi-View Isolated Sign Recognition](https://arxiv.org/abs/2409.15284) (UVA.NL)
- [ ] [\[2409.15313\] Deep Transfer Learning for Breast Cancer Classification](https://arxiv.org/abs/2409.15313) (Michigan State University)
- [ ] [\[2409.15557\] Mixture of Efficient Diffusion Experts Through Automatic Interval and Sub-Network Selection](https://arxiv.org/abs/2409.15557) (ECCV)
- [ ] [\[2409.15679\] PDT: Uav Target Detection Dataset for Pests and Diseases Tree](https://arxiv.org/abs/2409.15679) (ECCV)
- [ ] [\[2409.15689\] Plenoptic PNG: Real-Time Neural Radiance Fields in 150 KB](https://arxiv.org/abs/2409.15689) (AWS)
- [ ] [\[2409.15715\] Disentangled Generation and Aggregation for Robust Radiance Fields](https://arxiv.org/abs/2409.15715) (ECCV)
- [ ] [\[2409.15727\] LaPose: Laplacian Mixture Shape Modeling for RGB-Based Category-Level Object Pose Estimation](https://arxiv.org/abs/2409.15727) (ECCV)
- [ ] [\[2409.15739\] Teaching Tailored to Talent: Adverse Weather Restoration via Prompt Pool and Depth-Anything Constraint](https://arxiv.org/abs/2409.15739) (HKUST, ECCV)
- [ ] [\[2409.15801\] DIAL: Dense Image-text ALignment for Weakly Supervised Semantic Segmentation](https://arxiv.org/abs/2409.15801) (ECCV)
- [ ] [\[2409.15803\] 3D-JEPA: A Joint Embedding Predictive Architecture for 3D Self-Supervised Representation Learning](https://arxiv.org/abs/2409.15803) (XJTU)
- [ ] [\[2409.15810\] Hyperbolic Image-and-Pointcloud Contrastive Learning for 3D Classification](https://arxiv.org/abs/2409.15810) (XJTU)
- [ ] [\[2409.15841\] FSF-Net: Enhance 4D Occupancy Forecasting with Coarse BEV Scene Flow for Autonomous Driving](https://arxiv.org/abs/2409.15841) (HUST)
- [ ] [\[2409.15875\] Zero-Shot Detection of AI-Generated Images](https://arxiv.org/abs/2409.15875) (TUM)
- [ ] [\[2409.15893\] Unsupervised Attention Regularization Based Domain Adaptation for Oracle Character Recognition](https://arxiv.org/abs/2409.15893) (BUPT)
- [ ] [\[2409.15904\] Unimotion: Unifying 3D Human Motion Synthesis and Understanding](https://arxiv.org/abs/2409.15904) (MPI)
- [ ] [\[2409.15914\] Exploring the potential of collaborative UAV 3D mapping in Kenyan savanna for wildlife research](https://arxiv.org/abs/2409.15914) (WHU)
- [ ] [\[2409.15939\] Self-supervised Shape Completion via Involution and Implicit Correspondences](https://arxiv.org/abs/2409.15939) (Google, ECCV)
- [ ] [\[2409.15959\] Semantics-Controlled Gaussian Splatting for Outdoor Scene Reconstruction and Rendering in Virtual Reality](https://arxiv.org/abs/2409.15959) (TUM)
- [ ] [\[2409.15968\] Adversarial Backdoor Defense in CLIP](https://arxiv.org/abs/2409.15968) (SYSU)
- [ ] [\[2409.15980\] Leveraging Unsupervised Learning for Cost-Effective Visual Anomaly Detection](https://arxiv.org/abs/2409.15980) (Cambridge)
- [ ] [\[2409.16057\] Towards Robust Object Detection: Identifying and Removing Backdoors via Module Inconsistency Analysis](https://arxiv.org/abs/2409.16057) (Peking)
- [ ] [\[2409.16063\] Benchmarking Robustness of Endoscopic Depth Estimation with Synthetically Corrupted Data](https://arxiv.org/abs/2409.16063) (CUHK)
- [ ] [\[2409.16073\] Open-World Object Detection with Instance Representation Learning](https://arxiv.org/abs/2409.16073) (CMU)
- [ ] [\[2409.16084\] MM-CamObj: A Comprehensive Multimodal Dataset for Camouflaged Object Scenarios](https://arxiv.org/abs/2409.16084) (SJTU)
- [ ] [\[2409.16145\] Learning to Localize Actions in Instructional Videos with LLM-Based Multi-Pathway Text-Video Alignment](https://arxiv.org/abs/2409.16145) (ECCV)
- [ ] [\[2409.16209\] LLMCount: Enhancing Stationary mmWave Detection with Multimodal-LLM](https://arxiv.org/abs/2409.16209) (BUPT)
- [ ] [\[2409.16271\] AIM 2024 Challenge on UHD Blind Photo Quality Assessment](https://arxiv.org/abs/2409.16271) (ECCV)
- [ ] [\[2409.16278\] Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation](https://arxiv.org/abs/2409.16278) (Tsinghua)
- [ ] [\[2409.16288\] Self-Supervised Any-Point Tracking by Contrastive Random Walks](https://arxiv.org/abs/2409.16288) (ECCV)
- [ ] [\[2409.16294\] GenCAD: Image-Conditioned Computer-Aided Design Generation with Transformer-Based Contrastive Representation and Diffusion Priors](https://arxiv.org/abs/2409.16294) (MIT)
- [ ] [\[2409.16491\] Proactive Schemes: A Survey of Adversarial Attacks for Social Good](https://arxiv.org/abs/2409.16491) (Michigan State University)
- [ ] [\[2409.16600\] FAFA: Frequency-Aware Flow-Aided Self-Supervision for Underwater Object Pose Estimation](https://arxiv.org/abs/2409.16600) (ECCV)
- [ ] [\[2409.16631\] Enhancing Nighttime UAV Tracking with Light Distribution Suppression](https://arxiv.org/abs/2409.16631) (Tongji)
- [ ] [\[2409.16652\] Progressive Representation Learning for Real-Time UAV Tracking](https://arxiv.org/abs/2409.16652) (Tongji)
- [ ] [\[2409.16689\] Layout-Corrector: Alleviating Layout Sticking Phenomenon in Discrete Diffusion Model](https://arxiv.org/abs/2409.16689) (ECCV)
- [ ] [\[2409.16709\] Pose-Guided Fine-Grained Sign Language Video Generation](https://arxiv.org/abs/2409.16709) (ECCV)
- [ ] [\[2409.16718\] Vision-Language Model Fine-Tuning via Simple Parameter-Efficient Modification](https://arxiv.org/abs/2409.16718) (University of Tokyo)
- [ ] [\[2409.16736\] Commonly Interesting Images](https://arxiv.org/abs/2409.16736) (ECCV)
- [ ] [\[2409.16756\] Navigating the Maze of Explainable AI: A Systematic Approach to Evaluating Methods and Metrics](https://arxiv.org/abs/2409.16756) (NIPS)
- [ ] [\[2409.16845\] IRASNet: Improved Feature-Level Clutter Reduction for Domain Generalized SAR-ATR](https://arxiv.org/abs/2409.16845) (POSTECH)
- [ ] [\[2409.16855\] A Versatile and Differentiable Hand-Object Interaction Representation](https://arxiv.org/abs/2409.16855) (MPI)
- [ ] [\[2409.16863\] Towards Unified 3D Hair Reconstruction from Single-View Portraits](https://arxiv.org/abs/2409.16863) (SIGGRAPH)
- [ ] [\[2409.16902\] Towards Underwater Camouflaged Object Tracking: An Experimental Evaluation of SAM and SAM 2](https://arxiv.org/abs/2409.16902) (HKUST(GZ))
- [ ] [\[2409.16925\] Game4Loc: A UAV Geo-Localization Benchmark from Game Data](https://arxiv.org/abs/2409.16925) (Xiamen)
- [ ] [\[2409.16945\] Face Forgery Detection with Elaborate Backbone](https://arxiv.org/abs/2409.16945) (ICT CAS)
- [ ] [\[2409.16953\] Path-adaptive Spatio-Temporal State Space Model for Event-based Recognition with Arbitrary Duration](https://arxiv.org/abs/2409.16953) (HKUST)
- [ ] [\[2409.17029\] EventHDR: from Event to High-Speed HDR Videos and Beyond](https://arxiv.org/abs/2409.17029) (BIT, TPAMI)
- [ ] [\[2409.17058\] Degradation-Guided One-Step Image Super-Resolution with Diffusion Priors](https://arxiv.org/abs/2409.17058) (SYSU)
- [ ] [\[2409.17085\] Parameter-efficient Bayesian Neural Networks for Uncertainty-aware Depth Estimation](https://arxiv.org/abs/2409.17085) (TUM)
- [ ] [\[2409.17106\] Text2CAD: Generating Sequential CAD Models from Beginner-to-Expert Level Text Prompts](https://arxiv.org/abs/2409.17106) (NIPS)
- [ ] [\[2409.17143\] Attention Prompting on Image for Large Vision-Language Models](https://arxiv.org/abs/2409.17143) (NUS)
- [ ] [\[2409.17145\] DreamWaltz-G: Expressive 3D Gaussian Avatars from Skeleton-Guided 2D Diffusion](https://arxiv.org/abs/2409.17145) (HKU)
- [ ] [\[2409.17221\] Walker: Self-supervised Multiple Object Tracking by Walking on Temporal Appearance Graphs](https://arxiv.org/abs/2409.17221) (ECCV)
- [ ] [\[2409.17313\] Navigating the Nuances: A Fine-grained Evaluation of Vision-Language Navigation](https://arxiv.org/abs/2409.17313) (Peking)
- [ ] [\[2409.17316\] Bi-TTA: Bidirectional Test-Time Adapter for Remote Physiological Measurement](https://arxiv.org/abs/2409.17316) (HKUST)
- [ ] [\[2409.17331\] ChatCam: Empowering Camera Control through Conversational AI](https://arxiv.org/abs/2409.17331) (NIPS)
- [ ] [\[2409.17363\] Improving satellite imagery segmentation using multiple Sentinel-2 revisits](https://arxiv.org/abs/2409.17363) (NYU)
- [ ] [\[2409.17432\] HazeSpace2M: A Dataset for Haze Aware Single Image Dehazing](https://arxiv.org/abs/2409.17432) (Sungkyunkwan University, ACMMM)
- [ ] [\[2409.17453\] AgMTR: Agent Mining Transformer for Few-shot Segmentation in Remote Sensing](https://arxiv.org/abs/2409.17453) (UCAS)
- [ ] [\[2409.17459\] TFS-NeRF: Template-Free NeRF for Semantic 3D Reconstruction of Dynamic Scene](https://arxiv.org/abs/2409.17459) (NIPS)
- [ ] [\[2409.17485\] Revisiting Deep Ensemble Uncertainty for Enhanced Medical Anomaly Detection](https://arxiv.org/abs/2409.17485) (HKUST)
- [ ] [\[2409.17487\] Learning Quantized Adaptive Conditions for Diffusion Models](https://arxiv.org/abs/2409.17487) (Peking)
- [ ] [\[2409.17512\] SCOMatch: Alleviating Overtrusting in Open-set Semi-supervised Learning](https://arxiv.org/abs/2409.17512) (University of Tokyo, ECCV)
- [ ] [\[2409.17523\] EAGLE: Egocentric AGgregated Language-video Engine](https://arxiv.org/abs/2409.17523) (ACMMM)
- [ ] [\[2409.17524\] JoyType: A Robust Design for Multilingual Visual Text Creation](https://arxiv.org/abs/2409.17524) (UCAS)
- [ ] [\[2409.17531\] SimVG: A Simple Framework for Visual Grounding with Decoupled Multi-modal Fusion](https://arxiv.org/abs/2409.17531) (NIPS)
- [ ] [\[2409.17547\] Triple Point Masking](https://arxiv.org/abs/2409.17547) (SJTU)
- [ ] [\[2409.17565\] Pixel-Space Post-Training of Latent Diffusion Models](https://arxiv.org/abs/2409.17565) (Princeton)
- [ ] [\[2409.17576\] ID$^3$: Identity-Preserving-yet-Diversified Diffusion Models for Synthetic Face Recognition](https://arxiv.org/abs/2409.17576) (NIPS)
- [ ] [\[2409.17589\] Improving Fast Adversarial Training via Self-Knowledge Guidance](https://arxiv.org/abs/2409.17589) (HKUST)
- [ ] [\[2409.17647\] MECD: Unlocking Multi-Event Causal Discovery in Video Reasoning](https://arxiv.org/abs/2409.17647) (NIPS)
- [ ] [\[2409.17682\] Dark Miner: Defend against unsafe generation for text-to-image diffusion models](https://arxiv.org/abs/2409.17682) (IA CAS)
- [ ] [\[2409.17686\] MoGenTS: Motion Generation based on Spatial-Temporal Joint Modeling](https://arxiv.org/abs/2409.17686) (NIPS)
- [ ] [\[2409.17717\] Behaviour4All: in-the-wild Facial Behaviour Analysis Toolkit](https://arxiv.org/abs/2409.17717) (QMUL)
- [ ] [\[2409.17728\] AlterMOMA: Fusion Redundancy Pruning for Camera-LiDAR Fusion Models with Alternative Modality Masking](https://arxiv.org/abs/2409.17728) (NIPS)
- [ ] [\[2409.17778\] Taming Diffusion Prior for Image Super-Resolution with Domain Shift SDEs](https://arxiv.org/abs/2409.17778) (NIPS)
- [ ] [\[2409.17805\] Cascade Prompt Learning for Vision-Language Model Adaptation](https://arxiv.org/abs/2409.17805) (ECCV)
- [ ] [\[2409.17823\] Kendall's $\tau$ Coefficient for Logits Distillation](https://arxiv.org/abs/2409.17823) (Tsinghua)
- [ ] [\[2409.17830\] Unsupervised Learning Based Multi-Scale Exposure Fusion](https://arxiv.org/abs/2409.17830) (A*STAR,)
- [ ] [\[2409.17880\] Self-Distilled Depth Refinement with Noisy Poisson Fusion](https://arxiv.org/abs/2409.17880) (NIPS)
- [ ] [\[2409.17920\] Resolving Multi-Condition Confusion for Finetuning-Free Personalized Image Generation](https://arxiv.org/abs/2409.17920) (Alibaba)
- [ ] [\[2409.17977\] Cross-Modality Attack Boosted by Gradient-Evolutionary Multiform Optimization](https://arxiv.org/abs/2409.17977) (Xiamen)
- [ ] [\[2409.17987\] LLM4Brain: Training a Large Language Model for Brain Video Understanding](https://arxiv.org/abs/2409.17987) (Fudan)
- [ ] [\[2409.17988\] Deblur e-NeRF: NeRF from Motion-Blurred Events under High-speed or Low-light Conditions](https://arxiv.org/abs/2409.17988) (ECCV)
- [ ] [\[2409.18049\] Revisit Anything: Visual Place Recognition via Image Segment Retrieval](https://arxiv.org/abs/2409.18049) (ECCV)
- [ ] [\[2409.18083\] Stable Video Portraits](https://arxiv.org/abs/2409.18083) (ECCV)
- [ ] [\[2409.18104\] Find Rhinos without Finding Rhinos: Active Learning with Multimodal Imagery of South African Rhino Habitats](https://arxiv.org/abs/2409.18104) (Harvard)
- [ ] [\[2409.18111\] E.T. Bench: Towards Open-Ended Event-Level Video-Language Understanding](https://arxiv.org/abs/2409.18111) (NIPS)
- [ ] [\[2409.18124\] Lotus: Diffusion-based Visual Foundation Model for High-quality Dense Prediction](https://arxiv.org/abs/2409.18124) (HKUST)
- [ ] [\[2409.18128\] FlowTurbo: Towards Real-time Flow-Based Image Generation with Velocity Refiner](https://arxiv.org/abs/2409.18128) (NIPS)
- [ ] [\[2409.18147\] SSP-RACL: Classification of Noisy Fundus Images with Self-Supervised Pretraining and Robust Adaptive Credal Loss](https://arxiv.org/abs/2409.18147) (Fudan)
- [ ] [\[2409.18211\] Evaluation of Security of ML-based Watermarking: Copy and Removal Attacks](https://arxiv.org/abs/2409.18211) (Inria)
- [ ] [\[2409.18228\] Analysis of Spatial augmentation in Self-supervised models in the purview of training and test distributions](https://arxiv.org/abs/2409.18228) (KU Leuven)
- [ ] [\[2409.18261\] Omni6D: Large-Vocabulary 3D Object Dataset for Category-Level 6D Object Pose Estimation](https://arxiv.org/abs/2409.18261) (NTU, ECCV)
- [ ] [\[2409.18300\] SOAR: Self-supervision Optimized UAV Action Recognition with Efficient Object-Aware Pretraining](https://arxiv.org/abs/2409.18300) (UMD)
- [ ] [\[2409.18336\] DeBaRA: Denoising-Based 3D Room Arrangement Generation](https://arxiv.org/abs/2409.18336) (NIPS)
- [ ] [\[2409.18364\] Multi-hypotheses Conditioned Point Cloud Diffusion for 3D Human Reconstruction from Occluded Images](https://arxiv.org/abs/2409.18364) (KAIST, NIPS)
- [ ] [\[2409.18372\] You Only Speak Once to See](https://arxiv.org/abs/2409.18372) (Tianjin)
- [ ] [\[2409.18431\] Search3D: Hierarchical Open-Vocabulary 3D Segmentation](https://arxiv.org/abs/2409.18431) (ETH)
- [ ] [\[2409.18457\] DynaWeightPnP: Toward global real-time 3D-2D solver in PnP without correspondences](https://arxiv.org/abs/2409.18457) (University of Michigan)
- [ ] [\[2409.18478\] Temporal2Seq: A Unified Framework for Temporal Video Understanding Tasks](https://arxiv.org/abs/2409.18478) (NJU)
- [ ] [\[2409.18533\] Prompt-Driven Temporal Domain Adaptation for Nighttime UAV Tracking](https://arxiv.org/abs/2409.18533) (Tongji)
- [ ] [\[2409.18561\] AL-GTD: Deep Active Learning for Gaze Target Detection](https://arxiv.org/abs/2409.18561) (ACMMM)
- [ ] [\[2409.18569\] Cross-video Identity Correlating for Person Re-identification Pre-training](https://arxiv.org/abs/2409.18569) (NIPS)
- [ ] [\[2409.18591\] Off to new Shores: A Dataset & Benchmark for (near-)coastal Flood Inundation Forecasting](https://arxiv.org/abs/2409.18591) (NIPS)
- [ ] [\[2409.18636\] Unsupervised Fingerphoto Presentation Attack Detection With Diffusion Models](https://arxiv.org/abs/2409.18636) (NTU)
- [ ] [\[2409.18686\] A Novel Unified Architecture for Low-Shot Counting by Detection and Segmentation](https://arxiv.org/abs/2409.18686) (NIPS)
- [ ] [\[2409.18694\] Learning from Pattern Completion: Self-supervised Controllable Generation](https://arxiv.org/abs/2409.18694) (UCAS)
- [ ] [\[2409.18737\] MemFusionMap: Working Memory Fusion for Online Vectorized HD Map Construction](https://arxiv.org/abs/2409.18737) (University of Michigan)
- [ ] [\[2409.18800\] MiniVLN: Efficient Vision-and-Language Navigation by Progressive Knowledge Distillation](https://arxiv.org/abs/2409.18800) (IA CAS)
- [ ] [\[2409.18839\] MinerU: An Open-Source Solution for Precise Document Content Extraction](https://arxiv.org/abs/2409.18839) (Shanghai AI Lab)
- [ ] [\[2409.18852\] Space-time 2D Gaussian Splatting for Accurate Surface Reconstruction under Complex Dynamic Scenes](https://arxiv.org/abs/2409.18852) (HKU)
- [ ] [\[2409.18860\] LW2G: Learning Whether to Grow for Prompt-based Continual Learning](https://arxiv.org/abs/2409.18860) (NIPS)
- [ ] [\[2409.18876\] CemiFace: Center-based Semi-hard Synthetic Face Generation for Face Recognition](https://arxiv.org/abs/2409.18876) (QMUL, NIPS)
- [ ] [\[2409.18899\] Unsupervised Low-light Image Enhancement with Lookup Tables and Diffusion Priors](https://arxiv.org/abs/2409.18899) (Xiamen)
- [ ] [\[2409.18932\] ReviveDiff: A Universal Diffusion Model for Restoring Images in Adverse Weather Conditions](https://arxiv.org/abs/2409.18932) (UTS)
- [ ] [\[2409.18951\] Spectral Wavelet Dropout: Regularization in the Wavelet Domain](https://arxiv.org/abs/2409.18951) (Bosch, ICML)
- [ ] [\[2409.18953\] UniCal: Unified Neural Sensor Calibration](https://arxiv.org/abs/2409.18953) (ECCV)
- [ ] [\[2409.18961\] ProMerge: Prompt and Merge for Unsupervised Instance Segmentation](https://arxiv.org/abs/2409.18961) (Oxford, ECCV)
- [ ] [\[2409.18962\] Exploring Token Pruning in Vision State Space Models](https://arxiv.org/abs/2409.18962) (NIPS)
- [ ] [\[2409.18964\] PhysGen: Rigid-Body Physics-Grounded Image-to-Video Generation](https://arxiv.org/abs/2409.18964) (ECCV)
- [ ] [\[2409.18974\] Neural Product Importance Sampling via Warp Composition](https://arxiv.org/abs/2409.18974) (SIGGRAPH)
- [ ] [\[2409.19149\] Multimodal Pragmatic Jailbreak on Text-to-image Models](https://arxiv.org/abs/2409.19149) (Oxford)
- [ ] [\[2409.19210\] Learning to Obstruct Few-Shot Image Classification over Restricted Classes](https://arxiv.org/abs/2409.19210) (ECCV)
- [ ] [\[2409.19232\] TrojVLM: Backdoor Attack Against Vision Language Models](https://arxiv.org/abs/2409.19232) (ECCV)
- [ ] [\[2409.19252\] Beyond Euclidean: Dual-Space Representation Learning for Weakly Supervised Video Violence Detection](https://arxiv.org/abs/2409.19252) (NIPS)
- [ ] [\[2409.19293\] VLAD-BuFF: Burst-aware Fast Feature Aggregation for Visual Place Recognition](https://arxiv.org/abs/2409.19293) (ECCV)
- [ ] [\[2409.19306\] CausalVE: Face Video Privacy Encryption via Causal Video Prediction](https://arxiv.org/abs/2409.19306) (ICLR)
- [ ] [\[2409.19330\] 3D-CT-GPT: Generating 3D Radiology Reports through Integration of Large Vision-Language Models](https://arxiv.org/abs/2409.19330) (NWPU)
- [ ] [\[2409.19342\] X-Prompt: Multi-modal Visual Prompt for Video Object Segmentation](https://arxiv.org/abs/2409.19342) (Fudan, ACMMM)
- [ ] [\[2409.19365\] Conditional Image Synthesis with Diffusion Models: A Survey](https://arxiv.org/abs/2409.19365) (ZJU)
- [ ] [\[2409.19403\] Restore Anything with Masks: Leveraging Mask Image Modeling for Blind All-in-One Image Restoration](https://arxiv.org/abs/2409.19403) (ECCV)
- [ ] [\[2409.19405\] G3R: Gradient Guided Generalizable Reconstruction](https://arxiv.org/abs/2409.19405) (ECCV)
- [ ] [\[2409.19429\] Fast Encoding and Decoding for Implicit Video Representation](https://arxiv.org/abs/2409.19429) (ECCV)
- [ ] [\[2409.19436\] Introducing SDICE: An Index for Assessing Diversity of Synthetic Medical Datasets](https://arxiv.org/abs/2409.19436) (MBZUAI)
- [ ] [\[2409.19439\] Contrastive ground-level image and remote sensing pre-training improves representation learning for natural world imagery](https://arxiv.org/abs/2409.19439) (ECCV)
- [ ] [\[2409.19472\] Towards Croppable Implicit Neural Representations](https://arxiv.org/abs/2409.19472) (NIPS)
- [ ] [\[2409.19532\] Video DataFlywheel: Resolving the Impossible Data Trinity in Video-Language Understanding](https://arxiv.org/abs/2409.19532) (HIT)
- [ ] [\[2409.19540\] LoRKD: Low-Rank Knowledge Decomposition for Medical Foundation Models](https://arxiv.org/abs/2409.19540) (CVPR)
- [ ] [\[2409.19580\] High Quality Human Image Animation using Regional Supervision and Motion Blur Condition](https://arxiv.org/abs/2409.19580) (NTU)
- [ ] [\[2409.19589\] Effective Diffusion Transformer Architecture for Image Super-Resolution](https://arxiv.org/abs/2409.19589) (Xidian)
- [ ] [\[2409.19592\] DiffCP: Ultra-Low Bit Collaborative Perception via Diffusion Model](https://arxiv.org/abs/2409.19592) (Tsinghua)
- [ ] [\[2409.19599\] Gradient is All You Need: Gradient-Based Attention Fusion for Infrared Small Target Detection](https://arxiv.org/abs/2409.19599) (UESTC)
- [ ] [\[2409.19608\] Causal Deciphering and Inpainting in Spatio-Temporal Dynamics via Diffusion Model](https://arxiv.org/abs/2409.19608) (USTC)
- [ ] [\[2409.19613\] Hybrid Mamba for Few-Shot Segmentation](https://arxiv.org/abs/2409.19613) (Peking, NIPS)
- [ ] [\[2409.19638\] BadHMP: Backdoor Attack against Human Motion Prediction](https://arxiv.org/abs/2409.19638) (NTU)
- [ ] [\[2409.19660\] All-in-One Image Coding for Joint Human-Machine Vision with Multi-Path Aggregation](https://arxiv.org/abs/2409.19660) (NIPS)
- [ ] [\[2409.19679\] SemiDDM-Weather: A Semi-supervised Learning Framework for All-in-one Adverse Weather Removal](https://arxiv.org/abs/2409.19679) (SYSU)
- [ ] [\[2409.19681\] Simple and Fast Distillation of Diffusion Models](https://arxiv.org/abs/2409.19681) (NIPS)
- [ ] [\[2409.19685\] Underwater Organism Color Enhancement via Color Code Decomposition, Adaptation and Interpolation](https://arxiv.org/abs/2409.19685) (USyd)
- [ ] [\[2409.19686\] Text-driven Human Motion Generation with Motion Masked Diffusion Model](https://arxiv.org/abs/2409.19686) (UCL)
- [ ] [\[2409.19690\] Neural-Polyptych: Content Controllable Painting Recreation for Diverse Genres](https://arxiv.org/abs/2409.19690) (Peking)
- [ ] [\[2409.19702\] RNG: Relightable Neural Gaussians](https://arxiv.org/abs/2409.19702) (NJU)
- [ ] [\[2409.19720\] FAST: A Dual-tier Few-Shot Learning Paradigm for Whole Slide Image Classification](https://arxiv.org/abs/2409.19720) (NIPS)
- [ ] [\[2409.19734\] T2Vs Meet VLMs: A Scalable Multimodal Dataset for Visual Harmfulness Recognition](https://arxiv.org/abs/2409.19734) (NIPS)
- [ ] [\[2409.19754\] Offline Signature Verification Based on Feature Disentangling Aided Variational Autoencoder](https://arxiv.org/abs/2409.19754) (UCSD)
- [ ] [\[2409.19772\] PPLNs: Parametric Piecewise Linear Networks for Event-Based Temporal Modeling and Beyond](https://arxiv.org/abs/2409.19772) (NIPS)
- [ ] [\[2409.19811\] Robust Incremental Structure-from-Motion with Hybrid Features](https://arxiv.org/abs/2409.19811) (ECCV)
- [ ] [\[2409.19821\] Tracking Everything in Robotic-Assisted Surgery](https://arxiv.org/abs/2409.19821) (Imperial)
- [ ] [\[2409.19835\] GrokLST: Towards High-Resolution Benchmark and Toolkit for Land Surface Temperature Downscaling](https://arxiv.org/abs/2409.19835) (UCL)
- [ ] [\[2409.19840\] Textual Training for the Hassle-Free Removal of Unwanted Visual Data](https://arxiv.org/abs/2409.19840) (NIPS)
- [ ] [\[2409.19846\] Towards Open-Vocabulary Semantic Segmentation Without Semantic Labels](https://arxiv.org/abs/2409.19846) (Google, NIPS)
- [ ] [\[2409.19865\] TokenBinder: Text-Video Retrieval with One-to-Many Alignment Paradigm](https://arxiv.org/abs/2409.19865) (Queensland)
- [ ] [\[2409.19872\] Towards Unified Multimodal Editing with Enhanced Knowledge Collaboration](https://arxiv.org/abs/2409.19872) (NUS, NIPS)
- [ ] [\[2409.19899\] OpenKD: Opening Prompt Diversity for Zero- and Few-shot Keypoint Detection](https://arxiv.org/abs/2409.19899) (ECCV)
- [ ] [\[2409.19933\] CCDepth: A Lightweight Self-supervised Depth Estimation Network with Enhanced Interpretability](https://arxiv.org/abs/2409.19933) (HKU)
- [ ] [\[2409.19952\] Image Copy Detection for Diffusion Models](https://arxiv.org/abs/2409.19952) (NIPS)
- [ ] [\[2409.19954\] Attribute-Text Guided Forgetting Compensation for Lifelong Person Re-Identification](https://arxiv.org/abs/2409.19954) (HIT)
- [ ] [\[2409.19961\] Multimodal LLM Enhanced Cross-lingual Cross-modal Retrieval](https://arxiv.org/abs/2409.19961) (XJTU, ACMMM)
- [ ] [\[2409.19967\] Magnet: We Never Know How Text-to-Image Diffusion Models Work, Until We Learn How Vision-Language Models Function](https://arxiv.org/abs/2409.19967) (NIPS)
- [ ] [\[2409.19987\] OccRWKV: Rethinking Efficient 3D Semantic Occupancy Prediction with Linear Complexity](https://arxiv.org/abs/2409.19987) (HKU)
- [ ] [\[2409.20013\] Single-shot reconstruction of three-dimensional morphology of biological cells in digital holographic microscopy using a physics-driven neural network](https://arxiv.org/abs/2409.20013) (POSTECH)
- [ ] [\[2409.20034\] Camera Calibration using a Collimator System](https://arxiv.org/abs/2409.20034) (NUDT, ECCV)
- [ ] [\[2409.20043\] OPONeRF: One-Point-One NeRF for Robust Neural Rendering](https://arxiv.org/abs/2409.20043) (Tsinghua)
- [ ] [\[2409.20081\] ProFD: Prompt-Guided Feature Disentangling for Occluded Person Re-Identification](https://arxiv.org/abs/2409.20081) (ACMMM)
- [ ] [\[2409.20083\] SurgPETL: Parameter-Efficient Image-to-Surgical-Video Transfer Learning for Surgical Phase Recognition](https://arxiv.org/abs/2409.20083) (HKUST)
- [ ] [\[2409.20116\] REST-HANDS: Rehabilitation with Egocentric Vision Using Smartglasses for Treatment of Hands after Surviving Stroke](https://arxiv.org/abs/2409.20116) (ECCV)
- [ ] [\[2409.20146\] VMAD: Visual-enhanced Multimodal Large Language Model for Zero-Shot Anomaly Detection](https://arxiv.org/abs/2409.20146) (USTC)
- [ ] [\[2409.20164\] Erase, then Redraw: A Novel Data Augmentation Approach for Free Space Detection Using Diffusion Model](https://arxiv.org/abs/2409.20164) (HKUST)
- [ ] [\[2409.20166\] Task-Oriented Pre-Training for Drivable Area Detection](https://arxiv.org/abs/2409.20166) (HKUST(GZ))
- [ ] [\[2409.20171\] Annotation-Free Curb Detection Leveraging Altitude Difference Image](https://arxiv.org/abs/2409.20171) (HKUST(GZ))
- [ ] [\[2409.20276\] Active Neural Mapping at Scale](https://arxiv.org/abs/2409.20276) (Tsinghua)
- [ ] [\[2409.20324\] HEADS-UP: Head-Mounted Egocentric Dataset for Trajectory Prediction in Blind Assistance Systems](https://arxiv.org/abs/2409.20324) (EPFL)
- [ ] [\[2409.20353\] CableInspect-AD: An Expert-Annotated Anomaly Detection Dataset](https://arxiv.org/abs/2409.20353) (NIPS)
- [ ] [\[2409.20409\] Physics-Regularized Multi-Modal Image Assimilation for Brain Tumor Localization](https://arxiv.org/abs/2409.20409) (NIPS)
- [ ] [\[2409.20419\] AI-Based Fully Automatic Analysis of Retinal Vascular Morphology in Pediatric High Myopia](https://arxiv.org/abs/2409.20419) (TUM)
- [ ] [\[2409.20424\] World to Code: Multi-modal Data Generation via Self-Instructed Compositional Captioning and Filtering](https://arxiv.org/abs/2409.20424) (UCAS)
- [ ] [\[2409.20426\] Navigating Threats: A Survey of Physical Adversarial Attacks on LiDAR Perception Systems in Autonomous Vehicles](https://arxiv.org/abs/2409.20426) (NYU)
- [ ] [\[2409.20474\] IRFusionFormer: Enhancing Pavement Crack Segmentation with RGB-T Fusion and Topological-Based Loss](https://arxiv.org/abs/2409.20474) (HKUST)
- [ ] [\[2409.20520\] Accelerating Non-Maximum Suppression: A Graph Theory Perspective](https://arxiv.org/abs/2409.20520) (XJTU)
- [ ] [\[2409.20530\] Dual Encoder GAN Inversion for High-Fidelity 3D Head Reconstruction from Single Images](https://arxiv.org/abs/2409.20530) (NIPS)
- [ ] [\[2409.20557\] Propose, Assess, Search: Harnessing LLMs for Goal-Oriented Planning in Instructional Videos](https://arxiv.org/abs/2409.20557) (ECCV)
- [ ] [\[2409.20562\] SpaceMesh: A Continuous Representation for Learning Manifold Surface Meshes](https://arxiv.org/abs/2409.20562) (SIGGRAPH)
- [ ] [\[2409.20563\] DressRecon: Freeform 4D Human Reconstruction from Monocular Video](https://arxiv.org/abs/2409.20563) (CMU)
- [ ] [\[2410.00132\] CVVLSNet: Vehicle Location and Speed Estimation Using Partial Connected Vehicle Trajectory Data](https://arxiv.org/abs/2410.00132) (HKU)
- [ ] [\[2410.00166\] EEG Emotion Copilot: Pruning LLMs for Emotional EEG Interpretation with Assisted Medical Record Generation](https://arxiv.org/abs/2410.00166) (PolyU)
- [ ] [\[2410.00201\] DreamStruct: Understanding Slides and User Interfaces via Synthetic Data Generation](https://arxiv.org/abs/2410.00201) (UT Austin, ECCV)
- [ ] [\[2410.00263\] Procedure-Aware Surgical Video-language Pretraining with Hierarchical Knowledge Augmentation](https://arxiv.org/abs/2410.00263) (NIPS)
- [ ] [\[2410.00289\] Delving Deep into Engagement Prediction of Short Videos](https://arxiv.org/abs/2410.00289) (CUHK, ECCV)
- [ ] [\[2410.00299\] GSPR: Multimodal Place Recognition Using 3D Gaussian Splatting for Autonomous Driving](https://arxiv.org/abs/2410.00299) (BIT)
- [ ] [\[2410.00307\] RadGazeGen: Radiomics and Gaze-guided Medical Image Generation using Diffusion Models](https://arxiv.org/abs/2410.00307) (Columbia University)
- [ ] [\[2410.00309\] Ask, Pose, Unite: Scaling Data Acquisition for Close Interactions with Vision Language Models](https://arxiv.org/abs/2410.00309) (Stanford)
- [ ] [\[2410.00320\] PointAD: Comprehending 3D Anomalies from Points and Pixels for Zero-shot 3D Anomaly Detection](https://arxiv.org/abs/2410.00320) (NIPS)
- [ ] [\[2410.00321\] A Cat Is A Cat (Not A Dog!): Unraveling Information Mix-ups in Text-to-Image Encoders through Causal Analysis and Embedding Optimization](https://arxiv.org/abs/2410.00321) (GIT, NIPS)
- [ ] [\[2410.00350\] Efficient Training of Large Vision Models via Advanced Automated Progressive Learning](https://arxiv.org/abs/2410.00350) (UTS)
- [ ] [\[2410.00360\] TFCT-I2P: Three stream fusion network with color aware transformer for image-to-point cloud registration](https://arxiv.org/abs/2410.00360) (HUST)
- [ ] [\[2410.00386\] Seamless Augmented Reality Integration in Arthroscopy: A Pipeline for Articular Reconstruction and Guidance](https://arxiv.org/abs/2410.00386) (JHU)
- [ ] [\[2410.00464\] Enabling Synergistic Full-Body Control in Prompt-Based Co-Speech Motion Generation](https://arxiv.org/abs/2410.00464) (ZJU)
- [ ] [\[2410.00485\] A Hitchhikers Guide to Fine-Grained Face Forgery Detection Using Common Sense Reasoning](https://arxiv.org/abs/2410.00485) (NIPS)
- [ ] [\[2410.00486\] CaRtGS: Computational Alignment for Real-Time Gaussian Splatting SLAM](https://arxiv.org/abs/2410.00486) (HKU)
- [ ] [\[2410.00557\] STanH : Parametric Quantization for Variable Rate Learned Image Compression](https://arxiv.org/abs/2410.00557) (TIP)
- [ ] [\[2410.00589\] GERA: Geometric Embedding for Efficient Point Registration Analysis](https://arxiv.org/abs/2410.00589) (NTU)
- [ ] [\[2410.00630\] Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures](https://arxiv.org/abs/2410.00630) (SIGGRAPH)
- [ ] [\[2410.00672\] GMT: Enhancing Generalizable Neural Rendering via Geometry-Driven Multi-Reference Texture Transfer](https://arxiv.org/abs/2410.00672) (ECCV)
- [ ] [\[2410.00713\] RAD: A Dataset and Benchmark for Real-Life Anomaly Detection with Robotic Observations](https://arxiv.org/abs/2410.00713) (Peking)
- [ ] [\[2410.00772\] On the Generalization and Causal Explanation in Self-Supervised Learning](https://arxiv.org/abs/2410.00772) (Tsinghua)
- [ ] [\[2410.00823\] Squeeze-and-Remember Block](https://arxiv.org/abs/2410.00823) (Bosch, ICML)
- [ ] [\[2410.00979\] Towards Full-parameter and Parameter-efficient Self-learning For Endoscopic Camera Depth Estimation](https://arxiv.org/abs/2410.00979) (ECCV)
- [ ] [\[2410.01055\] ARPOV: Expanding Visualization of Object Detection in AR with Panoramic Mosaic Stitching](https://arxiv.org/abs/2410.01055) (NYU)
- [ ] [\[2410.01083\] Deep Nets with Subsampling Layers Unwittingly Discard Useful Activations at Test-Time](https://arxiv.org/abs/2410.01083) (ECCV)
- [ ] [\[2410.01089\] FMBench: Benchmarking Fairness in Multimodal Large Language Models on Medical Tasks](https://arxiv.org/abs/2410.01089) (Imperial)
- [ ] [\[2410.01148\] Automatic Image Unfolding and Stitching Framework for Esophageal Lining Video Based on Density-Weighted Feature Matching](https://arxiv.org/abs/2410.01148) (Vanderbilt University)
- [ ] [\[2410.01251\] Facial Action Unit Detection by Adaptively Constraining Self-Attention and Causally Deconfounding Sample](https://arxiv.org/abs/2410.01251) (JHU)
- [ ] [\[2410.01261\] OCC-MLLM:Empowering Multimodal Large Language Model For the Understanding of Occluded Objects](https://arxiv.org/abs/2410.01261) (University of Toronto)
- [ ] [\[2410.01336\] VectorGraphNET: Graph Attention Networks for Accurate Segmentation of Complex Technical Drawings](https://arxiv.org/abs/2410.01336) (TUM)
- [ ] [\[2410.01341\] Cognition Transferring and Decoupling for Text-supervised Egocentric Semantic Segmentation](https://arxiv.org/abs/2410.01341) (UESTC)
- [ ] [\[2410.01360\] High-quality Animatable Eyelid Shapes from Lightweight Captures](https://arxiv.org/abs/2410.01360) (SIGGRAPH)
- [ ] [\[2410.01366\] Harnessing the Latent Diffusion Model for Training-Free Image Style Transfer](https://arxiv.org/abs/2410.01366) (University of Tokyo)
- [ ] [\[2410.01407\] AgriCLIP: Adapting CLIP for Agriculture and Livestock via Domain-Specialized Cross-Model Alignment](https://arxiv.org/abs/2410.01407) (MBZUAI)
- [ ] [\[2410.01408\] SHAP-CAT: A interpretable multi-modal framework enhancing WSI classification via virtual staining and shapley-value-based multimodal fusion](https://arxiv.org/abs/2410.01408) (MBZUAI)
- [ ] [\[2410.01417\] The Labyrinth of Links: Navigating the Associative Maze of Multi-modal LLMs](https://arxiv.org/abs/2410.01417) (SJTU)
- [ ] [\[2410.01534\] Toward a Holistic Evaluation of Robustness in CLIP Models](https://arxiv.org/abs/2410.01534) (NIPS)
- [ ] [\[2410.01573\] PASS:Test-Time Prompting to Adapt Styles and Semantic Shapes in Medical Image Segmentation](https://arxiv.org/abs/2410.01573) (SJTU)
- [ ] [\[2410.01577\] Coordinate-Based Neural Representation Enabling Zero-Shot Learning for 3D Multiparametric Quantitative MRI](https://arxiv.org/abs/2410.01577) (SJTU)
- [ ] [\[2410.01594\] MM-LDM: Multi-Modal Latent Diffusion Model for Sounding Video Generation](https://arxiv.org/abs/2410.01594) (IA CAS, ACMMM)
- [ ] [\[2410.01609\] DAViD: Domain Adaptive Visually-Rich Document Understanding with Synthetic Insights](https://arxiv.org/abs/2410.01609) (USyd)
- [ ] [\[2410.01620\] LMOD: A Large Multimodal Ophthalmology Dataset and Benchmark for Large Vision-Language Models](https://arxiv.org/abs/2410.01620) (Yale)
- [ ] [\[2410.01718\] COMUNI: Decomposing Common and Unique Video Signals for Diffusion-based Video Generation](https://arxiv.org/abs/2410.01718) (IA CAS)
- [ ] [\[2410.01723\] HarmoniCa: Harmonizing Training and Inference for Better Feature Cache in Diffusion Transformer Acceleration](https://arxiv.org/abs/2410.01723) (HKUST)
- [ ] [\[2410.01768\] SegEarth-OV: Towards Traning-Free Open-Vocabulary Segmentation for Remote Sensing Images](https://arxiv.org/abs/2410.01768) (XJTU)
- [ ] [\[2410.01801\] FabricDiffusion: High-Fidelity Texture Transfer for 3D Garments Generation from In-The-Wild Clothing Images](https://arxiv.org/abs/2410.01801) (CMU, SIGGRAPH)
- [ ] [\[2410.01804\] EVER: Exact Volumetric Ellipsoid Rendering for Real-time View Synthesis](https://arxiv.org/abs/2410.01804) (UCSD)
- [ ] [\[2410.01813\] Privacy-Preserving SAM Quantization for Efficient Edge Intelligence in Healthcare](https://arxiv.org/abs/2410.01813) (IA CAS)
- [ ] [\[2410.01817\] From Experts to the Public: Governing Multimodal Language Models in Politically Sensitive Video Analysis](https://arxiv.org/abs/2410.01817) (Berkeley)
- [ ] [\[2410.01835\] EgoAvatar: Egocentric View-Driven and Photorealistic Full-body Avatars](https://arxiv.org/abs/2410.01835) (MPI)
- [ ] [\[2410.01928\] Deep learning assisted high resolution microscopy image processing for phase segmentation in functional composite materials](https://arxiv.org/abs/2410.01928) (UCSD)
- [ ] [\[2410.01944\] One-step Noisy Label Mitigation](https://arxiv.org/abs/2410.01944) (UESTC)
- [ ] [\[2410.02067\] DisEnvisioner: Disentangled and Enriched Visual Prompt for Customized Image Generation](https://arxiv.org/abs/2410.02067) (HKUST)
- [ ] [\[2410.02080\] EMMA: Efficient Visual Alignment in Multi-Modal LLMs](https://arxiv.org/abs/2410.02080) (NYU)
- [ ] [\[2410.02098\] EC-DIT: Scaling Diffusion Transformers with Adaptive Expert-Choice Routing](https://arxiv.org/abs/2410.02098) (GIT)
- [ ] [\[2410.02101\] Orient Anything](https://arxiv.org/abs/2410.02101) (MIT)
- [ ] [\[2410.02224\] Efficient Semantic Segmentation via Lightweight Multiple-Information Interaction Network](https://arxiv.org/abs/2410.02224) (UTS)
- [ ] [\[2410.02237\] Key-Grid: Unsupervised 3D Keypoints Detection using Grid Heatmap Features](https://arxiv.org/abs/2410.02237) (Tsinghua)
- [ ] [\[2410.02240\] SCA: Highly Efficient Semantic-Consistent Unrestricted Adversarial Attack](https://arxiv.org/abs/2410.02240) (SYSU)
- [ ] [\[2410.02249\] Spiking Neural Network as Adaptive Event Stream Slicer](https://arxiv.org/abs/2410.02249) (HKUST(GZ), NIPS)
- [ ] [\[2410.02250\] Probabilistic road classification in historical maps using synthetic data and deep learning](https://arxiv.org/abs/2410.02250) (ETH)
- [ ] [\[2410.02288\] Computer-aided Colorization State-of-the-science: A Survey](https://arxiv.org/abs/2410.02288) (PolyU)
- [ ] [\[2410.02305\] The Comparison of Individual Cat Recognition Using Neural Networks](https://arxiv.org/abs/2410.02305) (ZJU)
- [ ] [\[2410.02309\] Decoupling Layout from Glyph in Online Chinese Handwriting Generation](https://arxiv.org/abs/2410.02309) (IA CAS)
- [ ] [\[2410.02331\] Self-eXplainable AI for Medical Image Analysis: A Survey and New Outlooks](https://arxiv.org/abs/2410.02331) (HKUST)
- [ ] [\[2410.02369\] Unleashing the Potential of the Diffusion Model in Few-shot Semantic Segmentation](https://arxiv.org/abs/2410.02369) (NIPS)
- [ ] [\[2410.02396\] Parameter Competition Balancing for Model Merging](https://arxiv.org/abs/2410.02396) (HIT, NIPS)
- [ ] [\[2410.02401\] SynCo: Synthetic Hard Negatives in Contrastive Learning for Better Unsupervised Visual Representations](https://arxiv.org/abs/2410.02401) (Imperial)
- [ ] [\[2410.02483\] Event-Customized Image Generation](https://arxiv.org/abs/2410.02483) (HKUST)
- [ ] [\[2410.02492\] DTVLT: A Multi-modal Diverse Text Benchmark for Visual Language Tracking Based on LLM](https://arxiv.org/abs/2410.02492) (IA CAS)
- [ ] [\[2410.02505\] Dog-IQA: Standard-guided Zero-shot MLLM for Mix-grained Image Quality Assessment](https://arxiv.org/abs/2410.02505) (SJTU)
- [ ] [\[2410.02527\] Learning from Offline Foundation Features with Tensor Augmentations](https://arxiv.org/abs/2410.02527) (NIPS)
- [ ] [\[2410.02534\] Pseudo-Stereo Inputs: A Solution to the Occlusion Challenge in Self-Supervised Stereo Matching](https://arxiv.org/abs/2410.02534) (TIP)
- [ ] [\[2410.02592\] IC3M: In-Car Multimodal Multi-object Monitoring for Abnormal Status of Both Driver and Passengers](https://arxiv.org/abs/2410.02592) (HKU)
- [ ] [\[2410.02619\] GI-GS: Global Illumination Decomposition on Gaussian Splatting for Inverse Rendering](https://arxiv.org/abs/2410.02619) (HKUST)
- [ ] [\[2410.02671\] Unsupervised Point Cloud Completion through Unbalanced Optimal Transport](https://arxiv.org/abs/2410.02671) (GIT)
- [ ] [\[2410.02745\] AVG-LLaVA: A Large Multimodal Model with Adaptive Visual Granularity](https://arxiv.org/abs/2410.02745) (Xiamen)
- [ ] [\[2410.02768\] BoViLA: Bootstrapping Video-Language Alignment via LLM-Based Self-Questioning and Answering](https://arxiv.org/abs/2410.02768) (XJTU)
- [ ] [\[2410.02786\] Robust Symmetry Detection via Riemannian Langevin Dynamics](https://arxiv.org/abs/2410.02786) (Stanford)
- [ ] [\[2410.02787\] Navigation with VLM framework: Go to Any Language](https://arxiv.org/abs/2410.02787) (UTS)
- [ ] [\[2410.02788\] RoMo: A Robust Solver for Full-body Unlabeled Optical Motion Capture](https://arxiv.org/abs/2410.02788) (SIGGRAPH)
- [ ] [\[2410.02789\] Logic-Free Building Automation: Learning the Control of Room Facilities with Wall Switches and Ceiling Camera](https://arxiv.org/abs/2410.02789) (University of Tokyo)
- [ ] [\[2410.02921\] AirLetters: An Open Video Dataset of Characters Drawn in the Air](https://arxiv.org/abs/2410.02921) (University of Toronto)
- [ ] [\[2410.03039\] Revealing the Unseen: Guiding Personalized Diffusion Models to Expose Training Data](https://arxiv.org/abs/2410.03039) (CMU)
- [ ] [\[2410.03058\] DiffKillR: Killing and Recreating Diffeomorphisms for Cell Annotation in Dense Microscopy Images](https://arxiv.org/abs/2410.03058) (Yale)
- [ ] [\[2410.03061\] DocKD: Knowledge Distillation from LLMs for Open-World Document Understanding Models](https://arxiv.org/abs/2410.03061) (KAIST)
- [ ] [\[2410.03097\] Combing Text-based and Drag-based Editing for Precise and Flexible Image Editing](https://arxiv.org/abs/2410.03097) (ZJU)
- [ ] [\[2410.03129\] ARB-LLM: Alternating Refined Binarizations for Large Language Models](https://arxiv.org/abs/2410.03129) (SJTU)
- [ ] [\[2410.03171\] Selective Transformer for Hyperspectral Image Classification](https://arxiv.org/abs/2410.03171) (WHU)
- [ ] [\[2410.03174\] HRVMamba: High-Resolution Visual State Space Model for Dense Prediction](https://arxiv.org/abs/2410.03174) (XJTU)
- [ ] [\[2410.03176\] Investigating and Mitigating Object Hallucinations in Pretrained Vision-Language (CLIP) Models](https://arxiv.org/abs/2410.03176) (Fudan)
- [ ] [\[2410.03226\] Frame-Voyager: Learning to Query Frames for Video Large Language Models](https://arxiv.org/abs/2410.03226) (NTU)
- [ ] [\[2410.03276\] Sm: enhanced localization in Multiple Instance Learning for medical imaging classification](https://arxiv.org/abs/2410.03276) (NIPS)
- [ ] [\[2410.03290\] Grounded-VideoLLM: Sharpening Fine-grained Temporal Grounding in Video Large Language Models](https://arxiv.org/abs/2410.03290) (Fudan)
- [ ] [\[2410.03302\] Action Selection Learning for Multi-label Multi-view Action Recognition](https://arxiv.org/abs/2410.03302) (ACMMM)
- [ ] [\[2410.03311\] Quo Vadis, Motion Generation? From Large Language Models to Large Motion Models](https://arxiv.org/abs/2410.03311) (Peking)
- [ ] [\[2410.03321\] Visual-O1: Understanding Ambiguous Instructions via Multi-modal Multi-turn Chain-of-thoughts Reasoning](https://arxiv.org/abs/2410.03321) (PolyU)
- [ ] [\[2410.03355\] LANTERN: Accelerating Visual Autoregressive Models with Relaxed Speculative Decoding](https://arxiv.org/abs/2410.03355) (KAIST)
- [ ] [\[2410.03390\] Lightning UQ Box: A Comprehensive Framework for Uncertainty Quantification in Deep Learning](https://arxiv.org/abs/2410.03390) (TUM)
- [ ] [\[2410.03417\] Img2CAD: Conditioned 3D CAD Model Generation from Single Image with Structured Visual Geometry](https://arxiv.org/abs/2410.03417) (ZJU)
- [ ] [\[2410.03430\] Images Speak Volumes: User-Centric Assessment of Image Generation for Accessible Communication](https://arxiv.org/abs/2410.03430) (TUM)
- [ ] [\[2410.03441\] CLoSD: Closing the Loop between Simulation and Diffusion for multi-task character control](https://arxiv.org/abs/2410.03441) (Tel Aviv)
- [ ] [\[2410.03478\] VEDIT: Latent Prediction Architecture For Procedural Video Representation Learning](https://arxiv.org/abs/2410.03478) (Meta)
- [ ] [\[2410.03505\] Classification-Denoising Networks](https://arxiv.org/abs/2410.03505) (NYU)
- [ ] [\[2410.03558\] Not All Diffusion Model Activations Have Been Evaluated as Discriminative Features](https://arxiv.org/abs/2410.03558) (SYSU)
- [ ] [\[2410.03577\] Look Twice Before You Answer: Memory-Space Visual Retracing for Hallucination Mitigation in Multimodal Large Language Models](https://arxiv.org/abs/2410.03577) (HKUST(GZ))
- [ ] [\[2410.03644\] Unlearnable 3D Point Clouds: Class-wise Transformation Is All You Need](https://arxiv.org/abs/2410.03644) (NIPS)
- [ ] [\[2410.03659\] Unraveling Cross-Modality Knowledge Conflicts in Large Vision-Language Models](https://arxiv.org/abs/2410.03659) (Fudan)
- [ ] [\[2410.03675\] Controllable Shape Modeling with Neural Generalized Cylinder](https://arxiv.org/abs/2410.03675) (SIGGRAPH)
- [ ] [\[2410.03858\] Unsupervised Prior Learning: Discovering Categorical Pose Priors from Videos](https://arxiv.org/abs/2410.03858) (NTU)
- [ ] [\[2410.03860\] MDMP: Multi-modal Diffusion for supervised Motion Predictions with uncertainty](https://arxiv.org/abs/2410.03860) (University of Michigan)
- [ ] [\[2410.03878\] SPARTUN3D: Situated Spatial Understanding of 3D World in Large Language Models](https://arxiv.org/abs/2410.03878) (Michigan State University)
- [ ] [\[2410.03936\] Learning Truncated Causal History Model for Video Restoration](https://arxiv.org/abs/2410.03936) (University of Alberta, NIPS)
- [ ] [\[2410.03987\] Mamba Capsule Routing Towards Part-Whole Relational Camouflaged Object Detection](https://arxiv.org/abs/2410.03987) (HUST)
- [ ] [\[2410.04161\] Overcoming False Illusions in Real-World Face Restoration with Multi-Modal Guided Diffusion Model](https://arxiv.org/abs/2410.04161) (USyd)
- [ ] [\[2410.04201\] IT$^3$: Idempotent Test-Time Training](https://arxiv.org/abs/2410.04201) (EPFL)
- [ ] [\[2410.04342\] Accelerating Inference of Networks in the Frequency Domain](https://arxiv.org/abs/2410.04342) (University of Alberta, ACMMM)
- [ ] [\[2410.04345\] MVP-Bench: Can Large Vision--Language Models Conduct Multi-level Visual Perception Like Humans?](https://arxiv.org/abs/2410.04345) (NUS)
- [ ] [\[2410.04354\] StreetSurfGS: Scalable Urban Street Surface Reconstruction with Planar-based Gaussian Splatting](https://arxiv.org/abs/2410.04354) (USTC)
- [ ] [\[2410.04372\] DiffusionFake: Enhancing Generalization in Deepfake Detection via Guided Stable Diffusion](https://arxiv.org/abs/2410.04372) (NIPS)
- [ ] [\[2410.04402\] Deformable NeRF using Recursively Subdivided Tetrahedra](https://arxiv.org/abs/2410.04402) (USTC, ACMMM)
- [ ] [\[2410.04421\] Disentangling Regional Primitives for Image Generation](https://arxiv.org/abs/2410.04421) (SJTU)
- [ ] [\[2410.04434\] A Mathematical Explanation of UNet](https://arxiv.org/abs/2410.04434) (BU)
- [ ] [\[2410.04439\] Empowering Backbone Models for Visual Text Generation with Input Granularity Control and Glyph-Aware Training](https://arxiv.org/abs/2410.04439) (Xiamen)
- [ ] [\[2410.04492\] Interpret Your Decision: Logical Reasoning Regularization for Generalization in Visual Classification](https://arxiv.org/abs/2410.04492) (NIPS)
- [ ] [\[2410.04521\] MC-CoT: A Modular Collaborative CoT Framework for Zero-shot Medical-VQA with LLM and MLLM Integration](https://arxiv.org/abs/2410.04521) (HUST)
- [ ] [\[2410.04634\] Is What You Ask For What You Get? Investigating Concept Associations in Text-to-Image Models](https://arxiv.org/abs/2410.04634) (Harvard)
- [ ] [\[2410.04671\] CAR: Controllable Autoregressive Modeling for Visual Generation](https://arxiv.org/abs/2410.04671) (Peking)
- [ ] [\[2410.04733\] PredFormer: Transformers Are Effective Spatial-Temporal Predictive Learners](https://arxiv.org/abs/2410.04733) (SJTU)
- [ ] [\[2410.04738\] Diffusion Models in 3D Vision: A Survey](https://arxiv.org/abs/2410.04738) (University of Tokyo)
- [ ] [\[2410.04780\] Mitigating Modality Prior-Induced Hallucinations in Multimodal Large Language Models via Deciphering Attention Causality](https://arxiv.org/abs/2410.04780) (HKUST(GZ))
- [ ] [\[2410.04817\] Resource-Efficient Multiview Perception: Integrating Semantic Masking with Masked Autoencoders](https://arxiv.org/abs/2410.04817) (USyd)
- [ ] [\[2410.04823\] CAT: Concept-level backdoor ATtacks for Concept Bottleneck Models](https://arxiv.org/abs/2410.04823) (HKUST(GZ))
- [ ] [\[2410.04833\] Multimodal Fusion Strategies for Mapping Biophysical Landscape Features](https://arxiv.org/abs/2410.04833) (Harvard)
- [ ] [\[2410.04842\] A Simple Image Segmentation Framework via In-Context Examples](https://arxiv.org/abs/2410.04842) (NIPS)
- [ ] [\[2410.04873\] TeX-NeRF: Neural Radiance Fields from Pseudo-TeX Vision](https://arxiv.org/abs/2410.04873) (BIT)
- [ ] [\[2410.04884\] Patch is Enough: Naturalistic Adversarial Patch against Vision-Language Pre-training Models](https://arxiv.org/abs/2410.04884) (SYSU)
- [ ] [\[2410.04939\] PRFusion: Toward Effective and Robust Multi-Modal Place Recognition with Image and Point Cloud Fusion](https://arxiv.org/abs/2410.04939) (NTU)
- [ ] [\[2410.04965\] Revealing Directions for Text-guided 3D Face Editing](https://arxiv.org/abs/2410.04965) (SJTU)
- [ ] [\[2410.05051\] HE-Drive: Human-Like End-to-End Driving with Vision Language Models](https://arxiv.org/abs/2410.05051) (HKU)
- [ ] [\[2410.05057\] SELECT: A Large-Scale Benchmark of Data Curation Strategies for Image Classification](https://arxiv.org/abs/2410.05057) (NYU, NIPS)
- [ ] [\[2410.05058\] Improving Object Detection via Local-global Contrastive Learning](https://arxiv.org/abs/2410.05058) (University of Edinburgh)
- [ ] [\[2410.05097\] DreamSat: Towards a General 3D Model for Novel View Synthesis of Space Objects](https://arxiv.org/abs/2410.05097) (MIT)
- [ ] [\[2410.05103\] MetaDD: Boosting Dataset Distillation with Neural Network Architecture-Invariant Generalization](https://arxiv.org/abs/2410.05103) (BIT)
- [ ] [\[2410.05159\] MIBench: A Comprehensive Benchmark for Model Inversion Attack and Defense](https://arxiv.org/abs/2410.05159) (HIT)
- [ ] [\[2410.05160\] VLM2Vec: Training Vision-Language Models for Massive Multimodal Embedding Tasks](https://arxiv.org/abs/2410.05160) (Salesforce)
- [ ] [\[2410.05182\] MARs: Multi-view Attention Regularizations for Patch-based Feature Recognition of Space Terrain](https://arxiv.org/abs/2410.05182) (ECCV)
- [ ] [\[2410.05234\] DiffuseReg: Denoising Diffusion Model for Obtaining Deformation Fields in Unsupervised Deformable Image Registration](https://arxiv.org/abs/2410.05234) (SJTU)
- [ ] [\[2410.05273\] HiRT: Enhancing Robotic Control with Hierarchical Robot Transformers](https://arxiv.org/abs/2410.05273) (Berkeley)
- [ ] [\[2410.05363\] Towards World Simulator: Crafting Physical Commonsense-Based Benchmark for Video Generation](https://arxiv.org/abs/2410.05363) (Shanghai AI Lab)
- [ ] [\[2410.05497\] EgoQR: Efficient QR Code Reading in Egocentric Settings](https://arxiv.org/abs/2410.05497) (Meta, ICLR)
- [ ] [\[2410.05525\] Generative Portrait Shadow Removal](https://arxiv.org/abs/2410.05525) (SIGGRAPH)
- [ ] [\[2410.05557\] Rethinking Weak-to-Strong Augmentation in Source-Free Domain Adaptive Object Detection](https://arxiv.org/abs/2410.05557) (UESTC)
- [ ] [\[2410.05586\] TeaserGen: Generating Teasers for Long Documentaries](https://arxiv.org/abs/2410.05586) (MIT)
- [ ] [\[2410.05591\] TweedieMix: Improving Multi-Concept Fusion for Diffusion-based Image/Video Generation](https://arxiv.org/abs/2410.05591) (KAIST)
- [ ] [\[2410.05601\] ReFIR: Grounding Large Restoration Models with Retrieval Augmentation](https://arxiv.org/abs/2410.05601) (NIPS)
- [ ] [\[2410.05627\] CLOSER: Towards Better Representation Learning for Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2410.05627) (ECCV)
- [ ] [\[2410.05650\] SIA-OVD: Shape-Invariant Adapter for Bridging the Image-Region Gap in Open-Vocabulary Detection](https://arxiv.org/abs/2410.05650) (Peking)
- [ ] [\[2410.05665\] Edge-Cloud Collaborative Satellite Image Analysis for Efficient Man-Made Structure Recognition](https://arxiv.org/abs/2410.05665) (CMU)
- [ ] [\[2410.05677\] T2V-Turbo-v2: Enhancing Video Generation Model Post-Training through Data, Reward, and Conditional Guidance Design](https://arxiv.org/abs/2410.05677) (UCLA)
- [ ] [\[2410.05710\] PixLens: A Novel Framework for Disentangled Evaluation in Diffusion-Based Image Editing with Object Detection + SAM](https://arxiv.org/abs/2410.05710) (ETH)
- [ ] [\[2410.05714\] Enhancing Temporal Modeling of Video LLMs via Time Gating](https://arxiv.org/abs/2410.05714) (CUHK)
- [ ] [\[2410.05729\] Equi-GSPR: Equivariant SE(3) Graph Network Model for Sparse Point Cloud Registration](https://arxiv.org/abs/2410.05729) (QMUL)
- [ ] [\[2410.05735\] CUBE360: Learning Cubic Field Representation for Monocular 360 Depth Estimation for Virtual Reality](https://arxiv.org/abs/2410.05735) (USTC)
- [ ] [\[2410.05746\] Wolf2Pack: The AutoFusion Framework for Dynamic Parameter Fusion](https://arxiv.org/abs/2410.05746) (HKUST(GZ))
- [ ] [\[2410.05760\] Training-free Diffusion Model Alignment with Sampling Demons](https://arxiv.org/abs/2410.05760) (Google)
- [ ] [\[2410.05762\] Guided Self-attention: Find the Generalized Necessarily Distinct Vectors for Grain Size Grading](https://arxiv.org/abs/2410.05762) (USTC)
- [ ] [\[2410.05771\] Cefdet: Cognitive Effectiveness Network Based on Fuzzy Inference for Action Detection](https://arxiv.org/abs/2410.05771) (Sungkyunkwan University, ACMMM)
- [ ] [\[2410.05773\] GLRT-Based Metric Learning for Remote Sensing Object Retrieval](https://arxiv.org/abs/2410.05773) (Tsinghua)
- [ ] [\[2410.05799\] SeeClear: Semantic Distillation Enhances Pixel Condensation for Video Super-Resolution](https://arxiv.org/abs/2410.05799) (NIPS)
- [ ] [\[2410.05804\] CASA: Class-Agnostic Shared Attributes in Vision-Language Models for Efficient Incremental Object Detection](https://arxiv.org/abs/2410.05804) (Peking)
- [ ] [\[2410.05805\] PostCast: Generalizable Postprocessing for Precipitation Nowcasting via Unsupervised Blurriness Modeling](https://arxiv.org/abs/2410.05805) (CUHK)
- [ ] [\[2410.05905\] MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model](https://arxiv.org/abs/2410.05905) (NWPU)
- [ ] [\[2410.05935\] Learning Gaussian Data Augmentation in Feature Space for One-shot Object Detection in Manga](https://arxiv.org/abs/2410.05935) (University of Tokyo, ACMMM)
- [ ] [\[2410.05938\] EMMA: Empowering Multi-modal Mamba with Structural and Hierarchical Alignment](https://arxiv.org/abs/2410.05938) (ICT CAS)
- [ ] [\[2410.05954\] Pyramidal Flow Matching for Efficient Video Generative Modeling](https://arxiv.org/abs/2410.05954) (Peking)
- [ ] [\[2410.05963\] Training-Free Open-Ended Object Detection and Segmentation via Attention as Prompts](https://arxiv.org/abs/2410.05963) (NIPS)
- [ ] [\[2410.05964\] STNet: Deep Audio-Visual Fusion Network for Robust Speaker Tracking](https://arxiv.org/abs/2410.05964) (Peking)
- [ ] [\[2410.05969\] Deep neural network-based detection of counterfeit products from smartphone images](https://arxiv.org/abs/2410.05969) (Stanford)
- [ ] [\[2410.05982\] DeMo: Decoupling Motion Forecasting into Directional Intentions and Dynamic States](https://arxiv.org/abs/2410.05982) (Fudan, NIPS)
- [ ] [\[2410.06007\] Motion Forecasting in Continuous Driving](https://arxiv.org/abs/2410.06007) (Fudan, NIPS)
- [ ] [\[2410.06044\] HyperDet: Generalizable Detection of Synthesized Images by Generating and Merging A Mixture of Hyper LoRAs](https://arxiv.org/abs/2410.06044) (Imperial)
- [ ] [\[2410.06149\] Toward Scalable Image Feature Compression: A Content-Adaptive and Diffusion-Based Approach](https://arxiv.org/abs/2410.06149) (Peking)
- [ ] [\[2410.06166\] Temporal Reasoning Transfer from Text to Video](https://arxiv.org/abs/2410.06166) (UCSD)
- [ ] [\[2410.06194\] Prompting DirectSAM for Semantic Contour Extraction in Remote Sensing Images](https://arxiv.org/abs/2410.06194) (HKUST)
- [ ] [\[2410.06234\] TEOChat: A Large Vision-Language Assistant for Temporal Earth Observation Data](https://arxiv.org/abs/2410.06234) (Stanford)
- [ ] [\[2410.06236\] SD-$\pi$XL: Generating Low-Resolution Quantized Imagery via Score Distillation](https://arxiv.org/abs/2410.06236) (SIGGRAPH)
- [ ] [\[2410.06285\] Monocular Visual Place Recognition in LiDAR Maps via Cross-Modal State Space Model and Multi-View Matching](https://arxiv.org/abs/2410.06285) (ZJU)
- [ ] [\[2410.06353\] Language-Assisted Human Part Motion Learning for Skeleton-Based Temporal Action Segmentation](https://arxiv.org/abs/2410.06353) (HIT)
- [ ] [\[2410.06456\] From Generalist to Specialist: Adapting Vision Language Models via Task-Specific Visual Instruction Tuning](https://arxiv.org/abs/2410.06456) (A*STAR,)
- [ ] [\[2410.06475\] 3D Representation Methods: A Survey](https://arxiv.org/abs/2410.06475) (Peking)
- [ ] [\[2410.06488\] HFH-Font: Few-shot Chinese Font Synthesis with Higher Quality, Faster Speed, and Higher Resolution](https://arxiv.org/abs/2410.06488) (Peking, SIGGRAPH)
- [ ] [\[2410.06513\] MotionRL: Align Text-to-Motion Generation to Human Preferences with Multi-Reward Reinforcement Learning](https://arxiv.org/abs/2410.06513) (USTC)
- [ ] [\[2410.06535\] Happy: A Debiased Learning Framework for Continual Generalized Category Discovery](https://arxiv.org/abs/2410.06535) (IA CAS, NIPS)
- [ ] [\[2410.06558\] Deep Correlated Prompting for Visual Recognition with Missing Modalities](https://arxiv.org/abs/2410.06558) (NIPS)
- [ ] [\[2410.06613\] ES-Gaussian: Gaussian Splatting Mapping via Error Space-Based Gaussian Completion](https://arxiv.org/abs/2410.06613) (HKUST(GZ))
- [ ] [\[2410.06626\] Open-RGBT: Open-vocabulary RGB-T Zero-shot Semantic Segmentation in Open-world Environments](https://arxiv.org/abs/2410.06626) (BIT)
- [ ] [\[2410.06645\] Continual Learning in the Frequency Domain](https://arxiv.org/abs/2410.06645) (UCAS, NIPS)
- [ ] [\[2410.06682\] Enhancing Multimodal LLM for Detailed and Accurate Video Captioning using Multi-Round Preference Optimization](https://arxiv.org/abs/2410.06682) (Tsinghua)
- [ ] [\[2410.06689\] Perceptual Quality Assessment of Trisoup-Lifting Encoded 3D Point Clouds](https://arxiv.org/abs/2410.06689) (Peking)
- [ ] [\[2410.06699\] Break the Visual Perception: Adversarial Attacks Targeting Encoded Visual Tokens of Large Vision-Language Models](https://arxiv.org/abs/2410.06699) (USTC, ACMMM)
- [ ] [\[2410.06719\] Suppress Content Shift: Better Diffusion Features via Off-the-Shelf Generation Techniques](https://arxiv.org/abs/2410.06719) (SYSU)
- [ ] [\[2410.06734\] MimicTalk: Mimicking a personalized and expressive 3D talking face in minutes](https://arxiv.org/abs/2410.06734) (NIPS)
- [ ] [\[2410.06756\] DreamMesh4D: Video-to-4D Generation with Sparse-Controlled Gaussian-Mesh Hybrid Representation](https://arxiv.org/abs/2410.06756) (NIPS)
- [ ] [\[2410.06811\] Rethinking the Evaluation of Visible and Infrared Image Fusion](https://arxiv.org/abs/2410.06811) (HIT)
- [ ] [\[2410.06842\] SurANet: Surrounding-Aware Network for Concealed Object Detection via Highly-Efficient Interactive Contrastive Learning Strategy](https://arxiv.org/abs/2410.06842) (NWPU)
- [ ] [\[2410.06893\] Learning from Spatio-temporal Correlation for Semi-Supervised LiDAR Semantic Segmentation](https://arxiv.org/abs/2410.06893) (KAIST)
- [ ] [\[2410.06964\] Bridge the Points: Graph-based Few-shot Segment Anything Semantically](https://arxiv.org/abs/2410.06964) (NIPS)
- [ ] [\[2410.06982\] Structure-Centric Robust Monocular Depth Estimation via Knowledge Distillation](https://arxiv.org/abs/2410.06982) (ICT CAS)
- [ ] [\[2410.07025\] Preference Fine-Tuning for Factuality in Chest X-Ray Interpretation Models Without Human Feedback](https://arxiv.org/abs/2410.07025) (Stanford)
- [ ] [\[2410.07046\] S2HPruner: Soft-to-Hard Distillation Bridges the Discretization Gap in Pruning](https://arxiv.org/abs/2410.07046) (Fudan, NIPS)
- [ ] [\[2410.07112\] VHELM: A Holistic Evaluation of Vision Language Models](https://arxiv.org/abs/2410.07112) (NIPS)

  - [ ] [\[2410.07113\] Personalized Visual Instruction Tuning](https://arxiv.org/abs/2410.07113) (WHU)

- [ ] [\[2410.07128\] Neural Differential Appearance Equations](https://arxiv.org/abs/2410.07128) (UCL, SIGGRAPH)
- [ ] [\[2410.07151\] FaceVid-1K: A Large-Scale High-Quality Multiracial Human Face Video Dataset](https://arxiv.org/abs/2410.07151) (HIT)
- [ ] [\[2410.07153\] CHASE: Learning Convex Hull Adaptive Shift for Skeleton-based Multi-Entity Action Recognition](https://arxiv.org/abs/2410.07153) (SYSU, NIPS)
- [ ] [\[2410.07155\] Trans4D: Realistic Geometry-Aware Transition for Compositional Text-to-4D Synthesis](https://arxiv.org/abs/2410.07155) (Peking)
- [ ] [\[2410.07268\] Learning Content-Aware Multi-Modal Joint Input Pruning via Bird's-Eye-View Representation](https://arxiv.org/abs/2410.07268) (NTU)
- [ ] [\[2410.07273\] BELM: Bidirectional Explicit Linear Multi-step Sampler for Exact Inversion in Diffusion Models](https://arxiv.org/abs/2410.07273) (Tsinghua, NIPS)
- [ ] [\[2410.07303\] Rectified Diffusion: Straightness Is Not Your Need in Rectified Flow](https://arxiv.org/abs/2410.07303) (CUHK)
- [ ] [\[2410.07460\] Generalizing Segmentation Foundation Model Under Sim-to-real Domain-shift for Guidewire Segmentation in X-ray Fluoroscopy](https://arxiv.org/abs/2410.07460) (EPFL)
- [ ] [\[2410.07528\] CountMamba: Exploring Multi-directional Selective State-Space Models for Plant Counting](https://arxiv.org/abs/2410.07528) (Peking)
- [ ] [\[2410.07540\] CoPESD: A Multi-Level Surgical Motion Dataset for Training Large Vision-Language Models to Co-Pilot Endoscopic Submucosal Dissection](https://arxiv.org/abs/2410.07540) (CUHK)
- [ ] [\[2410.07579\] Teddy: Efficient Large-Scale Dataset Distillation via Taylor-Approximated Matching](https://arxiv.org/abs/2410.07579) (ECCV)
- [ ] [\[2410.07593\] A Unified Debiasing Approach for Vision-Language Models across Modalities and Tasks](https://arxiv.org/abs/2410.07593) (NIPS)
- [ ] [\[2410.07605\] A Variational Bayesian Inference Theory of Elasticity and Its Mixed Probabilistic Finite Element Method for Inverse Deformation Solutions in Any Dimension](https://arxiv.org/abs/2410.07605) (Berkeley)
- [ ] [\[2410.07613\] Explainability of Deep Neural Networks for Brain Tumor Detection](https://arxiv.org/abs/2410.07613) (Sungkyunkwan University)
- [ ] [\[2410.07618\] Moyun: A Diffusion-Based Model for Style-Specific Chinese Calligraphy Generation](https://arxiv.org/abs/2410.07618) (Fudan)
- [ ] [\[2410.07679\] Relational Diffusion Distillation for Efficient Image Generation](https://arxiv.org/abs/2410.07679) (ICT CAS, ACMMM)
- [ ] [\[2410.07707\] MotionGS: Exploring Explicit Motion Guidance for Deformable 3D Gaussian Splatting](https://arxiv.org/abs/2410.07707) (NIPS)
- [ ] [\[2410.07757\] MMHead: Towards Fine-grained Multi-modal 3D Facial Animation](https://arxiv.org/abs/2410.07757) (SJTU, ACMMM)
- [ ] [\[2410.07763\] HARIVO: Harnessing Text-to-Image Models for Video Generation](https://arxiv.org/abs/2410.07763) (ECCV)
- [ ] [\[2410.07795\] Optimal-State Dynamics Estimation for Physics-based Human Motion Capture from Videos](https://arxiv.org/abs/2410.07795) (NIPS)
- [ ] [\[2410.07832\] LaB-CL: Localized and Balanced Contrastive Learning for improving parking slot detection](https://arxiv.org/abs/2410.07832) (Sungkyunkwan University)
- [ ] [\[2410.07901\] Semi-Supervised Video Desnowing Network via Temporal Decoupling Experts and Distribution-Driven Contrastive Regularization](https://arxiv.org/abs/2410.07901) (HKUST)
- [ ] [\[2410.07912\] Understanding Spatio-Temporal Relations in Human-Object Interaction using Pyramid Graph Convolutional Network](https://arxiv.org/abs/2410.07912) (TUM)
- [ ] [\[2410.07971\] Generalizable and Animatable Gaussian Head Avatar](https://arxiv.org/abs/2410.07971) (University of Tokyo, NIPS)
- [ ] [\[2410.08021\] OneRef: Unified One-tower Expression Grounding and Segmentation with Mask Referring Modeling](https://arxiv.org/abs/2410.08021) (NIPS)
- [ ] [\[2410.08023\] GrabDAE: An Innovative Framework for Unsupervised Domain Adaptation Utilizing Grab-Mask and Denoise Auto-Encoder](https://arxiv.org/abs/2410.08023) (SYSU)
- [ ] [\[2410.08049\] Scaling Up Your Kernels: Large Kernel Design in ConvNets towards Universal Representations](https://arxiv.org/abs/2410.08049) (CUHK)
- [ ] [\[2410.08091\] Distribution Guidance Network for Weakly Supervised Point Cloud Semantic Segmentation](https://arxiv.org/abs/2410.08091) (Peking)
- [ ] [\[2410.08092\] UW-SDF: Exploiting Hybrid Geometric Priors for Neural SDF Reconstruction from Underwater Multi-view Monocular Images](https://arxiv.org/abs/2410.08092) (Tsinghua)
- [ ] [\[2410.08114\] Parameter-Efficient Fine-Tuning in Spectral Domain for Point Cloud Learning](https://arxiv.org/abs/2410.08114) (HUST)
- [ ] [\[2410.08119\] Q-VLM: Post-training Quantization for Large Vision-Language Models](https://arxiv.org/abs/2410.08119) (NTU)
- [ ] [\[2410.08159\] DART: Denoising Autoregressive Transformer for Scalable Text-to-Image Generation](https://arxiv.org/abs/2410.08159) (CUHK)
- [ ] [\[2410.08188\] DifFRelight: Diffusion-Based Facial Performance Relighting](https://arxiv.org/abs/2410.08188) (SIGGRAPH)
- [ ] [\[2410.08189\] SG-Nav: Online 3D Scene Graph Prompting for LLM-based Zero-shot Object Navigation](https://arxiv.org/abs/2410.08189) (BUPT, NIPS)
- [ ] [\[2410.08190\] Poison-splat: Computation Cost Attack on 3D Gaussian Splatting](https://arxiv.org/abs/2410.08190) (NUS)
- [ ] [\[2410.08192\] HybridBooth: Hybrid Prompt Inversion for Efficient Subject-Driven Generation](https://arxiv.org/abs/2410.08192) (NJU, ECCV)
- [ ] [\[2410.08210\] PointOBB-v2: Towards Simpler, Faster, and Stronger Single Point Supervised Oriented Object Detection](https://arxiv.org/abs/2410.08210) (Tsinghua)
- [ ] [\[2410.08257\] Neural Material Adaptor for Visual Grounding of Intrinsic Dynamics](https://arxiv.org/abs/2410.08257) (NIPS)

  - [ ] [\[2410.08258\] In Search of Forgotten Domain Generalization](https://arxiv.org/abs/2410.08258) (University of TÃ¼bingen)

- [ ] [\[2410.08326\] Neural Architecture Search of Hybrid Models for NPU-CIM Heterogeneous AR/VR Devices](https://arxiv.org/abs/2410.08326) (CMU)
- [ ] [\[2410.08405\] AgroGPT: Efficient Agricultural Vision-Language Model with Expert Tuning](https://arxiv.org/abs/2410.08405) (GIT)
- [ ] [\[2410.08454\] HorGait: Advancing Gait Recognition with Efficient High-Order Spatial Interactions in LiDAR Point Clouds](https://arxiv.org/abs/2410.08454) (BIT)
- [ ] [\[2410.08456\] A Unified Deep Semantic Expansion Framework for Domain-Generalized Person Re-identification](https://arxiv.org/abs/2410.08456) (NTU)
- [ ] [\[2410.08460\] Diverse Deep Feature Ensemble Learning for Omni-Domain Generalized Person Re-identification](https://arxiv.org/abs/2410.08460) (NTU)
- [ ] [\[2410.08466\] Aligned Divergent Pathways for Omni-Domain Generalized Person Re-Identification](https://arxiv.org/abs/2410.08466) (NTU)
- [ ] [\[2410.08530\] Ego3DT: Tracking Every 3D Object in Ego-centric Videos](https://arxiv.org/abs/2410.08530) (ZJU, ACMMM)
- [ ] [\[2410.08534\] Quality Prediction of AI Generated Images and Videos: Emerging Trends and Opportunities](https://arxiv.org/abs/2410.08534) (UT Austin)
- [ ] [\[2410.08551\] Context-Aware Full Body Anonymization using Text-to-Image Diffusion Models](https://arxiv.org/abs/2410.08551) (University of TÃ¼bingen)
- [ ] [\[2410.08567\] Diffusion-Based Depth Inpainting for Transparent and Reflective Objects](https://arxiv.org/abs/2410.08567) (Tsinghua)
- [ ] [\[2410.08593\] VERIFIED: A Video Corpus Moment Retrieval Benchmark for Fine-Grained Video Understanding](https://arxiv.org/abs/2410.08593) (NIPS)
- [ ] [\[2410.08611\] Conjugated Semantic Pool Improves OOD Detection with Pre-trained Vision-Language Models](https://arxiv.org/abs/2410.08611) (IA CAS, NIPS)
- [ ] [\[2410.08613\] Cross-Modal Bidirectional Interaction Model for Referring Remote Sensing Image Segmentation](https://arxiv.org/abs/2410.08613) (HIT)
- [ ] [\[2410.08649\] E-Motion: Future Motion Simulation via Event Sequence Diffusion](https://arxiv.org/abs/2410.08649) (Xidian, NIPS)
- [ ] [\[2410.08680\] Gait Sequence Upsampling using Diffusion Models for Single LiDAR Sensors](https://arxiv.org/abs/2410.08680) (NASA)
- [ ] [\[2410.08688\] Chain-of-Restoration: Multi-Task Image Restoration Models are Zero-Shot Step-by-Step Universal Image Restorers](https://arxiv.org/abs/2410.08688) (XJTU)
- [ ] [\[2410.08695\] Dynamic Multimodal Evaluation with Flexible Complexity by Vision-Language Bootstrapping](https://arxiv.org/abs/2410.08695) (Shanghai AI Lab)
- [ ] [\[2410.08713\] Impact of Surface Reflections in Maritime Obstacle Detection](https://arxiv.org/abs/2410.08713) (NYU)
- [ ] [\[2410.08739\] MMLF: Multi-modal Multi-class Late Fusion for Object Detection with Uncertainty Estimation](https://arxiv.org/abs/2410.08739) (UESTC)
- [ ] [\[2410.08824\] One-shot Generative Domain Adaptation in 3D GANs](https://arxiv.org/abs/2410.08824) (USTC)
- [ ] [\[2410.08840\] Learning Interaction-aware 3D Gaussian Splatting for One-shot Hand Avatars](https://arxiv.org/abs/2410.08840) (SYSU, NIPS)
- [ ] [\[2410.08885\] Can GPTs Evaluate Graphic Design Based on Design Principles?](https://arxiv.org/abs/2410.08885) (SIGGRAPH)
- [ ] [\[2410.08895\] Calibrated Cache Model for Few-Shot Vision-Language Model Adaptation](https://arxiv.org/abs/2410.08895) (IA CAS)
- [ ] [\[2410.08926\] Zero-Shot Pupil Segmentation with SAM 2: A Case Study of Over 14 Million Images](https://arxiv.org/abs/2410.08926) (TUM)
- [ ] [\[2410.08941\] MeshGS: Adaptive Mesh-Aligned Gaussian Splatting for High-Quality Rendering](https://arxiv.org/abs/2410.08941) (UMD)
- [ ] [\[2410.09004\] DA-Ada: Learning Domain-Aware Adapter for Domain Adaptive Object Detection](https://arxiv.org/abs/2410.09004) (IS CAS, NIPS)
- [ ] [\[2410.09009\] Semantic Score Distillation Sampling for Compositional Text-to-3D Generation](https://arxiv.org/abs/2410.09009) (Peking)
- [ ] [\[2410.09049\] SceneCraft: Layout-Guided 3D Scene Generation](https://arxiv.org/abs/2410.09049) (NIPS)
- [ ] [\[2410.09135\] Enabling Advanced Land Cover Analytics: An Integrated Data Extraction Pipeline for Predictive Modeling with the Dynamic World Dataset](https://arxiv.org/abs/2410.09135) (MIT)
- [ ] [\[2410.09292\] SurgicalGS: Dynamic 3D Gaussian Splatting for Accurate Robotic-Assisted Surgical Scene Reconstruction](https://arxiv.org/abs/2410.09292) (Imperial)
- [ ] [\[2410.09299\] Hierarchical uncertainty estimation for learning-based registration in neuroimaging](https://arxiv.org/abs/2410.09299) (Harvard)
- [ ] [\[2410.09312\] Towards Multi-Modal Animal Pose Estimation: An In-Depth Analysis](https://arxiv.org/abs/2410.09312) (Oxford)
- [ ] [\[2410.09377\] GEM-VPC: A dual Graph-Enhanced Multimodal integration for Video Paragraph Captioning](https://arxiv.org/abs/2410.09377) (USyd)
- [ ] [\[2410.09379\] Multi-granularity Contrastive Cross-modal Collaborative Generation for End-to-End Long-term Video Question Answering](https://arxiv.org/abs/2410.09379) (UCAS, TIP)
- [ ] [\[2410.09380\] Prompting Video-Language Foundation Models with Domain-specific Fine-grained Heuristics for Video Question Answering](https://arxiv.org/abs/2410.09380) (ICT CAS)
- [ ] [\[2410.09400\] CtrLoRA: An Extensible and Efficient Framework for Controllable Image Generation](https://arxiv.org/abs/2410.09400) (ICT CAS)
- [ ] [\[2410.09416\] Can Vision-Language Models Replace Human Annotators: A Case Study with CelebA Dataset](https://arxiv.org/abs/2410.09416) (GIT)
- [ ] [\[2410.09421\] VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language Models Alignment](https://arxiv.org/abs/2410.09421) (HKU)
- [ ] [\[2410.09474\] Distilling Invariant Representations with Dual Augmentation](https://arxiv.org/abs/2410.09474) (Imperial)
- [ ] [\[2410.09529\] Preserving Old Memories in Vivid Detail: Human-Interactive Photo Restoration Framework](https://arxiv.org/abs/2410.09529) (Sungkyunkwan University)
- [ ] [\[2410.09539\] Bi-temporal Gaussian Feature Dependency Guided Change Detection in Remote Sensing Images](https://arxiv.org/abs/2410.09539) (WHU)
- [ ] [\[2410.09550\] DiffuTraj: A Stochastic Vessel Trajectory Prediction Approach via Guided Diffusion Process](https://arxiv.org/abs/2410.09550) (UESTC)
- [ ] [\[2410.09563\] Robust Optical Flow Computation: A Higher-Order Differential Approach](https://arxiv.org/abs/2410.09563) (CMU)
- [ ] [\[2410.09633\] DuoDiff: Accelerating Diffusion Models with a Dual-Backbone Approach](https://arxiv.org/abs/2410.09633) (UVA.NL, NIPS)
- [ ] [\[2410.09690\] FAMOUS: High-Fidelity Monocular 3D Human Digitization Using View Synthesis](https://arxiv.org/abs/2410.09690) (CMU)
