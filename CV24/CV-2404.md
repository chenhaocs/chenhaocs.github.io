- [ ] [\[2405.08055\] DiffTF++: 3D-aware Diffusion Transformer for Large-Vocabulary 3D Generation](https://arxiv.org/abs/2405.08055) (NTU)
- [ ] [\[2405.08204\] A Semantic and Motion-Aware Spatiotemporal Transformer Network for Action Detection](https://arxiv.org/abs/2405.08204) (Transactions on Pattern Analysis and Machine Intelligence)
- [ ] [\[2405.08245\] Progressive enhancement and restoration for mural images under low-light and defected conditions based on multi-receptive field strategy](https://arxiv.org/abs/2405.08245) (XJTU)
- [ ] [\[2405.08246\] Compositional Text-to-Image Generation with Dense Blob Representations](https://arxiv.org/abs/2405.08246) (NVIDIA, ICML)
- [ ] [\[2405.08251\] Multimodal Collaboration Networks for Geospatial Vehicle Detection in Dense, Occluded, and Large-Scale Events](https://arxiv.org/abs/2405.08251) (Inria)
- [ ] [\[2405.08270\] Towards Clinician-Preferred Segmentation: Leveraging Human-in-the-Loop for Test Time Adaptation in Medical Image Segmentation](https://arxiv.org/abs/2405.08270) (NWPU)
- [ ] [\[2405.08300\] Vector-Symbolic Architecture for Event-Based Optical Flow](https://arxiv.org/abs/2405.08300) (UESTC)
- [ ] [\[2405.08322\] StraightPCF: Straight Point Cloud Filtering](https://arxiv.org/abs/2405.08322) (CVPR)
- [ ] [\[2405.08419\] WaterMamba: Visual State Space Model for Underwater Image Enhancement](https://arxiv.org/abs/2405.08419) (BU)
- [ ] [\[2405.08458\] Rethinking Prior Information Generation with CLIP for Few-Shot Segmentation](https://arxiv.org/abs/2405.08458) (CVPR)
- [ ] [\[2405.08487\] Semantic Contextualization of Face Forgery: A New Definition, Dataset, and Detection Method](https://arxiv.org/abs/2405.08487) (USyd)
- [ ] [\[2405.08547\] Exploring Graph-based Knowledge: Multi-Level Feature Distillation via Channels Relational Graph](https://arxiv.org/abs/2405.08547) (ZJU)
- [ ] [\[2405.08593\] Open-Vocabulary Object Detection via Neighboring Region Attention Alignment](https://arxiv.org/abs/2405.08593) (SJTU)
- [ ] [\[2405.08658\] Beyond the Black Box: Do More Complex Models Provide Superior XAI Explanations?](https://arxiv.org/abs/2405.08658) (UW)
- [ ] [\[2405.08681\] Achieving Fairness Through Channel Pruning for Dermatological Disease Diagnosis](https://arxiv.org/abs/2405.08681) (CUHK)
- [ ] [\[2405.08720\] The Lost Melody: Empirical Observations on Text-to-Video Generation From A Storytelling Perspective](https://arxiv.org/abs/2405.08720) (University of Tokyo)
- [ ] [\[2405.08765\] Image to Pseudo-Episode: Boosting Few-Shot Segmentation by Unlabeled Data](https://arxiv.org/abs/2405.08765) (Microsoft)
- [ ] [\[2405.08768\] EfficientTrain++: Generalized Curriculum Learning for Efficient Visual Backbone Training](https://arxiv.org/abs/2405.08768) (Tsinghua, ICCV)
- [ ] [\[2405.08780\] Harnessing the power of longitudinal medical imaging for eye disease prognosis using Transformer-based sequence modeling](https://arxiv.org/abs/2405.08780) (Cornell)
- [ ] [\[2405.08786\] Incorporating Clinical Guidelines through Adapting Multi-modal Large Language Model for Prostate Cancer PI-RADS Scoring](https://arxiv.org/abs/2405.08786) (CUHK)
- [ ] [\[2405.08807\] SciFIBench: Benchmarking Large Multimodal Models for Scientific Figure Interpretation](https://arxiv.org/abs/2405.08807) (Cambridge)
- [ ] [\[2405.08815\] Efficient Vision-Language Pre-training by Cluster Masking](https://arxiv.org/abs/2405.08815) (CVPR)
- [ ] [\[2405.08890\] Language-Guided Self-Supervised Video Summarization Using Text Semantic Matching Considering the Diversity of the Video](https://arxiv.org/abs/2405.08890) (University of Tokyo)
- [ ] [\[2405.08909\] ADA-Track: End-to-End Multi-Camera 3D Multi-Object Tracking with Alternating Detection and Association](https://arxiv.org/abs/2405.08909) (CVPR)
- [ ] [\[2405.09032\] ICAL: Implicit Character-Aided Learning for Enhanced Handwritten Mathematical Expression Recognition](https://arxiv.org/abs/2405.09032) (Peking)
- [ ] [\[2405.09045\] AMSNet: Netlist Dataset for AMS Circuits](https://arxiv.org/abs/2405.09045) (UCLA)
- [ ] [\[2405.09059\] Task-adaptive Q-Face](https://arxiv.org/abs/2405.09059) (ECCV)
- [ ] [\[2405.09114\] SOEDiff: Efficient Distillation for Small Object Editing](https://arxiv.org/abs/2405.09114) (USyd)
- [ ] [\[2405.09150\] Curriculum Dataset Distillation](https://arxiv.org/abs/2405.09150) (XJTU)
- [ ] [\[2405.09266\] Dance Any Beat: Blending Beats with Visuals in Dance Video Generation](https://arxiv.org/abs/2405.09266) (USyd)
- [ ] [\[2405.09288\] DeCoDEx: Confounder Detector Guidance for Improved Diffusion-based Counterfactual Explanations](https://arxiv.org/abs/2405.09288) (Google)
- [ ] [\[2405.09291\] Sensitivity Decouple Learning for Image Compression Artifacts Reduction](https://arxiv.org/abs/2405.09291) (Peking, Transactions on Image Processing)
- [ ] [\[2405.09321\] ReconBoost: Boosting Can Achieve Modality Reconcilement](https://arxiv.org/abs/2405.09321) (ICML)
- [ ] [\[2405.09342\] Progressive Depth Decoupling and Modulating for Flexible Depth Completion](https://arxiv.org/abs/2405.09342) (XJTU)
- [ ] [\[2405.09365\] SARATR-X: A Foundation Model for Synthetic Aperture Radar Images Target Recognition](https://arxiv.org/abs/2405.09365) (NUDT)
- [ ] [\[2405.09431\] A Survey On Text-to-3D Contents Generation In The Wild](https://arxiv.org/abs/2405.09431) (HKUST)
- [ ] [\[2405.09463\] Gaze-DETR: Using Expert Gaze to Reduce False Positives in Vulvovaginal Candidiasis Screening](https://arxiv.org/abs/2405.09463) (ShanghaiTech)
- [ ] [\[2405.09487\] Color Space Learning for Cross-Color Person Re-Identification](https://arxiv.org/abs/2405.09487) (NTU)
- [ ] [\[2405.09544\] Classifying geospatial objects from multiview aerial imagery using semantic meshes](https://arxiv.org/abs/2405.09544) (CMU)
- [ ] [\[2405.09546\] BEHAVIOR Vision Suite: Customizable Dataset Generation via Simulation](https://arxiv.org/abs/2405.09546) (Stanford, CVPR)
- [ ] [\[2405.09582\] AD-Aligning: Emulating Human-like Generalization for Cognitive Domain Adaptation in Deep Learning](https://arxiv.org/abs/2405.09582) (JHU)
- [ ] [\[2405.09713\] SOK-Bench: A Situated Video Reasoning Benchmark with Aligned Open-World Knowledge](https://arxiv.org/abs/2405.09713) (CVPR)
- [ ] [\[2405.09782\] Size-invariance Matters: Rethinking Metrics and Losses for Imbalanced Multi-object Salient Object Detection](https://arxiv.org/abs/2405.09782) (ICML)
- [ ] [\[2405.09789\] LeMeViT: Efficient Vision Transformer with Learnable Meta Tokens for Remote Sensing Image Interpretation](https://arxiv.org/abs/2405.09789) (USyd)
- [ ] [\[2405.09806\] MediSyn: Text-Guided Diffusion Models for Broad Medical 2D and 3D Image Synthesis](https://arxiv.org/abs/2405.09806) (Stanford)
- [ ] [\[2405.09827\] Parallel Backpropagation for Shared-Feature Visualization](https://arxiv.org/abs/2405.09827) (University of TÃ¼bingen)
- [ ] [\[2405.09828\] PillarNeXt: Improving the 3D detector by introducing Voxel2Pillar feature encoding and extracting multi-scale features](https://arxiv.org/abs/2405.09828) (Chongqing)
- [ ] [\[2405.09858\] Towards Realistic Incremental Scenario in Class Incremental Semantic Segmentation](https://arxiv.org/abs/2405.09858) (NYU)
- [ ] [\[2405.09863\] Box-Free Model Watermarks Are Prone to Black-Box Removal Attacks](https://arxiv.org/abs/2405.09863) (NTU)
- [ ] [\[2405.09874\] Dual3D: Efficient and Consistent Text-to-3D Generation with Dual-mode Multi-view Latent Diffusion](https://arxiv.org/abs/2405.09874) (Xiamen)
- [ ] [\[2405.09879\] Generative Unlearning for Any Identity](https://arxiv.org/abs/2405.09879) (CVPR)
- [ ] [\[2405.09883\] RoScenes: A Large-scale Multi-view 3D Dataset for Roadside Perception](https://arxiv.org/abs/2405.09883) (Alibaba, ECCV)
- [ ] [\[2405.09924\] Infrared Adversarial Car Stickers](https://arxiv.org/abs/2405.09924) (CVPR)
- [ ] [\[2405.09931\] Learning from Observer Gaze:Zero-Shot Attention Prediction Oriented by Human-Object Interaction Recognition](https://arxiv.org/abs/2405.09931) (SYSU, CVPR)
- [ ] [\[2405.09964\] KPNDepth: Depth Estimation of Lane Images under Complex Rainy Environment](https://arxiv.org/abs/2405.09964) (UESTC)
- [ ] [\[2405.09981\] Adversarial Robustness for Visual Grounding of Multimodal Large Language Models](https://arxiv.org/abs/2405.09981) (Tsinghua)
- [ ] [\[2405.09985\] VirtualModel: Generating Object-ID-retentive Human-object Interaction Image by Diffusion Model for E-commerce Marketing](https://arxiv.org/abs/2405.09985) (Alibaba)
- [ ] [\[2405.09996\] Driving-Video Dehazing with Non-Aligned Regularization for Safety Assistance](https://arxiv.org/abs/2405.09996) (HKUST(GZ), CVPR)
- [ ] [\[2405.10008\] Solving the enigma: Deriving optimal explanations of deep networks](https://arxiv.org/abs/2405.10008) (Cambridge)
- [ ] [\[2405.10037\] Bilateral Event Mining and Complementary for Event Stream Super-Resolution](https://arxiv.org/abs/2405.10037) (SYSU, CVPR)
- [ ] [\[2405.10053\] SHiNe: Semantic Hierarchy Nexus for Open-vocabulary Object Detection](https://arxiv.org/abs/2405.10053) (CVPR)
- [ ] [\[2405.10122\] Generating Coherent Sequences of Visual Illustrations for Real-World Manual Tasks](https://arxiv.org/abs/2405.10122) (Google)
- [ ] [\[2405.10140\] Libra: Building Decoupled Vision System on Large Language Models](https://arxiv.org/abs/2405.10140) (ICML)
- [ ] [\[2405.10148\] SpecDETR: A Transformer-based Hyperspectral Point Object Detection Network](https://arxiv.org/abs/2405.10148) (NUDT)
- [ ] [\[2405.10185\] DiverGen: Improving Instance Segmentation by Learning Wider Data Distribution with More Diverse Generative Data](https://arxiv.org/abs/2405.10185) (CVPR)
- [ ] [\[2405.10255\] When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models](https://arxiv.org/abs/2405.10255) (Oxford)
- [ ] [\[2405.10272\] Faces that Speak: Jointly Synthesising Talking Face and Speech from Text](https://arxiv.org/abs/2405.10272) (CVPR)
- [ ] [\[2405.10286\] FFF: Fixing Flawed Foundations in contrastive pre-training results in very strong Vision-Language models](https://arxiv.org/abs/2405.10286) (CVPR)
- [ ] [\[2405.10305\] 4D Panoptic Scene Graph Generation](https://arxiv.org/abs/2405.10305) (NIPS)
- [ ] [\[2405.10316\] Analogist: Out-of-the-box Visual In-Context Learning with Image Diffusion Model](https://arxiv.org/abs/2405.10316) (NJU)
- [ ] [\[2405.10317\] Text-to-Vector Generation with Neural Path Representation](https://arxiv.org/abs/2405.10317) (SIGGRAPH)
- [ ] [\[2405.10347\] Networking Systems for Video Anomaly Detection: A Tutorial and Survey](https://arxiv.org/abs/2405.10347) (Fudan)
- [ ] [\[2405.10357\] RGB Guided ToF Imaging System: A Survey of Deep Learning-based Methods](https://arxiv.org/abs/2405.10357) (XJTU)
- [ ] [\[2405.10518\] Enhancing Perception Quality in Remote Sensing Image Compression via Invertible Neural Network](https://arxiv.org/abs/2405.10518) (XJTU)
- [ ] [\[2405.10529\] Safeguarding Vision-Language Models Against Patched Visual Prompt Injectors](https://arxiv.org/abs/2405.10529) (University of Michigan)
- [ ] [\[2405.10530\] CM-UNet: Hybrid CNN-Mamba UNet for Remote Sensing Image Semantic Segmentation](https://arxiv.org/abs/2405.10530) (ZJU)
- [ ] [\[2405.10557\] Resolving Symmetry Ambiguity in Correspondence-based Methods for Instance-level Object Pose Estimation](https://arxiv.org/abs/2405.10557) (ZJU)
- [ ] [\[2405.10577\] DuoSpaceNet: Leveraging Both Bird's-Eye-View and Perspective View Representations for 3D Object Detection](https://arxiv.org/abs/2405.10577) (UCSD)
- [ ] [\[2405.10591\] GEOcc: Geometrically Enhanced 3D Occupancy Network with Implicit-Explicit Depth Fusion and Contextual Self-Supervision](https://arxiv.org/abs/2405.10591) (SJTU)
- [ ] [\[2405.10610\] Driving Referring Video Object Segmentation with Vision-Language Pre-trained Models](https://arxiv.org/abs/2405.10610) (HIT)
- [ ] [\[2405.10612\] Not All Prompts Are Secure: A Switchable Backdoor Attack Against Pre-trained Vision Transformers](https://arxiv.org/abs/2405.10612) (Tsinghua)
- [ ] [\[2405.10690\] CoLeaF: A Contrastive-Collaborative Learning Framework for Weakly Supervised Audio-Visual Video Parsing](https://arxiv.org/abs/2405.10690) (ECCV)
- [ ] [\[2405.10707\] HARIS: Human-Like Attention for Reference Image Segmentation](https://arxiv.org/abs/2405.10707) (Tianjin)
- [ ] [\[2405.10748\] Deep Data Consistency: a Fast and Robust Diffusion Model-based Solver for Inverse Problems](https://arxiv.org/abs/2405.10748) (Tsinghua)
- [ ] [\[2405.10879\] One registration is worth two segmentations](https://arxiv.org/abs/2405.10879) (UCL)
- [ ] [\[2405.10913\] Blackbox Adaptation for Medical Image Segmentation](https://arxiv.org/abs/2405.10913) (JHU)
- [ ] [\[2405.10934\] Reconstruction of Manipulated Garment with Guided Deformation Prior](https://arxiv.org/abs/2405.10934) (EPFL)
- [ ] [\[2405.10948\] Surgical-LVLM: Learning to Adapt Large Vision-Language Model for Grounded Visual Question Answering in Robotic Surgery](https://arxiv.org/abs/2405.10948) (CUHK)
- [ ] [\[2405.10954\] Multimodal CLIP Inference for Meta-Few-Shot Image Classification](https://arxiv.org/abs/2405.10954) (Princeton)
- [ ] [\[2405.11126\] Flexible Motion In-betweening with Diffusion Models](https://arxiv.org/abs/2405.11126) (Tel Aviv, SIGGRAPH)
- [ ] [\[2405.11129\] MotionGS : Compact Gaussian Splatting SLAM by Motion Filter](https://arxiv.org/abs/2405.11129) (SJTU)
- [ ] [\[2405.11145\] Detecting Multimodal Situations with Insufficient Context and Abstaining from Baseless Predictions](https://arxiv.org/abs/2405.11145) (Columbia University)
- [ ] [\[2405.11190\] ReasonPix2Pix: Instruction Reasoning Dataset for Advanced Image Editing](https://arxiv.org/abs/2405.11190) (USTC)
- [ ] [\[2405.11270\] HR Human: Modeling Human Avatars with Triangular Mesh and High-Resolution Textures from Videos](https://arxiv.org/abs/2405.11270) (ZJU)
- [ ] [\[2405.11276\] Visible and Clear: Finding Tiny Objects in Difference Map](https://arxiv.org/abs/2405.11276) (ECCV)
- [ ] [\[2405.11293\] InfRS: Incremental Few-Shot Object Detection in Remote Sensing Images](https://arxiv.org/abs/2405.11293) (WHU)
- [ ] [\[2405.11315\] MediCLIP: Adapting CLIP for Few-shot Medical Image Anomaly Detection](https://arxiv.org/abs/2405.11315) (BUPT)
- [ ] [\[2405.11336\] UPAM: Unified Prompt Attack in Text-to-Image Generation Models Against Both Textual Filters and Visual Checkers](https://arxiv.org/abs/2405.11336) (ICML)
- [ ] [\[2405.11338\] EyeFound: A Multimodal Generalist Foundation Model for Ophthalmic Imaging](https://arxiv.org/abs/2405.11338) (PolyU)
- [ ] [\[2405.11351\] PlantTracing: Tracing Arabidopsis Thaliana Apex with CenterTrack](https://arxiv.org/abs/2405.11351) (NYU)
- [ ] [\[2405.11437\] The First Swahili Language Scene Text Detection and Recognition Dataset](https://arxiv.org/abs/2405.11437) (HUST)
- [ ] [\[2405.11442\] Unifying 3D Vision-Language Understanding via Promptable Queries](https://arxiv.org/abs/2405.11442) (ECCV)
- [ ] [\[2405.11467\] AdaAugment: A Tuning-Free and Adaptive Approach to Enhance Data Augmentation](https://arxiv.org/abs/2405.11467) (NJU)
- [ ] [\[2405.11483\] MICap: A Unified Model for Identity-aware Movie Descriptions](https://arxiv.org/abs/2405.11483) (CVPR)
- [ ] [\[2405.11487\] "Previously on ..." From Recaps to Story Summarization](https://arxiv.org/abs/2405.11487) (CVPR)
- [ ] [\[2405.11496\] DEMO: A Statistical Perspective for Efficient Image-Text Matching](https://arxiv.org/abs/2405.11496) (GIT)
- [ ] [\[2405.11574\] Reproducibility Study of CDUL: CLIP-Driven Unsupervised Learning for Multi-Label Image Classification](https://arxiv.org/abs/2405.11574) (Oxford)
- [ ] [\[2405.11582\] SLAB: Efficient Transformers with Simplified Linear Attention and Progressive Re-parameterized Batch Normalization](https://arxiv.org/abs/2405.11582) (ICML)
- [ ] [\[2405.11618\] Transcriptomics-guided Slide Representation Learning in Computational Pathology](https://arxiv.org/abs/2405.11618) (Harvard, CVPR)
- [ ] [\[2405.11643\] Morphological Prototyping for Unsupervised Slide Representation Learning in Computational Pathology](https://arxiv.org/abs/2405.11643) (Harvard, CVPR)
- [ ] [\[2405.11655\] Track Anything Rapter(TAR)](https://arxiv.org/abs/2405.11655) (UMD)
- [ ] [\[2405.11754\] Versatile Teacher: A Class-aware Teacher-student Framework for Cross-domain Adaptation](https://arxiv.org/abs/2405.11754) (HUST)
- [ ] [\[2405.11757\] DLAFormer: An End-to-End Transformer For Document Layout Analysis](https://arxiv.org/abs/2405.11757) (USTC)
- [ ] [\[2405.11765\] DATR: Unsupervised Domain Adaptive Detection Transformer with Dataset-Level Adaptation and Prototypical Alignment](https://arxiv.org/abs/2405.11765) (BIT, Transactions on Image Processing)
- [ ] [\[2405.11809\] Distill-then-prune: An Efficient Compression Framework for Real-time Stereo Matching Network on Edge Devices](https://arxiv.org/abs/2405.11809) (BUPT)
- [ ] [\[2405.11852\] Evolving Storytelling: Benchmarks and Methods for New Character Customization with Diffusion Models](https://arxiv.org/abs/2405.11852) (NTU)
- [ ] [\[2405.11862\] SEMv3: A Fast and Robust Approach to Table Separation Line Detection](https://arxiv.org/abs/2405.11862) (USTC)
- [ ] [\[2405.11867\] Depth Prompting for Sensor-Agnostic Depth Estimation](https://arxiv.org/abs/2405.11867) (CVPR)
- [ ] [\[2405.11905\] CSTA: CNN-based Spatiotemporal Attention for Video Summarization](https://arxiv.org/abs/2405.11905) (CVPR)
- [ ] [\[2405.11913\] Diff-BGM: A Diffusion Model for Video Background Music Generation](https://arxiv.org/abs/2405.11913) (Peking, CVPR)
- [ ] [\[2405.11914\] PT43D: A Probabilistic Transformer for Generating 3D Shapes from Single Highly-Ambiguous RGB Images](https://arxiv.org/abs/2405.11914) (TUM)
- [ ] [\[2405.11936\] UAV-VisLoc: A Large-scale Dataset for UAV Visual Localization](https://arxiv.org/abs/2405.11936) (BUPT)
- [ ] [\[2405.11993\] GGAvatar: Geometric Adjustment of Gaussian Head Avatar](https://arxiv.org/abs/2405.11993) (ZJU)
- [ ] [\[2405.12006\] Depth Reconstruction with Neural Signed Distance Fields in Structured Light Systems](https://arxiv.org/abs/2405.12006) (Peking)
- [ ] [\[2405.12057\] NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo](https://arxiv.org/abs/2405.12057) (Cambridge)
- [ ] [\[2405.12110\] CoR-GS: Sparse-View 3D Gaussian Splatting via Co-Regularization](https://arxiv.org/abs/2405.12110) (ECCV)
- [ ] [\[2405.12114\] A New Cross-Space Total Variation Regularization Model for Color Image Restoration with Quaternion Blur Operator](https://arxiv.org/abs/2405.12114) (BU)
- [ ] [\[2405.12200\] Multi-View Attentive Contextualization for Multi-View 3D Object Detection](https://arxiv.org/abs/2405.12200) (CVPR)
- [ ] [\[2405.12211\] Slicedit: Zero-Shot Video Editing With Text-to-Image Diffusion Models Using Spatio-Temporal Slices](https://arxiv.org/abs/2405.12211) (ICML)
- [ ] [\[2405.12218\] MVSGaussian: Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo](https://arxiv.org/abs/2405.12218) (ECCV)
- [ ] [\[2405.12313\] Deep learning-based hyperspectral image reconstruction for quality assessment of agro-product](https://arxiv.org/abs/2405.12313) (Illinois)
- [ ] [\[2405.12460\] Physics-based Scene Layout Generation from Human Motion](https://arxiv.org/abs/2405.12460) (CUHK, SIGGRAPH)
- [ ] [\[2405.12476\] Benchmarking Fish Dataset and Evaluation Metric in Keypoint Detection -- Towards Precise Fish Morphological Assessment in Aquaculture Breeding](https://arxiv.org/abs/2405.12476) (Shanghai AI Lab)
- [ ] [\[2405.12503\] CLRKDNet: Speeding up Lane Detection with Knowledge Distillation](https://arxiv.org/abs/2405.12503) (HKUST(GZ))
- [ ] [\[2405.12509\] Active Object Detection with Knowledge Aggregation and Distillation from Large Models](https://arxiv.org/abs/2405.12509) (Peking)
- [ ] [\[2405.12607\] S3O: A Dual-Phase Approach for Reconstructing Dynamic Shape and Skeleton of Articulated Objects from Single Monocular Video](https://arxiv.org/abs/2405.12607) (Illinois, ICML)
- [ ] [\[2405.12648\] Scene Graph Generation Strategy with Co-occurrence Knowledge and Learnable Term Frequency](https://arxiv.org/abs/2405.12648) (ICML)
- [ ] [\[2405.12705\] Multimodal Adaptive Inference for Document Image Classification with Anytime Early Exiting](https://arxiv.org/abs/2405.12705) (Microsoft)
- [ ] [\[2405.12721\] StarLKNet: Star Mixup with Large Kernel Networks for Palm Vein Identification](https://arxiv.org/abs/2405.12721) (BU)
- [ ] [\[2405.12736\] Predicting the Influence of Adverse Weather on Pedestrian Detection with Automotive Radar and Lidar Sensors](https://arxiv.org/abs/2405.12736) (MIT)
- [ ] [\[2405.12742\] Multi-Subject Personalization](https://arxiv.org/abs/2405.12742) (NIPS)
- [ ] [\[2405.12791\] Adaptive local boundary conditions to improve Deformable Image Registration](https://arxiv.org/abs/2405.12791) (Inria)
- [ ] [\[2405.12891\] DARK: Denoising, Amplification, Restoration Kit](https://arxiv.org/abs/2405.12891) (University of Michigan)
- [ ] [\[2405.12914\] An Empirical Study and Analysis of Text-to-Image Generation Using Large Language Model-Powered Textual Representation](https://arxiv.org/abs/2405.12914) (Fudan, ECCV)
- [ ] [\[2405.12944\] AMFD: Distillation via Adaptive Multimodal Fusion for Multispectral Pedestrian Detection](https://arxiv.org/abs/2405.12944) (SJTU)
- [ ] [\[2405.12970\] Face Adapter for Pre-Trained Diffusion Models with Fine-Grained ID and Attribute Control](https://arxiv.org/abs/2405.12970) (ZJU, ECCV)
- [ ] [\[2405.12971\] BiomedParse: a biomedical foundation model for image parsing of everything everywhere all at once](https://arxiv.org/abs/2405.12971) (Microsoft)
- [ ] [\[2405.12978\] Personalized Residuals for Concept-Driven Text-to-Image Generation](https://arxiv.org/abs/2405.12978) (GIT, CVPR)
- [ ] [\[2405.12979\] OmniGlue: Generalizable Feature Matching with Foundation Model Guidance](https://arxiv.org/abs/2405.12979) (CVPR)
- [ ] [\[2405.13194\] KPConvX: Modernizing Kernel Point Convolution with Kernel Attention](https://arxiv.org/abs/2405.13194) (CVPR)
- [ ] [\[2405.13267\] FLARE up your data: Diffusion-based Augmentation Method in Astronomical Imaging](https://arxiv.org/abs/2405.13267) (MBZUAI)
- [ ] [\[2405.13360\] How to Trace Latent Generative Model Generated Images without Artificial Watermark?](https://arxiv.org/abs/2405.13360) (ICML)
- [ ] [\[2405.13389\] HR-INR: Continuous Space-Time Video Super-Resolution via Event Camera](https://arxiv.org/abs/2405.13389) (University of Tokyo)
- [ ] [\[2405.13518\] PerSense: Personalized Instance Segmentation in Dense Images](https://arxiv.org/abs/2405.13518) (MBZUAI)
- [ ] [\[2405.13532\] What Makes Good Few-shot Examples for Vision-Language Models?](https://arxiv.org/abs/2405.13532) (Fudan)
- [ ] [\[2405.13581\] Safety Alignment for Vision Language Models](https://arxiv.org/abs/2405.13581) (NJU)
- [ ] [\[2405.13686\] Embedding Generalized Semantic Knowledge into Few-Shot Remote Sensing Segmentation](https://arxiv.org/abs/2405.13686) (NWPU)
- [ ] [\[2405.13694\] Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances](https://arxiv.org/abs/2405.13694) (Tsinghua)
- [ ] [\[2405.13722\] InstaDrag: Lightning Fast and Accurate Drag-based Image Editing Emerging from Videos](https://arxiv.org/abs/2405.13722) (NUS)
- [ ] [\[2405.13758\] Counterfactual Gradients-based Quantification of Prediction Trust in Neural Networks](https://arxiv.org/abs/2405.13758) (GIT)
- [ ] [\[2405.13762\] A Versatile Diffusion Transformer with Mixture of Noise Levels for Audiovisual Generation](https://arxiv.org/abs/2405.13762) (Google)
- [ ] [\[2405.13777\] No Filter: Cultural and Socioeconomic Diversity in Contrastive Vision-Language Models](https://arxiv.org/abs/2405.13777) (ETH)
- [ ] [\[2405.13824\] GMMFormer v2: An Uncertainty-aware Framework for Partially Relevant Video Retrieval](https://arxiv.org/abs/2405.13824) (Tsinghua)
- [ ] [\[2405.13864\] Just rotate it! Uncertainty estimation in closed-source models via multiple queries](https://arxiv.org/abs/2405.13864) (Inria)
- [ ] [\[2405.13870\] FreeCustom: Tuning-Free Customized Image Generation for Multi-Concept Composition](https://arxiv.org/abs/2405.13870) (CVPR)
- [ ] [\[2405.13911\] TOPA: Extend Large Language Models for Video Understanding via Text-Only Pre-Alignment](https://arxiv.org/abs/2405.13911) (NUS)
- [ ] [\[2405.13943\] DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus](https://arxiv.org/abs/2405.13943) (NUS)
- [ ] [\[2405.13949\] PitVQA: Image-grounded Text Embedding LLM for Visual Question Answering in Pituitary Surgery](https://arxiv.org/abs/2405.13949) (UCL)
- [ ] [\[2405.14019\] BrainMorph: A Foundational Keypoint Model for Robust and Flexible Brain MRI Registration](https://arxiv.org/abs/2405.14019) (Cornell)
- [ ] [\[2405.14077\] Learning to Transform Dynamically for Better Adversarial Transferability](https://arxiv.org/abs/2405.14077) (CVPR)
- [ ] [\[2405.14101\] Enhancing Image Layout Control with Loss-Guided Diffusion Models](https://arxiv.org/abs/2405.14101) (University of Toronto)
- [ ] [\[2405.14136\] Efficient Multitask Dense Predictor via Binarization](https://arxiv.org/abs/2405.14136) (HKUST, CVPR)
- [ ] [\[2405.14142\] Imagery as Inquiry: Exploring A Multimodal Dataset for Conversational Recommendation](https://arxiv.org/abs/2405.14142) (UCSD)
- [ ] [\[2405.14174\] Multi-Scale VMamba: Hierarchy in Hierarchy Visual State Space Model](https://arxiv.org/abs/2405.14174) (USyd)
- [ ] [\[2405.14200\] Awesome Multi-modal Object Tracking](https://arxiv.org/abs/2405.14200) (SJTU)
- [ ] [\[2405.14201\] FreeTuner: Any Subject in Any Style with Training-free Diffusion](https://arxiv.org/abs/2405.14201) (ZJU)
- [ ] [\[2405.14241\] NeuroGauss4D-PCI: 4D Neural Fields and Gaussian Deformation Fields for Point Cloud Interpolation](https://arxiv.org/abs/2405.14241) (Tsinghua)
- [ ] [\[2405.14294\] Tuning-free Universally-Supervised Semantic Segmentation](https://arxiv.org/abs/2405.14294) (ZJU)
- [ ] [\[2405.14312\] Improving Gloss-free Sign Language Translation by Reducing Representation Density](https://arxiv.org/abs/2405.14312) (HKUST(GZ))
- [ ] [\[2405.14334\] Hierarchical Salient Patch Identification for Interpretable Fundus Disease Localization](https://arxiv.org/abs/2405.14334) (Tongji)
- [ ] [\[2405.14452\] JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression](https://arxiv.org/abs/2405.14452) (SJTU)
- [ ] [\[2405.14475\] MagicDrive3D: Controllable 3D Generation for Any-View Rendering in Street Scenes](https://arxiv.org/abs/2405.14475) (HKUST)
- [ ] [\[2405.14497\] Improving Single Domain-Generalized Object Detection: A Focus on Diversification and Alignment](https://arxiv.org/abs/2405.14497) (MBZUAI)
- [ ] [\[2405.14516\] Towards Realistic Long-tailed Semi-supervised Learning in an Open World](https://arxiv.org/abs/2405.14516) (Peking)
- [ ] [\[2405.14530\] Multistable Shape from Shading Emerges from Patch Diffusion](https://arxiv.org/abs/2405.14530) (Harvard)
- [ ] [\[2405.14554\] SearchLVLMs: A Plug-and-Play Framework for Augmenting Large Vision-Language Models by Searching Up-to-Date Internet Knowledge](https://arxiv.org/abs/2405.14554) (BIT)
- [ ] [\[2405.14672\] Towards Imperceptible Backdoor Attack in Self-supervised Learning](https://arxiv.org/abs/2405.14672) (ZJU)
- [ ] [\[2405.14700\] Sparse-Tuning: Adapting Vision Transformers with Efficient Fine-tuning and Inference](https://arxiv.org/abs/2405.14700) (NUDT)
- [ ] [\[2405.14736\] GIFT: Unlocking Full Potential of Labels in Distilled Dataset at Near-zero Cost](https://arxiv.org/abs/2405.14736) (UCL)
- [ ] [\[2405.14737\] CLIPScope: Enhancing Zero-Shot OOD Detection with Bayesian Scoring](https://arxiv.org/abs/2405.14737) (NYU)
- [ ] [\[2405.14785\] EditWorld: Simulating World Dynamics for Instruction-Following Image Editing](https://arxiv.org/abs/2405.14785) (Peking)
- [ ] [\[2405.14822\] PaGoDA: Progressive Growing of a One-Step Generator from a Low-Resolution Diffusion Teacher](https://arxiv.org/abs/2405.14822) (Stanford)
- [ ] [\[2405.14824\] Camera Relocalization in Shadow-free Neural Radiance Fields](https://arxiv.org/abs/2405.14824) (Tsinghua)
- [ ] [\[2405.14841\] MOD-UV: Learning Mobile Object Detectors from Unlabeled Videos](https://arxiv.org/abs/2405.14841) (ECCV)
- [ ] [\[2405.14847\] Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling](https://arxiv.org/abs/2405.14847) (CVPR)
- [ ] [\[2405.14855\] Synergistic Global-space Camera and Human Reconstruction from Videos](https://arxiv.org/abs/2405.14855) (CVPR)
- [ ] [\[2405.14857\] Semantica: An Adaptable Image-Conditioned Diffusion Model](https://arxiv.org/abs/2405.14857) (Google)
- [ ] [\[2405.14864\] Video Diffusion Models are Training-free Motion Interpreter and Controller](https://arxiv.org/abs/2405.14864) (Peking)
- [ ] [\[2405.14866\] Tele-Aloha: A Low-budget and High-authenticity Telepresence System Using Sparse RGB Cameras](https://arxiv.org/abs/2405.14866) (Tsinghua, SIGGRAPH)
- [ ] [\[2405.14868\] Generative Camera Dolly: Extreme Monocular Dynamic Novel View Synthesis](https://arxiv.org/abs/2405.14868) (ECCV)
- [ ] [\[2405.14869\] PuzzleAvatar: Assembling 3D Avatars from Personal Albums](https://arxiv.org/abs/2405.14869) (MPI)
- [ ] [\[2405.14873\] Federated Online Adaptation for Deep Stereo](https://arxiv.org/abs/2405.14873) (CVPR)
- [ ] [\[2405.14880\] Dissecting Query-Key Interaction in Vision Transformers](https://arxiv.org/abs/2405.14880) (Michigan State University)
- [ ] [\[2405.14881\] DiffuseMix: Label-Preserving Data Augmentation with Diffusion Models](https://arxiv.org/abs/2405.14881) (CVPR)
- [ ] [\[2405.14959\] EvGGS: A Collaborative Learning Framework for Event-based Generalizable Gaussian Splatting](https://arxiv.org/abs/2405.14959) (HKUST)
- [ ] [\[2405.15118\] GS-Hider: Hiding Messages into 3D Gaussian Splatting](https://arxiv.org/abs/2405.15118) (Peking)
- [ ] [\[2405.15137\] An Approximate Dynamic Programming Framework for Occlusion-Robust Multi-Object Tracking](https://arxiv.org/abs/2405.15137) (MIT)
- [ ] [\[2405.15155\] CLIP model is an Efficient Online Lifelong Learner](https://arxiv.org/abs/2405.15155) (BUPT)
- [ ] [\[2405.15157\] Rethinking Class-Incremental Learning from a Dynamic Imbalanced Learning Perspective](https://arxiv.org/abs/2405.15157) (BUPT)
- [ ] [\[2405.15169\] Bring Adaptive Binding Prototypes to Generalized Referring Expression Segmentation](https://arxiv.org/abs/2405.15169) (BUPT)
- [ ] [\[2405.15170\] Label-efficient Semantic Scene Completion with Scribble Annotations](https://arxiv.org/abs/2405.15170) (ZJU)
- [ ] [\[2405.15196\] DisC-GS: Discontinuity-aware Gaussian Splatting](https://arxiv.org/abs/2405.15196) (NTU)
- [ ] [\[2405.15199\] ODGEN: Domain-specific Object Detection Data Generation with Diffusion Models](https://arxiv.org/abs/2405.15199) (Tsinghua)
- [ ] [\[2405.15209\] Unsupervised Motion Segmentation for Neuromorphic Aerial Surveillance](https://arxiv.org/abs/2405.15209) (USyd)
- [ ] [\[2405.15223\] iVideoGPT: Interactive VideoGPTs are Scalable World Models](https://arxiv.org/abs/2405.15223) (Tsinghua)
- [ ] [\[2405.15225\] Unbiased Faster R-CNN for Single-source Domain Generalized Object Detection](https://arxiv.org/abs/2405.15225) (CVPR)
- [ ] [\[2405.15253\] Seeing the World through an Antenna's Eye: Reception Quality Visualization Using Incomplete Technical Signal Information](https://arxiv.org/abs/2405.15253) (DLR)
- [ ] [\[2405.15267\] Off-the-shelf ChatGPT is a Good Few-shot Human Motion Predictor](https://arxiv.org/abs/2405.15267) (NTU)
- [ ] [\[2405.15274\] Talk to Parallel LiDARs: A Human-LiDAR Interaction Method Based on 3D Visual Grounding](https://arxiv.org/abs/2405.15274) (BIT)
- [ ] [\[2405.15279\] Towards Global Optimal Visual In-Context Learning Prompt Selection](https://arxiv.org/abs/2405.15279) (HKUST)
- [ ] [\[2405.15289\] Learning Invariant Causal Mechanism from Vision-Language Models](https://arxiv.org/abs/2405.15289) (IS CAS)
- [ ] [\[2405.15330\] Towards Understanding the Working Mechanism of Text-to-Image Diffusion Model](https://arxiv.org/abs/2405.15330) (NJU)
- [ ] [\[2405.15343\] Distinguish Any Fake Videos: Unleashing the Power of Large-scale Data and Motion Features](https://arxiv.org/abs/2405.15343) (BU)
- [ ] [\[2405.15365\] U3M: Unbiased Multiscale Modal Fusion Model for Multimodal Semantic Segmentation](https://arxiv.org/abs/2405.15365) (NWPU)
- [ ] [\[2405.15385\] CPT-Interp: Continuous sPatial and Temporal Motion Modeling for 4D Medical Image Interpolation](https://arxiv.org/abs/2405.15385) (ETH)
- [ ] [\[2405.15541\] Learning Generalizable Human Motion Generator with Reinforcement Learning](https://arxiv.org/abs/2405.15541) (USTC)
- [ ] [\[2405.15574\] Meteor: Mamba-based Traversal of Rationale for Large Language and Vision Models](https://arxiv.org/abs/2405.15574) (KAIST)
- [ ] [\[2405.15700\] Trackastra: Transformer-based cell tracking for live-cell microscopy](https://arxiv.org/abs/2405.15700) (EPFL, ECCV)
- [ ] [\[2405.15734\] LM4LV: A Frozen Large Language Model for Low-level Vision Tasks](https://arxiv.org/abs/2405.15734) (SJTU)
- [ ] [\[2405.15738\] ConvLLaVA: Hierarchical Backbones as Visual Encoder for Large Multimodal Models](https://arxiv.org/abs/2405.15738) (Tsinghua)
- [ ] [\[2405.15758\] InstructAvatar: Text-Guided Emotion and Motion Control for Avatar Generation](https://arxiv.org/abs/2405.15758) (Peking)
- [ ] [\[2405.15973\] Enhancing Visual-Language Modality Alignment in Large Vision Language Models via Self-Improvement](https://arxiv.org/abs/2405.15973) (UMD)
- [ ] [\[2405.15989\] TreeFormers -- An Exploration of Vision Transformers for Deforestation Driver Classification](https://arxiv.org/abs/2405.15989) (Stanford)
- [ ] [\[2405.16034\] DiffuBox: Refining 3D Object Detection with Point Diffusion](https://arxiv.org/abs/2405.16034) (Cornell)
- [ ] [\[2405.16038\] Rethinking Early-Fusion Strategies for Improved Multispectral Object Detection](https://arxiv.org/abs/2405.16038) (ZJU)
- [ ] [\[2405.16108\] OmniBind: Teach to Build Unequal-Scale Modality Interaction for Omni-Bind of All](https://arxiv.org/abs/2405.16108) (HKUST(GZ))
- [ ] [\[2405.16152\] SuDA: Support-based Domain Adaptation for Sim2Real Motion Capture with Flexible Sensors](https://arxiv.org/abs/2405.16152) (Xiamen, ICML)
- [ ] [\[2405.16204\] VOODOO XP: Expressive One-Shot Head Reenactment for VR Telepresence](https://arxiv.org/abs/2405.16204) (MBZUAI)
- [ ] [\[2405.16341\] R.A.C.E.: Robust Adversarial Concept Erasure for Secure Text-to-Image Diffusion Model](https://arxiv.org/abs/2405.16341) (ECCV)
- [ ] [\[2405.16382\] Video Prediction Models as General Visual Encoders](https://arxiv.org/abs/2405.16382) (CMU)
- [ ] [\[2405.16401\] Understanding the Effect of using Semantically Meaningful Tokens for Visual Representation Learning](https://arxiv.org/abs/2405.16401) (UMD)
- [ ] [\[2405.16417\] CRoFT: Robust Fine-Tuning with Concurrent Optimization for OOD Generalization and Open-Set OOD Detection](https://arxiv.org/abs/2405.16417) (SJTU, ICML)
- [ ] [\[2405.16419\] Enhancing Feature Diversity Boosts Channel-Adaptive Vision Transformers](https://arxiv.org/abs/2405.16419) (BU)
- [ ] [\[2405.16501\] User-Friendly Customized Generation with Multi-Modal Prompts](https://arxiv.org/abs/2405.16501) (SJTU)
- [ ] [\[2405.16534\] Pruning for Robust Concept Erasing in Diffusion Models](https://arxiv.org/abs/2405.16534) (USyd)
- [ ] [\[2405.16573\] FRCNet Frequency and Region Consistency for Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2405.16573) (Nankai)
- [ ] [\[2405.16591\] CapS-Adapter: Caption-based MultiModal Adapter in Zero-Shot Classification](https://arxiv.org/abs/2405.16591) (Tsinghua)
- [ ] [\[2405.16596\] Protect-Your-IP: Scalable Source-Tracing and Attribution against Personalized Generation](https://arxiv.org/abs/2405.16596) (Peking)
- [ ] [\[2405.16597\] Content and Salient Semantics Collaboration for Cloth-Changing Person Re-Identification](https://arxiv.org/abs/2405.16597) (Fudan)
- [ ] [\[2405.16600\] Image-Text-Image Knowledge Transferring for Lifelong Person Re-Identification with Hybrid Clothing States](https://arxiv.org/abs/2405.16600) (Fudan)
- [ ] [\[2405.16628\] Competing for pixels: a self-play algorithm for weakly-supervised segmentation](https://arxiv.org/abs/2405.16628) (UCL)
- [ ] [\[2405.16761\] Masked Face Recognition with Generative-to-Discriminative Representations](https://arxiv.org/abs/2405.16761) (ICML)
- [ ] [\[2405.16785\] PromptFix: You Prompt and We Fix the Photo](https://arxiv.org/abs/2405.16785) (Microsoft)
- [ ] [\[2405.16788\] 3D Reconstruction with Fast Dipole Sums](https://arxiv.org/abs/2405.16788) (CMU)
- [ ] [\[2405.16796\] DualContrast: Unsupervised Disentangling of Content and Transformations with Implicit Parameterization](https://arxiv.org/abs/2405.16796) (CMU)
- [ ] [\[2405.16822\] Vidu4D: Single Generated Video to High-Fidelity 4D Reconstruction with Dynamic Gaussian Surfels](https://arxiv.org/abs/2405.16822) (Tongji)
- [ ] [\[2405.16829\] PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting](https://arxiv.org/abs/2405.16829) (HKUST(GZ))
- [ ] [\[2405.16847\] TokenUnify: Scalable Autoregressive Visual Pre-training with Mixture Token Prediction](https://arxiv.org/abs/2405.16847) (USTC)
- [ ] [\[2405.16848\] A re-calibration method for object detection with multi-modal alignment bias in autonomous driving](https://arxiv.org/abs/2405.16848) (Tsinghua)
- [ ] [\[2405.16860\] Think Before You Act: A Two-Stage Framework for Mitigating Gender Bias Towards Vision-Language Tasks](https://arxiv.org/abs/2405.16860) (GIT)
- [ ] [\[2405.16868\] RCDN: Towards Robust Camera-Insensitivity Collaborative Perception via Dynamic Feature-based 3D Neural Modeling](https://arxiv.org/abs/2405.16868) (Tongji)
- [ ] [\[2405.16874\] CoCoGesture: Toward Coherent Co-speech 3D Gesture Generation in the Wild](https://arxiv.org/abs/2405.16874) (HKUST)
- [ ] [\[2405.16886\] Hawk: Learning to Understand Open-World Video Anomalies](https://arxiv.org/abs/2405.16886) (NWPU)
- [ ] [\[2405.16923\] SA-GS: Semantic-Aware Gaussian Splatting for Large Scene Reconstruction with Geometry Constrain](https://arxiv.org/abs/2405.16923) (BIT)
- [ ] [\[2405.16925\] OED: Towards One-stage End-to-End Dynamic Scene Graph Generation](https://arxiv.org/abs/2405.16925) (Peking, CVPR)
- [ ] [\[2405.16930\] From Obstacle to Opportunity: Enhancing Semi-supervised Learning with Synthetic Data](https://arxiv.org/abs/2405.16930) (University of Tokyo)
- [ ] [\[2405.16934\] Do Vision-Language Transformers Exhibit Visual Commonsense? An Empirical Study of VCR](https://arxiv.org/abs/2405.16934) (NUS)
- [ ] [\[2405.16960\] DCPI-Depth: Explicitly Infusing Dense Correspondence Prior to Unsupervised Monocular Depth Estimation](https://arxiv.org/abs/2405.16960) (Tongji)
- [ ] [\[2405.16996\] Mitigating Noisy Correspondence by Geometrical Structure Consistency Learning](https://arxiv.org/abs/2405.16996) (BU)
- [ ] [\[2405.17004\] Efficient Visual Fault Detection for Freight Train via Neural Architecture Search with Data Volume Robustness](https://arxiv.org/abs/2405.17004) (HUST)
- [ ] [\[2405.17013\] MotionLLM: Multimodal Motion-Language Learning with Large Language Models](https://arxiv.org/abs/2405.17013) (HKUST)
- [ ] [\[2405.17016\] $\text{Di}^2\text{Pose}$: Discrete Diffusion Model for Occluded 3D Human Pose Estimation](https://arxiv.org/abs/2405.17016) (ZJU)
- [ ] [\[2405.17022\] Compositional Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2405.17022) (HUST)
- [ ] [\[2405.17082\] Ensembling Diffusion Models via Adaptive Feature Aggregation](https://arxiv.org/abs/2405.17082) (NJU)
- [ ] [\[2405.17104\] LLM-Optic: Unveiling the Capabilities of Large Language Models for Universal Visual Grounding](https://arxiv.org/abs/2405.17104) (HKUST)
- [ ] [\[2405.17136\] PanoTree: Autonomous Photo-Spot Explorer in Virtual Reality Scenes](https://arxiv.org/abs/2405.17136) (Inria)
- [ ] [\[2405.17137\] Jump-teaching: Ultra Efficient and Robust Learning with Noisy Label](https://arxiv.org/abs/2405.17137) (Xidian)
- [ ] [\[2405.17149\] LCM: Locally Constrained Compact Point Cloud Model for Masked Point Modeling](https://arxiv.org/abs/2405.17149) (Tsinghua)
- [ ] [\[2405.17191\] MCGAN: Enhancing GAN Training with Regression-Based Generator Loss](https://arxiv.org/abs/2405.17191) (UCL)
- [ ] [\[2405.17201\] Diagnosing the Compositional Knowledge of Vision Language Models from a Game-Theoretic View](https://arxiv.org/abs/2405.17201) (HKU)
- [ ] [\[2405.17240\] Content-Style Decoupling for Unsupervised Makeup Transfer without Generating Pseudo Ground Truth](https://arxiv.org/abs/2405.17240) (CVPR)
- [ ] [\[2405.17306\] Controllable Longer Image Animation with Diffusion Models](https://arxiv.org/abs/2405.17306) (Alibaba)
- [ ] [\[2405.17315\] All-day Depth Completion](https://arxiv.org/abs/2405.17315) (UCLA)
- [ ] [\[2405.17393\] EASI-Tex: Edge-Aware Mesh Texturing from Single Image](https://arxiv.org/abs/2405.17393) (SIGGRAPH)
- [ ] [\[2405.17397\] Occlusion Handling in 3D Human Pose Estimation with Perturbed Positional Encoding](https://arxiv.org/abs/2405.17397) (Microsoft)
- [ ] [\[2405.17398\] Vista: A Generalizable Driving World Model with High Fidelity and Versatile Controllability](https://arxiv.org/abs/2405.17398) (HKUST)
- [ ] [\[2405.17419\] MultiOOD: Scaling Out-of-Distribution Detection for Multiple Modalities](https://arxiv.org/abs/2405.17419) (EPFL)
- [ ] [\[2405.17422\] Hardness-Aware Scene Synthesis for Semi-Supervised 3D Object Detection](https://arxiv.org/abs/2405.17422) (Tsinghua)
- [ ] [\[2405.17426\] Benchmarking and Improving Bird's Eye View Perception Robustness in Autonomous Driving](https://arxiv.org/abs/2405.17426) (NTU)
- [ ] [\[2405.17429\] GaussianFormer: Scene as Gaussians for Vision-Based 3D Semantic Occupancy Prediction](https://arxiv.org/abs/2405.17429) (Tsinghua)
- [ ] [\[2405.17447\] How to train your ViT for OOD Detection](https://arxiv.org/abs/2405.17447) (University of TÃ¼bingen)
- [ ] [\[2405.17455\] WeatherFormer: A Pretrained Encoder Model for Learning Robust Weather Representations from Small Datasets](https://arxiv.org/abs/2405.17455) (MIT)
- [ ] [\[2405.17456\] Optimized Linear Measurements for Inverse Problems using Diffusion-Based Image Generation](https://arxiv.org/abs/2405.17456) (NYU)
- [ ] [\[2405.17457\] Data-Free Federated Class Incremental Learning with Diffusion-Based Generative Memory](https://arxiv.org/abs/2405.17457) (NUS)
- [ ] [\[2405.17531\] Evolutive Rendering Models](https://arxiv.org/abs/2405.17531) (MPI)
- [ ] [\[2405.17596\] GOI: Find 3D Gaussians of Interest with an Optimizable Open-vocabulary Semantic-space Hyperplane](https://arxiv.org/abs/2405.17596) (Xiamen)
- [ ] [\[2405.17609\] GarmentCodeData: A Dataset of 3D Made-to-Measure Garments With Sewing Patterns](https://arxiv.org/abs/2405.17609) (ECCV)
- [ ] [\[2405.17613\] A Framework for Multi-modal Learning: Jointly Modeling Inter- & Intra-Modality Dependencies](https://arxiv.org/abs/2405.17613) (NYU)
- [ ] [\[2405.17661\] RefDrop: Controllable Consistency in Image or Video Generation via Reference Feature Guidance](https://arxiv.org/abs/2405.17661) (GIT)
- [ ] [\[2405.17677\] Understanding differences in applying DETR to natural and medical images](https://arxiv.org/abs/2405.17677) (NYU)
- [ ] [\[2405.17678\] TIMA: Text-Image Mutual Awareness for Balancing Zero-Shot Adversarial Robustness and Generalization Ability](https://arxiv.org/abs/2405.17678) (HKUST(GZ))
- [ ] [\[2405.17698\] BaboonLand Dataset: Tracking Primates in the Wild and Automating Behaviour Recognition from Drone Videos](https://arxiv.org/abs/2405.17698) (Princeton)
- [ ] [\[2405.17725\] Color Shift Estimation-and-Correction for Image Enhancement](https://arxiv.org/abs/2405.17725) (CVPR)
- [ ] [\[2405.17730\] MMPareto: Boosting Multimodal Learning with Innocent Unimodal Assistance](https://arxiv.org/abs/2405.17730) (ICML)
- [ ] [\[2405.17765\] PTM-VQA: Efficient Video Quality Assessment Leveraging Diverse PreTrained Models from the Wild](https://arxiv.org/abs/2405.17765) (Tsinghua, CVPR)
- [ ] [\[2405.17774\] Gradually Vanishing Gap in Prototypical Network for Unsupervised Domain Adaptation](https://arxiv.org/abs/2405.17774) (USTC)
- [ ] [\[2405.17788\] Enhancing Road Safety: Real-Time Detection of Driver Distraction through Convolutional Neural Networks](https://arxiv.org/abs/2405.17788) (Illinois)
- [ ] [\[2405.17793\] SafeguardGS: 3D Gaussian Primitive Pruning While Avoiding Catastrophic Scene Destruction](https://arxiv.org/abs/2405.17793) (JHU)
- [ ] [\[2405.17814\] FAIntbench: A Holistic and Precise Benchmark for Bias Evaluation in Text-to-Image Models](https://arxiv.org/abs/2405.17814) (ZJU)
- [ ] [\[2405.17816\] Pursuing Feature Separation based on Neural Collapse for Out-of-Distribution Detection](https://arxiv.org/abs/2405.17816) (SJTU)
- [ ] [\[2405.17835\] Deform3DGS: Flexible Deformation for Fast Surgical Scene Reconstruction with Gaussian Splatting](https://arxiv.org/abs/2405.17835) (NUS)
- [ ] [\[2405.17871\] Seeing the Image: Prioritizing Visual Correlation by Contrastive Alignment](https://arxiv.org/abs/2405.17871) (WHU)
- [ ] [\[2405.17872\] HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction](https://arxiv.org/abs/2405.17872) (WHU)
- [ ] [\[2405.17873\] MixDQ: Memory-Efficient Few-Step Text-to-Image Diffusion Models with Metric-Decoupled Mixed Precision Quantization](https://arxiv.org/abs/2405.17873) (Tsinghua)
- [ ] [\[2405.17894\] White-box Multimodal Jailbreaks Against Large Vision-Language Models](https://arxiv.org/abs/2405.17894) (Fudan)
- [ ] [\[2405.17903\] Reliable Object Tracking by Multimodal Hybrid Feature Extraction and Transformer-Based Fusion](https://arxiv.org/abs/2405.17903) (UESTC)
- [ ] [\[2405.17913\] OV-DQUO: Open-Vocabulary DETR with Denoising Text Query Training and Open-World Unknown Objects Supervision](https://arxiv.org/abs/2405.17913) (HIT)
- [ ] [\[2405.17929\] Towards Unified Robustness Against Both Backdoor and Adversarial Attacks](https://arxiv.org/abs/2405.17929) (Michigan State University)
- [ ] [\[2405.17942\] Self-supervised Pre-training for Transferable Multi-modal Perception](https://arxiv.org/abs/2405.17942) (University of Michigan)
- [ ] [\[2405.17958\] FreeSplat: Generalizable 3D Gaussian Splatting Towards Free-View Synthesis of Indoor Scenes](https://arxiv.org/abs/2405.17958) (NUS)
- [ ] [\[2405.18021\] MULi-Ev: Maintaining Unperturbed LiDAR-Event Calibration](https://arxiv.org/abs/2405.18021) (CNRS)
- [ ] [\[2405.18087\] FlowSDF: Flow Matching for Medical Image Segmentation Using Distance Transforms](https://arxiv.org/abs/2405.18087) (ETH)
- [ ] [\[2405.18132\] EG4D: Explicit Generation of 4D Object without Score Distillation](https://arxiv.org/abs/2405.18132) (Cornell)
- [ ] [\[2405.18304\] Multi-modal Generation via Cross-Modal In-Context Learning](https://arxiv.org/abs/2405.18304) (MBZUAI)
- [ ] [\[2405.18322\] SCE-MAE: Selective Correspondence Enhancement with Masked Autoencoder for Self-Supervised Landmark Estimation](https://arxiv.org/abs/2405.18322) (CVPR)
- [ ] [\[2405.18326\] VITON-DiT: Learning In-the-Wild Video Try-On from Human Dance Videos via Diffusion Transformers](https://arxiv.org/abs/2405.18326) (SYSU)
- [ ] [\[2405.18361\] Is a 3D-Tokenized LLM the Key to Reliable Autonomous Driving?](https://arxiv.org/abs/2405.18361) (XJTU)
- [ ] [\[2405.18416\] 3D StreetUnveiler with Semantic-Aware 2DGS](https://arxiv.org/abs/2405.18416) (ShanghaiTech)
- [ ] [\[2405.18425\] ViG: Linear-complexity Visual Sequence Learning with Gated Linear Attention](https://arxiv.org/abs/2405.18425) (HUST)
- [ ] [\[2405.18426\] GFlow: Recovering 4D World from Monocular Video](https://arxiv.org/abs/2405.18426) (NUS)
- [ ] [\[2405.18428\] DiG: Scalable and Efficient Diffusion Models with Gated Linear Attention](https://arxiv.org/abs/2405.18428) (HUST)
- [ ] [\[2405.18437\] Transductive Zero-Shot and Few-Shot CLIP](https://arxiv.org/abs/2405.18437) (CVPR)
- [ ] [\[2405.18483\] Towards Open Domain Text-Driven Synthesis of Multi-Person Motions](https://arxiv.org/abs/2405.18483) (ECCV)
- [ ] [\[2405.18511\] Feasibility and benefits of joint learning from MRI databases with different brain diseases and modalities for segmentation](https://arxiv.org/abs/2405.18511) (Oxford)
- [ ] [\[2405.18525\] REPARO: Compositional 3D Assets Generation with Differentiable 3D Layout Alignment](https://arxiv.org/abs/2405.18525) (Tsinghua)
- [ ] [\[2405.18527\] Task-Driven Uncertainty Quantification in Inverse Problems via Conformal Prediction](https://arxiv.org/abs/2405.18527) (European Conference on Computer Vision)
- [ ] [\[2405.18570\] It's Not a Modality Gap: Characterizing and Addressing the Contrastive Gap](https://arxiv.org/abs/2405.18570) (University of Alberta)
- [ ] [\[2405.18616\] Wavelet-Based Image Tokenizer for Vision Transformers](https://arxiv.org/abs/2405.18616) (Google)
- [ ] [\[2405.18700\] Multi-Condition Latent Diffusion Network for Scene-Aware Neural Human Motion Prediction](https://arxiv.org/abs/2405.18700) (XJTU, Transactions on Image Processing)
- [ ] [\[2405.18706\] FocSAM: Delving Deeply into Focused Objects in Segmenting Anything](https://arxiv.org/abs/2405.18706) (CVPR)
- [ ] [\[2405.18715\] NeRF On-the-go: Exploiting Uncertainty for Distractor-free NeRFs in the Wild](https://arxiv.org/abs/2405.18715) (CVPR)
- [ ] [\[2405.18721\] Correctable Landmark Discovery via Large Models for Vision-Language Navigation](https://arxiv.org/abs/2405.18721) (SYSU, TPAMI)
- [ ] [\[2405.18750\] T2V-Turbo: Breaking the Quality Bottleneck of Video Consistency Model with Mixed Reward Feedback](https://arxiv.org/abs/2405.18750) (Google)
- [ ] [\[2405.18751\] On the Limits of Multi-modal Meta-Learning with Auxiliary Task Modulation Using Conditional Batch Normalization](https://arxiv.org/abs/2405.18751) (University of Edinburgh)
- [ ] [\[2405.18769\] OUS: Scene-Guided Dynamic Facial Expression Recognition](https://arxiv.org/abs/2405.18769) (Fudan)
- [ ] [\[2405.18770\] Leveraging Many-To-Many Relationships for Defending Against Visual-Language Adversarial Attacks](https://arxiv.org/abs/2405.18770) (University of Tokyo)
- [ ] [\[2405.18784\] LP-3DGS: Learning to Prune 3D Gaussian Splatting](https://arxiv.org/abs/2405.18784) (JHU)
- [ ] [\[2405.18790\] Opinion-Unaware Blind Image Quality Assessment using Multi-Scale Deep Feature Statistics](https://arxiv.org/abs/2405.18790) (Tongji)
- [ ] [\[2405.18801\] SketchTriplet: Self-Supervised Scenarized Sketch-Text-Image Triplet Generation](https://arxiv.org/abs/2405.18801) (BUPT)
- [ ] [\[2405.18808\] BRACTIVE: A Brain Activation Approach to Human Visual Brain Learning](https://arxiv.org/abs/2405.18808) (MIT)
- [ ] [\[2405.18810\] UniPTS: A Unified Framework for Proficient Post-Training Sparsity](https://arxiv.org/abs/2405.18810) (CVPR)
- [ ] [\[2405.18812\] MindSemantix: Deciphering Brain Visual Experiences with a Brain-Language Model](https://arxiv.org/abs/2405.18812) (Xidian)
- [ ] [\[2405.18816\] Flow Priors for Linear Inverse Problems via Iterative Corrupted Trajectory Matching](https://arxiv.org/abs/2405.18816) (UCLA)
- [ ] [\[2405.18839\] MEGA: Masked Generative Autoencoder for Human Mesh Recovery](https://arxiv.org/abs/2405.18839) (Inria)
- [ ] [\[2405.18840\] Parameter-efficient Fine-tuning in Hyperspherical Space for Open-vocabulary Semantic Segmentation](https://arxiv.org/abs/2405.18840) (SJTU)
- [ ] [\[2405.18842\] Descriptive Image Quality Assessment in the Wild](https://arxiv.org/abs/2405.18842) (USyd)
- [ ] [\[2405.18853\] Supervised Contrastive Learning for Snapshot Spectral Imaging Face Anti-Spoofing](https://arxiv.org/abs/2405.18853) (SJTU)
- [ ] [\[2405.18861\] Domain-Inspired Sharpness-Aware Minimization Under Domain Shifts](https://arxiv.org/abs/2405.18861) (ICLR)
- [ ] [\[2405.18897\] MLAE: Masked LoRA Experts for Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2405.18897) (SJTU)
- [ ] [\[2405.18959\] Transcending Fusion: A Multi-Scale Alignment Method for Remote Sensing Image-Text Retrieval](https://arxiv.org/abs/2405.18959) (Xidian)
- [ ] [\[2405.19009\] Enhancing Vision-Language Model with Unmasked Token Alignment](https://arxiv.org/abs/2405.19009) (CUHK)
- [ ] [\[2405.19074\] Resurrecting Old Classes with New Data for Exemplar-Free Continual Learning](https://arxiv.org/abs/2405.19074) (CVPR)
- [ ] [\[2405.19149\] CaLa: Complementary Association Learning for Augmenting Composed Image Retrieval](https://arxiv.org/abs/2405.19149) (XJTU)
- [ ] [\[2405.19203\] $E^{3}$Gen: Efficient, Expressive and Editable Avatars Generation](https://arxiv.org/abs/2405.19203) (SJTU)
- [ ] [\[2405.19283\] Programmable Motion Generation for Open-Set Motion Control Tasks](https://arxiv.org/abs/2405.19283) (Tsinghua, CVPR)
- [ ] [\[2405.19296\] Neural Isometries: Taming Transformations for Equivariant ML](https://arxiv.org/abs/2405.19296) (MIT)
- [ ] [\[2405.19326\] Reasoning3D -- Grounding and Reasoning in 3D: Fine-Grained Zero-Shot Open-Vocabulary 3D Reasoning Part Segmentation via Large Vision-Language Models](https://arxiv.org/abs/2405.19326) (ZJU)
- [ ] [\[2405.19333\] Multi-Modal Generative Embedding Model](https://arxiv.org/abs/2405.19333) (USTC)
- [ ] [\[2405.19424\] Diffusion Policy Attacker: Crafting Adversarial Attacks for Diffusion-based Policies](https://arxiv.org/abs/2405.19424) (GIT)
- [ ] [\[2405.19568\] Organizing Background to Explore Latent Classes for Incremental Few-shot Semantic Segmentation](https://arxiv.org/abs/2405.19568) (BUPT)
- [ ] [\[2405.19586\] SAM-E: Leveraging Visual Foundation Model with Sequence Imitation for Embodied Manipulation](https://arxiv.org/abs/2405.19586) (Shanghai AI Lab, ICML)
- [ ] [\[2405.19609\] SMPLX-Lite: A Realistic and Drivable Avatar Benchmark with Rich Geometry and Texture Annotations](https://arxiv.org/abs/2405.19609) (Tsinghua)
- [ ] [\[2405.19638\] Learning Robust Correlation with Foundation Model for Weakly-Supervised Few-Shot Segmentation](https://arxiv.org/abs/2405.19638) (BUPT)
- [ ] [\[2405.19646\] FaceLift: Semi-supervised 3D Facial Landmark Localization](https://arxiv.org/abs/2405.19646) (CVPR)
- [ ] [\[2405.19652\] Dual sparse training framework: inducing activation map sparsity via Transformed $\ell1$ regularization](https://arxiv.org/abs/2405.19652) (Xidian)
- [ ] [\[2405.19659\] CSANet: Channel Spatial Attention Network for Robust 3D Face Alignment and Reconstruction](https://arxiv.org/abs/2405.19659) (CMU)
- [ ] [\[2405.19668\] AutoBreach: Universal and Adaptive Jailbreaking with Efficient Wordplay-Guided Optimization](https://arxiv.org/abs/2405.19668) (Tsinghua)
- [ ] [\[2405.19682\] Fully Test-Time Adaptation for Monocular 3D Object Detection](https://arxiv.org/abs/2405.19682) (NTU)
- [ ] [\[2405.19688\] DNPM: A Neural Parametric Model for the Synthesis of Facial Geometric Details](https://arxiv.org/abs/2405.19688) (Xiamen)
- [ ] [\[2405.19695\] Distribution Aligned Semantics Adaption for Lifelong Person Re-Identification](https://arxiv.org/abs/2405.19695) (Fudan)
- [ ] [\[2405.19718\] LED: A Large-scale Real-world Paired Dataset for Event Camera Denoising](https://arxiv.org/abs/2405.19718) (CVPR)
- [ ] [\[2405.19727\] Automatic Dance Video Segmentation for Understanding Choreography](https://arxiv.org/abs/2405.19727) (University of Tokyo)
- [ ] [\[2405.19732\] Two Optimizers Are Better Than One: LLM Catalyst Empowers Gradient-Based Optimization for Prompt Tuning](https://arxiv.org/abs/2405.19732) (HIT)
- [ ] [\[2405.19743\] May the Dance be with You: Dance Generation Framework for Non-Humanoids](https://arxiv.org/abs/2405.19743) (NIPS)
- [ ] [\[2405.19745\] GaussianPrediction: Dynamic 3D Gaussian Prediction for Motion Extrapolation and Free View Synthesis](https://arxiv.org/abs/2405.19745) (ZJU, SIGGRAPH)
- [ ] [\[2405.19751\] HQ-DiT: Efficient Diffusion Transformer with FP4 Hybrid Quantization](https://arxiv.org/abs/2405.19751) (NYU)
- [ ] [\[2405.19765\] Towards Unified Multi-granularity Text Detection with Interactive Attention](https://arxiv.org/abs/2405.19765) (ICML)
- [ ] [\[2405.19773\] VQA Training Sets are Self-play Environments for Generating Few-shot Pools](https://arxiv.org/abs/2405.19773) (Google)
- [ ] [\[2405.19775\] Puff-Net: Efficient Style Transfer with Pure Content and Style Feature Fusion Network](https://arxiv.org/abs/2405.19775) (CVPR)
- [ ] [\[2405.19783\] Instruction-Guided Visual Masking](https://arxiv.org/abs/2405.19783) (Tsinghua)
- [ ] [\[2405.19818\] WebUOT-1M: Advancing Deep Underwater Object Tracking with A Million-Scale Benchmark](https://arxiv.org/abs/2405.19818) (HKUST(GZ))
- [ ] [\[2405.19833\] KITRO: Refining Human Mesh by 2D Clues and Kinematic-tree Rotation](https://arxiv.org/abs/2405.19833) (CVPR)
- [ ] [\[2405.19899\] Open-Set Domain Adaptation for Semantic Segmentation](https://arxiv.org/abs/2405.19899) (CVPR)
- [ ] [\[2405.19917\] Multimodal Cross-Domain Few-Shot Learning for Egocentric Action Recognition](https://arxiv.org/abs/2405.19917) (ECCV)
- [ ] [\[2405.19931\] Exploring Diffusion Models' Corruption Stage in Few-Shot Fine-tuning and Mitigating with Bayesian Neural Networks](https://arxiv.org/abs/2405.19931) (Tsinghua)
- [ ] [\[2405.19949\] Hyper-Transformer for Amodal Completion](https://arxiv.org/abs/2405.19949) (Fudan)
- [ ] [\[2405.19990\] DiffPhysBA: Diffusion-based Physical Backdoor Attack against Person Re-Identification in Real-World](https://arxiv.org/abs/2405.19990) (Microsoft)
- [ ] [\[2405.20025\] From Forest to Zoo: Great Ape Behavior Recognition with ChimpBehave](https://arxiv.org/abs/2405.20025) (Computer Vision and Pattern Recognition)
- [ ] [\[2405.20044\] A Point-Neighborhood Learning Framework for Nasal Endoscope Image Segmentation](https://arxiv.org/abs/2405.20044) (SYSU)
- [ ] [\[2405.20067\] N-Dimensional Gaussians for Fitting of High Dimensional Functions](https://arxiv.org/abs/2405.20067) (Inria)
- [ ] [\[2405.20072\] Faces of the Mind: Unveiling Mental Health States Through Facial Expressions in 11,427 Adolescents](https://arxiv.org/abs/2405.20072) (Yale)
- [ ] [\[2405.20112\] RIGID: A Training-free and Model-Agnostic Framework for Robust AI-Generated Image Detection](https://arxiv.org/abs/2405.20112) (CUHK)
- [ ] [\[2405.20141\] OpenDAS: Domain Adaptation for Open-Vocabulary Segmentation](https://arxiv.org/abs/2405.20141) (ETH)
- [ ] [\[2405.20188\] SPARE: Symmetrized Point-to-Plane Distance for Robust Non-Rigid Registration](https://arxiv.org/abs/2405.20188) (USTC)
- [ ] [\[2405.20222\] MOFA-Video: Controllable Image Animation via Generative Motion Field Adaptions in Frozen Image-to-Video Diffusion Model](https://arxiv.org/abs/2405.20222) (University of Tokyo, ECCV)
- [ ] [\[2405.20305\] Can't make an Omelette without Breaking some Eggs: Plausible Action Anticipation using Large Video-Language Models](https://arxiv.org/abs/2405.20305) (CMU, CVPR)
- [ ] [\[2405.20320\] Improving the Training of Rectified Flows](https://arxiv.org/abs/2405.20320) (CMU)
- [ ] [\[2405.20323\] $\textit{S}^3$Gaussian: Self-Supervised Street Gaussians for Autonomous Driving](https://arxiv.org/abs/2405.20323) (Peking)
- [ ] [\[2405.20324\] Don't drop your samples! Coherence-aware training benefits Conditional diffusion](https://arxiv.org/abs/2405.20324) (CVPR)
- [ ] [\[2405.20462\] Multi-Label Guided Soft Contrastive Learning for Efficient Earth Observation Pretraining](https://arxiv.org/abs/2405.20462) (TUM)
- [ ] [\[2405.20494\] Slight Corruption in Pre-training Data Makes Better Diffusion Models](https://arxiv.org/abs/2405.20494) (CMU)
- [ ] [\[2405.20584\] Disrupting Diffusion: Token-Level Attention Erasure Attack against Diffusion-based Customization](https://arxiv.org/abs/2405.20584) (ACMMM)
- [ ] [\[2405.20596\] Generalized Semi-Supervised Learning via Self-Supervised Feature Adaptation](https://arxiv.org/abs/2405.20596) (NIPS)
- [ ] [\[2405.20606\] Vision-Language Meets the Skeleton: Progressively Distillation with Cross-Modal Knowledge for 3D Action Representation Learning](https://arxiv.org/abs/2405.20606) (UESTC)
- [ ] [\[2405.20610\] Revisiting and Maximizing Temporal Knowledge in Semi-supervised Semantic Segmentation](https://arxiv.org/abs/2405.20610) (TPAMI)
- [ ] [\[2405.20648\] Shotluck Holmes: A Family of Efficient Small-Scale Large Language Vision Models For Video Captioning and Summarization](https://arxiv.org/abs/2405.20648) (GIT)
- [ ] [\[2405.20666\] MASA: Motion-aware Masked Autoencoder with Semantic Alignment for Sign Language Recognition](https://arxiv.org/abs/2405.20666) (USTC)
- [ ] [\[2405.20669\] Fourier123: One Image to High-Quality 3D Object Generation with Hybrid Fourier Score Distillation](https://arxiv.org/abs/2405.20669) (Peking)
- [ ] [\[2405.20729\] Extreme Point Supervised Instance Segmentation](https://arxiv.org/abs/2405.20729) (CVPR)
- [ ] [\[2405.20786\] Stratified Avatar Generation from Sparse Observations](https://arxiv.org/abs/2405.20786) (CVPR)
- [ ] [\[2405.20795\] InsightSee: Advancing Multi-agent Vision-Language Models for Enhanced Visual Understanding](https://arxiv.org/abs/2405.20795) (Fudan)
- [ ] [\[2405.20797\] Ovis: Structural Embedding Alignment for Multimodal Large Language Model](https://arxiv.org/abs/2405.20797) (NJU)
- [ ] [\[2405.20881\] S4Fusion: Saliency-aware Selective State Space Model for Infrared Visible Image Fusion](https://arxiv.org/abs/2405.20881) (ZJU)
- [ ] [\[2405.20980\] Neural Gaussian Scale-Space Fields](https://arxiv.org/abs/2405.20980) (MPI, SIGGRAPH)
- [ ] [\[2405.21070\] Generalization Beyond Data Imbalance: A Controlled Study on CLIP for Transferable Insights](https://arxiv.org/abs/2405.21070) (Shanghai AI Lab)
- [ ] [\[2406.00135\] Advancing Ear Biometrics: Enhancing Accuracy and Robustness through Deep Learning](https://arxiv.org/abs/2406.00135) (BU)
- [ ] [\[2406.00195\] SNED: Superposition Network Architecture Search for Efficient Video Diffusion Model](https://arxiv.org/abs/2406.00195) (CVPR)
- [ ] [\[2406.00210\] A-SDM: Accelerating Stable Diffusion through Model Assembly and Feature Inheritance Strategies](https://arxiv.org/abs/2406.00210) (Nankai)
- [ ] [\[2406.00275\] StyDeSty: Min-Max Stylization and Destylization for Single Domain Generalization](https://arxiv.org/abs/2406.00275) (NUS, ICML)
- [ ] [\[2406.00282\] Adversarial 3D Virtual Patches using Integrated Gradients](https://arxiv.org/abs/2406.00282) (Imperial)
- [ ] [\[2406.00287\] GenPalm: Contactless Palmprint Generation with Diffusion Models](https://arxiv.org/abs/2406.00287) (Michigan State University)
- [ ] [\[2406.00334\] Image Captioning via Dynamic Path Customization](https://arxiv.org/abs/2406.00334) (Xiamen)
- [ ] [\[2406.00345\] DeCoOp: Robust Prompt Tuning with Out-of-Distribution Detection](https://arxiv.org/abs/2406.00345) (NJU, ICML)
- [ ] [\[2406.00383\] SpikeMM: Flexi-Magnification of High-Speed Micro-Motions](https://arxiv.org/abs/2406.00383) (WHU)
- [ ] [\[2406.00409\] Arabic Handwritten Text for Person Biometric Identification: A Deep Learning Approach](https://arxiv.org/abs/2406.00409) (BU)
- [ ] [\[2406.00427\] You Only Need Less Attention at Each Stage in Vision Transformers](https://arxiv.org/abs/2406.00427) (Microsoft, CVPR)
- [ ] [\[2406.00429\] Towards Generalizable Multi-Object Tracking](https://arxiv.org/abs/2406.00429) (CVPR)
- [ ] [\[2406.00448\] Bilateral Guided Radiance Field Processing](https://arxiv.org/abs/2406.00448) (CUHK, SIGGRAPH)
- [ ] [\[2406.00474\] Adapting Fine-Grained Cross-View Localization to Areas without Fine Ground Truth](https://arxiv.org/abs/2406.00474) (EPFL)
- [ ] [\[2406.00480\] AlignSAM: Aligning Segment Anything Model to Open Context via Reinforcement Learning](https://arxiv.org/abs/2406.00480) (CVPR)
- [ ] [\[2406.00490\] Research on the Application of Computer Vision Based on Deep Learning in Autonomous Driving Technology](https://arxiv.org/abs/2406.00490) (Columbia University)
- [ ] [\[2406.00500\] 2nd Place Solution for PVUW Challenge 2024: Video Panoptic Segmentation](https://arxiv.org/abs/2406.00500) (CVPR)
- [ ] [\[2406.00501\] Diffusion-based Image Generation for In-distribution Data Augmentation in Surface Defect Detection](https://arxiv.org/abs/2406.00501) (ICCV)
- [ ] [\[2406.00508\] FlowIE: Efficient Image Enhancement via Rectified Flow](https://arxiv.org/abs/2406.00508) (CVPR)
- [ ] [\[2406.00510\] Learning Background Prompts to Discover Implicit Knowledge for Open Vocabulary Object Detection](https://arxiv.org/abs/2406.00510) (HKU, CVPR)
- [ ] [\[2406.00545\] Memory-guided Network with Uncertainty-based Feature Augmentation for Few-shot Semantic Segmentation](https://arxiv.org/abs/2406.00545) (Tongji)
- [ ] [\[2406.00587\] Semi-supervised Video Semantic Segmentation Using Unreliable Pseudo Labels for PVUW2024](https://arxiv.org/abs/2406.00587) (CVPR)
- [ ] [\[2406.00598\] Efficient Neural Light Fields (ENeLF) for Mobile Devices](https://arxiv.org/abs/2406.00598) (GIT)
- [ ] [\[2406.00609\] SuperGaussian: Repurposing Video Models for 3D Super Resolution](https://arxiv.org/abs/2406.00609) (ECCV)
- [ ] [\[2406.00622\] Compositional 4D Dynamic Scenes Understanding with Physics Priors for Video Question Answering](https://arxiv.org/abs/2406.00622) (Tsinghua)
- [ ] [\[2406.00625\] SAM-LAD: Segment Anything Model Meets Zero-Shot Logic Anomaly Detection](https://arxiv.org/abs/2406.00625) (Tongji)
- [ ] [\[2406.00631\] MGI: Multimodal Contrastive pre-training of Genomic and Medical Imaging](https://arxiv.org/abs/2406.00631) (NUS)
- [ ] [\[2406.00639\] An Information Compensation Framework for Zero-Shot Skeleton-based Action Recognition](https://arxiv.org/abs/2406.00639) (Xidian)
- [ ] [\[2406.00644\] Ultrasound Report Generation with Cross-Modality Feature Alignment via Unsupervised Guidance](https://arxiv.org/abs/2406.00644) (TUM)
- [ ] [\[2406.00670\] Cascade-CLIP: Cascaded Vision-Language Embeddings Alignment for Zero-Shot Semantic Segmentation](https://arxiv.org/abs/2406.00670) (Nankai, ICML)
- [ ] [\[2406.00672\] Task-oriented Embedding Counts: Heuristic Clustering-driven Feature Fine-tuning for Whole Slide Image Classification](https://arxiv.org/abs/2406.00672) (Tsinghua)
- [ ] [\[2406.00696\] Bilinear-Convolutional Neural Network Using a Matrix Similarity-based Joint Loss Function for Skin Disease Classification](https://arxiv.org/abs/2406.00696) (HUST)
- [ ] [\[2406.00699\] Towards General Robustness Verification of MaxPool-based Convolutional Neural Networks via Tightening Linear Approximation](https://arxiv.org/abs/2406.00699) (CVPR)
- [ ] [\[2406.00721\] Explore Internal and External Similarity for Single Image Deraining with Graph Neural Networks](https://arxiv.org/abs/2406.00721) (SYSU)
- [ ] [\[2406.00750\] Freeplane: Unlocking Free Lunch in Triplane-Based Sparse-View Reconstruction Models](https://arxiv.org/abs/2406.00750) (HKUST)
- [ ] [\[2406.00777\] Diffusion Features to Bridge Domain Gap for Semantic Segmentation](https://arxiv.org/abs/2406.00777) (Xiamen)
- [ ] [\[2406.00798\] PruNeRF: Segment-Centric Dataset Pruning via 3D Spatial Consistency](https://arxiv.org/abs/2406.00798) (KAIST)
- [ ] [\[2406.00808\] EchoNet-Synthetic: Privacy-preserving Video Generation for Safe Medical Data Sharing](https://arxiv.org/abs/2406.00808) (Imperial)
- [ ] [\[2406.00830\] Collaborative Novel Object Discovery and Box-Guided Cross-Modal Alignment for Open-Vocabulary 3D Object Detection](https://arxiv.org/abs/2406.00830) (TPAMI)
- [ ] [\[2406.00934\] LanEvil: Benchmarking the Robustness of Lane Detection to Environmental Illusions](https://arxiv.org/abs/2406.00934) (NTU, ACMMM)
- [ ] [\[2406.01040\] Synthetic Data Generation for 3D Myocardium Deformation Analysis](https://arxiv.org/abs/2406.01040) (Tel Aviv)
- [ ] [\[2406.01062\] Layout-Agnostic Scene Text Image Synthesis with Diffusion Models](https://arxiv.org/abs/2406.01062) (CVPR)
- [ ] [\[2406.01063\] DANCE: Dual-View Distribution Alignment for Dataset Condensation](https://arxiv.org/abs/2406.01063) (Fudan)
- [ ] [\[2406.01069\] UniQA: Unified Vision-Language Pre-training for Image Quality and Aesthetic Assessment](https://arxiv.org/abs/2406.01069) (Tsinghua)
- [ ] [\[2406.01073\] Understanding the Cross-Domain Capabilities of Video-Based Few-Shot Action Recognition Models](https://arxiv.org/abs/2406.01073) (USyd)
- [ ] [\[2406.01076\] Estimating Canopy Height at Scale](https://arxiv.org/abs/2406.01076) (ICML)
- [ ] [\[2406.01112\] BACON: Bayesian Optimal Condensation Framework for Dataset Distillation](https://arxiv.org/abs/2406.01112) (NTU)
- [ ] [\[2406.01125\] $\Delta$-DiT: A Training-Free Acceleration Method Tailored for Diffusion Transformers](https://arxiv.org/abs/2406.01125) (Fudan)
- [ ] [\[2406.01188\] UniAnimate: Taming Unified Video Diffusion Models for Consistent Human Image Animation](https://arxiv.org/abs/2406.01188) (HUST)
- [ ] [\[2406.01210\] GeminiFusion: Efficient Pixel-wise Multimodal Fusion for Vision Transformer](https://arxiv.org/abs/2406.01210) (Peking, ICML)
- [ ] [\[2406.01302\] Pulmonary Embolism Mortality Prediction Using Multimodal Learning Based on Computed Tomography Angiography and Clinical Data](https://arxiv.org/abs/2406.01302) (Xidian)
- [ ] [\[2406.01315\] Scale-Free Image Keypoints Using Differentiable Persistent Homology](https://arxiv.org/abs/2406.01315) (ICML)
- [ ] [\[2406.01316\] Enhancing Inertial Hand based HAR through Joint Representation of Language, Pose and Synthetic IMUs](https://arxiv.org/abs/2406.01316) (HKUST(GZ))
- [ ] [\[2406.01326\] TabPedia: Towards Comprehensive Visual Table Understanding with Concept Synergy](https://arxiv.org/abs/2406.01326) (USTC)
- [ ] [\[2406.01334\] HHMR: Holistic Hand Mesh Recovery by Enhancing the Multimodal Controllability of Graph Diffusion Models](https://arxiv.org/abs/2406.01334) (CVPR)
- [ ] [\[2406.01337\] ARCH2S: Dataset, Benchmark and Challenges for Learning Exterior Architectural Structures from Point Clouds](https://arxiv.org/abs/2406.01337) (CUHK)
- [ ] [\[2406.01380\] Convolutional Unscented Kalman Filter for Multi-Object Tracking with Outliers](https://arxiv.org/abs/2406.01380) (Tsinghua)
- [ ] [\[2406.01402\] Mixture of Rationale: Multi-Modal Reasoning Mixture for Visual Question Answering](https://arxiv.org/abs/2406.01402) (Microsoft)
- [ ] [\[2406.01425\] Sensitivity-Informed Augmentation for Robust Segmentation](https://arxiv.org/abs/2406.01425) (UMD)
- [ ] [\[2406.01429\] EAGLE: Efficient Adaptive Geometry-based Learning in Cross-view Understanding](https://arxiv.org/abs/2406.01429) (CMU)
- [ ] [\[2406.01432\] ED-SAM: An Efficient Diffusion Sampling Approach to Domain Generalization in Vision-Language Foundation Models](https://arxiv.org/abs/2406.01432) (CMU)
- [ ] [\[2406.01451\] SAM as the Guide: Mastering Pseudo-Label Refinement in Semi-Supervised Referring Expression Segmentation](https://arxiv.org/abs/2406.01451) (Xiamen, ICML)
- [ ] [\[2406.01460\] MLIP: Efficient Multi-Perspective Language-Image Pretraining with Exhaustive Data Utilization](https://arxiv.org/abs/2406.01460) (ICML)
- [ ] [\[2406.01480\] Towards Automating the Retrospective Generation of BIM Models: A Unified Framework for 3D Semantic Reconstruction of the Built Environment](https://arxiv.org/abs/2406.01480) (CUHK)
- [ ] [\[2406.01489\] DA-HFNet: Progressive Fine-Grained Forgery Image Detection and Localization Based on Dual Attention](https://arxiv.org/abs/2406.01489) (NUDT)
- [ ] [\[2406.01551\] ELSA: Evaluating Localization of Social Activities in Urban Streets](https://arxiv.org/abs/2406.01551) (MIT)
- [ ] [\[2406.01559\] Prototypical Transformer as Unified Motion Learners](https://arxiv.org/abs/2406.01559) (Rochester Institute of Technology)
- [ ] [\[2406.01561\] Long and Short Guidance in Score identity Distillation for One-Step Text-to-Image Generation](https://arxiv.org/abs/2406.01561) (UT Austin)
- [ ] [\[2406.01579\] Tetrahedron Splatting for 3D Generation](https://arxiv.org/abs/2406.01579) (Fudan)
- [ ] [\[2406.01583\] Decomposing and Interpreting Image Representations via Text in ViTs Beyond CLIP](https://arxiv.org/abs/2406.01583) (UMD)
- [ ] [\[2406.01592\] Text-guided Controllable Mesh Refinement for Interactive 3D Modeling](https://arxiv.org/abs/2406.01592) (SIGGRAPH)
- [ ] [\[2406.01594\] DiffUHaul: A Training-Free Method for Object Dragging in Images](https://arxiv.org/abs/2406.01594) (SIGGRAPH)
- [ ] [\[2406.01598\] D2E-An Autonomous Decision-making Dataset involving Driver States and Human Evaluation](https://arxiv.org/abs/2406.01598) (Tsinghua)
- [ ] [\[2406.01662\] Few-Shot Classification of Interactive Activities of Daily Living (InteractADL)](https://arxiv.org/abs/2406.01662) (Stanford)
- [ ] [\[2406.01820\] Finding Lottery Tickets in Vision Models via Data-driven Spectral Foresight Pruning](https://arxiv.org/abs/2406.01820) (CVPR)
- [ ] [\[2406.01843\] L-MAGIC: Language Model Assisted Generation of Images with Coherence](https://arxiv.org/abs/2406.01843) (CVPR)
- [ ] [\[2406.01884\] Rank-based No-reference Quality Assessment for Face Swapping](https://arxiv.org/abs/2406.01884) (USTC)
- [ ] [\[2406.01938\] Nutrition Estimation for Dietary Management: A Transformer Approach with Depth Sensing](https://arxiv.org/abs/2406.01938) (NVIDIA)
- [ ] [\[2406.01954\] Plug-and-Play Diffusion Distillation](https://arxiv.org/abs/2406.01954) (CVPR)
- [ ] [\[2406.01956\] Enhance Image-to-Image Generation with LLaVA Prompt and Negative Prompt](https://arxiv.org/abs/2406.01956) (Columbia University)
- [ ] [\[2406.01970\] The Crystal Ball Hypothesis in diffusion models: Anticipating object positions from initial noise](https://arxiv.org/abs/2406.01970) (UCLA)
- [ ] [\[2406.02038\] Leveraging Predicate and Triplet Learning for Scene Graph Generation](https://arxiv.org/abs/2406.02038) (CVPR)
- [ ] [\[2406.02074\] FaceCom: Towards High-fidelity 3D Facial Shape Completion via Optimization and Inpainting Guidance](https://arxiv.org/abs/2406.02074) (Peking, CVPR)
- [ ] [\[2406.02158\] Radar Spectra-Language Model for Automotive Scene Parsing](https://arxiv.org/abs/2406.02158) (Bosch)
- [ ] [\[2406.02253\] PuFace: Defending against Facial Cloaking Attacks for Facial Recognition Models](https://arxiv.org/abs/2406.02253) (HKU)
- [ ] [\[2406.02264\] Image contrast enhancement based on the Schr\"odinger operator spectrum](https://arxiv.org/abs/2406.02264) (Inria)
- [ ] [\[2406.02345\] Progressive Confident Masking Attention Network for Audio-Visual Segmentation](https://arxiv.org/abs/2406.02345) (Imperial)
- [ ] [\[2406.02355\] FedDr+: Stabilizing Dot-regression with Global Feature Distillation for Federated Learning](https://arxiv.org/abs/2406.02355) (KAIST)
- [ ] [\[2406.02385\] Low-Rank Adaption on Transformer-based Oriented Object Detector for Satellite Onboard Processing of Remote Sensing Images](https://arxiv.org/abs/2406.02385) (Fudan)
- [ ] [\[2406.02435\] Generative Active Learning for Long-tailed Instance Segmentation](https://arxiv.org/abs/2406.02435) (ZJU, ICML)
- [ ] [\[2406.02461\] RoomTex: Texturing Compositional Indoor Scenes via Iterative Inpainting](https://arxiv.org/abs/2406.02461) (Shanghai AI Lab)
- [ ] [\[2406.02462\] Learning Image Priors through Patch-based Diffusion Models for Solving Inverse Problems](https://arxiv.org/abs/2406.02462) (University of Michigan)
- [ ] [\[2406.02495\] GenS: Generalizable Neural Surface Reconstruction from Multi-View Images](https://arxiv.org/abs/2406.02495) (Peking, NIPS)
- [ ] [\[2406.02506\] An Open-Source Tool for Mapping War Destruction at Scale in Ukraine using Sentinel-1 Time Series](https://arxiv.org/abs/2406.02506) (ETH)
- [ ] [\[2406.02511\] V-Express: Conditional Dropout for Progressive Training of Portrait Video Generation](https://arxiv.org/abs/2406.02511) (NJU)
- [ ] [\[2406.02539\] Parrot: Multilingual Visual Instruction Tuning](https://arxiv.org/abs/2406.02539) (NJU)
- [ ] [\[2406.02548\] Open-YOLO 3D: Towards Fast and Accurate Open-Vocabulary 3D Instance Segmentation](https://arxiv.org/abs/2406.02548) (TUM)
- [ ] [\[2406.02706\] Window to Wall Ratio Detection using SegFormer](https://arxiv.org/abs/2406.02706) (MIT)
- [ ] [\[2406.02774\] Diffusion-Refined VQA Annotations for Semi-Supervised Gaze Following](https://arxiv.org/abs/2406.02774) (ECCV)
- [ ] [\[2406.02831\] Distilling Aggregated Knowledge for Weakly-Supervised Video Anomaly Detection](https://arxiv.org/abs/2406.02831) (CMU)
- [ ] [\[2406.02833\] DenoDet: Attention as Deformable Multi-Subspace Feature Denoising for Target Detection in SAR Images](https://arxiv.org/abs/2406.02833) (UCL)
- [ ] [\[2406.02862\] Rethinking Guidance Information to Utilize Unlabeled Samples:A Label Encoding Perspective](https://arxiv.org/abs/2406.02862) (ZJU, ICML)
- [ ] [\[2406.02881\] Inv-Adapter: ID Customization Generation via Image Inversion and Lightweight Adapter](https://arxiv.org/abs/2406.02881) (USTC)
- [ ] [\[2406.02884\] PosterLLaVa: Constructing a Unified Multi-modal Layout Generator with LLM](https://arxiv.org/abs/2406.02884) (PolyU)
- [ ] [\[2406.02915\] Visual-Text Cross Alignment: Refining the Similarity Score in Vision-Language Models](https://arxiv.org/abs/2406.02915) (ICML)
- [ ] [\[2406.02930\] P2PFormer: A Primitive-to-polygon Method for Regular Building Contour Extraction from Remote Sensing Images](https://arxiv.org/abs/2406.02930) (WHU)
- [ ] [\[2406.02951\] AVFF: Audio-Visual Feature Fusion for Video Deepfake Detection](https://arxiv.org/abs/2406.02951) (CVPR)
- [ ] [\[2406.02965\] Understanding the Impact of Negative Prompts: When and How Do They Take Effect?](https://arxiv.org/abs/2406.02965) (UCLA)
- [ ] [\[2406.02976\] DA-Flow: Dual Attention Normalizing Flow for Skeleton-based Video Anomaly Detection](https://arxiv.org/abs/2406.02976) (UESTC)
- [ ] [\[2406.02977\] Sparse Color-Code Net: Real-Time RGB-Based 6D Object Pose Estimation on Edge Devices](https://arxiv.org/abs/2406.02977) (UW)
- [ ] [\[2406.02978\] Self-Supervised Skeleton-Based Action Representation Learning: A Benchmark and Beyond](https://arxiv.org/abs/2406.02978) (Peking)
- [ ] [\[2406.02987\] Enhancing Multimodal Large Language Models with Multi-instance Visual Prompt Generator for Visual Representation Enrichment](https://arxiv.org/abs/2406.02987) (AWS)
- [ ] [\[2406.02990\] Predicting Genetic Mutation from Whole Slide Images via Biomedical-Linguistic Knowledge Enhanced Multi-label Classification](https://arxiv.org/abs/2406.02990) (Stanford)
- [ ] [\[2406.03001\] EdgeSync: Faster Edge-model Updating via Adaptive Continuous Learning for Video Data Drift](https://arxiv.org/abs/2406.03001) (XJTU)
- [ ] [\[2406.03008\] DriVLMe: Enhancing LLM-based Autonomous Driving Agents with Embodied and Social Experiences](https://arxiv.org/abs/2406.03008) (University of Michigan)
- [ ] [\[2406.03032\] Instructing Prompt-to-Prompt Generation for Zero-Shot Learning](https://arxiv.org/abs/2406.03032) (NUS)
- [ ] [\[2406.03051\] Adapter-X: A Novel General Parameter-Efficient Fine-Tuning Framework for Vision](https://arxiv.org/abs/2406.03051) (Fudan)
- [ ] [\[2406.03070\] A-Bench: Are LMMs Masters at Evaluating AI-generated Images?](https://arxiv.org/abs/2406.03070) (SJTU)
- [ ] [\[2406.03177\] FAPNet: An Effective Frequency Adaptive Point-based Eye Tracker](https://arxiv.org/abs/2406.03177) (HKUST(GZ))
- [ ] [\[2406.03215\] Searching Priors Makes Text-to-Video Synthesis Better](https://arxiv.org/abs/2406.03215) (ZJU)
- [ ] [\[2406.03250\] Prompt-based Visual Alignment for Zero-shot Policy Transfer](https://arxiv.org/abs/2406.03250) (ICML)
- [ ] [\[2406.03293\] Text-to-Image Rectified Flow as Plug-and-Play Priors](https://arxiv.org/abs/2406.03293) (NTU)
- [ ] [\[2406.03394\] Gaussian Representation for Deformable Image Registration](https://arxiv.org/abs/2406.03394) (Peking)
- [ ] [\[2406.03421\] Post-hoc Part-prototype Networks](https://arxiv.org/abs/2406.03421) (HKUST, ICML)
- [ ] [\[2406.03461\] Polarization Wavefront Lidar: Learning Large Scene Reconstruction from Polarized Wavefronts](https://arxiv.org/abs/2406.03461) (CVPR)
- [ ] [\[2406.03625\] Degrees of Freedom Matter: Inferring Dynamics from Point Trajectories](https://arxiv.org/abs/2406.03625) (CVPR)
- [ ] [\[2406.03684\] Principles of Designing Robust Remote Face Anti-Spoofing Systems](https://arxiv.org/abs/2406.03684) (AWS)
- [ ] [\[2406.03697\] Superpoint Gaussian Splatting for Real-Time High-Fidelity Dynamic Scene Reconstruction](https://arxiv.org/abs/2406.03697) (Peking, ICML)
- [ ] [\[2406.03723\] Gear-NeRF: Free-Viewpoint Rendering and Tracking with Motion-aware Spatio-Temporal Sampling](https://arxiv.org/abs/2406.03723) (HKUST, CVPR)
- [ ] [\[2406.03747\] Instance Segmentation and Teeth Classification in Panoramic X-rays](https://arxiv.org/abs/2406.03747) (Microsoft)
- [ ] [\[2406.03818\] Amortized Equation Discovery in Hybrid Dynamical Systems](https://arxiv.org/abs/2406.03818) (UVA.NL, ICML)
- [ ] [\[2406.03865\] Semantic Similarity Score for Measuring Visual Similarity at Semantic Level](https://arxiv.org/abs/2406.03865) (BUPT)
- [ ] [\[2406.03984\] LNQ Challenge 2023: Learning Mediastinal Lymph Node Segmentation with a Probabilistic Lymph Node Atlas](https://arxiv.org/abs/2406.03984) (DLR)
- [ ] [\[2406.04002\] 3rd Place Solution for PVUW Challenge 2024: Video Panoptic Segmentation](https://arxiv.org/abs/2406.04002) (CVPR)
- [ ] [\[2406.04100\] Class-Aware Cartilage Segmentation for Autonomous US-CT Registration in Robotic Intercostal Ultrasound Imaging](https://arxiv.org/abs/2406.04100) (TUM)
- [ ] [\[2406.04101\] How Far Can We Compress Instant-NGP-Based NeRF?](https://arxiv.org/abs/2406.04101) (SJTU)
- [ ] [\[2406.04129\] LenslessFace: An End-to-End Optimized Lensless System for Privacy-Preserving Face Verification](https://arxiv.org/abs/2406.04129) (CUHK)
- [ ] [\[2406.04155\] Improving Physics-Augmented Continuum Neural Radiance Field-Based Geometry-Agnostic System Identification with Lagrangian Particle Optimization](https://arxiv.org/abs/2406.04155) (CVPR)
- [ ] [\[2406.04158\] Sparse Multi-baseline SAR Cross-modal 3D Reconstruction of Vehicle Targets](https://arxiv.org/abs/2406.04158) (BIT)
- [ ] [\[2406.04178\] Encoding Semantic Priors into the Weights of Implicit Neural Representation](https://arxiv.org/abs/2406.04178) (NJU)
- [ ] [\[2406.04221\] Matching Anything by Segmenting Anything](https://arxiv.org/abs/2406.04221) (CVPR)
- [ ] [\[2406.04230\] M3LEO: A Multi-Modal, Multi-Label Earth Observation Dataset Integrating Interferometric SAR and RGB Data](https://arxiv.org/abs/2406.04230) (Cambridge)
- [ ] [\[2406.04236\] Understanding Information Storage and Transfer in Multi-modal Large Language Models](https://arxiv.org/abs/2406.04236) (UMD)
- [ ] [\[2406.04249\] Conv-INR: Convolutional Implicit Neural Representation for Multimodal Visual Signals](https://arxiv.org/abs/2406.04249) (NJU)
- [ ] [\[2406.04309\] ReFiNe: Recursive Field Networks for Cross-modal Multi-scene Representation](https://arxiv.org/abs/2406.04309) (SIGGRAPH)
- [ ] [\[2406.04312\] ReNO: Enhancing One-step Text-to-Image Models through Reward-based Noise Optimization](https://arxiv.org/abs/2406.04312) (TUM)
- [ ] [\[2406.04322\] DIRECT-3D: Learning Direct Text-to-3D Generation on Massive Noisy 3D Data](https://arxiv.org/abs/2406.04322) (CVPR)
- [ ] [\[2406.04330\] Parameter-Inverted Image Pyramid Networks](https://arxiv.org/abs/2406.04330) (Tsinghua)
- [ ] [\[2406.04332\] Coarse-To-Fine Tensor Trains for Compact Visual Representations](https://arxiv.org/abs/2406.04332) (University of Copenhagen)
- [ ] [\[2406.04339\] RoboMamba: Multimodal State Space Model for Efficient Robot Reasoning and Manipulation](https://arxiv.org/abs/2406.04339) (Peking)
- [ ] [\[2406.04340\] GLACE: Global Local Accelerated Coordinate Encoding](https://arxiv.org/abs/2406.04340) (CVPR)
- [ ] [\[2406.04342\] Learning 1D Causal Visual Representation with De-focus Attention Networks](https://arxiv.org/abs/2406.04342) (SenseTime)
- [ ] [\[2406.04343\] Flash3D: Feed-Forward Generalisable 3D Scene Reconstruction from a Single Image](https://arxiv.org/abs/2406.04343) (Oxford)
- [ ] [\[2406.04345\] Stereo-Depth Fusion through Virtual Pattern Projection](https://arxiv.org/abs/2406.04345) (ICCV)
- [ ] [\[2406.04413\] Efficient 3D-Aware Facial Image Editing via Attribute-Specific Prompt Learning](https://arxiv.org/abs/2406.04413) (ECCV)
- [ ] [\[2406.04542\] M&M VTO: Multi-Garment Virtual Try-On and Editing](https://arxiv.org/abs/2406.04542) (CVPR)
- [ ] [\[2406.04573\] Attention Fusion Reverse Distillation for Multi-Lighting Image Anomaly Detection](https://arxiv.org/abs/2406.04573) (HUST)
- [ ] [\[2406.04629\] STAR: Skeleton-aware Text-based 4D Avatar Generation with In-Network Motion Retargeting](https://arxiv.org/abs/2406.04629) (NUS)
- [ ] [\[2406.04649\] SMART: Scene-motion-aware human action recognition framework for mental disorder group](https://arxiv.org/abs/2406.04649) (SJTU)
- [ ] [\[2406.04659\] LocLLM: Exploiting Generalizable Human Keypoint Localization via Large Language Model](https://arxiv.org/abs/2406.04659) (Peking, CVPR)
- [ ] [\[2406.04673\] MeLFusion: Synthesizing Music from Image and Language Cues using Diffusion Models](https://arxiv.org/abs/2406.04673) (University of Toronto, CVPR)
- [ ] [\[2406.04675\] OVMR: Open-Vocabulary Recognition with Multi-Modal References](https://arxiv.org/abs/2406.04675) (Peking, CVPR)
- [ ] [\[2406.04765\] SMC++: Masked Learning of Unsupervised Video Semantic Compression](https://arxiv.org/abs/2406.04765) (Shanghai AI Lab)
- [ ] [\[2406.04802\] Predictive Dynamic Fusion](https://arxiv.org/abs/2406.04802) (Tianjin, ICML)
- [ ] [\[2406.04888\] Zero-Shot Video Editing through Adaptive Sliding Score Distillation](https://arxiv.org/abs/2406.04888) (NJU)
- [ ] [\[2406.04906\] RU-AI: A Large Multimodal Dataset for Machine Generated Content Detection](https://arxiv.org/abs/2406.04906) (USyd)
- [ ] [\[2406.04949\] Nacala-Roof-Material: Drone Imagery for Roof Detection, Classification, and Segmentation to Support Mosquito-borne Disease Risk Assessment](https://arxiv.org/abs/2406.04949) (University of Copenhagen)
- [ ] [\[2406.04961\] Multiplane Prior Guided Few-Shot Aerial Scene Rendering](https://arxiv.org/abs/2406.04961) (CVPR)
- [ ] [\[2406.04983\] CityCraft: A Real Crafter for 3D City Generation](https://arxiv.org/abs/2406.04983) (ZJU)
- [ ] [\[2406.05039\] Bootstrapping Referring Multi-Object Tracking](https://arxiv.org/abs/2406.05039) (WHU)
- [ ] [\[2406.05082\] CoNo: Consistency Noise Injection for Tuning-free Long Video Diffusion](https://arxiv.org/abs/2406.05082) (USTC)
- [ ] [\[2406.05120\] Contextual fusion enhances robustness to image blurring](https://arxiv.org/abs/2406.05120) (UCSD)
- [ ] [\[2406.05261\] Split-and-Fit: Learning B-Reps via Structure-Aware Voronoi Partitioning](https://arxiv.org/abs/2406.05261) (SIGGRAPH)
- [ ] [\[2406.05271\] USE: Universal Segment Embeddings for Open-Vocabulary Image Segmentation](https://arxiv.org/abs/2406.05271) (Bosch)
- [ ] [\[2406.05288\] Optimal Eye Surgeon: Finding Image Priors through Sparse Generators at Initialization](https://arxiv.org/abs/2406.05288) (Michigan State University)
- [ ] [\[2406.05477\] Attri-Net: A Globally and Locally Inherently Interpretable Model for Multi-Label Classification Using Class-Specific Counterfactuals](https://arxiv.org/abs/2406.05477) (University of TÃ¼bingen)
- [ ] [\[2406.05478\] Revisiting Non-Autoregressive Transformers for Efficient Image Synthesis](https://arxiv.org/abs/2406.05478) (CVPR)
- [ ] [\[2406.05485\] Training-Free Robust Interactive Video Object Segmentation](https://arxiv.org/abs/2406.05485) (XJTU)
- [ ] [\[2406.05491\] One Perturbation is Enough: On Generating Universal Adversarial Perturbations against Vision-Language Pre-training Models](https://arxiv.org/abs/2406.05491) (Tsinghua)
- [ ] [\[2406.05620\] Beat: Bi-directional One-to-Many Embedding Alignment for Text-based Person Retrieval](https://arxiv.org/abs/2406.05620) (Xiamen, ACMMM)
- [ ] [\[2406.05629\] Separating the "Chirp" from the "Chat": Self-supervised Visual Grounding of Sound and Language](https://arxiv.org/abs/2406.05629) (MIT, Computer Vision and Pattern Recognition)
- [ ] [\[2406.05630\] Ctrl-V: Higher Fidelity Video Generation with Bounding-Box Controlled Object Motion](https://arxiv.org/abs/2406.05630) (University of Montreal)
- [ ] [\[2406.05645\] Anomaly Multi-classification in Industrial Scenarios: Transferring Few-shot Learning to a New Task](https://arxiv.org/abs/2406.05645) (XJTU)
- [ ] [\[2406.05658\] Visual Prompt Tuning in Null Space for Continual Learning](https://arxiv.org/abs/2406.05658) (NWPU)
- [ ] [\[2406.05668\] SRC-Net: Bi-Temporal Spatial Relationship Concerned Network for Change Detection](https://arxiv.org/abs/2406.05668) (WHU)
- [ ] [\[2406.05677\] Evolution-aware VAriance (EVA) Coreset Selection for Medical Image Classification](https://arxiv.org/abs/2406.05677) (Xidian, ACM Multimedia)
- [ ] [\[2406.05691\] Diverse 3D Human Pose Generation in Scenes based on Decoupled Structure](https://arxiv.org/abs/2406.05691) (XJTU)
- [ ] [\[2406.05704\] Hierarchical Features Matter: A Deep Exploration of GAN Priors for Improved Dataset Distillation](https://arxiv.org/abs/2406.05704) (Tsinghua)
- [ ] [\[2406.05768\] MLCM: Multistep Consistency Distillation of Latent Diffusion Model](https://arxiv.org/abs/2406.05768) (SJTU)
- [ ] [\[2406.05773\] CorrMAE: Pre-training Correspondence Transformers with Masked Autoencoder](https://arxiv.org/abs/2406.05773) (WHU)
- [ ] [\[2406.05774\] VCR-GauS: View Consistent Depth-Normal Regularizer for Gaussian Surface Reconstruction](https://arxiv.org/abs/2406.05774) (NUS)
- [ ] [\[2406.05785\] A Survey on Text-guided 3D Visual Grounding: Elements, Recent Advances, and Future Directions](https://arxiv.org/abs/2406.05785) (Peking)
- [ ] [\[2406.05786\] CAMS: Convolution and Attention-Free Mamba-based Cardiac Image Segmentation](https://arxiv.org/abs/2406.05786) (UCL)
- [ ] [\[2406.05814\] Unified Text-to-Image Generation and Retrieval](https://arxiv.org/abs/2406.05814) (NTU)
- [ ] [\[2406.05821\] F-LMM: Grounding Frozen Large Multimodal Models](https://arxiv.org/abs/2406.05821) (NTU)
- [ ] [\[2406.05837\] Solution for CVPR 2024 UG2+ Challenge Track on All Weather Semantic Segmentation](https://arxiv.org/abs/2406.05837) (USTC, CVPR)
- [ ] [\[2406.05850\] Scaling Graph Convolutions for Mobile Vision](https://arxiv.org/abs/2406.05850) (UT Austin)
- [ ] [\[2406.05852\] RefGaussian: Disentangling Reflections from 3D Gaussian Splatting for Realistic Rendering](https://arxiv.org/abs/2406.05852) (Fudan)
- [ ] [\[2406.05857\] Self-supervised Adversarial Training of Monocular Depth Estimation against Physical-World Attacks](https://arxiv.org/abs/2406.05857) (Rochester Institute of Technology, ICLR)
- [ ] [\[2406.06039\] Diving into Underwater: Segment Anything Model Guided Underwater Salient Instance Segmentation and A Large-scale Dataset](https://arxiv.org/abs/2406.06039) (ICML)
- [ ] [\[2406.06040\] Vript: A Video Is Worth Thousands of Words](https://arxiv.org/abs/2406.06040) (NIPS)
- [ ] [\[2406.06044\] FRAG: Frequency Adapting Group for Diffusion Video Editing](https://arxiv.org/abs/2406.06044) (KAIST, ICML)
- [ ] [\[2406.06045\] Synthesizing Efficient Data with Diffusion Models for Person Re-Identification Pre-Training](https://arxiv.org/abs/2406.06045) (Fudan)
- [ ] [\[2406.06048\] Robust Latent Representation Tuning for Image-text Classification](https://arxiv.org/abs/2406.06048) (ZJU)
- [ ] [\[2406.06062\] ProcessPainter: Learn Painting Process from Sequence Data](https://arxiv.org/abs/2406.06062) (NUS)
- [ ] [\[2406.06072\] Adapting Pretrained ViTs with Convolution Injector for Visuo-Motor Control](https://arxiv.org/abs/2406.06072) (KAIST, ICML)
- [ ] [\[2406.06133\] ExtraNeRF: Visibility-Aware View Extrapolation of Neural Radiance Fields with Diffusion Models](https://arxiv.org/abs/2406.06133) (CVPR)
- [ ] [\[2406.06211\] iMotion-LLM: Motion Prediction Instruction Tuning](https://arxiv.org/abs/2406.06211) (Meta)
- [ ] [\[2406.06258\] Tuning-Free Visual Customization via View Iterative Self-Attention Control](https://arxiv.org/abs/2406.06258) (Tsinghua)
- [ ] [\[2406.06264\] DualAD: Disentangling the Dynamic and Static World for End-to-End Driving](https://arxiv.org/abs/2406.06264) (CVPR)
- [ ] [\[2406.06382\] Diffusion-RPO: Aligning Diffusion Models through Relative Preference Optimization](https://arxiv.org/abs/2406.06382) (Microsoft)
- [ ] [\[2406.06386\] FPN-IAIA-BL: A Multi-Scale Interpretable Deep Learning Model for Classification of Mass Margins in Digital Mammography](https://arxiv.org/abs/2406.06386) (Harvard)
- [ ] [\[2406.06462\] VCR: Visual Caption Restoration](https://arxiv.org/abs/2406.06462) (HKUST)
- [ ] [\[2406.06512\] Merlin: A Vision Language Foundation Model for 3D Computed Tomography](https://arxiv.org/abs/2406.06512) (Stanford)
- [ ] [\[2406.06517\] Genomics-guided Representation Learning for Pathologic Pan-cancer Tumor Microenvironment Subtype Prediction](https://arxiv.org/abs/2406.06517) (Tongji)
- [ ] [\[2406.06521\] PGSR: Planar-based Gaussian Splatting for Efficient and High-Fidelity Surface Reconstruction](https://arxiv.org/abs/2406.06521) (SenseTime)
- [ ] [\[2406.06612\] SEE-2-SOUND: Zero-Shot Spatial Environment-to-Spatial Sound](https://arxiv.org/abs/2406.06612) (University of Toronto)
- [ ] [\[2406.06703\] Video-based Exercise Classification and Activated Muscle Group Prediction with Hybrid X3D-SlowFast Network](https://arxiv.org/abs/2406.06703) (Oxford)
- [ ] [\[2406.06730\] TRINS: Towards Multimodal Language Models that Can Read](https://arxiv.org/abs/2406.06730) (CVPR)
- [ ] [\[2406.06796\] FlexLoc: Conditional Neural Networks for Zero-Shot Sensor Perspective Invariance in Object Localization with Distributed Multimodal Sensors](https://arxiv.org/abs/2406.06796) (UCLA)
- [ ] [\[2406.06813\] Stable Neighbor Denoising for Source-free Domain Adaptive Segmentation](https://arxiv.org/abs/2406.06813) (Computer Vision and Pattern Recognition)
- [ ] [\[2406.06820\] Adapters Strike Back](https://arxiv.org/abs/2406.06820) (CVPR)
- [ ] [\[2406.06911\] AsyncDiff: Parallelizing Diffusion Models by Asynchronous Denoising](https://arxiv.org/abs/2406.06911) (NUS)
- [ ] [\[2406.06948\] Neural Visibility Field for Uncertainty-Driven Active Mapping](https://arxiv.org/abs/2406.06948) (CVPR)
- [ ] [\[2406.06949\] Triple-domain Feature Learning with Frequency-aware Memory Enhancement for Moving Infrared Small Target Detection](https://arxiv.org/abs/2406.06949) (UESTC)
- [ ] [\[2406.06973\] RWKV-CLIP: A Robust Vision-Language Representation Learner](https://arxiv.org/abs/2406.06973) (USyd)
- [ ] [\[2406.06978\] Hydra-MDP: End-to-end Multimodal Planning with Multi-target Hydra-Distillation](https://arxiv.org/abs/2406.06978) (CVPR)
- [ ] [\[2406.07037\] PanoSSC: Exploring Monocular Panoptic 3D Scene Reconstruction for Autonomous Driving](https://arxiv.org/abs/2406.07037) (Tsinghua)
- [ ] [\[2406.07042\] EFFOcc: A Minimal Baseline for EFficient Fusion-based 3D Occupancy Network](https://arxiv.org/abs/2406.07042) (Tsinghua)
- [ ] [\[2406.07050\] DualMamba: A Lightweight Spectral-Spatial Mamba-Convolution Network for Hyperspectral Image Classification](https://arxiv.org/abs/2406.07050) (Fudan)
- [ ] [\[2406.07089\] RS-Agent: Automating Remote Sensing Tasks through Intelligent Agents](https://arxiv.org/abs/2406.07089) (BUPT)
- [ ] [\[2406.07111\] NeRSP: Neural 3D Reconstruction for Reflective Objects with Sparse Polarized Images](https://arxiv.org/abs/2406.07111) (Peking)
- [ ] [\[2406.07146\] Benchmarking and Boosting Radiology Report Generation for 3D High-Resolution Medical Images](https://arxiv.org/abs/2406.07146) (Imperial)
- [ ] [\[2406.07170\] VoxNeuS: Enhancing Voxel-Based Neural Surface Reconstruction via Gradient Interpolation](https://arxiv.org/abs/2406.07170) (NUDT)
- [ ] [\[2406.07176\] RAD: A Comprehensive Dataset for Benchmarking the Robustness of Image Anomaly Detection](https://arxiv.org/abs/2406.07176) (HUST)
- [ ] [\[2406.07221\] Open-World Human-Object Interaction Detection via Multi-modal Prompts](https://arxiv.org/abs/2406.07221) (CVPR)
- [ ] [\[2406.07230\] Needle In A Multimodal Haystack](https://arxiv.org/abs/2406.07230) (Shanghai AI Lab)
- [ ] [\[2406.07284\] Unsupervised Object Detection with Theoretical Guarantees](https://arxiv.org/abs/2406.07284) (Oxford)
- [ ] [\[2406.07320\] A Framework for Efficient Model Evaluation through Stratification, Sampling, and Estimation](https://arxiv.org/abs/2406.07320) (AWS, ECCV)
- [ ] [\[2406.07333\] Global-Regularized Neighborhood Regression for Efficient Zero-Shot Texture Anomaly Detection](https://arxiv.org/abs/2406.07333) (HUST)
- [ ] [\[2406.07398\] Visual Representation Learning with Stochastic Frame Prediction](https://arxiv.org/abs/2406.07398) (KAIST, ICML)
- [ ] [\[2406.07471\] OphNet: A Large-Scale Video Benchmark for Ophthalmic Surgical Workflow Understanding](https://arxiv.org/abs/2406.07471) (ECCV)
- [ ] [\[2406.07487\] GLAD: Towards Better Reconstruction with Global and Local Adaptive Diffusion Models for Unsupervised Anomaly Detection](https://arxiv.org/abs/2406.07487) (ECCV)
- [ ] [\[2406.07502\] Image Textualization: An Automatic Framework for Creating Accurate and Detailed Image Descriptions](https://arxiv.org/abs/2406.07502) (WHU)
- [ ] [\[2406.07506\] Understanding Visual Concepts Across Models](https://arxiv.org/abs/2406.07506) (CMU)
- [ ] [\[2406.07543\] Vision Model Pre-training on Interleaved Image-Text Data via Latent Compression Learning](https://arxiv.org/abs/2406.07543) (XJTU)
- [ ] [\[2406.07544\] Situational Awareness Matters in 3D Vision Language Reasoning](https://arxiv.org/abs/2406.07544) (CVPR)
- [ ] [\[2406.07548\] Image and Video Tokenization with Binary Spherical Quantization](https://arxiv.org/abs/2406.07548) (UT Austin)
