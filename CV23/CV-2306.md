- [ ] [\[2309.01296\] EMR-MSF: Self-Supervised Recurrent Monocular Scene Flow Exploiting Ego-Motion Rigidity](https://arxiv.org/abs/2309.01296) (ICCV)
- [ ] [\[2309.01327\] Can I Trust Your Answer? Visually Grounded Video Question Answering](https://arxiv.org/abs/2309.01327) (CVPR)
- [ ] [\[2309.01351\] Adv3D: Generating 3D Adversarial Examples for 3D Object Detection in Driving Scenarios with NeRF](https://arxiv.org/abs/2309.01351) (HKUST(GZ))
- [ ] [\[2309.01365\] Refined Temporal Pyramidal Compression-and-Amplification Transformer for 3D Human Pose Estimation](https://arxiv.org/abs/2309.01365) (Tsinghua)
- [ ] [\[2309.01374\] ImmersiveNeRF: Hybrid Radiance Fields for Unbounded Immersive Light Field Reconstruction](https://arxiv.org/abs/2309.01374) (Tsinghua)
- [ ] [\[2309.01377\] Memory augment is All You Need for image restoration](https://arxiv.org/abs/2309.01377) (Tianjin)
- [ ] [\[2309.01390\] Bridging the Projection Gap: Overcoming Projection Bias Through Parameterized Distance Learning](https://arxiv.org/abs/2309.01390) (Oxford)
- [ ] [\[2309.01391\] SSVOD: Semi-Supervised Video Object Detection with Sparse Annotations](https://arxiv.org/abs/2309.01391) (AWS)
- [ ] [\[2309.01420\] Unified Pre-training with Pseudo Texts for Text-To-Image Person Re-identification](https://arxiv.org/abs/2309.01420) (ICCV)
- [ ] [\[2309.01429\] Adapting Segment Anything Model for Change Detection in HR Remote Sensing Images](https://arxiv.org/abs/2309.01429) (WHU)
- [ ] [\[2309.01430\] DAT++: Spatially Dynamic Vision Transformer with Deformable Attention](https://arxiv.org/abs/2309.01430) (Tsinghua)
- [ ] [\[2309.01479\] Parameter and Computation Efficient Transfer Learning for Vision-Language Pre-trained Models](https://arxiv.org/abs/2309.01479) (Xiamen)
- [ ] [\[2309.01483\] CA2: Class-Agnostic Adaptive Feature Adaptation for One-class Classification](https://arxiv.org/abs/2309.01483) (XJTU)
- [ ] [\[2309.01488\] On the use of Mahalanobis distance for out-of-distribution detection with neural networks for medical imaging](https://arxiv.org/abs/2309.01488) (Oxford)
- [ ] [\[2309.01512\] Neural Vector Fields: Generalizing Distance Vector Fields by Codebooks and Zero-Curl Regularization](https://arxiv.org/abs/2309.01512) (USyd)
- [ ] [\[2309.01539\] TSTTC: A Large-Scale Dataset for Time-to-Contact Estimation in Driving Scenarios](https://arxiv.org/abs/2309.01539) (Tianjin)
- [ ] [\[2309.01582\] Improving Visual Quality and Transferability of Adversarial Attacks on Face Recognition Simultaneously with Adversarial Restoration](https://arxiv.org/abs/2309.01582) (HUST)
- [ ] [\[2309.01624\] AGG-Net: Attention Guided Gated-convolutional Network for Depth Image Completion](https://arxiv.org/abs/2309.01624) (ICCV)
- [ ] [\[2309.01656\] Building Footprint Extraction in Dense Areas using Super Resolution and Frame Field Learning](https://arxiv.org/abs/2309.01656) (NTU)
- [ ] [\[2309.01692\] Mask-Attention-Free Transformer for 3D Instance Segmentation](https://arxiv.org/abs/2309.01692) (ICCV)
- [ ] [\[2309.01782\] 3D View Prediction Models of the Dorsal Visual Stream](https://arxiv.org/abs/2309.01782) (CMU)
- [ ] [\[2309.01793\] Neural-Singular-Hessian: Implicit Neural Representation of Unoriented Point Clouds by Enforcing Singular Hessian](https://arxiv.org/abs/2309.01793) (BU)
- [ ] [\[2309.01850\] Uncertainty in AI: Evaluating Deep Neural Networks on Out-of-Distribution Images](https://arxiv.org/abs/2309.01850) (UCL)
- [ ] [\[2309.01858\] Towards Universal Image Embeddings: A Large-Scale Dataset and Challenge for Generic Image Representations](https://arxiv.org/abs/2309.01858) (Google, ICCV)
- [ ] [\[2309.01899\] Unsupervised Skin Lesion Segmentation via Structural Entropy Minimization on Multi-Scale Superpixel Graphs](https://arxiv.org/abs/2309.01899) (Salesforce)
- [ ] [\[2309.01907\] SyntheWorld: A Large-Scale Synthetic Dataset for Land Cover Mapping and Building Change Detection](https://arxiv.org/abs/2309.01907) (University of Tokyo)
- [ ] [\[2309.01925\] DR-Pose: A Two-stage Deformation-and-Registration Pipeline for Category-level 6D Object Pose Estimation](https://arxiv.org/abs/2309.01925) (NUS)
- [ ] [\[2309.01943\] Extract-and-Adaptation Network for 3D Interacting Hand Mesh Recovery](https://arxiv.org/abs/2309.01943) (Meta)
- [ ] [\[2309.01949\] Variational Bayesian Imaging with an Efficient Surrogate Score-based Prior](https://arxiv.org/abs/2309.01949) (Caltech)
- [ ] [\[2309.01958\] Empowering Low-Light Image Enhancer through Customized Learnable Priors](https://arxiv.org/abs/2309.01958) (USTC, ICCV)
- [ ] [\[2309.02041\] Learning Cross-Modal Affinity for Referring Video Object Segmentation Targeting Limited Samples](https://arxiv.org/abs/2309.02041) (ICCV)
- [ ] [\[2309.02054\] An Adaptive Spatial-Temporal Local Feature Difference Method for Infrared Small-moving Target Detection](https://arxiv.org/abs/2309.02054) (BUPT)
- [ ] [\[2309.02102\] Iterative Superquadric Recomposition of 3D Objects from Multiple Views](https://arxiv.org/abs/2309.02102) (ICCV)
- [ ] [\[2309.02119\] Hierarchical Masked 3D Diffusion Model for Video Outpainting](https://arxiv.org/abs/2309.02119) (ICT CAS, ACMMM)
- [ ] [\[2309.02120\] Multi-label affordance mapping from egocentric vision](https://arxiv.org/abs/2309.02120) (ICCV)
- [ ] [\[2309.02155\] S3C: Semi-Supervised VQA Natural Language Explanation via Self-Critical Learning](https://arxiv.org/abs/2309.02155) (CVPR)
- [ ] [\[2309.02185\] BEVTrack: A Simple and Strong Baseline for 3D Single Object Tracking in Bird's-Eye View](https://arxiv.org/abs/2309.02185) (USyd)
- [ ] [\[2309.02186\] AniPortraitGAN: Animatable 3D Portrait Generation from 2D Image Collections](https://arxiv.org/abs/2309.02186) (SIGGRAPH)
- [ ] [\[2309.02218\] Robustness and Generalizability of Deepfake Detection: A Study with Diffusion Models](https://arxiv.org/abs/2309.02218) (Tsinghua)
- [ ] [\[2309.02224\] Dense Object Grounding in 3D Scenes](https://arxiv.org/abs/2309.02224) (Peking, ACMMM)
- [ ] [\[2309.02230\] DCP-Net: A Distributed Collaborative Perception Network for Remote Sensing Semantic Segmentation](https://arxiv.org/abs/2309.02230) (UCAS)
- [ ] [\[2309.02290\] ATM: Action Temporality Modeling for Video Question Answering](https://arxiv.org/abs/2309.02290) (Michigan State University)
- [ ] [\[2309.02318\] TiAVox: Time-aware Attenuation Voxels for Sparse-view 4D DSA Reconstruction](https://arxiv.org/abs/2309.02318) (HUST)
- [ ] [\[2309.02401\] Prototype-based Dataset Comparison](https://arxiv.org/abs/2309.02401) (UVA.NL, ICCV)
- [ ] [\[2309.02405\] Generating Realistic Images from In-the-wild Sounds](https://arxiv.org/abs/2309.02405) (ICCV)
- [ ] [\[2309.02420\] Doppelgangers: Learning to Disambiguate Images of Similar Structures](https://arxiv.org/abs/2309.02420) (ICCV)
- [ ] [\[2309.02423\] EgoPCA: A New Framework for Egocentric Hand-Object Interaction Understanding](https://arxiv.org/abs/2309.02423) (HKUST, ICCV)
- [ ] [\[2309.02429\] Building a Winning Team: Selecting Source Model Ensembles using a Submodular Transferability Estimation Approach](https://arxiv.org/abs/2309.02429) (ICCV)
- [ ] [\[2309.02434\] ReliTalk: Relightable Talking Portrait Generation from a Single Video](https://arxiv.org/abs/2309.02434) (NTU)
- [ ] [\[2309.02436\] GO-SLAM: Global Optimization for Consistent 3D Instant Reconstruction](https://arxiv.org/abs/2309.02436) (ICCV)
- [ ] [\[2309.02527\] A skeletonization algorithm for gradient-based optimization](https://arxiv.org/abs/2309.02527) (ICCV)
- [ ] [\[2309.02578\] Anatomy-Driven Pathology Detection on Chest X-rays](https://arxiv.org/abs/2309.02578) (TUM)
- [ ] [\[2309.02713\] SlAction: Non-intrusive, Lightweight Obstructive Sleep Apnea Detection using Infrared Video](https://arxiv.org/abs/2309.02713) (Columbia University, ICCV)
- [ ] [\[2309.02742\] MLN-net: A multi-source medical image segmentation method for clustered microcalcifications using multiple layer normalization](https://arxiv.org/abs/2309.02742) (ZJU)
- [ ] [\[2309.02777\] LightNeuS: Neural Surface Reconstruction in Endoscopy using Illumination Decline](https://arxiv.org/abs/2309.02777) (EPFL)
- [ ] [\[2309.02833\] Image-Object-Specific Prompt Learning for Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2309.02833) (KAIST)
- [ ] [\[2309.02875\] MAD: Modality Agnostic Distance Measure for Image Registration](https://arxiv.org/abs/2309.02875) (Imperial)
- [ ] [\[2309.02923\] Patched Line Segment Learning for Vector Road Mapping](https://arxiv.org/abs/2309.02923) (Google)
- [ ] [\[2309.02965\] Dynamic Hyperbolic Attention Network for Fine Hand-object Reconstruction](https://arxiv.org/abs/2309.02965) (TUM, ICCV)
- [ ] [\[2309.02999\] Vote2Cap-DETR++: Decoupling Localization and Describing for End-to-End 3D Dense Captioning](https://arxiv.org/abs/2309.02999) (Fudan)
- [ ] [\[2309.03020\] SEAL: A Framework for Systematic Evaluation of Real-World Super-Resolution](https://arxiv.org/abs/2309.03020) (SJTU, ICLR)
- [ ] [\[2309.03160\] ResFields: Residual Neural Fields for Spatiotemporal Signals](https://arxiv.org/abs/2309.03160) (ICLR)
- [ ] [\[2309.03173\] PDiscoNet: Semantically consistent part discovery for fine-grained recognition](https://arxiv.org/abs/2309.03173) (ICCV)
- [ ] [\[2309.03331\] Expert Uncertainty and Severity Aware Chest X-Ray Classification by Multi-Relationship Graph Learning](https://arxiv.org/abs/2309.03331) (University of Tokyo)
- [ ] [\[2309.03406\] Distribution-Aware Prompt Tuning for Vision-Language Models](https://arxiv.org/abs/2309.03406) (ICCV)
- [ ] [\[2309.03453\] SyncDreamer: Generating Multiview-consistent Images from a Single-view Image](https://arxiv.org/abs/2309.03453) (ICLR)
- [ ] [\[2309.03467\] Autoregressive Omni-Aware Outpainting for Open-Vocabulary 360-Degree Image Generation](https://arxiv.org/abs/2309.03467) (USyd)
- [ ] [\[2309.03472\] Perceptual Quality Assessment of 360$^\circ$ Images Based on Generative Scanpath Representation](https://arxiv.org/abs/2309.03472) (NTU)
- [ ] [\[2309.03473\] Temporal Collection and Distribution for Referring Video Object Segmentation](https://arxiv.org/abs/2309.03473) (ICCV)
- [ ] [\[2309.03483\] DetermiNet: A Large-Scale Diagnostic Dataset for Complex Visually-Grounded Referencing using Determiners](https://arxiv.org/abs/2309.03483) (A*STAR,)
- [ ] [\[2309.03504\] Stroke-based Neural Painting and Stylization with Dynamically Predicted Painting Region](https://arxiv.org/abs/2309.03504) (SJTU, ACMMM)
- [ ] [\[2309.03508\] Dynamic Frame Interpolation in Wavelet Domain](https://arxiv.org/abs/2309.03508) (SJTU, TIP)
- [ ] [\[2309.03539\] YOLO series target detection algorithms for underwater environments](https://arxiv.org/abs/2309.03539) (ZJU)
- [ ] [\[2309.03549\] Reuse and Diffuse: Iterative Denoising for Text-to-Video Generation](https://arxiv.org/abs/2309.03549) (Fudan)
- [ ] [\[2309.03575\] Toward High Quality Facial Representation Learning](https://arxiv.org/abs/2309.03575) (SJTU, ACMMM)
- [ ] [\[2309.03576\] DropPos: Pre-Training Vision Transformers by Reconstructing Dropped Positions](https://arxiv.org/abs/2309.03576) (NIPS)
- [ ] [\[2309.03598\] Enhancing Sample Utilization through Sample Adaptive Augmentation in Semi-Supervised Learning](https://arxiv.org/abs/2309.03598) (NJU, ICCV)
- [ ] [\[2309.03671\] Dataset Generation and Bonobo Classification from Weakly Labelled Videos](https://arxiv.org/abs/2309.03671) (MPI)
- [ ] [\[2309.03722\] A boundary-aware point clustering approach in Euclidean and embedding spaces for roof plane segmentation](https://arxiv.org/abs/2309.03722) (WHU)
- [ ] [\[2309.03726\] Interpretable Visual Question Answering via Reasoning Supervision](https://arxiv.org/abs/2309.03726) (ETH)
- [ ] [\[2309.03729\] Phasic Content Fusing Diffusion Model with Directional Distribution Consistency for Few-Shot Model Adaption](https://arxiv.org/abs/2309.03729) (ICCV)
- [ ] [\[2309.03809\] SimNP: Learning Self-Similarity Priors Between Neural Points](https://arxiv.org/abs/2309.03809) (ICCV)
- [ ] [\[2309.03811\] Panoramas from Photons](https://arxiv.org/abs/2309.03811) (ICCV)
- [ ] [\[2309.03815\] T2IW: Joint Text to Image & Watermark Generation](https://arxiv.org/abs/2309.03815) (Tianjin)
- [ ] [\[2309.03874\] Box-based Refinement for Weakly Supervised and Unsupervised Localization Tasks](https://arxiv.org/abs/2309.03874) (Tel Aviv)
- [ ] [\[2309.03897\] ProPainter: Improving Propagation and Transformer for Video Inpainting](https://arxiv.org/abs/2309.03897) (ICCV)
- [ ] [\[2309.03899\] The Making and Breaking of Camouflage](https://arxiv.org/abs/2309.03899) (ICCV)
- [ ] [\[2309.03903\] Tracking Anything with Decoupled Video Segmentation](https://arxiv.org/abs/2309.03903) (ICCV)
- [ ] [\[2309.03930\] Random Expert Sampling for Deep Learning Segmentation of Acute Ischemic Stroke on Non-contrast CT](https://arxiv.org/abs/2309.03930) (Stanford)
- [ ] [\[2309.03933\] BluNF: Blueprint Neural Field](https://arxiv.org/abs/2309.03933) (ICCV)
- [ ] [\[2309.03955\] SimpleNeRF: Regularizing Sparse Input Neural Radiance Fields with Simpler Solutions](https://arxiv.org/abs/2309.03955) (SIGGRAPH)
- [ ] [\[2309.03989\] CDFSL-V: Cross-Domain Few-Shot Learning for Videos](https://arxiv.org/abs/2309.03989) (ICCV)
- [ ] [\[2309.03999\] Adapting Self-Supervised Representations to Multi-Domain Setups](https://arxiv.org/abs/2309.03999) (UMD)
- [ ] [\[2309.04038\] S-Adapter: Generalizing Vision Transformer for Face Anti-Spoofing with Statistical Tokens](https://arxiv.org/abs/2309.04038) (BU)
- [ ] [\[2309.04109\] From Text to Mask: Localizing Entities Using the Attention of Text-to-Image Diffusion Models](https://arxiv.org/abs/2309.04109) (Tsinghua)
- [ ] [\[2309.04145\] Depth Completion with Multiple Balanced Bases and Confidence for Dense Monocular SLAM](https://arxiv.org/abs/2309.04145) (SenseTime)
- [ ] [\[2309.04158\] Context-Aware Prompt Tuning for Vision-Language Model with Dual-Alignment](https://arxiv.org/abs/2309.04158) (SJTU)
- [ ] [\[2309.04172\] Unsupervised Object Localization with Representer Point Selection](https://arxiv.org/abs/2309.04172) (MIT, ICCV)
- [ ] [\[2309.04220\] Score-PA: Score-based 3D Part Assembly](https://arxiv.org/abs/2309.04220) (Imperial)
- [ ] [\[2309.04247\] Towards Practical Capture of High-Fidelity Relightable Avatars](https://arxiv.org/abs/2309.04247) (SIGGRAPH)
- [ ] [\[2309.04410\] DeformToon3D: Deformable 3D Toonification from Neural Radiance Fields](https://arxiv.org/abs/2309.04410) (ICCV)
- [ ] [\[2309.04422\] Video Task Decathlon: Unifying Image and Video Tasks in Autonomous Driving](https://arxiv.org/abs/2309.04422) (ICCV)
- [ ] [\[2309.04437\] Single View Refractive Index Tomography with Neural Fields](https://arxiv.org/abs/2309.04437) (Caltech)
- [ ] [\[2309.04502\] On the Efficacy of Multi-scale Data Samplers for Vision Applications](https://arxiv.org/abs/2309.04502) (UCLA)
- [ ] [\[2309.04542\] Examining Autoexposure for Challenging Scenes](https://arxiv.org/abs/2309.04542) (ICCV)
- [ ] [\[2309.04549\] Poster: Making Edge-assisted LiDAR Perceptions Robust to Lossy Point Cloud Compression](https://arxiv.org/abs/2309.04549) (GIT)
- [ ] [\[2309.04561\] Four Ways to Improve Verbo-visual Fusion for Dense 3D Visual Grounding](https://arxiv.org/abs/2309.04561) (ECCV)
- [ ] [\[2309.04659\] Progressive Feature Adjustment for Semi-supervised Learning from Pretrained Models](https://arxiv.org/abs/2309.04659) (ZJU)
- [ ] [\[2309.04669\] Unified Language-Vision Pretraining in LLM with Dynamic Discrete Visual Tokenization](https://arxiv.org/abs/2309.04669) (Peking, ICLR)
- [ ] [\[2309.04682\] DeNoising-MOT: Towards Multiple Object Tracking with Severe Occlusions](https://arxiv.org/abs/2309.04682) (Fudan, ACMMM)
- [ ] [\[2309.04702\] A Spatial-Temporal Deformable Attention based Framework for Breast Lesion Detection in Videos](https://arxiv.org/abs/2309.04702) (MBZUAI)
- [ ] [\[2309.04723\] Frequency-Aware Self-Supervised Long-Tailed Learning](https://arxiv.org/abs/2309.04723) (NVIDIA)
- [ ] [\[2309.04734\] Towards Better Multi-modal Keyphrase Generation via Visual Entity Enhancement and Multi-granularity Image Noise Filtering](https://arxiv.org/abs/2309.04734) (Xiamen, ACMMM)
- [ ] [\[2309.04747\] When to Learn What: Model-Adaptive Data Augmentation Curriculum](https://arxiv.org/abs/2309.04747) (UMD, ICCV)
- [ ] [\[2309.04752\] Deep Video Restoration for Under-Display Camera](https://arxiv.org/abs/2309.04752) (NJU)
- [ ] [\[2309.04795\] Self-Supervised Transformer with Domain Adaptive Reconstruction for General Face Forgery Video Detection](https://arxiv.org/abs/2309.04795) (Tsinghua)
- [ ] [\[2309.04803\] Towards Real-World Burst Image Super-Resolution: Benchmark and Method](https://arxiv.org/abs/2309.04803) (SYSU, ICCV)
- [ ] [\[2309.04806\] Timely Fusion of Surround Radar/Lidar for Object Detection in Autonomous Driving Systems](https://arxiv.org/abs/2309.04806) (Yale)
- [ ] [\[2309.04891\] How to Evaluate Semantic Communications for Images with ViTScore Metric?](https://arxiv.org/abs/2309.04891) (SYSU)
- [ ] [\[2309.04907\] Effective Real Image Editing with Accelerated Iterative Diffusion Inversion](https://arxiv.org/abs/2309.04907) (ICCV)
- [ ] [\[2309.05049\] Multi-view Self-supervised Disentanglement for General Image Denoising](https://arxiv.org/abs/2309.05049) (ICCV)
- [ ] [\[2309.05073\] FreeMan: Towards Benchmarking 3D Human Pose Estimation under Real-World Conditions](https://arxiv.org/abs/2309.05073) (CVPR)
- [ ] [\[2309.05090\] Sculpting Efficiency: Pruning Medical Imaging Models for On-Device Inference](https://arxiv.org/abs/2309.05090) (Imperial, NIPS)
- [ ] [\[2309.05095\] MaskRenderer: 3D-Infused Multi-Mask Realistic Face Reenactment](https://arxiv.org/abs/2309.05095) (University of Toronto)
- [ ] [\[2309.05098\] 3D Implicit Transporter for Temporally Consistent Keypoint Discovery](https://arxiv.org/abs/2309.05098) (Tsinghua, ICCV)
- [ ] [\[2309.05139\] A Skeleton-based Approach For Rock Crack Detection Towards A Climbing Robot Application](https://arxiv.org/abs/2309.05139) (Stanford)
- [ ] [\[2309.05148\] Beyond Skin Tone: A Multidimensional Measure of Apparent Skin Color](https://arxiv.org/abs/2309.05148) (ICCV)
- [ ] [\[2309.05150\] Faster, Lighter, More Accurate: A Deep Learning Ensemble for Content Moderation](https://arxiv.org/abs/2309.05150) (Illinois, ICML)
- [ ] [\[2309.05192\] Towards Viewpoint Robustness in Bird's Eye View Segmentation](https://arxiv.org/abs/2309.05192) (NVIDIA, ICCV)
- [ ] [\[2309.05209\] Phase-Specific Augmented Reality Guidance for Microscopic Cataract Surgery Using Long-Short Spatiotemporal Aggregation Transformer](https://arxiv.org/abs/2309.05209) (SJTU)
- [ ] [\[2309.05214\] Angle Range and Identity Similarity Enhanced Gaze and Head Redirection based on Synthetic data](https://arxiv.org/abs/2309.05214) (University of Tokyo)
- [ ] [\[2309.05251\] Multi3DRefer: Grounding Text Description to Multiple 3D Objects](https://arxiv.org/abs/2309.05251) (ICCV)
- [ ] [\[2309.05254\] Towards Better Data Exploitation in Self-Supervised Monocular Depth Estimation](https://arxiv.org/abs/2309.05254) (SJTU)
- [ ] [\[2309.05281\] Class-Incremental Grouping Network for Continual Audio-Visual Learning](https://arxiv.org/abs/2309.05281) (ICCV)
- [ ] [\[2309.05300\] Decoupling Common and Unique Representations for Multimodal Self-supervised Learning](https://arxiv.org/abs/2309.05300) (ECCV)
- [ ] [\[2309.05330\] Diff-Privacy: Diffusion-based Face Privacy Protection](https://arxiv.org/abs/2309.05330) (Xidian)
- [ ] [\[2309.05448\] Panoptic Vision-Language Feature Fields](https://arxiv.org/abs/2309.05448) (ETH)
- [ ] [\[2309.05499\] Zero-Shot Co-salient Object Detection Framework](https://arxiv.org/abs/2309.05499) (Xiamen)
- [ ] [\[2309.05517\] Stream-based Active Learning by Exploiting Temporal Properties in Perception with Temporal Predicted Loss](https://arxiv.org/abs/2309.05517) (TUM)
- [ ] [\[2309.05527\] ReSimAD: Zero-Shot 3D Domain Transfer for Autonomous Driving with Source Reconstruction and Target Simulation](https://arxiv.org/abs/2309.05527) (ICLR)
- [ ] [\[2309.05569\] ITI-GEN: Inclusive Text-to-Image Generation](https://arxiv.org/abs/2309.05569) (ICCV)
- [ ] [\[2309.05573\] UniSeg: A Unified Multi-Modal LiDAR Segmentation Network and the OpenPCSeg Codebase](https://arxiv.org/abs/2309.05573) (ICCV)
- [ ] [\[2309.05590\] Temporal Action Localization with Enhanced Instant Discriminability](https://arxiv.org/abs/2309.05590) (CVPR)
- [ ] [\[2309.05613\] Learning the Geodesic Embedding with Graph Neural Networks](https://arxiv.org/abs/2309.05613) (Peking, SIGGRAPH)
- [ ] [\[2309.05652\] An Effective Two-stage Training Paradigm Detector for Small Dataset](https://arxiv.org/abs/2309.05652) (Yale)
- [ ] [\[2309.05663\] Diffusion-Guided Reconstruction of Everyday Hand-Object Interaction Clips](https://arxiv.org/abs/2309.05663) (ICCV)
- [ ] [\[2309.05809\] Divergences in Color Perception between Deep Neural Networks and Humans](https://arxiv.org/abs/2309.05809) (Berkeley)
- [ ] [\[2309.05810\] SHIFT3D: Synthesizing Hard Inputs For Tricking 3D Detectors](https://arxiv.org/abs/2309.05810) (ICCV)
- [ ] [\[2309.05911\] Quality-Agnostic Deepfake Detection with Intra-model Collaborative Learning](https://arxiv.org/abs/2309.05911) (Sungkyunkwan University)
- [ ] [\[2309.05956\] Beyond Generation: Harnessing Text to Image Models for Object Detection and Segmentation](https://arxiv.org/abs/2309.05956) (Harvard)
- [ ] [\[2309.05994\] ATTA: Anomaly-aware Test-Time Adaptation for Out-of-Distribution Detection in Segmentation](https://arxiv.org/abs/2309.05994) (NIPS)
- [ ] [\[2309.06004\] TSSAT: Two-Stage Statistics-Aware Transformation for Artistic Style Transfer](https://arxiv.org/abs/2309.06004) (ZJU, ACMMM)
- [ ] [\[2309.06047\] Real-Time Semantic Segmentation: A Brief Survey & Comparative Study in Remote Sensing](https://arxiv.org/abs/2309.06047) (University of Tokyo)
- [ ] [\[2309.06105\] Towards Visual Taxonomy Expansion](https://arxiv.org/abs/2309.06105) (Fudan, ACMMM)
- [ ] [\[2309.06142\] Towards Reliable Domain Generalization: A New Dataset and Evaluations](https://arxiv.org/abs/2309.06142) (IA CAS)
- [ ] [\[2309.06159\] Active Label Refinement for Semantic Segmentation of Satellite Images](https://arxiv.org/abs/2309.06159) (DLR)
- [ ] [\[2309.06199\] SCP: Scene Completion Pre-training for 3D Object Detection](https://arxiv.org/abs/2309.06199) (ISPRS)
- [ ] [\[2309.06202\] Fast Sparse PCA via Positive Semidefinite Projection for Unsupervised Feature Selection](https://arxiv.org/abs/2309.06202) (NUDT)
- [ ] [\[2309.06219\] Human Action Co-occurrence in Lifestyle Vlogs using Graph Link Prediction](https://arxiv.org/abs/2309.06219) (University of Michigan)
- [ ] [\[2309.06255\] Enhancing multimodal cooperation via sample-level modality valuation](https://arxiv.org/abs/2309.06255) (CVPR)
- [ ] [\[2309.06262\] Modality Unifying Network for Visible-Infrared Person Re-Identification](https://arxiv.org/abs/2309.06262) (Stanford, ICCV)
- [ ] [\[2309.06284\] Fg-T2M: Fine-Grained Text-Driven Human Motion Generation via Diffusion Model](https://arxiv.org/abs/2309.06284) (TUM)
- [ ] [\[2309.06337\] Exploring Flat Minima for Domain Generalization with Large Learning Rates](https://arxiv.org/abs/2309.06337) (NJU)
- [ ] [\[2309.06438\] Exploring Non-additive Randomness on ViT against Query-Based Black-Box Attacks](https://arxiv.org/abs/2309.06438) (Microsoft)
- [ ] [\[2309.06581\] Zero-Shot Visual Classification with Guided Cropping](https://arxiv.org/abs/2309.06581) (Bosch)
- [ ] [\[2309.06703\] VLSlice: Interactive Vision-and-Language Slice Discovery](https://arxiv.org/abs/2309.06703) (Google, ICCV)
- [ ] [\[2309.06714\] MPI-Flow: Learning Realistic Optical Flow with Multiplane Images](https://arxiv.org/abs/2309.06714) (BIT, ICCV)
- [ ] [\[2309.06735\] GelFlow: Self-supervised Learning of Optical Flow for Vision-Based Tactile Sensor Displacement Measurement](https://arxiv.org/abs/2309.06735) (HUST)
- [ ] [\[2309.06745\] VEATIC: Video-based Emotion and Affect Tracking in Context Dataset](https://arxiv.org/abs/2309.06745) (University of Michigan)
- [ ] [\[2309.06747\] Integrating GAN and Texture Synthesis for Enhanced Road Damage Detection](https://arxiv.org/abs/2309.06747) (SYSU)
- [ ] [\[2309.06750\] MFL-YOLO: An Object Detection Model for Damaged Traffic Signs](https://arxiv.org/abs/2309.06750) (SYSU)
- [ ] [\[2309.06751\] Remote Sensing Object Detection Meets Deep Learning: A Meta-review of Challenges and Advances](https://arxiv.org/abs/2309.06751) (Xidian)
- [ ] [\[2309.06810\] Leveraging SE(3) Equivariance for Learning 3D Geometric Shape Assembly](https://arxiv.org/abs/2309.06810) (ICCV)
- [ ] [\[2309.06828\] UniBrain: Universal Brain MRI Diagnosis with Hierarchical Knowledge-enhanced Pre-training](https://arxiv.org/abs/2309.06828) (USTC)
- [ ] [\[2309.06877\] Video Infringement Detection via Feature Disentanglement and Mutual Information Maximization](https://arxiv.org/abs/2309.06877) (ZJU, ACMMM)
- [ ] [\[2309.06891\] Keep It SimPool: Who Said Supervised Transformers Suffer from Attention Deficit?](https://arxiv.org/abs/2309.06891) (ICCV)
- [ ] [\[2309.06924\] Contrast-Phys+: Unsupervised and Weakly-supervised Video-based Remote Physiological Measurement via Spatiotemporal Contrast](https://arxiv.org/abs/2309.06924) (TPAMI)
- [ ] [\[2309.06941\] DEFormer: DCT-driven Enhancement Transformer for Low-light Image and Dark Vision](https://arxiv.org/abs/2309.06941) (USTC)
- [ ] [\[2309.06961\] Towards Reliable Dermatology Evaluation Benchmarks](https://arxiv.org/abs/2309.06961) (Stanford)
- [ ] [\[2309.07084\] SupFusion: Supervised LiDAR-Camera Fusion for 3D Object Detection](https://arxiv.org/abs/2309.07084) (ICCV)
- [ ] [\[2309.07113\] Contrastive Deep Encoding Enables Uncertainty-aware Machine-learning-assisted Histopathology](https://arxiv.org/abs/2309.07113) (Harvard)
- [ ] [\[2309.07122\] Tree-Structured Shading Decomposition](https://arxiv.org/abs/2309.07122) (ICCV)
- [ ] [\[2309.07186\] LCReg: Long-Tailed Image Classification with Latent Categories based Recognition](https://arxiv.org/abs/2309.07186) (NTU)
- [ ] [\[2309.07297\] Multi-Modal Hybrid Learning and Sequential Training for RGB-T Saliency Detection](https://arxiv.org/abs/2309.07297) (UCL)
- [ ] [\[2309.07361\] Judging a video by its bitstream cover](https://arxiv.org/abs/2309.07361) (Tsinghua)
- [ ] [\[2309.07394\] Nucleus-aware Self-supervised Pretraining Using Unpaired Image-to-image Translation for Histopathology Images](https://arxiv.org/abs/2309.07394) (ZJU)
- [ ] [\[2309.07398\] Semantic Adversarial Attacks via Diffusion Models](https://arxiv.org/abs/2309.07398) (University of Michigan)
- [ ] [\[2309.07403\] Flexible Visual Recognition by Evidential Modeling of Confusion and Ignorance](https://arxiv.org/abs/2309.07403) (ICCV)
- [ ] [\[2309.07428\] Physical Invisible Backdoor Based on Camera Imaging](https://arxiv.org/abs/2309.07428) (Fudan)
- [ ] [\[2309.07471\] EP2P-Loc: End-to-End 3D Point to 2D Pixel Localization for Large-Scale Visual Localization](https://arxiv.org/abs/2309.07471) (ICCV)
- [ ] [\[2309.07616\] Road Disease Detection based on Latent Domain Background Feature Separation and Suppression](https://arxiv.org/abs/2309.07616) (SYSU)
- [ ] [\[2309.07640\] Indoor Scene Reconstruction with Fine-Grained Details Using Hybrid Representation and Normal Prior Enhancement](https://arxiv.org/abs/2309.07640) (Tsinghua)
- [ ] [\[2309.07668\] CoRF : Colorizing Radiance Fields using Knowledge Distillation](https://arxiv.org/abs/2309.07668) (ICCV)
- [ ] [\[2309.07749\] OmnimatteRF: Robust Omnimatte with 3D Background Modeling](https://arxiv.org/abs/2309.07749) (ICCV)
- [ ] [\[2309.07752\] DT-NeRF: Decomposed Triplane-Hash Neural Radiance Fields for High-Fidelity Talking Portrait Synthesis](https://arxiv.org/abs/2309.07752) (Tsinghua)
- [ ] [\[2309.07753\] Co-Salient Object Detection with Semantic-Level Consensus Extraction and Dispersion](https://arxiv.org/abs/2309.07753) (Peking, ACMMM)
- [ ] [\[2309.07760\] PRE: Vision-Language Prompt Learning with Reparameterization Encoder](https://arxiv.org/abs/2309.07760) (QMUL)
- [ ] [\[2309.07808\] What Matters to Enhance Traffic Rule Compliance of Imitation Learning for End-to-End Autonomous Driving](https://arxiv.org/abs/2309.07808) (TUM)
- [ ] [\[2309.07823\] Large-scale Weakly Supervised Learning for Road Extraction from Satellite Imagery](https://arxiv.org/abs/2309.07823) (Tongji)
- [ ] [\[2309.07846\] MC-NeRF: Multi-Camera Neural Radiance Fields for Multi-Camera Image Acquisition Systems](https://arxiv.org/abs/2309.07846) (BIT)
- [ ] [\[2309.07849\] TFNet: Exploiting Temporal Cues for Fast and Accurate LiDAR Semantic Segmentation](https://arxiv.org/abs/2309.07849) (HKUST(GZ))
- [ ] [\[2309.07866\] Gradient constrained sharpness-aware prompt learning for vision-language models](https://arxiv.org/abs/2309.07866) (Xidian)
- [ ] [\[2309.07910\] TEMPO: Efficient Multi-View Pose Estimation, Tracking, and Forecasting](https://arxiv.org/abs/2309.07910) (CMU, ICCV)
- [ ] [\[2309.07911\] Disentangling Spatial and Temporal Learning for Efficient Image-to-Video Transfer Learning](https://arxiv.org/abs/2309.07911) (ICCV)
- [ ] [\[2309.07914\] ALWOD: Active Learning for Weakly-Supervised Object Detection](https://arxiv.org/abs/2309.07914) (ICCV)
- [ ] [\[2309.07920\] Large-Vocabulary 3D Diffusion Model with Transformer](https://arxiv.org/abs/2309.07920) (CUHK)
- [ ] [\[2309.07929\] Prompting Segmentation with Sound Is Generalizable Audio-Visual Source Localizer](https://arxiv.org/abs/2309.07929) (NWPU)
- [ ] [\[2309.07986\] Viewpoint Textual Inversion: Discovering Scene Representations and 3D View Control in 2D Diffusion Models](https://arxiv.org/abs/2309.07986) (ECCV)
- [ ] [\[2309.08020\] Temporal-aware Hierarchical Mask Classification for Video Semantic Segmentation](https://arxiv.org/abs/2309.08020) (ETH)
- [ ] [\[2309.08036\] BEA: Revisiting anchor-based object detection DNN using Budding Ensemble Architecture](https://arxiv.org/abs/2309.08036) (TUM)
- [ ] [\[2309.08042\] Towards Large-scale Building Attribute Mapping using Crowdsourced Images: Scene Text Recognition on Flickr and Problems to be Solved](https://arxiv.org/abs/2309.08042) (TUM)
- [ ] [\[2309.08113\] MetaF2N: Blind Image Super-Resolution by Learning Efficient Model Adaptation from Faces](https://arxiv.org/abs/2309.08113) (HIT, ICCV)
- [ ] [\[2309.08134\] AnyOKP: One-Shot and Instance-Aware Object Keypoint Extraction with Pretrained ViT](https://arxiv.org/abs/2309.08134) (IA CAS)
- [ ] [\[2309.08159\] AdSEE: Investigating the Impact of Image Style Editing on Advertisement Attractiveness](https://arxiv.org/abs/2309.08159) (University of Alberta)
- [ ] [\[2309.08179\] STDG: Semi-Teacher-Student Training Paradigram for Depth-guided One-stage Scene Graph Generation](https://arxiv.org/abs/2309.08179) (Tsinghua)
- [ ] [\[2309.08196\] ECEA: Extensible Co-Existing Attention for Few-Shot Object Detection](https://arxiv.org/abs/2309.08196) (HUST)
- [ ] [\[2309.08204\] One-stage Modality Distillation for Incomplete Multimodal Learning](https://arxiv.org/abs/2309.08204) (UESTC)
- [ ] [\[2309.08206\] Salient Object Detection in Optical Remote Sensing Images Driven by Transformer](https://arxiv.org/abs/2309.08206) (TIP)
- [ ] [\[2309.08220\] UniST: Towards Unifying Saliency Transformer for Video Saliency Prediction and Detection](https://arxiv.org/abs/2309.08220) (NWPU)
- [ ] [\[2309.08239\] Human-Inspired Topological Representations for Visual Object Recognition in Unseen Environments](https://arxiv.org/abs/2309.08239) (UW)
- [ ] [\[2309.08265\] Edge Based Oriented Object Detection](https://arxiv.org/abs/2309.08265) (HIT)
- [ ] [\[2309.08369\] An Efficient Wide-Range Pseudo-3D Vehicle Detection Using A Single Camera](https://arxiv.org/abs/2309.08369) (XJTU)
- [ ] [\[2309.08372\] Beyond Domain Gap: Exploiting Subjectivity in Sketch-Based Person Retrieval](https://arxiv.org/abs/2309.08372) (WHU, ACMMM)
- [ ] [\[2309.08442\] Toward responsible face datasets: modeling the distribution of a disentangled latent space for sampling face images from demographic groups](https://arxiv.org/abs/2309.08442) (EPFL)
- [ ] [\[2309.08480\] PoseFix: Correcting 3D Human Poses with Natural Language](https://arxiv.org/abs/2309.08480) (ICCV)
- [ ] [\[2309.08481\] 3D Arterial Segmentation via Single 2D Projections and Depth Supervision in Contrast-Enhanced CT Images](https://arxiv.org/abs/2309.08481) (TUM)
- [ ] [\[2309.08513\] SCT: A Simple Baseline for Parameter-Efficient Fine-Tuning via Salient Channels](https://arxiv.org/abs/2309.08513) (Alibaba)
- [ ] [\[2309.08535\] Visual Speech Recognition for Languages with Limited Labeled Data using Automatic Labels from Whisper](https://arxiv.org/abs/2309.08535) (CMU)
- [ ] [\[2309.08588\] Robust Frame-to-Frame Camera Rotation Estimation in Crowded Scenes](https://arxiv.org/abs/2309.08588) (ICCV)
- [ ] [\[2309.08596\] Robust e-NeRF: NeRF from Sparse & Noisy Events under Non-Uniform Motion](https://arxiv.org/abs/2309.08596) (ICCV)
- [ ] [\[2309.08644\] Towards Robust and Smooth 3D Multi-Person Pose Estimation from Monocular Videos in the Wild](https://arxiv.org/abs/2309.08644) (ICCV)
- [ ] [\[2309.08690\] BANSAC: A dynamic BAyesian Network for adaptive SAmple Consensus](https://arxiv.org/abs/2309.08690) (ICCV)
- [ ] [\[2309.08727\] Segmentation of Tubular Structures Using Iterative Training with Tailored Samples](https://arxiv.org/abs/2309.08727) (ICCV)
- [ ] [\[2309.08743\] Active Learning for Fine-Grained Sketch-Based Image Retrieval](https://arxiv.org/abs/2309.08743) (CMU)
- [ ] [\[2309.08747\] Unified Brain MR-Ultrasound Synthesis using Multi-Modal Hierarchical Representations](https://arxiv.org/abs/2309.08747) (Harvard)
- [ ] [\[2309.08769\] The Use of Multi-Scale Fiducial Markers To Aid Takeoff and Landing Navigation by Rotorcraft](https://arxiv.org/abs/2309.08769) (Illinois)
- [ ] [\[2309.08771\] Rethinking Cross-Domain Pedestrian Detection: A Background-Focused Distribution Alignment Framework for Instance-Free One-Stage Detectors](https://arxiv.org/abs/2309.08771) (Fudan, TIP)
- [ ] [\[2309.08816\] EgoObjects: A Large-Scale Egocentric Dataset for Fine-Grained Object Understanding](https://arxiv.org/abs/2309.08816) (ICCV)
- [ ] [\[2309.08842\] MA-SAM: Modality-agnostic SAM Adaptation for 3D Medical Image Segmentation](https://arxiv.org/abs/2309.08842) (Harvard)
- [ ] [\[2309.08851\] Enhancing Visual Perception in Novel Environments via Incremental Data Augmentation Based on Style Transfer](https://arxiv.org/abs/2309.08851) (Stanford)
- [ ] [\[2309.08888\] GCL: Gradient-Guided Contrastive Learning for Medical Image Segmentation with Multi-Perspective Meta Labels](https://arxiv.org/abs/2309.08888) (ZJU)
- [ ] [\[2309.08912\] Delving into Multimodal Prompting for Fine-grained Visual Classification](https://arxiv.org/abs/2309.08912) (Tongji)
- [ ] [\[2309.08919\] Pixel Adapter: A Graph-Based Post-Processing Approach for Scene Text Image Super-Resolution](https://arxiv.org/abs/2309.08919) (USTC)
- [ ] [\[2309.08927\] DynaMoN: Motion-Aware Fast and Robust Camera Localization for Dynamic Neural Radiance Fields](https://arxiv.org/abs/2309.08927) (TUM)
- [ ] [\[2309.08928\] In-Style: Bridging Text and Uncurated Videos with Style Transfer for Text-Video Retrieval](https://arxiv.org/abs/2309.08928) (ICCV)
- [ ] [\[2309.08942\] AffordPose: A Large-scale Dataset of Hand-Object Interactions with Affordance-driven Hand Pose](https://arxiv.org/abs/2309.08942) (ICCV)
- [ ] [\[2309.08947\] Staged Contact-Aware Global Human Motion Forecasting](https://arxiv.org/abs/2309.08947) (TUM)
- [ ] [\[2309.08953\] Robust Backdoor Attacks on Object Detection in Real World](https://arxiv.org/abs/2309.08953) (IS CAS)
- [ ] [\[2309.08966\] FF-LOGO: Cross-Modality Point Cloud Registration with Feature Filtering and Local to Global Optimization](https://arxiv.org/abs/2309.08966) (Tsinghua)
- [ ] [\[2309.09003\] RingMo-lite: A Remote Sensing Multi-task Lightweight Network with CNN-Transformer Hybrid Framework](https://arxiv.org/abs/2309.09003) (UCAS)
- [ ] [\[2309.09083\] FrameRS: A Video Frame Compression Model Composed by Self supervised Video Frame Reconstructor and Key Frame Selector](https://arxiv.org/abs/2309.09083) (ZJU)
- [ ] [\[2309.09118\] Uncertainty-aware 3D Object-Level Mapping with Deep Shape Priors](https://arxiv.org/abs/2309.09118) (TUM)
- [ ] [\[2309.09122\] FDCNet: Feature Drift Compensation Network for Class-Incremental Weakly Supervised Object Localization](https://arxiv.org/abs/2309.09122) (ACMMM)
- [ ] [\[2309.09179\] Syntax Tree Constrained Graph Network for Visual Question Answering](https://arxiv.org/abs/2309.09179) (BIT)
- [ ] [\[2309.09196\] Efficient Pyramid Channel Attention Network for Pathological Myopia Recognition](https://arxiv.org/abs/2309.09196) (SUSTech)
- [ ] [\[2309.09211\] Neural Gradient Learning and Optimization for Oriented Point Normal Estimation](https://arxiv.org/abs/2309.09211) (Tsinghua, SIGGRAPH)
- [ ] [\[2309.09276\] MVP: Meta Visual Prompt Tuning for Few-Shot Remote Sensing Image Scene Classification](https://arxiv.org/abs/2309.09276) (NUDT)
- [ ] [\[2309.09294\] LivelySpeaker: Towards Semantic-Aware Co-Speech Gesture Generation](https://arxiv.org/abs/2309.09294) (ICCV)
- [ ] [\[2309.09297\] Chasing Day and Night: Towards Robust and Efficient All-Day Object Detection Guided by an Event Camera](https://arxiv.org/abs/2309.09297) (HKUST(GZ))
- [ ] [\[2309.09301\] RenderIH: A Large-scale Synthetic Dataset for 3D Interacting Hand Pose Estimation](https://arxiv.org/abs/2309.09301) (ICCV)
- [ ] [\[2309.09311\] Towards Debiasing Frame Length Bias in Text-Video Retrieval via Causal Intervention](https://arxiv.org/abs/2309.09311) (NTU)
- [ ] [\[2309.09319\] Active Learning for Semantic Segmentation with Multi-class Label Query](https://arxiv.org/abs/2309.09319) (NIPS)
- [ ] [\[2309.09456\] Object2Scene: Putting Objects in Context for Open-Vocabulary 3D Detection](https://arxiv.org/abs/2309.09456) (HKU)
- [ ] [\[2309.09464\] Reducing Adversarial Training Cost with Gradient Approximation](https://arxiv.org/abs/2309.09464) (USyd)
- [ ] [\[2309.09472\] Reconstructing Existing Levels through Level Inpainting](https://arxiv.org/abs/2309.09472) (University of Alberta)
- [ ] [\[2309.09473\] Self-supervised Multi-view Clustering in Computer Vision: A Survey](https://arxiv.org/abs/2309.09473) (ICT CAS)
- [ ] [\[2309.09480\] Stealthy Physical Masked Face Recognition Attack via Adversarial Style Optimization](https://arxiv.org/abs/2309.09480) (USyd)
- [ ] [\[2309.09502\] RenderOcc: Vision-Centric 3D Occupancy Prediction with 2D Rendering Supervision](https://arxiv.org/abs/2309.09502) (Peking)
- [ ] [\[2309.09526\] DFIL: Deepfake Incremental Learning by Exploiting Domain-invariant Forgery Clues](https://arxiv.org/abs/2309.09526) (ZJU, ACMMM)
- [ ] [\[2309.09534\] Selective Volume Mixup for Video Action Recognition](https://arxiv.org/abs/2309.09534) (USTC)
- [ ] [\[2309.09563\] RIDE: Self-Supervised Learning of Rotation-Equivariant Keypoint Detection and Invariant Description for Endoscopy](https://arxiv.org/abs/2309.09563) (TUM)
- [ ] [\[2309.09611\] Collaborative Three-Stream Transformers for Video Captioning](https://arxiv.org/abs/2309.09611) (IS CAS)
- [ ] [\[2309.09637\] Designing a Hybrid Neural System to Learn Real-world Crack Segmentation from Fractal-based Simulation](https://arxiv.org/abs/2309.09637) (University of Tübingen)
- [ ] [\[2309.09668\] DFormer: Rethinking RGBD Representation Learning for Semantic Segmentation](https://arxiv.org/abs/2309.09668) (Nankai, ICLR)
- [ ] [\[2309.09689\] Ugly Ducklings or Swans: A Tiered Quadruplet Network with Patient-Specific Mining for Improved Skin Lesion Classification](https://arxiv.org/abs/2309.09689) (Queensland)
- [ ] [\[2309.09709\] CATR: Combinatorial-Dependence Audio-Queried Transformer for Audio-Visual Video Segmentation](https://arxiv.org/abs/2309.09709) (ZJU, ACMMM)
- [ ] [\[2309.09724\] Robust Geometry-Preserving Depth Estimation Using Differentiable Rendering](https://arxiv.org/abs/2309.09724) (Fudan, ICCV)
- [ ] [\[2309.09730\] Scribble-based 3D Multiple Abdominal Organ Segmentation via Triple-branch Multi-dilated Network with Pixel- and Class-wise Consistency](https://arxiv.org/abs/2309.09730) (UESTC)
- [ ] [\[2309.09739\] Improving Neural Indoor Surface Reconstruction with Mask-Guided Adaptive Consistency Constraints](https://arxiv.org/abs/2309.09739) (ZJU)
- [ ] [\[2309.09765\] Localization-Guided Track: A Deep Association Multi-Object Tracking Framework Based on Localization Confidence of Detections](https://arxiv.org/abs/2309.09765) (Chongqing)
- [ ] [\[2309.09809\] A Continual Learning Paradigm for Non-differentiable Visual Programming Frameworks on Visual Reasoning Tasks](https://arxiv.org/abs/2309.09809) (SYSU)
- [ ] [\[2309.09812\] R2GenGPT: Radiology Report Generation with Frozen LLMs](https://arxiv.org/abs/2309.09812) (USyd)
- [ ] [\[2309.09858\] Unsupervised Open-Vocabulary Object Localization in Videos](https://arxiv.org/abs/2309.09858) (Fudan)
- [ ] [\[2309.09887\] On Model Explanations with Transferable Neural Pathways](https://arxiv.org/abs/2309.09887) (Rochester Institute of Technology)
- [ ] [\[2309.09934\] Hierarchical Attention and Graph Neural Networks: Toward Drift-Free Pose Estimation](https://arxiv.org/abs/2309.09934) (Inria)
- [ ] [\[2309.09975\] GEDepth: Ground Embedding for Monocular Depth Estimation](https://arxiv.org/abs/2309.09975) (ICCV)
- [ ] [\[2309.09982\] Introspective Deep Metric Learning](https://arxiv.org/abs/2309.09982) (Tsinghua)
- [ ] [\[2309.10013\] Hyperbolic vs Euclidean Embeddings in Few-Shot Learning: Two Sides of the Same Coin](https://arxiv.org/abs/2309.10013) (CMU)
- [ ] [\[2309.10019\] Long-Tail Learning with Foundation Model: Heavy Fine-Tuning Hurts](https://arxiv.org/abs/2309.10019) (NJU, ICML)
- [ ] [\[2309.10091\] Unified Coarse-to-Fine Alignment for Video-Text Retrieval](https://arxiv.org/abs/2309.10091) (ICCV)
- [ ] [\[2309.10206\] Image-Text Pre-Training for Logo Recognition](https://arxiv.org/abs/2309.10206) (AWS)
- [ ] [\[2309.10230\] Learning Point-wise Abstaining Penalty for Point Cloud Anomaly Detection](https://arxiv.org/abs/2309.10230) (Xiamen)
- [ ] [\[2309.10244\] UPL-SFDA: Uncertainty-aware Pseudo Label Guided Source-Free Domain Adaptation for Medical Image Segmentation](https://arxiv.org/abs/2309.10244) (UESTC)
- [ ] [\[2309.10279\] 360$^\circ$ Reconstruction From a Single Image Using Space Carved Outpainting](https://arxiv.org/abs/2309.10279) (POSTECH, SIGGRAPH)
- [ ] [\[2309.10336\] Anti-Aliased Neural Implicit Surfaces with Encoding Level of Detail](https://arxiv.org/abs/2309.10336) (NJU, SIGGRAPH)
- [ ] [\[2309.10356\] RoadFormer: Duplex Transformer for RGB-Normal Semantic Road Scene Parsing](https://arxiv.org/abs/2309.10356) (HKUST)
- [ ] [\[2309.10361\] Improving CLIP Robustness with Knowledge Distillation and Self-Training](https://arxiv.org/abs/2309.10361) (Bosch)
- [ ] [\[2309.10369\] GloPro: Globally-Consistent Uncertainty-Aware 3D Human Pose Estimation & Tracking in the Wild](https://arxiv.org/abs/2309.10369) (Imperial)
- [ ] [\[2309.10388\] SideGAN: 3D-Aware Generative Model for Improved Side-View Image Synthesis](https://arxiv.org/abs/2309.10388) (ICCV)
- [ ] [\[2309.10421\] Exploring Different Levels of Supervision for Detecting and Localizing Solar Panels on Remote Sensing Imagery](https://arxiv.org/abs/2309.10421) (UVA.NL)
- [ ] [\[2309.10431\] Sample-adaptive Augmentation for Point Cloud Recognition Against Real-world Corruptions](https://arxiv.org/abs/2309.10431) (ICCV)
- [ ] [\[2309.10438\] AutoDiffusion: Training-Free Optimization of Time Steps and Architectures for Automated Diffusion Model Acceleration](https://arxiv.org/abs/2309.10438) (Xiamen)
- [ ] [\[2309.10475\] LineMarkNet: Line Landmark Detection for Valet Parking](https://arxiv.org/abs/2309.10475) (Fudan)
- [ ] [\[2309.10518\] Unsupervised Landmark Discovery Using Consistency Guided Bottleneck](https://arxiv.org/abs/2309.10518) (MBZUAI)
- [ ] [\[2309.10527\] SPOT: Scalable 3D Pre-training via Occupancy Prediction for Learning Transferable 3D Representations](https://arxiv.org/abs/2309.10527) (Shanghai AI Lab)
- [ ] [\[2309.10528\] Retinex-guided Channel-grouping based Patch Swap for Arbitrary Style Transfer](https://arxiv.org/abs/2309.10528) (Xidian)
- [ ] [\[2309.10556\] Forgedit: Text Guided Image Editing via Learning and Forgetting](https://arxiv.org/abs/2309.10556) (Alibaba)
- [ ] [\[2309.10588\] Few-shot Object Detection in Remote Sensing: Lifting the Curse of Incompletely Annotated Novel Objects](https://arxiv.org/abs/2309.10588) (TUM)
- [ ] [\[2309.10592\] NDDepth: Normal-Distance Assisted Monocular Depth Estimation](https://arxiv.org/abs/2309.10592) (A*STAR,, ICCV)
- [ ] [\[2309.10649\] Cross-modal and Cross-domain Knowledge Transfer for Label-free 3D Segmentation](https://arxiv.org/abs/2309.10649) (ShanghaiTech)
- [ ] [\[2309.10650\] MUSTANG: Multi-Stain Self-Attention Graph Multiple Instance Learning Pipeline for Histopathology Whole Slide Images](https://arxiv.org/abs/2309.10650) (QMUL)
- [ ] [\[2309.10684\] Locally Stylized Neural Radiance Fields](https://arxiv.org/abs/2309.10684) (ICCV)
- [ ] [\[2309.10689\] ReShader: View-Dependent Highlights for Single Image View-Synthesis](https://arxiv.org/abs/2309.10689) (SIGGRAPH)
- [ ] [\[2309.10711\] Latent Space Energy-based Model for Fine-grained Open Set Recognition](https://arxiv.org/abs/2309.10711) (Michigan State University)
- [ ] [\[2309.10714\] Reconstruct-and-Generate Diffusion Model for Detail-Preserving Image Denoising](https://arxiv.org/abs/2309.10714) (Shanghai AI Lab)
- [ ] [\[2309.10724\] Sound Source Localization is All about Cross-Modal Alignment](https://arxiv.org/abs/2309.10724) (ICCV)
- [ ] [\[2309.10725\] Causality-Driven One-Shot Learning for Prostate Cancer Grading from MRI](https://arxiv.org/abs/2309.10725) (ICCV)
- [ ] [\[2309.10836\] CMRxRecon: An open cardiac MRI dataset for the competition of accelerated image reconstruction](https://arxiv.org/abs/2309.10836) (Fudan)
- [ ] [\[2309.11002\] PPD: A New Valet Parking Pedestrian Fisheye Dataset for Autonomous Driving](https://arxiv.org/abs/2309.11002) (Fudan)
- [ ] [\[2309.11077\] Weak Supervision for Label Efficient Visual Bug Detection](https://arxiv.org/abs/2309.11077) (Microsoft)
- [ ] [\[2309.11081\] Dense 2D-3D Indoor Prediction with Sound via Aligned Cross-Modal Distillation](https://arxiv.org/abs/2309.11081) (ICCV)
- [ ] [\[2309.11082\] Dual-Modal Attention-Enhanced Text-Video Retrieval with Triplet Partial Margin Contrastive Learning](https://arxiv.org/abs/2309.11082) (Fudan, ACMMM)
- [ ] [\[2309.11091\] Learning Segment Similarity and Alignment in Large-Scale Content Based Video Retrieval](https://arxiv.org/abs/2309.11091) (ACMMM)
- [ ] [\[2309.11092\] Generalized Face Forgery Detection via Adaptive Learning for Pre-trained Vision Transformer](https://arxiv.org/abs/2309.11092) (SYSU)
- [ ] [\[2309.11109\] Self-supervised Domain-agnostic Domain Adaptation for Satellite Images](https://arxiv.org/abs/2309.11109) (TUM)
- [ ] [\[2309.11122\] Hyperspectral Benchmark: Bridging the Gap between HSI Applications through Comprehensive Dataset and Pretraining](https://arxiv.org/abs/2309.11122) (University of Tübingen)
- [ ] [\[2309.11131\] Locate and Verify: A Two-Stream Network for Improved Deepfake Detection](https://arxiv.org/abs/2309.11131) (ZJU, ACMMM)
- [ ] [\[2309.11132\] Contrastive Pseudo Learning for Open-World DeepFake Attribution](https://arxiv.org/abs/2309.11132) (ICCV)
- [ ] [\[2309.11133\] Shape Anchor Guided Holistic Indoor Scene Understanding](https://arxiv.org/abs/2309.11133) (IA CAS)
- [ ] [\[2309.11144\] GL-Fusion: Global-Local Fusion Network for Multi-view Echocardiogram Video Segmentation](https://arxiv.org/abs/2309.11144) (HKUST)
- [ ] [\[2309.11145\] GraphEcho: Graph-Driven Unsupervised Domain Adaptation for Echocardiogram Video Segmentation](https://arxiv.org/abs/2309.11145) (HKUST, ICCV)
- [ ] [\[2309.11160\] Multi-grained Temporal Prototype Learning for Few-shot Video Object Segmentation](https://arxiv.org/abs/2309.11160) (ICCV)
- [ ] [\[2309.11170\] AutoSynth: Learning to Generate 3D Training Data for Object Point Cloud Registration](https://arxiv.org/abs/2309.11170) (ICCV)
- [ ] [\[2309.11222\] Generalized Few-Shot Point Cloud Segmentation Via Geometric Words](https://arxiv.org/abs/2309.11222) (NUS, ICCV)
- [ ] [\[2309.11228\] Towards Robust Few-shot Point Cloud Semantic Segmentation](https://arxiv.org/abs/2309.11228) (NUS)
- [ ] [\[2309.11267\] From Classification to Segmentation with Explainable AI: A Study on Crack Detection and Growth Monitoring](https://arxiv.org/abs/2309.11267) (EPFL)
- [ ] [\[2309.11268\] StructChart: Perception, Structuring, Reasoning for Visual Chart Understanding](https://arxiv.org/abs/2309.11268) (Shanghai AI Lab)
- [ ] [\[2309.11281\] Language-driven Object Fusion into Neural Radiance Fields with Pose-Conditioned Dataset Updates](https://arxiv.org/abs/2309.11281) (CVPR)
- [ ] [\[2309.11306\] FaceDiffuser: Speech-Driven 3D Facial Animation Synthesis Using Diffusion](https://arxiv.org/abs/2309.11306) (SIGGRAPH)
- [ ] [\[2309.11331\] Gold-YOLO: Efficient Object Detector via Gather-and-Distribute Mechanism](https://arxiv.org/abs/2309.11331) (NIPS)
- [ ] [\[2309.11443\] Signature Activation: A Sparse Signal View for Holistic Saliency](https://arxiv.org/abs/2309.11443) (Harvard)
- [ ] [\[2309.11445\] SkeleTR: Towrads Skeleton-based Action Recognition in the Wild](https://arxiv.org/abs/2309.11445) (ICCV)
- [ ] [\[2309.11499\] DreamLLM: Synergistic Multimodal Comprehension and Creation](https://arxiv.org/abs/2309.11499) (ICLR)
- [ ] [\[2309.11523\] RMT: Retentive Networks Meet Vision Transformers](https://arxiv.org/abs/2309.11523) (IA CAS)
- [ ] [\[2309.11627\] GenLayNeRF: Generalizable Layered Representations with 3D Model Alignment for Multi-Human View Synthesis](https://arxiv.org/abs/2309.11627) (MBZUAI)
- [ ] [\[2309.11667\] Understanding Pose and Appearance Disentanglement in 3D Human Pose Estimation](https://arxiv.org/abs/2309.11667) (EPFL)
- [ ] [\[2309.11707\] Efficient Long-Short Temporal Attention Network for Unsupervised Video Object Segmentation](https://arxiv.org/abs/2309.11707) (ZJU)
- [ ] [\[2309.11711\] MoDA: Leveraging Motion Priors from Videos for Advancing Unsupervised Domain Adaptation in Semantic Segmentation](https://arxiv.org/abs/2309.11711) (University of Michigan)
- [ ] [\[2309.11718\] CPR-Coach: Recognizing Composite Error Actions based on Single-class Training](https://arxiv.org/abs/2309.11718) (Fudan)
- [ ] [\[2309.11782\] DimCL: Dimensional Contrastive Learning For Improving Self-Supervised Learning](https://arxiv.org/abs/2309.11782) (KAIST)
- [ ] [\[2309.11857\] TCOVIS: Temporally Consistent Online Video Instance Segmentation](https://arxiv.org/abs/2309.11857) (ICCV)
- [ ] [\[2309.11858\] OSNet & MNetO: Two Types of General Reconstruction Architectures for Linear Computed Tomography in Multi-Scenarios](https://arxiv.org/abs/2309.11858) (Chongqing)
- [ ] [\[2309.11962\] Ego3DPose: Capturing 3D Cues from Binocular Egocentric Views](https://arxiv.org/abs/2309.11962) (SIGGRAPH)
- [ ] [\[2309.12042\] Beyond Image Borders: Learning Feature Extrapolation for Unbounded Image Composition](https://arxiv.org/abs/2309.12042) (HIT)
- [ ] [\[2309.12047\] Self-Calibrating, Fully Differentiable NLOS Inverse Rendering](https://arxiv.org/abs/2309.12047) (KAIST)
- [ ] [\[2309.12090\] Multi-Task Cooperative Learning via Searching for Flat Minima](https://arxiv.org/abs/2309.12090) (Oxford)
- [ ] [\[2309.12140\] Unsupervised Domain Adaptation for Self-Driving from Past Traversal Features](https://arxiv.org/abs/2309.12140) (Cornell)
- [ ] [\[2309.12172\] SANPO: A Scene Understanding, Accessibility, Navigation, Pathfinding, Obstacle Avoidance Dataset](https://arxiv.org/abs/2309.12172) (Google)
- [ ] [\[2309.12183\] ORTexME: Occlusion-Robust Human Shape and Pose via Temporal Average Texture and Mesh Encoding](https://arxiv.org/abs/2309.12183) (NUS)
- [ ] [\[2309.12302\] Text-Guided Vector Graphics Customization](https://arxiv.org/abs/2309.12302) (SIGGRAPH)
- [ ] [\[2309.12303\] PanoVOS: Bridging Non-panoramic and Panoramic Views with Transformer for Video Segmentation](https://arxiv.org/abs/2309.12303) (Fudan, ECCV)
- [ ] [\[2309.12311\] LLM-Grounder: Open-Vocabulary 3D Visual Grounding with Large Language Model as an Agent](https://arxiv.org/abs/2309.12311) (University of Michigan)
- [ ] [\[2309.12314\] TinyCLIP: CLIP Distillation via Affinity Mimicking and Weight Inheritance](https://arxiv.org/abs/2309.12314) (Microsoft, ICCV)
- [ ] [\[2309.12315\] Active Stereo Without Pattern Projector](https://arxiv.org/abs/2309.12315) (ICCV)
- [ ] [\[2309.12378\] Unsupervised Semantic Segmentation Through Depth-Guided Feature Correlation and Sampling](https://arxiv.org/abs/2309.12378) (CVPR)
- [ ] [\[2309.12382\] SCOB: Universal Text Understanding via Character-wise Supervised Contrastive Learning with Online Text Rendering for Bridging Domain Gap](https://arxiv.org/abs/2309.12382) (ICCV)
- [ ] [\[2309.12424\] DualToken-ViT: Position-aware Efficient Vision Transformer with Dual Token Fusion](https://arxiv.org/abs/2309.12424) (Alibaba)
- [ ] [\[2309.12530\] A Sentence Speaks a Thousand Images: Domain Generalization through Distilling CLIP with Language Guidance](https://arxiv.org/abs/2309.12530) (Imperial, ICCV)
- [ ] [\[2309.12557\] Triple-View Knowledge Distillation for Semi-Supervised Semantic Segmentation](https://arxiv.org/abs/2309.12557) (Peking)
- [ ] [\[2309.12594\] DeFormer: Integrating Transformers with Deformable Models for 3D Shape Abstraction from a Single Image](https://arxiv.org/abs/2309.12594) (ICCV)
- [ ] [\[2309.12639\] CINFormer: Transformer network with multi-stage CNN feature injection for surface defect segmentation](https://arxiv.org/abs/2309.12639) (Tianjin)
- [ ] [\[2309.12641\] Global Context Aggregation Network for Lightweight Saliency Detection of Surface Defects](https://arxiv.org/abs/2309.12641) (Tianjin)
- [ ] [\[2309.12642\] RHINO: Regularizing the Hash-based Implicit Neural Representation](https://arxiv.org/abs/2309.12642) (NJU)
- [ ] [\[2309.12657\] Exploiting Modality-Specific Features For Multi-Modal Manipulation Detection And Grounding](https://arxiv.org/abs/2309.12657) (USTC)
- [ ] [\[2309.12708\] PointSSC: A Cooperative Vehicle-Infrastructure Point Cloud Benchmark for Semantic Scene Completion](https://arxiv.org/abs/2309.12708) (Fudan)
- [ ] [\[2309.12780\] LMC: Large Model Collaboration with Cross-assessment for Training-Free Open-Set Object Recognition](https://arxiv.org/abs/2309.12780) (Meta, NIPS)
- [ ] [\[2309.12787\] EMS: 3D Eyebrow Modeling from Single-view Images](https://arxiv.org/abs/2309.12787) (SIGGRAPH)
- [ ] [\[2309.12790\] NTO3D: Neural Target Object 3D Reconstruction with Segment Anything](https://arxiv.org/abs/2309.12790) (Peking, CVPR)
- [ ] [\[2309.12804\] Scalable Semantic 3D Mapping of Coral Reefs with Deep Learning](https://arxiv.org/abs/2309.12804) (EPFL)
- [ ] [\[2309.12842\] SRFNet: Monocular Depth Estimation with Fine-grained Structure via Spatial Reliability-oriented Fusion of Frames and Events](https://arxiv.org/abs/2309.12842) (HKUST(GZ))
- [ ] [\[2309.12865\] Bridging Sensor Gaps via Attention Gated Tuning for Hyperspectral Image Classification](https://arxiv.org/abs/2309.12865) (NWPU)
- [ ] [\[2309.12867\] Accurate and Fast Compressed Video Captioning](https://arxiv.org/abs/2309.12867) (IS CAS, ICCV)
- [ ] [\[2309.12943\] Background Activation Suppression for Weakly Supervised Object Localization and Semantic Segmentation](https://arxiv.org/abs/2309.12943) (USTC)
- [ ] [\[2309.13006\] Deep3DSketch+: Rapid 3D Modeling from Single Free-hand Sketches](https://arxiv.org/abs/2309.13006) (JHU)
- [ ] [\[2309.13039\] NeRRF: 3D Reconstruction and View Synthesis for Transparent and Specular Objects with Neural Refractive-Reflective Fields](https://arxiv.org/abs/2309.13039) (Tsinghua)
- [ ] [\[2309.13042\] MosaicFusion: Diffusion Models as Data Augmenters for Large Vocabulary Instance Segmentation](https://arxiv.org/abs/2309.13042) (NTU)
- [ ] [\[2309.13097\] Zero-Shot Object Counting with Language-Vision Models](https://arxiv.org/abs/2309.13097) (EPFL, CVPR)
- [ ] [\[2309.13137\] Trading-off Mutual Information on Feature Aggregation for Face Recognition](https://arxiv.org/abs/2309.13137) (ICML)
- [ ] [\[2309.13216\] MISFIT-V: Misaligned Image Synthesis and Fusion using Information from Thermal and Visual](https://arxiv.org/abs/2309.13216) (UW)
- [ ] [\[2309.13226\] Real3D-AD: A Dataset of Point Cloud Anomaly Detection](https://arxiv.org/abs/2309.13226) (SUSTech)
- [ ] [\[2309.13237\] Spatial-Temporal Knowledge-Embedded Transformer for Video Scene Graph Generation](https://arxiv.org/abs/2309.13237) (SYSU)
- [ ] [\[2309.13242\] UniHead: Unifying Multi-Perception for Detection Heads](https://arxiv.org/abs/2309.13242) (Tsinghua)
- [ ] [\[2309.13245\] RBFormer: Improve Adversarial Robustness of Transformer by Robust Bias](https://arxiv.org/abs/2309.13245) (HKUST(GZ))
- [ ] [\[2309.13247\] Multi-modal Domain Adaptation for REG via Relation Transfer](https://arxiv.org/abs/2309.13247) (Google)
- [ ] [\[2309.13248\] Rethinking Amodal Video Segmentation from Learning Supervised Signals with Object-centric Representation](https://arxiv.org/abs/2309.13248) (ICCV)
- [ ] [\[2309.13258\] Order-preserving Consistency Regularization for Domain Adaptation and Generalization](https://arxiv.org/abs/2309.13258) (UVA.NL, ICCV)
- [ ] [\[2309.13269\] Being Aware of Localization Accuracy By Generating Predicted-IoU-Guided Quality Scores](https://arxiv.org/abs/2309.13269) (HIT)
- [ ] [\[2309.13274\] GLOBER: Coherent Non-autoregressive Video Generation via GLOBal Guided Video DecodER](https://arxiv.org/abs/2309.13274) (IA CAS)
- [ ] [\[2309.13276\] Discwise Active Learning for LiDAR Semantic Segmentation](https://arxiv.org/abs/2309.13276) (ETH)
- [ ] [\[2309.13306\] Tackling the Incomplete Annotation Issue in Universal Lesion Detection Task By Exploratory Training](https://arxiv.org/abs/2309.13306) (NWPU)
- [ ] [\[2309.13401\] Dual-Reference Source-Free Active Domain Adaptation for Nasopharyngeal Carcinoma Tumor Segmentation across Multiple Hospitals](https://arxiv.org/abs/2309.13401) (UESTC)
- [ ] [\[2309.13446\] Video Timeline Modeling For News Story Understanding](https://arxiv.org/abs/2309.13446) (NIPS)
- [ ] [\[2309.13472\] Edge Aware Learning for 3D Point Cloud](https://arxiv.org/abs/2309.13472) (University of Copenhagen)
- [ ] [\[2309.13505\] Rewrite Caption Semantics: Bridging Semantic Gaps for Language-Supervised Semantic Segmentation](https://arxiv.org/abs/2309.13505) (NIPS)
- [ ] [\[2309.13523\] LiDAR-UDA: Self-ensembling Through Time for Unsupervised LiDAR Domain Adaptation](https://arxiv.org/abs/2309.13523) (ICCV)
- [ ] [\[2309.13524\] Global-correlated 3D-decoupling Transformer for Clothed Avatar Reconstruction](https://arxiv.org/abs/2309.13524) (NIPS)
- [ ] [\[2309.13546\] DFRD: Data-Free Robustness Distillation for Heterogeneous Federated Learning](https://arxiv.org/abs/2309.13546) (NIPS)
- [ ] [\[2309.13556\] LOGICSEG: Parsing Visual Semantics with Neural Logic Learning and Reasoning](https://arxiv.org/abs/2309.13556) (ICCV)
- [ ] [\[2309.13570\] Robust 6DoF Pose Estimation Against Depth Noise and a Comprehensive Evaluation on a Mobile Dataset](https://arxiv.org/abs/2309.13570) (Berkeley)
- [ ] [\[2309.13596\] Advancements in 3D Lane Detection Using LiDAR Point Clouds: From Data Collection to Model Development](https://arxiv.org/abs/2309.13596) (USyd)
- [ ] [\[2309.13598\] On the Posterior Distribution in Denoising: Application to Uncertainty Quantification](https://arxiv.org/abs/2309.13598) (ICLR)
- [ ] [\[2309.13600\] Multi-Dimensional Hyena for Spatial Inductive Bias](https://arxiv.org/abs/2309.13600) (Tel Aviv)
- [ ] [\[2309.13604\] Distribution-Aware Continual Test-Time Adaptation for Semantic Segmentation](https://arxiv.org/abs/2309.13604) (Peking)
- [ ] [\[2309.13607\] MM-NeRF: Multimodal-Guided 3D Multi-Style Transfer of Neural Radiance Field](https://arxiv.org/abs/2309.13607) (USyd)
- [ ] [\[2309.13625\] GraphAdapter: Tuning Vision-Language Models With Dual Knowledge Graph](https://arxiv.org/abs/2309.13625) (USTC, NIPS)
- [ ] [\[2309.13672\] RL-I2IT: Image-to-Image Translation with Deep Reinforcement Learning](https://arxiv.org/abs/2309.13672) (Microsoft)
- [ ] [\[2309.13682\] Causal-DFQ: Causality Guided Data-free Network Quantization](https://arxiv.org/abs/2309.13682) (ICCV)
- [ ] [\[2309.13700\] Video Adverse-Weather-Component Suppression Network via Weather Messenger and Adversarial Backpropagation](https://arxiv.org/abs/2309.13700) (HKUST)
- [ ] [\[2309.13847\] Tuning Multi-mode Token-level Prompt Alignment across Modalities](https://arxiv.org/abs/2309.13847) (Xidian, NIPS)
- [ ] [\[2309.13851\] DISeR: Designing Imaging Systems with Reinforcement Learning](https://arxiv.org/abs/2309.13851) (ICCV)
- [ ] [\[2309.13857\] Adversarial Attacks on Video Object Segmentation with Hard Region Discovery](https://arxiv.org/abs/2309.13857) (Peking)
- [ ] [\[2309.13881\] Skip-Connected Neural Networks with Layout Graphs for Floor Plan Auto-Generation](https://arxiv.org/abs/2309.13881) (Sungkyunkwan University)
- [ ] [\[2309.13890\] Bitstream-Corrupted Video Recovery: A Novel Benchmark Dataset and Method](https://arxiv.org/abs/2309.13890) (PolyU, NIPS)
- [ ] [\[2309.13952\] VidChapters-7M: Video Chapters at Scale](https://arxiv.org/abs/2309.13952) (NIPS)
- [ ] [\[2309.14062\] FeCAM: Exploiting the Heterogeneity of Class Distributions in Exemplar-Free Continual Learning](https://arxiv.org/abs/2309.14062) (NIPS)
- [ ] [\[2309.14072\] BoIR: Box-Supervised Instance Representation for Multi-Person Pose Estimation](https://arxiv.org/abs/2309.14072) (POSTECH)
- [ ] [\[2309.14136\] Masked Image Residual Learning for Scaling Deeper Vision Transformers](https://arxiv.org/abs/2309.14136) (HUST)
- [ ] [\[2309.14137\] IEBins: Iterative Elastic Bins for Monocular Depth Estimation](https://arxiv.org/abs/2309.14137) (NIPS)
- [ ] [\[2309.14162\] Data Upcycling Knowledge Distillation for Image Super-Resolution](https://arxiv.org/abs/2309.14162) (HKUST)
- [ ] [\[2309.14183\] Species196: A One-Million Semi-supervised Dataset for Fine-grained Species Recognition](https://arxiv.org/abs/2309.14183) (NIPS)
- [ ] [\[2309.14203\] Detecting and Grounding Multi-Modal Media Manipulation and Beyond](https://arxiv.org/abs/2309.14203) (HIT, CVPR)
- [ ] [\[2309.14207\] Automatic Animation of Hair Blowing in Still Portrait Photos](https://arxiv.org/abs/2309.14207) (Peking, ICCV)
- [ ] [\[2309.14241\] Informative Data Mining for One-Shot Cross-Domain Semantic Segmentation](https://arxiv.org/abs/2309.14241) (IA CAS, ICCV)
- [ ] [\[2309.14282\] Calibration-based Dual Prototypical Contrastive Learning Approach for Domain Generalization Semantic Segmentation](https://arxiv.org/abs/2309.14282) (ACMMM)
- [ ] [\[2309.14291\] Tiled Multiplane Images for Practical 3D Photography](https://arxiv.org/abs/2309.14291) (ICCV)
- [ ] [\[2309.14303\] Dataset Diffusion: Diffusion-based Synthetic Dataset Generation for Pixel-Level Semantic Segmentation](https://arxiv.org/abs/2309.14303) (NIPS)
- [ ] [\[2309.14304\] Overview of Class Activation Maps for Visualization Explainability](https://arxiv.org/abs/2309.14304) (QMUL)
- [ ] [\[2309.14309\] Multiple Different Black Box Explanations for Image Classifiers](https://arxiv.org/abs/2309.14309) (Oxford)
- [ ] [\[2309.14335\] UnitedHuman: Harnessing Multi-Source Data for High-Resolution Human Generation](https://arxiv.org/abs/2309.14335) (NTU, ICCV)
- [ ] [\[2309.14338\] 3D Indoor Instance Segmentation in an Open-World](https://arxiv.org/abs/2309.14338) (NIPS)
- [ ] [\[2309.14339\] Chop & Learn: Recognizing and Generating Object-State Compositions](https://arxiv.org/abs/2309.14339) (ICCV)
- [ ] [\[2309.14491\] Unsupervised 3D Perception with 2D Vision-Language Distillation for Autonomous Driving](https://arxiv.org/abs/2309.14491) (ICCV)
- [ ] [\[2309.14494\] Free-Bloom: Zero-Shot Text-to-Video Generator with LLM Director and LDM Animator](https://arxiv.org/abs/2309.14494) (ShanghaiTech, NIPS)
- [ ] [\[2309.14514\] Accurate and Interactive Visual-Inertial Sensor Calibration with Next-Best-View and Next-Best-Trajectory Suggestion](https://arxiv.org/abs/2309.14514) (TUM)
- [ ] [\[2309.14538\] Dynamic Scene Graph Representation for Surgical Video](https://arxiv.org/abs/2309.14538) (TUM)
- [ ] [\[2309.14600\] Progressive Text-to-3D Generation for Automatic 3D Prototyping](https://arxiv.org/abs/2309.14600) (XJTU)
- [ ] [\[2309.14616\] NDC-Scene: Boost Monocular 3D Semantic Scene Completion in Normalized Device Coordinates Space](https://arxiv.org/abs/2309.14616) (UW, ICCV)
- [ ] [\[2309.14622\] Divide and Conquer in Video Anomaly Detection: A Comprehensive Review and New Approach](https://arxiv.org/abs/2309.14622) (PolyU)
- [ ] [\[2309.14623\] Text-to-Image Generation for Abstract Concepts](https://arxiv.org/abs/2309.14623) (USTC)
- [ ] [\[2309.14700\] Structure Invariant Transformation for better Adversarial Transferability](https://arxiv.org/abs/2309.14700) (HUST, ICCV)
- [ ] [\[2309.14704\] Tile Classification Based Viewport Prediction with Multi-modal Fusion Transformer](https://arxiv.org/abs/2309.14704) (XJTU)
- [ ] [\[2309.14744\] ADU-Depth: Attention-based Distillation with Uncertainty Modeling for Depth Estimation](https://arxiv.org/abs/2309.14744) (Fudan)
- [ ] [\[2309.14753\] Advanced Volleyball Stats for All Levels: Automatic Setting Tactic Detection and Classification with a Single Camera](https://arxiv.org/abs/2309.14753) (Meta)
- [ ] [\[2309.14755\] Image Denoising via Style Disentanglement](https://arxiv.org/abs/2309.14755) (HUST)
- [ ] [\[2309.14800\] 3D Density-Gradient based Edge Detection on Neural Radiance Fields (NeRFs) for Geometric Reconstruction](https://arxiv.org/abs/2309.14800) (ISPRS)
- [ ] [\[2309.14819\] Discrepancy Matters: Learning from Inconsistent Decoder Features for Consistent Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2309.14819) (NWPU)
- [ ] [\[2309.14820\] Three-dimensional Tracking of a Large Number of High Dynamic Objects from Multiple Views using Current Statistical Model](https://arxiv.org/abs/2309.14820) (NUDT)
- [ ] [\[2309.14859\] Navigating Text-To-Image Customization: From LyCORIS Fine-Tuning to Model Evaluation](https://arxiv.org/abs/2309.14859) (ICLR)
- [ ] [\[2309.14872\] Directional Texture Editing for 3D Models](https://arxiv.org/abs/2309.14872) (Alibaba)
- [ ] [\[2309.14888\] Nearest Neighbor Guidance for Out-of-Distribution Detection](https://arxiv.org/abs/2309.14888) (ICCV)
- [ ] [\[2309.14900\] Pre-training-free Image Manipulation Localization through Non-Mutually Exclusive Contrastive Learning](https://arxiv.org/abs/2309.14900) (ICCV)
- [ ] [\[2309.14916\] PHRIT: Parametric Hand Representation with Implicit Template](https://arxiv.org/abs/2309.14916) (ICCV)
- [ ] [\[2309.14928\] Noise-Tolerant Few-Shot Unsupervised Adapter for Vision-Language Models](https://arxiv.org/abs/2309.14928) (MBZUAI)
- [ ] [\[2309.14962\] GridFormer: Towards Accurate Table Structure Recognition via Grid Prediction](https://arxiv.org/abs/2309.14962) (ACMMM)
- [ ] [\[2309.14972\] Improving Unsupervised Visual Program Inference with Code Rewriting Families](https://arxiv.org/abs/2309.14972) (ICCV)
- [ ] [\[2309.14991\] Robust Sequential DeepFake Detection](https://arxiv.org/abs/2309.14991) (HIT, ECCV)
- [ ] [\[2309.15082\] RPEFlow: Multimodal Fusion of RGB-PointCloud-Event for Joint Optical Flow and Scene Flow Estimation](https://arxiv.org/abs/2309.15082) (ICCV)
- [ ] [\[2309.15084\] The Surveillance AI Pipeline](https://arxiv.org/abs/2309.15084) (Stanford)
- [ ] [\[2309.15086\] Video-adverb retrieval with compositional adverb-action embeddings](https://arxiv.org/abs/2309.15086) (University of Tübingen)
- [ ] [\[2309.15109\] DistillBEV: Boosting Multi-Camera 3D Object Detection with Cross-Modal Knowledge Distillation](https://arxiv.org/abs/2309.15109) (ICCV)
- [ ] [\[2309.15110\] Doduo: Learning Dense Visual Correspondence from Unsupervised Semantic-Aware Flow](https://arxiv.org/abs/2309.15110) (UT Austin)
- [ ] [\[2309.15112\] InternLM-XComposer: A Vision-Language Large Model for Advanced Text-image Comprehension and Composition](https://arxiv.org/abs/2309.15112) (Shanghai AI Lab)
- [ ] [\[2309.15117\] Generating Visual Scenes from Touch](https://arxiv.org/abs/2309.15117) (ICCV)
- [ ] [\[2309.15204\] CLRmatchNet: Enhancing Curved Lane Detection with Deep Matching Process](https://arxiv.org/abs/2309.15204) (Tel Aviv)
- [ ] [\[2309.15251\] VPA: Fully Test-Time Visual Prompt Adaptation](https://arxiv.org/abs/2309.15251) (University of Michigan)
- [ ] [\[2309.15273\] DECO: Dense Estimation of 3D Human-Scene Contact In The Wild](https://arxiv.org/abs/2309.15273) (UVA.NL, ICCV)
- [ ] [\[2309.15275\] Efficient Low-rank Backpropagation for Vision Transformer Adaptation](https://arxiv.org/abs/2309.15275) (NIPS)
- [ ] [\[2309.15289\] SEPT: Towards Efficient Scene Representation Learning for Motion Prediction](https://arxiv.org/abs/2309.15289) (Tsinghua)
- [ ] [\[2309.15329\] BASED: Bundle-Adjusting Surgical Endoscopic Dynamic Video Reconstruction using Neural Radiance Fields](https://arxiv.org/abs/2309.15329) (UCSD)
- [ ] [\[2309.15426\] NeuRBF: A Neural Fields Representation with Adaptive Radial Basis Functions](https://arxiv.org/abs/2309.15426) (ShanghaiTech, ICCV)
- [ ] [\[2309.15431\] Local Compressed Video Stream Learning for Generic Event Boundary Detection](https://arxiv.org/abs/2309.15431) (IS CAS)
- [ ] [\[2309.15490\] Survey on Deep Face Restoration: From Non-blind to Blind and Beyond](https://arxiv.org/abs/2309.15490) (ETH)
- [ ] [\[2309.15493\] CauDR: A Causality-inspired Domain Generalization Framework for Fundus-based Diabetic Retinopathy Grading](https://arxiv.org/abs/2309.15493) (CUHK)
- [ ] [\[2309.15533\] Uncertainty Quantification via Neural Posterior Principal Components](https://arxiv.org/abs/2309.15533) (NIPS)
- [ ] [\[2309.15555\] Low Latency of object detection for spikng neural network](https://arxiv.org/abs/2309.15555) (BUPT)
- [ ] [\[2309.15556\] Learning Dense Flow Field for Highly-accurate Cross-view Camera Localization](https://arxiv.org/abs/2309.15556) (ShanghaiTech)
- [ ] [\[2309.15572\] HPL-ViT: A Unified Perception Framework for Heterogeneous Parallel LiDARs in V2V](https://arxiv.org/abs/2309.15572) (IA CAS)
- [ ] [\[2309.15575\] Confidence-based Visual Dispersal for Few-shot Unsupervised Domain Adaptation](https://arxiv.org/abs/2309.15575) (Tsinghua, ICCV)
- [ ] [\[2309.15627\] Neuromorphic Imaging and Classification with Graph Learning](https://arxiv.org/abs/2309.15627) (HKU)
- [ ] [\[2309.15662\] Human Kinematics-inspired Skeleton-based Video Anomaly Detection](https://arxiv.org/abs/2309.15662) (PolyU)
- [ ] [\[2309.15664\] Dynamic Prompt Learning: Addressing Cross-Attention Leakage for Text-Based Image Editing](https://arxiv.org/abs/2309.15664) (NIPS)
- [ ] [\[2309.15683\] End-to-End Streaming Video Temporal Action Segmentation with Reinforce Learning](https://arxiv.org/abs/2309.15683) (Tsinghua)
- [ ] [\[2309.15755\] CAIT: Triple-Win Compression towards High Accuracy, Fast Inference, and Favorable Transferability For ViTs](https://arxiv.org/abs/2309.15755) (Tsinghua)
- [ ] [\[2309.15812\] Convolutional Networks with Oriented 1D Kernels](https://arxiv.org/abs/2309.15812) (CMU)
- [ ] [\[2309.15830\] OrthoPlanes: A Novel Representation for Better 3D-Awareness of GANs](https://arxiv.org/abs/2309.15830) (Tsinghua)
- [ ] [\[2309.15848\] SHACIRA: Scalable HAsh-grid Compression for Implicit Neural Representations](https://arxiv.org/abs/2309.15848) (UMD)
- [ ] [\[2309.15883\] Highly Efficient SNNs for High-speed Object Detection](https://arxiv.org/abs/2309.15883) (BUPT)
- [ ] [\[2309.15941\] AutoEncoding Tree for City Generation and Applications](https://arxiv.org/abs/2309.15941) (NYU)
- [ ] [\[2309.16019\] GasMono: Geometry-Aided Self-Supervised Monocular Depth Estimation for Indoor Scenes](https://arxiv.org/abs/2309.16019) (ICCV)
- [ ] [\[2309.16020\] GeoCLIP: Clip-Inspired Alignment between Locations and Images for Effective Worldwide Geo-localization](https://arxiv.org/abs/2309.16020) (NIPS)
- [ ] [\[2309.16127\] Open Compound Domain Adaptation with Object Style Compensation for Semantic Segmentation](https://arxiv.org/abs/2309.16127) (Tsinghua)
- [ ] [\[2309.16137\] Context-I2W: Mapping Images to Context-dependent Words for Accurate Zero-Shot Composed Image Retrieval](https://arxiv.org/abs/2309.16137) (BIT)
- [ ] [\[2309.16139\] Two-Step Active Learning for Instance Segmentation with Uncertainty and Diversity Sampling](https://arxiv.org/abs/2309.16139) (Google, ICCV)
- [ ] [\[2309.16141\] Align before Search: Aligning Ads Image to Text for Accurate Cross-Modal Sponsored Search](https://arxiv.org/abs/2309.16141) (BIT)
- [ ] [\[2309.16179\] BEVHeight++: Toward Robust Visual Centric 3D Object Detection](https://arxiv.org/abs/2309.16179) (Tsinghua)
- [ ] [\[2309.16189\] Cloth2Body: Generating 3D Human Body Mesh from 2D Clothing](https://arxiv.org/abs/2309.16189) (HKUST, ICCV)
- [ ] [\[2309.16207\] Parameter-Saving Adversarial Training: Reinforcing Multi-Perturbation Robustness via Hypernetworks](https://arxiv.org/abs/2309.16207) (USyd)
- [ ] [\[2309.16211\] VDC: Versatile Data Cleanser based on Visual-Linguistic Inconsistency by Multimodal Large Language Models](https://arxiv.org/abs/2309.16211) (ICLR)
- [ ] [\[2309.16217\] GAFlow: Incorporating Gaussian Attention into Optical Flow](https://arxiv.org/abs/2309.16217) (ICCV)
- [ ] [\[2309.16237\] Object Motion Guided Human Motion Synthesis](https://arxiv.org/abs/2309.16237) (Stanford, SIGGRAPH)
- [ ] [\[2309.16249\] FORB: A Flat Object Retrieval Benchmark for Universal Image Embedding](https://arxiv.org/abs/2309.16249) (NIPS)
- [ ] [\[2309.16283\] Self-supervised Cross-view Representation Reconstruction for Change Captioning](https://arxiv.org/abs/2309.16283) (UCAS, ICCV)
- [ ] [\[2309.16301\] Gated Cross-Attention Network for Depth Completion](https://arxiv.org/abs/2309.16301) (NUDT)
- [ ] [\[2309.16372\] Aperture Diffraction for Compact Snapshot Spectral Imaging](https://arxiv.org/abs/2309.16372) (ICCV)
- [ ] [\[2309.16388\] Exposing Image Splicing Traces in Scientific Publications via Uncertainty-guided Refinement](https://arxiv.org/abs/2309.16388) (BU)
- [ ] [\[2309.16393\] HIC-YOLOv5: Improved YOLOv5 For Small Object Detection](https://arxiv.org/abs/2309.16393) (HKUST)
- [ ] [\[2309.16414\] AutoCLIP: Auto-tuning Zero-Shot Classifiers for Vision-Language Models](https://arxiv.org/abs/2309.16414) (Bosch)
- [ ] [\[2309.16460\] Diverse Target and Contribution Scheduling for Domain Generalization](https://arxiv.org/abs/2309.16460) (SJTU)
- [ ] [\[2309.16483\] Rethinking Domain Generalization: Discriminability and Generalizability](https://arxiv.org/abs/2309.16483) (SJTU)
- [ ] [\[2309.16486\] HTC-DC Net: Monocular Height Estimation from Single Remote Sensing Images](https://arxiv.org/abs/2309.16486) (TUM)
- [ ] [\[2309.16494\] Accurate and lightweight dehazing via multi-receptive-field non-local network and novel contrastive regularization](https://arxiv.org/abs/2309.16494) (ZJU)
- [ ] [\[2309.16495\] Deep Single Models vs. Ensembles: Insights for a Fast Deployment of Parking Monitoring Systems](https://arxiv.org/abs/2309.16495) (ICML)
- [ ] [\[2309.16499\] Cross-City Matters: A Multimodal Remote Sensing Benchmark Dataset for Cross-City Semantic Segmentation using High-Resolution Domain Adaptation Networks](https://arxiv.org/abs/2309.16499) (TUM)
- [ ] [\[2309.16515\] Latent Noise Segmentation: How Neural Noise Leads to the Emergence of Segmentation and Grouping](https://arxiv.org/abs/2309.16515) (EPFL)
- [ ] [\[2309.16534\] MotionLM: Multi-Agent Motion Forecasting as Language Modeling](https://arxiv.org/abs/2309.16534) (ICCV)
- [ ] [\[2309.16553\] MatrixCity: A Large-scale City Dataset for City-scale Neural Rendering and Beyond](https://arxiv.org/abs/2309.16553) (ICCV)
- [ ] [\[2309.16585\] Text-to-3D using Gaussian Splatting](https://arxiv.org/abs/2309.16585) (Tsinghua, CVPR)
- [ ] [\[2309.16588\] Vision Transformers Need Registers](https://arxiv.org/abs/2309.16588) (Meta)
- [ ] [\[2309.16592\] Tensor Factorization for Leveraging Cross-Modal Knowledge in Data-Constrained Infrared Object Detection](https://arxiv.org/abs/2309.16592) (Rochester Institute of Technology)
- [ ] [\[2309.16643\] Deep Geometrized Cartoon Line Inbetweening](https://arxiv.org/abs/2309.16643) (UCLA, ICCV)
- [ ] [\[2309.16646\] Improving Equivariance in State-of-the-Art Supervised Depth and Normal Predictors](https://arxiv.org/abs/2309.16646) (ICCV)
- [ ] [\[2309.16649\] FLIP: Cross-domain Face Anti-spoofing with Language Guidance](https://arxiv.org/abs/2309.16649) (ICCV)
- [ ] [\[2309.16661\] SA2-Net: Scale-aware Attention Network for Microscopic Image Segmentation](https://arxiv.org/abs/2309.16661) (MBZUAI)
- [ ] [\[2309.16668\] RealFill: Reference-Driven Generation for Authentic Image Completion](https://arxiv.org/abs/2309.16668) (Cornell, SIGGRAPH)
- [ ] [\[2309.16670\] Decaf: Monocular Deformation Capture for Face and Hand Interactions](https://arxiv.org/abs/2309.16670) (MPI)
- [ ] [\[2309.16672\] Learning to Transform for Generalizable Instance-wise Invariance](https://arxiv.org/abs/2309.16672) (ICCV)
- [ ] [\[2309.16715\] MV-DeepSDF: Implicit Modeling with Multi-Sweep Point Clouds for 3D Vehicle Reconstruction in Autonomous Driving](https://arxiv.org/abs/2309.16715) (University of Toronto)
- [ ] [\[2309.16772\] XVO: Generalized Visual Odometry via Cross-Modal Self-Training](https://arxiv.org/abs/2309.16772) (ICCV)
- [ ] [\[2309.16779\] Intriguing properties of generative classifiers](https://arxiv.org/abs/2309.16779) (ICLR)
- [ ] [\[2309.16850\] Sketch2CADScript: 3D Scene Reconstruction from 2D Sketch using Visual Transformer and Rhino Grasshopper](https://arxiv.org/abs/2309.16850) (EPFL)
- [ ] [\[2309.16859\] Preface: A Data-driven Volumetric Prior for Few-shot Ultra High-resolution Face Synthesis](https://arxiv.org/abs/2309.16859) (ICCV)
- [ ] [\[2309.16902\] Investigating Shift Equivalence of Convolutional Neural Networks in Industrial Defect Segmentation](https://arxiv.org/abs/2309.16902) (IA CAS)
- [ ] [\[2309.16924\] Incremental Rotation Averaging Revisited and More: A New Rotation Averaging Benchmark](https://arxiv.org/abs/2309.16924) (IA CAS)
- [ ] [\[2309.16936\] PC-Adapter: Topology-Aware Adapter for Efficient Domain Adaption on Point Clouds with Rectified Pseudo-label](https://arxiv.org/abs/2309.16936) (KAIST, ICCV)
- [ ] [\[2309.16940\] Asynchrony-Robust Collaborative Perception via Bird's Eye View Flow](https://arxiv.org/abs/2309.16940) (NIPS)
- [ ] [\[2309.16949\] CrossZoom: Simultaneously Motion Deblurring and Event Super-Resolving](https://arxiv.org/abs/2309.16949) (ETH)
- [ ] [\[2309.16964\] AdaPose: Towards Cross-Site Device-Free Human Pose Estimation with Commodity WiFi](https://arxiv.org/abs/2309.16964) (NTU)
- [ ] [\[2309.16968\] Synthetic Data Generation and Deep Learning for the Topological Analysis of 3D Data](https://arxiv.org/abs/2309.16968) (MIT)
- [ ] [\[2309.16975\] Perceptual Tone Mapping Model for High Dynamic Range Imaging](https://arxiv.org/abs/2309.16975) (ZJU)
- [ ] [\[2309.16987\] SpikeMOT: Event-based Multi-Object Tracking with Sparse Motion Features](https://arxiv.org/abs/2309.16987) (HKU)
- [ ] [\[2309.16992\] Segment Anything Model is a Good Teacher for Local Feature Learning](https://arxiv.org/abs/2309.16992) (IA CAS)
- [ ] [\[2309.17024\] HoloAssist: an Egocentric Human Interaction Dataset for Interactive AI Assistants in the Real World](https://arxiv.org/abs/2309.17024) (ICCV)
- [ ] [\[2309.17031\] Scalable Multi-Temporal Remote Sensing Change Data Generation via Simulating Stochastic Change Process](https://arxiv.org/abs/2309.17031) (WHU, ICCV)
- [ ] [\[2309.17051\] On Uniform Scalar Quantization for Learned Image Compression](https://arxiv.org/abs/2309.17051) (USTC)
- [ ] [\[2309.17059\] GSDC Transformer: An Efficient and Effective Cue Fusion for Monocular Multi-Frame Depth Estimation](https://arxiv.org/abs/2309.17059) (ZJU)
- [ ] [\[2309.17083\] SegRCDB: Semantic Segmentation via Formula-Driven Supervised Learning](https://arxiv.org/abs/2309.17083) (ICCV)
- [ ] [\[2309.17093\] Prototype-based Aleatoric Uncertainty Quantification for Cross-modal Retrieval](https://arxiv.org/abs/2309.17093) (UESTC, NIPS)
- [ ] [\[2309.17102\] Guiding Instruction-based Image Editing via Multimodal Large Language Models](https://arxiv.org/abs/2309.17102) (ICLR)
- [ ] [\[2309.17105\] Continual Action Assessment via Task-Consistent Score-Discriminative Feature Distribution Modeling](https://arxiv.org/abs/2309.17105) (SYSU)
- [ ] [\[2309.17128\] HAvatar: High-fidelity Head Avatar via Facial Model Conditioned Neural Radiance Field](https://arxiv.org/abs/2309.17128) (Tsinghua)
- [ ] [\[2309.17175\] TextField3D: Towards Enhancing Open-Vocabulary 3D Generation with Noisy Text Fields](https://arxiv.org/abs/2309.17175) (HIT, ICLR)
- [ ] [\[2309.17187\] TBD Pedestrian Data Collection: Towards Rich, Portable, and Large-Scale Natural Pedestrian Data](https://arxiv.org/abs/2309.17187) (CMU)
- [ ] [\[2309.17190\] PARF: Primitive-Aware Radiance Fusion for Indoor Scene Novel View Synthesis](https://arxiv.org/abs/2309.17190) (Tsinghua, ICCV)
- [ ] [\[2309.17218\] When Epipolar Constraint Meets Non-local Operators in Multi-View Stereo](https://arxiv.org/abs/2309.17218) (ICCV)
- [ ] [\[2309.17239\] EGVD: Event-Guided Video Deraining](https://arxiv.org/abs/2309.17239) (USTC)
- [ ] [\[2309.17257\] A Survey on Deep Learning Techniques for Action Anticipation](https://arxiv.org/abs/2309.17257) (TPAMI)
- [ ] [\[2309.17281\] Information Flow in Self-Supervised Learning](https://arxiv.org/abs/2309.17281) (Tsinghua, ICML)
- [ ] [\[2309.17327\] Telling Stories for Common Sense Zero-Shot Action Recognition](https://arxiv.org/abs/2309.17327) (Oxford)
- [ ] [\[2309.17329\] Efficient Anatomical Labeling of Pulmonary Tree Structures via Implicit Point-Graph Networks](https://arxiv.org/abs/2309.17329) (EPFL)
- [ ] [\[2309.17336\] Robust 3D Object Detection from LiDAR-Radar Point Clouds via Cross-Modal Feature Augmentation](https://arxiv.org/abs/2309.17336) (UCL)
- [ ] [\[2309.17342\] Towards Free Data Selection with General-Purpose Models](https://arxiv.org/abs/2309.17342) (NIPS)
- [ ] [\[2309.17390\] Forward Flow for Novel View Synthesis of Dynamic Scenes](https://arxiv.org/abs/2309.17390) (NWPU, ICCV)
- [ ] [\[2309.17400\] Directly Fine-Tuning Diffusion Models on Differentiable Rewards](https://arxiv.org/abs/2309.17400) (ICLR)
- [ ] [\[2309.17430\] FACTS: First Amplify Correlations and Then Slice to Discover Bias](https://arxiv.org/abs/2309.17430) (ICCV)
- [ ] [\[2309.17444\] LLM-grounded Video Diffusion Models](https://arxiv.org/abs/2309.17444) (ICLR)
- [ ] [\[2309.17450\] Multi-task View Synthesis with Neural Radiance Fields](https://arxiv.org/abs/2309.17450) (ICCV)
- [ ] [\[2310.00093\] DataDAM: Efficient Dataset Distillation with Attention Matching](https://arxiv.org/abs/2310.00093) (ICCV)
- [ ] [\[2310.00119\] Fewshot learning on global multimodal embeddings for earth observation tasks](https://arxiv.org/abs/2310.00119) (Cambridge)
- [ ] [\[2310.00158\] Feedback-guided Data Synthesis for Imbalanced Classification](https://arxiv.org/abs/2310.00158) (Meta)
- [ ] [\[2310.00161\] Region-centric Image-Language Pretraining for Open-Vocabulary Detection](https://arxiv.org/abs/2310.00161) (ECCV)
- [ ] [\[2310.00164\] PRIME: Prioritizing Interpretability in Failure Mode Extraction](https://arxiv.org/abs/2310.00164) (ICLR)
- [ ] [\[2310.00224\] Steered Diffusion: A Generalized Framework for Plug-and-Play Conditional Image Synthesis](https://arxiv.org/abs/2310.00224) (ICCV)
- [ ] [\[2310.00240\] Learning Mask-aware CLIP Representations for Zero-Shot Segmentation](https://arxiv.org/abs/2310.00240) (NIPS)
- [ ] [\[2310.00249\] MMPI: a Flexible Radiance Field Representation by Multiple Multi-plane Images Blending](https://arxiv.org/abs/2310.00249) (Tsinghua)
- [ ] [\[2310.00258\] NAYER: Noisy Layer Data Generation for Efficient and Effective Data-free Knowledge Distillation](https://arxiv.org/abs/2310.00258) (CVPR)
- [ ] [\[2310.00296\] QUIZ: An Arbitrary Volumetric Point Matching Method for Medical Image Registration](https://arxiv.org/abs/2310.00296) (Stanford)
- [ ] [\[2310.00318\] Decoding Realistic Images from Brain Activity with Contrastive Self-supervision and Latent Diffusion](https://arxiv.org/abs/2310.00318) (KU Leuven)
- [ ] [\[2310.00362\] Diffusion Posterior Illumination for Ambiguity-aware Inverse Rendering](https://arxiv.org/abs/2310.00362) (MPI, SIGGRAPH)
- [ ] [\[2310.00390\] InstructCV: Instruction-Tuned Text-to-Image Diffusion Models as Vision Generalists](https://arxiv.org/abs/2310.00390) (ICLR)
- [ ] [\[2310.00413\] SSIF: Learning Continuous Image Representation for Spatial-Spectral Super-Resolution](https://arxiv.org/abs/2310.00413) (Stanford)
- [ ] [\[2310.00426\] PixArt-$\alpha$: Fast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis](https://arxiv.org/abs/2310.00426) (HKU)
- [ ] [\[2310.00434\] DiffPoseTalk: Speech-Driven Stylistic 3D Facial Animation and Head Pose Generation via Diffusion Models](https://arxiv.org/abs/2310.00434) (Tsinghua, SIGGRAPH)
- [ ] [\[2310.00438\] Human-Producible Adversarial Examples](https://arxiv.org/abs/2310.00438) (Oxford, ICLR)
- [ ] [\[2310.00454\] SimLVSeg: Simplifying Left Ventricular Segmentation in 2D+Time Echocardiograms with Self- and Weakly-Supervised Learning](https://arxiv.org/abs/2310.00454) (MBZUAI)
- [ ] [\[2310.00582\] Pink: Unveiling the Power of Referential Comprehension for Multi-modal LLMs](https://arxiv.org/abs/2310.00582) (Peking)
- [ ] [\[2310.00615\] Scene-aware Human Motion Forecasting via Mutual Distance Prediction](https://arxiv.org/abs/2310.00615) (ECCV)
- [ ] [\[2310.00626\] GhostEncoder: Stealthy Backdoor Attacks with Dynamic Triggers to Pre-trained Encoders in Self-supervised Learning](https://arxiv.org/abs/2310.00626) (WHU)
- [ ] [\[2310.00632\] Win-Win: Training High-Resolution Vision Transformers from Two Windows](https://arxiv.org/abs/2310.00632) (ICLR)
- [ ] [\[2310.00647\] Beyond Task Performance: Evaluating and Reducing the Flaws of Large Multimodal Models with In-Context Learning](https://arxiv.org/abs/2310.00647) (ICLR)
- [ ] [\[2310.00698\] Comics for Everyone: Generating Accessible Text Descriptions for Comic Strips](https://arxiv.org/abs/2310.00698) (Microsoft)
- [ ] [\[2310.00702\] You Do Not Need Additional Priors in Camouflage Object Detection](https://arxiv.org/abs/2310.00702) (Xidian)
- [ ] [\[2310.00723\] HOH: Markerless Multimodal Human-Object-Human Handover Dataset with Large Object Count](https://arxiv.org/abs/2310.00723) (NIPS)
- [ ] [\[2310.00761\] Counterfactual Image Generation for adversarially robust and interpretable Classifiers](https://arxiv.org/abs/2310.00761) (ETH)
- [ ] [\[2310.00826\] Large Scale Masked Autoencoding for Reducing Label Requirements on SAR Data](https://arxiv.org/abs/2310.00826) (Cambridge)
- [ ] [\[2310.00874\] PC-NeRF: Parent-Child Neural Radiance Fields under Partial Sensor Data Loss in Autonomous Driving Environments](https://arxiv.org/abs/2310.00874) (BIT)
- [ ] [\[2310.00920\] Every Dataset Counts: Scaling up Monocular 3D Object Detection with Joint Datasets Training](https://arxiv.org/abs/2310.00920) (HKUST)
- [ ] [\[2310.00936\] Trained Latent Space Navigation to Prevent Lack of Photorealism in Generated Images on Style-based Models](https://arxiv.org/abs/2310.00936) (University of Tokyo)
- [ ] [\[2310.01018\] Controlling Vision-Language Models for Multi-Task Image Restoration](https://arxiv.org/abs/2310.01018) (ICLR)
- [ ] [\[2310.01107\] Ground-A-Video: Zero-shot Grounded Video Editing using Text-to-image Diffusion Models](https://arxiv.org/abs/2310.01107) (ICLR)
- [ ] [\[2310.01140\] Neural Processing of Tri-Plane Hybrid Neural Fields](https://arxiv.org/abs/2310.01140) (ICLR)
- [ ] [\[2310.01164\] Segment Any Building](https://arxiv.org/abs/2310.01164) (University of Copenhagen)
- [ ] [\[2310.01251\] Generating 3D Brain Tumor Regions in MRI using Vector-Quantization Generative Adversarial Networks](https://arxiv.org/abs/2310.01251) (University of Toronto)
- [ ] [\[2310.01292\] Efficient Remote Sensing Segmentation With Generative Adversarial Transformer](https://arxiv.org/abs/2310.01292) (UESTC)
- [ ] [\[2310.01324\] ZeroI2V: Zero-Cost Adaptation of Pre-trained Transformers from Image to Video](https://arxiv.org/abs/2310.01324) (NJU, ECCV)
- [ ] [\[2310.01330\] Towards reporting bias in visual-language datasets: bimodal augmentation by decoupling object-attribute association](https://arxiv.org/abs/2310.01330) (University of Tokyo)
- [ ] [\[2310.01376\] Towards Distribution-Agnostic Generalized Category Discovery](https://arxiv.org/abs/2310.01376) (ZJU, NIPS)
- [ ] [\[2310.01400\] Sequential Data Generation with Groupwise Diffusion Process](https://arxiv.org/abs/2310.01400) (CMU)
- [ ] [\[2310.01401\] Pixel-Aligned Recurrent Queries for Multi-View 3D Object Detection](https://arxiv.org/abs/2310.01401) (ICCV)
- [ ] [\[2310.01403\] CLIPSelf: Vision Transformer Distills Itself for Open-Vocabulary Dense Prediction](https://arxiv.org/abs/2310.01403) (NTU)
- [ ] [\[2310.01449\] Elastic Interaction Energy-Informed Real-Time Traffic Scene Perception](https://arxiv.org/abs/2310.01449) (HKUST)
- [ ] [\[2310.01596\] ImagenHub: Standardizing the evaluation of conditional image generation models](https://arxiv.org/abs/2310.01596) (ICLR)
- [ ] [\[2310.01667\] STARS: Zero-shot Sim-to-Real Transfer for Segmentation of Shipwrecks in Sonar Imagery](https://arxiv.org/abs/2310.01667) (University of Michigan)
- [ ] [\[2310.01680\] Keypoint-Augmented Self-Supervised Learning for Medical Image Segmentation with Limited Annotation](https://arxiv.org/abs/2310.01680) (NYU, NIPS)
- [ ] [\[2310.01755\] ImageNet-OOD: Deciphering Modern Out-of-Distribution Detection Algorithms](https://arxiv.org/abs/2310.01755) (ICLR)
- [ ] [\[2310.01806\] Improvement and Enhancement of YOLOv5 Small Target Recognition Based on Multi-module Optimization](https://arxiv.org/abs/2310.01806) (XJTU)
- [ ] [\[2310.01819\] TP2O: Creative Text Pair-to-Object Generation using Balance Swap-Sampling](https://arxiv.org/abs/2310.01819) (ECCV)
- [ ] [\[2310.01821\] MIMO-NeRF: Fast Neural Rendering with Multi-input Multi-output Neural Radiance Fields](https://arxiv.org/abs/2310.01821) (ICCV)
- [ ] [\[2310.01830\] AI-Generated Images as Data Source: The Dawn of Synthetic Era](https://arxiv.org/abs/2310.01830) (NTU)
- [ ] [\[2310.01840\] Self-Supervised High Dynamic Range Imaging with Multi-Exposure Images in Dynamic Scenes](https://arxiv.org/abs/2310.01840) (HIT, ICLR)
- [ ] [\[2310.01852\] LanguageBind: Extending Video-Language Pretraining to N-modality by Language-based Semantic Alignment](https://arxiv.org/abs/2310.01852) (ICLR)
- [ ] [\[2310.01876\] A Dual Attentive Generative Adversarial Network for Remote Sensing Image Change Detection](https://arxiv.org/abs/2310.01876) (SJTU)
- [ ] [\[2310.01926\] DARTH: Holistic Test-time Adaptation for Multiple Object Tracking](https://arxiv.org/abs/2310.01926) (ETH, ICCV)
- [ ] [\[2310.01994\] Understanding Masked Autoencoders From a Local Contrastive Perspective](https://arxiv.org/abs/2310.01994) (Shanghai AI Lab)
- [ ] [\[2310.02048\] Exploring Generalisability of Self-Distillation with No Labels for SAR-Based Vegetation Prediction](https://arxiv.org/abs/2310.02048) (Cambridge)
- [ ] [\[2310.02110\] Sieve: Multimodal Dataset Pruning Using Image Captioning Models](https://arxiv.org/abs/2310.02110) (CVPR)
- [ ] [\[2310.02242\] Hierarchical Generation of Human-Object Interactions with Diffusion Probabilistic Models](https://arxiv.org/abs/2310.02242) (ICCV)
- [ ] [\[2310.02255\] MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts](https://arxiv.org/abs/2310.02255) (ICLR)
- [ ] [\[2310.02262\] RSRD: A Road Surface Reconstruction Dataset and Benchmark for Safe and Comfortable Autonomous Driving](https://arxiv.org/abs/2310.02262) (Tsinghua)
- [ ] [\[2310.02265\] DREAM: Visual Decoding from Reversing Human Visual System](https://arxiv.org/abs/2310.02265) (Inria)
- [ ] [\[2310.02386\] ScaleNet: An Unsupervised Representation Learning Method for Limited Information](https://arxiv.org/abs/2310.02386) (GIT)
- [ ] [\[2310.02401\] FT-Shield: A Watermark Against Unauthorized Fine-tuning in Text-to-Image Diffusion Models](https://arxiv.org/abs/2310.02401) (PolyU)
- [ ] [\[2310.02437\] EvDNeRF: Reconstructing Event Data with Dynamic Neural Radiance Fields](https://arxiv.org/abs/2310.02437) (Microsoft)
- [ ] [\[2310.02492\] FairVision: Equitable Deep Learning for Eye Disease Screening via Fair Identity Scaling](https://arxiv.org/abs/2310.02492) (Yale)
- [ ] [\[2310.02528\] On the Cognition of Visual Question Answering Models and Human Intelligence: A Comparative Study](https://arxiv.org/abs/2310.02528) (NYU)
- [ ] [\[2310.02557\] Generalization in diffusion models arises from geometry-adaptive harmonic representations](https://arxiv.org/abs/2310.02557) (NYU, ICLR)
- [ ] [\[2310.02569\] ReForm-Eval: Evaluating Large Vision Language Models via Unified Re-Formulation of Task-Oriented Benchmarks](https://arxiv.org/abs/2310.02569) (Fudan)
- [ ] [\[2310.02576\] A Prototype-Based Neural Network for Image Anomaly Detection and Localization](https://arxiv.org/abs/2310.02576) (UESTC)
- [ ] [\[2310.02596\] SweetDreamer: Aligning Geometric Priors in 2D Diffusion for Consistent Text-to-3D](https://arxiv.org/abs/2310.02596) (HKUST)
- [ ] [\[2310.02601\] MagicDrive: Street View Generation with Diverse 3D Geometry Control](https://arxiv.org/abs/2310.02601) (HKUST)
- [ ] [\[2310.02642\] GET: Group Event Transformer for Event-Based Vision](https://arxiv.org/abs/2310.02642) (USTC, ICCV)
- [ ] [\[2310.02674\] ObjFormer: Learning Land-Cover Changes From Paired OSM Data and Optical High-Resolution Imagery via Object-Guided Transformer](https://arxiv.org/abs/2310.02674) (University of Tokyo)
- [ ] [\[2310.02687\] USB-NeRF: Unrolling Shutter Bundle Adjusted Neural Radiance Fields](https://arxiv.org/abs/2310.02687) (ETH)
- [ ] [\[2310.02712\] ED-NeRF: Efficient Text-Guided Editing of 3D Scene with Latent Space NeRF](https://arxiv.org/abs/2310.02712) (ICLR)
- [ ] [\[2310.02714\] GETAvatar: Generative Textured Meshes for Animatable Human Avatars](https://arxiv.org/abs/2310.02714) (ICCV)
- [ ] [\[2310.02815\] CoBEV: Elevating Roadside 3D Object Detection with Depth and Height Complementarity](https://arxiv.org/abs/2310.02815) (ZJU)
- [ ] [\[2310.02848\] Magicremover: Tuning-free Text-guided Image inpainting with Diffusion Models](https://arxiv.org/abs/2310.02848) (Tsinghua)
- [ ] [\[2310.02887\] A Grammatical Compositional Model for Video Action Detection](https://arxiv.org/abs/2310.02887) (HUST)
- [ ] [\[2310.02894\] Human-centric Behavior Description in Videos: New Benchmark and Model](https://arxiv.org/abs/2310.02894) (NWPU)
- [ ] [\[2310.02960\] CoDA: Collaborative Novel Box Discovery and Cross-modal Alignment for Open-vocabulary 3D Object Detection](https://arxiv.org/abs/2310.02960) (NIPS)
- [ ] [\[2310.02977\] T$^3$Bench: Benchmarking Current Progress in Text-to-3D Generation](https://arxiv.org/abs/2310.02977) (Tsinghua)
- [ ] [\[2310.02998\] ECoFLaP: Efficient Coarse-to-Fine Layer-Wise Pruning for Vision-Language Models](https://arxiv.org/abs/2310.02998) (ICLR)
- [ ] [\[2310.03125\] Shielding the Unseen: Privacy Protection through Poisoning NeRF with Spatial Deformation](https://arxiv.org/abs/2310.03125) (UMD)
- [ ] [\[2310.03270\] EfficientDM: Efficient Quantization-Aware Fine-Tuning of Low-Bit Diffusion Models](https://arxiv.org/abs/2310.03270) (ICLR)
- [ ] [\[2310.03288\] PoseAction: Action Recognition for Patients in the Ward using Deep Learning Approaches](https://arxiv.org/abs/2310.03288) (NUS)
- [ ] [\[2310.03295\] Can pre-trained models assist in dataset distillation?](https://arxiv.org/abs/2310.03295) (NUS)
- [ ] [\[2310.03337\] Denoising Diffusion Step-aware Models](https://arxiv.org/abs/2310.03337) (ICLR)
- [ ] [\[2310.03360\] CSI: Enhancing the Robustness of 3D Point Cloud Recognition against Corruption](https://arxiv.org/abs/2310.03360) (Peking)
- [ ] [\[2310.03363\] Realistic Speech-to-Face Generation with Speech-Conditioned Latent Diffusion Model with Face Prior](https://arxiv.org/abs/2310.03363) (HKUST(GZ))
- [ ] [\[2310.03375\] Point-Based Radiance Fields for Controllable Human Motion Synthesis](https://arxiv.org/abs/2310.03375) (ETH)
- [ ] [\[2310.03377\] ACT-Net: Anchor-context Action Detection in Surgery Videos](https://arxiv.org/abs/2310.03377) (SUSTech)
- [ ] [\[2310.03420\] FreeReg: Image-to-Point Cloud Registration Leveraging Pretrained Diffusion Models and Monocular Depth Estimators](https://arxiv.org/abs/2310.03420) (HKU, ICLR)
- [ ] [\[2310.03431\] Robust Zero Level-Set Extraction from Unsigned Distance Fields Based on Double Covering](https://arxiv.org/abs/2310.03431) (NTU, SIGGRAPH)
- [ ] [\[2310.03432\] Mitigating the Influence of Domain Shift in Skin Lesion Classification: A Benchmark Study of Unsupervised Domain Adaptation Methods on Dermoscopic Images](https://arxiv.org/abs/2310.03432) (DLR)
- [ ] [\[2310.03507\] RL-based Stateful Neural Adaptive Sampling and Denoising for Real-Time Path Tracing](https://arxiv.org/abs/2310.03507) (NIPS)
- [ ] [\[2310.03513\] Exploring DINO: Emergent Properties and Limitations for Synthetic Aperture Radar Imagery](https://arxiv.org/abs/2310.03513) (Cambridge)
- [ ] [\[2310.03525\] V2X Cooperative Perception for Autonomous Driving: Recent Advances and Challenges](https://arxiv.org/abs/2310.03525) (A*STAR,)
- [ ] [\[2310.03534\] 3D-Aware Hypothesis & Verification for Generalizable Relative Object Pose Estimation](https://arxiv.org/abs/2310.03534) (EPFL)
- [ ] [\[2310.03624\] High-Degrees-of-Freedom Dynamic Neural Fields for Robot Self-Modeling and Motion Planning](https://arxiv.org/abs/2310.03624) (Columbia University)
- [ ] [\[2310.03661\] Robustness-Guided Image Synthesis for Data-Free Quantization](https://arxiv.org/abs/2310.03661) (ZJU)
- [ ] [\[2310.03669\] LumiNet: The Bright Side of Perceptual Knowledge Distillation](https://arxiv.org/abs/2310.03669) (AWS)
- [ ] [\[2310.03670\] Regress Before Construct: Regress Autoencoder for Point Cloud Self-supervised Learning](https://arxiv.org/abs/2310.03670) (Peking)
- [ ] [\[2310.03734\] Leveraging Unpaired Data for Vision-Language Generative Models via Cycle Consistency](https://arxiv.org/abs/2310.03734) (MIT)
- [ ] [\[2310.03740\] ContactGen: Generative Contact Modeling for Grasp Generation](https://arxiv.org/abs/2310.03740) (ICCV)
- [ ] [\[2310.03744\] Improved Baselines with Visual Instruction Tuning](https://arxiv.org/abs/2310.03744) (CVPR)
- [ ] [\[2310.03843\] Less is More: On the Feature Redundancy of Pretrained Models When Transferring to Few-shot Tasks](https://arxiv.org/abs/2310.03843) (HKU)
- [ ] [\[2310.03870\] Consistency Regularization Improves Placenta Segmentation in Fetal EPI MRI Time Series](https://arxiv.org/abs/2310.03870) (MIT)
- [ ] [\[2310.03956\] Gradient Descent Provably Solves Nonlinear Tomographic Reconstruction](https://arxiv.org/abs/2310.03956) (Berkeley)
- [ ] [\[2310.03959\] Towards Increasing the Robustness of Predictive Steering-Control Autonomous Navigation Systems Against Dash Cam Image Angle Perturbations Due to Pothole Encounters](https://arxiv.org/abs/2310.03959) (JHU)
- [ ] [\[2310.03967\] Sub-token ViT Embedding via Stochastic Resonance Transformers](https://arxiv.org/abs/2310.03967) (UCLA)
- [ ] [\[2310.04110\] Automated 3D Segmentation of Kidneys and Tumors in MICCAI KiTS 2023 Challenge](https://arxiv.org/abs/2310.04110) (NVIDIA)
- [ ] [\[2310.04122\] VI-Diff: Unpaired Visible-Infrared Translation Diffusion Model for Single Modality Labeled Visible-Infrared Person Re-identification](https://arxiv.org/abs/2310.04122) (IA CAS)
- [ ] [\[2310.04148\] Self-Supervised Neuron Segmentation with Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2310.04148) (USTC)
- [ ] [\[2310.04152\] Improving Neural Radiance Field using Near-Surface Sampling with Point Cloud Generation](https://arxiv.org/abs/2310.04152) (Sungkyunkwan University)
- [ ] [\[2310.04189\] Bridging the Gap between Human Motion and Action Semantics via Kinematic Phrases](https://arxiv.org/abs/2310.04189) (Stanford, ECCV)
- [ ] [\[2310.04247\] Semantic segmentation of longitudinal thermal images for identification of hot and cool spots in urban areas](https://arxiv.org/abs/2310.04247) (NUS)
- [ ] [\[2310.04311\] Distributed Deep Joint Source-Channel Coding with Decoder-Only Side Information](https://arxiv.org/abs/2310.04311) (ICML)
- [ ] [\[2310.04414\] CIFAR-10-Warehouse: Broad and More Realistic Testbeds in Model Generalization Analysis](https://arxiv.org/abs/2310.04414) (Queensland, ICLR)
- [ ] [\[2310.04416\] Alice Benchmarks: Connecting Real World Re-Identification with the Synthetic](https://arxiv.org/abs/2310.04416) (Tsinghua, ICLR)
- [ ] [\[2310.04432\] Training-free Linear Image Inverses via Flows](https://arxiv.org/abs/2310.04432) (CMU)
- [ ] [\[2310.04550\] Module-wise Adaptive Distillation for Multimodality Foundation Models](https://arxiv.org/abs/2310.04550) (GIT)
- [ ] [\[2310.04551\] MeSa: Masked, Geometric, and Supervised Pre-training for Monocular Depth Estimation](https://arxiv.org/abs/2310.04551) (NYU)
- [ ] [\[2310.04582\] Universal Humanoid Motion Representations for Physics-Based Control](https://arxiv.org/abs/2310.04582) (ICLR)
- [ ] [\[2310.04688\] PatchProto Networks for Few-shot Visual Anomaly Classification](https://arxiv.org/abs/2310.04688) (ZJU)
- [ ] [\[2310.04689\] SeeDS: Semantic Separable Diffusion Synthesizer for Zero-shot Food Detection](https://arxiv.org/abs/2310.04689) (ICT CAS, ACMMM)
- [ ] [\[2310.04714\] Generalized Robust Test-Time Adaptation in Continuous Dynamic Scenarios](https://arxiv.org/abs/2310.04714) (XJTU)
- [ ] [\[2310.04724\] Activate and Reject: Towards Safe Domain Generalization under Category Shift](https://arxiv.org/abs/2310.04724) (Xiamen, ICCV)
- [ ] [\[2310.04747\] Towards Dynamic and Small Objects Refinement for Unsupervised Domain Adaptative Nighttime Semantic Segmentation](https://arxiv.org/abs/2310.04747) (HKUST)
- [ ] [\[2310.04780\] IPMix: Label-Preserving Data Augmentation Method for Training Robust Classifiers](https://arxiv.org/abs/2310.04780) (NIPS)
- [ ] [\[2310.04991\] Video-Teller: Enhancing Cross-Modal Generation with Fusion and Decoupling](https://arxiv.org/abs/2310.04991) (IA CAS)
- [ ] [\[2310.04999\] Symmetrical Linguistic Feature Distillation with CLIP for Scene Text Recognition](https://arxiv.org/abs/2310.04999) (USTC, ACMMM)
- [ ] [\[2310.05010\] Building an Open-Vocabulary Video CLIP Model with Better Architectures, Optimization and Data](https://arxiv.org/abs/2310.05010) (Meta)
- [ ] [\[2310.05026\] Low-Resolution Self-Attention for Semantic Segmentation](https://arxiv.org/abs/2310.05026) (Nankai)
- [ ] [\[2310.05055\] FairTune: Optimizing Parameter Efficient Fine Tuning for Fairness in Medical Image Analysis](https://arxiv.org/abs/2310.05055) (ICLR)
- [ ] [\[2310.05056\] Open-Vocabulary Animal Keypoint Detection with Semantic-feature Matching](https://arxiv.org/abs/2310.05056) (XJTU)
- [ ] [\[2310.05058\] Learning Separable Hidden Unit Contributions for Speaker-Adaptive Lip-Reading](https://arxiv.org/abs/2310.05058) (UCAS)
- [ ] [\[2310.05060\] DeVAn: Dense Video Annotation for Video-Language Models](https://arxiv.org/abs/2310.05060) (Columbia University)
- [ ] [\[2310.05082\] Cross-head mutual Mean-Teaching for semi-supervised medical image segmentation](https://arxiv.org/abs/2310.05082) (BUPT)
- [ ] [\[2310.05107\] OV-PARTS: Towards Open-Vocabulary Part Segmentation](https://arxiv.org/abs/2310.05107) (HKU, NIPS)
- [ ] [\[2310.05109\] Lightweight In-Context Tuning for Multimodal Unified Models](https://arxiv.org/abs/2310.05109) (CUHK)
- [ ] [\[2310.05125\] Bidirectional Knowledge Reconfiguration for Lightweight Point Cloud Analysis](https://arxiv.org/abs/2310.05125) (BUPT)
- [ ] [\[2310.05133\] Geometry Aware Field-to-field Transformations for 3D Semantic Segmentation](https://arxiv.org/abs/2310.05133) (ETH)
- [ ] [\[2310.05192\] HOD: A Benchmark Dataset for Harmful Object Detection](https://arxiv.org/abs/2310.05192) (POSTECH)
- [ ] [\[2310.05193\] Improving Discriminative Multi-Modal Learning with Large-Scale Pre-Trained Models](https://arxiv.org/abs/2310.05193) (Tsinghua)
- [ ] [\[2310.05195\] GMMFormer: Gaussian-Mixture-Model Based Transformer for Efficient Partially Relevant Video Retrieval](https://arxiv.org/abs/2310.05195) (HIT)
- [ ] [\[2310.05202\] Enhancing Cross-Dataset Performance of Distracted Driving Detection With Score-Softmax Classifier](https://arxiv.org/abs/2310.05202) (UTS)
- [ ] [\[2310.05207\] Boosting Facial Action Unit Detection Through Jointly Learning Facial Landmark Detection and Domain Separation and Reconstruction](https://arxiv.org/abs/2310.05207) (HUST)
- [ ] [\[2310.05241\] SCANet: Scene Complexity Aware Network for Weakly-Supervised Video Moment Retrieval](https://arxiv.org/abs/2310.05241) (ICCV)
- [ ] [\[2310.05290\] MSight: An Edge-Cloud Infrastructure-based Perception System for Connected Automated Vehicles](https://arxiv.org/abs/2310.05290) (University of Michigan)
- [ ] [\[2310.05304\] GestSync: Determining who is speaking without a talking head](https://arxiv.org/abs/2310.05304) (Oxford)
- [ ] [\[2310.05316\] Understanding the Feature Norm for Out-of-Distribution Detection](https://arxiv.org/abs/2310.05316) (ICCV)
- [ ] [\[2310.05338\] Negative Object Presence Evaluation (NOPE) to Measure Object Hallucination in Vision-Language Models](https://arxiv.org/abs/2310.05338) (HKUST)
- [ ] [\[2310.05346\] Anyview: Generalizable Indoor 3D Object Detection with Variable Frames](https://arxiv.org/abs/2310.05346) (Tsinghua)
- [ ] [\[2310.05347\] Infrared Small Target Detection Using Double-Weighted Multi-Granularity Patch Tensor Model With Tensor-Train Decomposition](https://arxiv.org/abs/2310.05347) (UCAS)
- [ ] [\[2310.05370\] SocialCircle: Learning the Angle-based Social Interaction Representation for Pedestrian Trajectory Prediction](https://arxiv.org/abs/2310.05370) (HUST, CVPR)
- [ ] [\[2310.05400\] Efficient-VQGAN: Towards High-Resolution Image Generation with Efficient Vision Transformers](https://arxiv.org/abs/2310.05400) (IA CAS, ICCV)
- [ ] [\[2310.05447\] Towards Fair and Comprehensive Comparisons for Image-Based 3D Object Detection](https://arxiv.org/abs/2310.05447) (ICCV)
- [ ] [\[2310.05453\] Memory-Assisted Sub-Prototype Mining for Universal Domain Adaptation](https://arxiv.org/abs/2310.05453) (ICLR)
- [ ] [\[2310.05483\] HarmonicNeRF: Geometry-Informed Synthetic View Augmentation for 3D Scene Reconstruction in Driving Scenarios](https://arxiv.org/abs/2310.05483) (UW, ACMMM)
- [ ] [\[2310.05511\] Proposal-based Temporal Action Localization with Point-level Supervision](https://arxiv.org/abs/2310.05511) (University of Tokyo)
- [ ] [\[2310.05524\] Parameterization-driven Neural Surface Reconstruction for Object-oriented Editing in Neural Rendering](https://arxiv.org/abs/2310.05524) (NTU, ECCV)
- [ ] [\[2310.05615\] Adaptive Multi-head Contrastive Learning](https://arxiv.org/abs/2310.05615) (ECCV)
- [ ] [\[2310.05642\] Plug n' Play: Channel Shuffle Module for Enhancing Tiny Vision Transformers](https://arxiv.org/abs/2310.05642) (Queensland)
- [ ] [\[2310.05664\] ViTs are Everywhere: A Comprehensive Study Showcasing Vision Transformers in Different Domain](https://arxiv.org/abs/2310.05664) (BIT)
- [ ] [\[2310.05666\] Anchor-Intermediate Detector: Decoupling and Coupling Bounding Boxes for Accurate Object Detection](https://arxiv.org/abs/2310.05666) (Tsinghua, ICCV)
- [ ] [\[2310.05699\] Uni3DETR: Unified 3D Detection Transformer](https://arxiv.org/abs/2310.05699) (Tsinghua, NIPS)
- [ ] [\[2310.05720\] HyperLips: Hyper Control Lips with High Resolution Decoder for Talking Face Generation](https://arxiv.org/abs/2310.05720) (UESTC)
- [ ] [\[2310.05737\] Language Model Beats Diffusion -- Tokenizer is Key to Visual Generation](https://arxiv.org/abs/2310.05737) (ICLR)
- [ ] [\[2310.05768\] DANet: Enhancing Small Object Detection through an Efficient Deformable Attention Network](https://arxiv.org/abs/2310.05768) (BIT)
- [ ] [\[2310.05773\] Towards Lossless Dataset Distillation via Difficulty-Aligned Trajectory Matching](https://arxiv.org/abs/2310.05773) (MIT, ICLR)
- [ ] [\[2310.05873\] Implicit Concept Removal of Diffusion Models](https://arxiv.org/abs/2310.05873) (HKUST, ECCV)
- [ ] [\[2310.05922\] FLATTEN: optical FLow-guided ATTENtion for consistent text-to-video editing](https://arxiv.org/abs/2310.05922) (ICLR)
- [ ] [\[2310.05986\] The Unreasonable Effectiveness of Linear Prediction as a Perceptual Metric](https://arxiv.org/abs/2310.05986) (University of Toronto)
- [ ] [\[2310.05989\] QE-BEV: Query Evolution for Bird's Eye View Object Detection in Varied Contexts](https://arxiv.org/abs/2310.05989) (UW, ACMMM)
- [ ] [\[2310.06020\] DyST: Towards Dynamic Neural Scene Representations on Real-World Videos](https://arxiv.org/abs/2310.06020) (ICLR)
- [ ] [\[2310.06068\] Augmenting Vision-Based Human Pose Estimation with Rotation Matrix](https://arxiv.org/abs/2310.06068) (BU)
- [ ] [\[2310.06123\] Text-driven Prompt Generation for Vision-Language Models in Federated Learning](https://arxiv.org/abs/2310.06123) (Bosch)
- [ ] [\[2310.06138\] Layout Sequence Prediction From Noisy Mobile Modality](https://arxiv.org/abs/2310.06138) (ACMMM)
- [ ] [\[2310.06164\] DEUX: Active Exploration for Learning Unsupervised Depth Perception](https://arxiv.org/abs/2310.06164) (Yale)
- [ ] [\[2310.06214\] CoT3DRef: Chain-of-Thoughts Data-Efficient 3D Visual Grounding](https://arxiv.org/abs/2310.06214) (ICLR)
- [ ] [\[2310.06232\] Spiking PointNet: Spiking Neural Networks for Point Clouds](https://arxiv.org/abs/2310.06232) (Peking, NIPS)
- [ ] [\[2310.06234\] Efficient Adaptation of Large Vision Transformer via Adapter Re-Composing](https://arxiv.org/abs/2310.06234) (NIPS)
- [ ] [\[2310.06238\] Tackling Data Bias in MUSIC-AVQA: Crafting a Balanced Dataset for Unbiased Question-Answering](https://arxiv.org/abs/2310.06238) (UW)
- [ ] [\[2310.06313\] Advancing Pose-Guided Image Synthesis with Progressive Conditional Diffusion Models](https://arxiv.org/abs/2310.06313) (ICLR)
- [ ] [\[2310.06344\] Filter Pruning For CNN With Enhanced Linear Representation Redundancy](https://arxiv.org/abs/2310.06344) (UESTC)
- [ ] [\[2310.06368\] CoinSeg: Contrast Inter- and Intra- Class Representations for Incremental Segmentation](https://arxiv.org/abs/2310.06368) (BIT, ICCV)
- [ ] [\[2310.06370\] Advanced Efficient Strategy for Detection of Dark Objects Based on Spiking Network with Multi-Box Detection](https://arxiv.org/abs/2310.06370) (USTC)
- [ ] [\[2310.06389\] Learning Stackable and Skippable LEGO Bricks for Efficient, Reconfigurable, and Variable-Resolution Diffusion Modeling](https://arxiv.org/abs/2310.06389) (UT Austin)
- [ ] [\[2310.06468\] A Geometrical Approach to Evaluate the Adversarial Robustness of Deep Neural Networks](https://arxiv.org/abs/2310.06468) (Princeton)
- [ ] [\[2310.06577\] SketchBodyNet: A Sketch-Driven Multi-faceted Decoder Network for 3D Human Reconstruction](https://arxiv.org/abs/2310.06577) (SYSU)
- [ ] [\[2310.06594\] On the Evaluation and Refinement of Vision-Language Instruction Tuning Datasets](https://arxiv.org/abs/2310.06594) (SJTU)
- [ ] [\[2310.06629\] EViT: An Eagle Vision Transformer with Bi-Fovea Self-Attention](https://arxiv.org/abs/2310.06629) (Nankai)
- [ ] [\[2310.06633\] Blind Dates: Examining the Expression of Temporality in Historical Photographs](https://arxiv.org/abs/2310.06633) (UVA.NL)
- [ ] [\[2310.06641\] How (not) to ensemble LVLMs for VQA](https://arxiv.org/abs/2310.06641) (Imperial)
- [ ] [\[2310.06744\] HiFi-123: Towards High-fidelity One Image to 3D Content Generation](https://arxiv.org/abs/2310.06744) (ECCV)
- [ ] [\[2310.06838\] AutoAD II: The Sequel -- Who, When, and What in Movie Audio Description](https://arxiv.org/abs/2310.06838) (ICCV)
- [ ] [\[2310.06851\] BodyFormer: Semantics-guided 3D Body Gesture Synthesis with Transformer](https://arxiv.org/abs/2310.06851) (HKU)
- [ ] [\[2310.06854\] Learning with Noisy Labels for Human Fall Events Classification: Joint Cooperative Training with Trinity Networks](https://arxiv.org/abs/2310.06854) (Oxford)
- [ ] [\[2310.06906\] Distillation Improves Visual Place Recognition for Low-Quality Queries](https://arxiv.org/abs/2310.06906) (NYU)
- [ ] [\[2310.06907\] Self-supervised Object-Centric Learning for Videos](https://arxiv.org/abs/2310.06907) (SJTU, NIPS)
- [ ] [\[2310.06984\] Leveraging Neural Radiance Fields for Uncertainty-Aware Visual Localization](https://arxiv.org/abs/2310.06984) (MPI)
- [ ] [\[2310.07027\] Utilizing Synthetic Data for Medical Vision-Language Pre-training: Bypassing the Need for Real Images](https://arxiv.org/abs/2310.07027) (Imperial)
- [ ] [\[2310.07056\] TextPSG: Panoptic Scene Graph Generation from Textual Descriptions](https://arxiv.org/abs/2310.07056) (ICCV)
- [ ] [\[2310.07076\] Deformation Monitoring of Tunnel using Phase-based Motion Magnification and Optical Flow](https://arxiv.org/abs/2310.07076) (Berkeley)
- [ ] [\[2310.07138\] Denoising Task Routing for Diffusion Models](https://arxiv.org/abs/2310.07138) (ICLR)
- [ ] [\[2310.07176\] Improving mitosis detection on histopathology images using large vision-language models](https://arxiv.org/abs/2310.07176) (UCLA)
- [ ] [\[2310.07189\] SpikePoint: An Efficient Point-based Spiking Neural Network for Event Cameras Action Recognition](https://arxiv.org/abs/2310.07189) (ICLR)
- [ ] [\[2310.07206\] DeepSimHO: Stable Pose Estimation for Hand-Object Interaction via Physics Simulation](https://arxiv.org/abs/2310.07206) (NIPS)
- [ ] [\[2310.07222\] Uni-paint: A Unified Framework for Multimodal Image Inpainting with Pretrained Diffusion Model](https://arxiv.org/abs/2310.07222) (ACMMM)
- [ ] [\[2310.07248\] IBoxCLA: Towards Robust Box-supervised Segmentation of Polyp via Improved Box-dice and Contrastive Latent-anchors](https://arxiv.org/abs/2310.07248) (HUST)
- [ ] [\[2310.07265\] Distilling Efficient Vision Transformers from CNNs for Semantic Segmentation](https://arxiv.org/abs/2310.07265) (HKUST(GZ))
- [ ] [\[2310.07355\] IMITATE: Clinical Prior Guided Hierarchical Vision-Language Pre-training](https://arxiv.org/abs/2310.07355) (Imperial)
- [ ] [\[2310.07361\] Domain Generalization Guided by Gradient Signal to Noise Ratio of Parameters](https://arxiv.org/abs/2310.07361) (ICCV)
