- [ ] [\[2301.00114\] Skeletal Video Anomaly Detection using Deep Learning: Survey, Challenges and Future Directions](https://arxiv.org/abs/2301.00114) (University of Toronto)
- [ ] [\[2301.00131\] Guided Hybrid Quantization for Object detection in Multimodal Remote Sensing Imagery via One-to-one Self-teaching](https://arxiv.org/abs/2301.00131) (Xidian)
- [ ] [\[2301.00135\] TeViS:Translating Text Synopses to Video Storyboards](https://arxiv.org/abs/2301.00135) (Inria, ACMMM)
- [ ] [\[2301.00182\] Bidirectional Cross-Modal Knowledge Exploration for Video Recognition with Pre-trained Vision-Language Models](https://arxiv.org/abs/2301.00182) (CVPR)
- [ ] [\[2301.00184\] Cap4Video: What Can Auxiliary Captions Do for Text-Video Retrieval?](https://arxiv.org/abs/2301.00184) (CVPR)
- [ ] [\[2301.00250\] DensePose From WiFi](https://arxiv.org/abs/2301.00250) (CMU)
- [ ] [\[2301.00330\] Efficient On-device Training via Gradient Filtering](https://arxiv.org/abs/2301.00330) (CVPR)
- [ ] [\[2301.00345\] MTNeuro: A Benchmark for Evaluating Representations of Brain Structure Across Multiple Levels of Abstraction](https://arxiv.org/abs/2301.00345) (NIPS)
- [ ] [\[2301.00366\] SS-CPGAN: Self-Supervised Cut-and-Pasting Generative Adversarial Network for Object Segmentation](https://arxiv.org/abs/2301.00366) (UTS)
- [ ] [\[2301.00371\] Robust Domain Adaptive Object Detection with Unified Multi-Granularity Alignment](https://arxiv.org/abs/2301.00371) (IS CAS)
- [ ] [\[2301.00394\] Deep Learning Technique for Human Parsing: A Survey and Outlook](https://arxiv.org/abs/2301.00394) (BUPT)
- [ ] [\[2301.00406\] Curvature regularization for Non-line-of-sight Imaging from Under-sampled Data](https://arxiv.org/abs/2301.00406) (USTC)
- [ ] [\[2301.00493\] Argoverse 2: Next Generation Datasets for Self-Driving Perception and Forecasting](https://arxiv.org/abs/2301.00493) (NIPS)
- [ ] [\[2301.00514\] Rethinking the Video Sampling and Reasoning Strategies for Temporal Sentence Grounding](https://arxiv.org/abs/2301.00514) (Peking)
- [ ] [\[2301.00524\] Learning Confident Classifiers in the Presence of Label Noise](https://arxiv.org/abs/2301.00524) (MBZUAI)
- [ ] [\[2301.00531\] Multi-Stage Spatio-Temporal Aggregation Transformer for Video Person Re-identification](https://arxiv.org/abs/2301.00531) (HKU)
- [ ] [\[2301.00580\] Urban Visual Intelligence: Studying Cities with AI and Street-level Imagery](https://arxiv.org/abs/2301.00580) (HKUST)
- [ ] [\[2301.00620\] Dynamically Modular and Sparse General Continual Learning](https://arxiv.org/abs/2301.00620) (ICCV)
- [ ] [\[2301.00704\] Muse: Text-To-Image Generation via Masked Generative Transformers](https://arxiv.org/abs/2301.00704) (Google)
- [ ] [\[2301.00725\] Learning Invariance from Generated Variance for Unsupervised Person Re-identification](https://arxiv.org/abs/2301.00725) (TPAMI)
- [ ] [\[2301.00746\] NaQ: Leveraging Narrations as Queries to Supervise Episodic Memory](https://arxiv.org/abs/2301.00746) (CVPR)
- [ ] [\[2301.00772\] PCRLv2: A Unified Visual Information Preservation Framework for Self-supervised Pre-training in Medical Image Analysis](https://arxiv.org/abs/2301.00772) (ShanghaiTech, TPAMI)
- [ ] [\[2301.00794\] STEPs: Self-Supervised Key Step Extraction and Localization from Unlabeled Procedural Videos](https://arxiv.org/abs/2301.00794) (ICCV)
- [ ] [\[2301.00805\] Betrayed by Captions: Joint Caption Grounding and Generation for Open Vocabulary Instance Segmentation](https://arxiv.org/abs/2301.00805) (Peking, ICCV)
- [ ] [\[2301.00896\] Efficient Robustness Assessment via Adversarial Spatial-Temporal Focus on Videos](https://arxiv.org/abs/2301.00896) (TPAMI)
- [ ] [\[2301.00954\] PanopticPartFormer++: A Unified and Decoupled View for Panoptic Part Segmentation](https://arxiv.org/abs/2301.00954) (ECCV)
- [ ] [\[2301.00975\] Surveillance Face Anti-spoofing](https://arxiv.org/abs/2301.00975) (IA CAS)
- [ ] [\[2301.00985\] More is Better: A Database for Spontaneous Micro-Expression with High Frame Rates](https://arxiv.org/abs/2301.00985) (USTC)
- [ ] [\[2301.00998\] Vocabulary-informed Zero-shot and Open-set Learning](https://arxiv.org/abs/2301.00998) (CVPR)
- [ ] [\[2301.01006\] Policy Pre-training for Autonomous Driving via Self-supervised Geometric Modeling](https://arxiv.org/abs/2301.01006) (ICLR)
- [ ] [\[2301.01015\] Semi-Structured Object Sequence Encoders](https://arxiv.org/abs/2301.01015) (Microsoft)
- [ ] [\[2301.01036\] High-Quality Real-Time Rendering Using Subpixel Sampling Reconstruction](https://arxiv.org/abs/2301.01036) (Tsinghua)
- [ ] [\[2301.01060\] Knowledge-guided Causal Intervention for Weakly-supervised Object Localization](https://arxiv.org/abs/2301.01060) (ZJU)
- [ ] [\[2301.01081\] StyleTalk: One-shot Talking Head Generation with Controllable Speaking Styles](https://arxiv.org/abs/2301.01081) (Tsinghua)
- [ ] [\[2301.01147\] 4Seasons: Benchmarking Visual SLAM and Long-Term Localization for Autonomous Driving in Challenging Conditions](https://arxiv.org/abs/2301.01147) (TUM)
- [ ] [\[2301.01149\] I2F: A Unified Image-to-Feature Approach for Domain Adaptive Semantic Segmentation](https://arxiv.org/abs/2301.01149) (HKU, TPAMI)
- [ ] [\[2301.01216\] An end-to-end multi-scale network for action prediction in videos](https://arxiv.org/abs/2301.01216) (BUPT)
- [ ] [\[2301.01296\] TinyMIM: An Empirical Study of Distilling MIM Pre-trained Models](https://arxiv.org/abs/2301.01296) (Microsoft)
- [ ] [\[2301.01449\] Building Coverage Estimation with Low-resolution Remote Sensing Imagery](https://arxiv.org/abs/2301.01449) (Stanford)
- [ ] [\[2301.01531\] MoBYv2AL: Self-supervised Active Learning for Image Classification](https://arxiv.org/abs/2301.01531) (Imperial)
- [ ] [\[2301.01615\] StereoDistill: Pick the Cream from LiDAR for Distilling Stereo-based 3D Object Detection](https://arxiv.org/abs/2301.01615) (HUST)
- [ ] [\[2301.01635\] SPTS v2: Single-Point Scene Text Spotting](https://arxiv.org/abs/2301.01635) (CUHK, TPAMI)
- [ ] [\[2301.01661\] RecRecNet: Rectangling Rectified Wide-Angle Images by Thin-Plate Spline Model and DoF-based Curriculum Learning](https://arxiv.org/abs/2301.01661) (ICCV)
- [ ] [\[2301.01767\] Self-Supervised Video Forensics by Audio-Visual Anomaly Detection](https://arxiv.org/abs/2301.01767) (CVPR)
- [ ] [\[2301.01795\] PACO: Parts and Attributes of Common Objects](https://arxiv.org/abs/2301.01795) (Meta)
- [ ] [\[2301.01802\] MonoEdge: Monocular 3D Object Detection Using Local Perspectives](https://arxiv.org/abs/2301.01802) (University of Michigan)
- [ ] [\[2301.01841\] Classification of Single Tree Decay Stages from Combined Airborne LiDAR Data and CIR Imagery](https://arxiv.org/abs/2301.01841) (PolyU)
- [ ] [\[2301.01842\] Detecting Neighborhood Gentrification at Scale via Street-level Visual Data](https://arxiv.org/abs/2301.01842) (Stanford)
- [ ] [\[2301.01871\] Hypotheses Tree Building for One-Shot Temporal Sentence Localization](https://arxiv.org/abs/2301.01871) (HUST)
- [ ] [\[2301.01879\] Learning Feature Recovery Transformer for Occluded Person Re-identification](https://arxiv.org/abs/2301.01879) (IA CAS)
- [ ] [\[2301.01882\] InsPro: Propagating Instance Query and Proposal for Online Video Instance Segmentation](https://arxiv.org/abs/2301.01882) (NIPS)
- [ ] [\[2301.01928\] Event Camera Data Pre-training](https://arxiv.org/abs/2301.01928) (BIT, ICCV)
- [ ] [\[2301.01953\] Learning Trajectory-Word Alignments for Video-Language Tasks](https://arxiv.org/abs/2301.01953) (NTU)
- [ ] [\[2301.01970\] CAT: LoCalization and IdentificAtion Cascade Detection Transformer for Open-World Object Detection](https://arxiv.org/abs/2301.01970) (CVPR)
- [ ] [\[2301.02008\] Expressive Speech-driven Facial Animation with controllable emotions](https://arxiv.org/abs/2301.02008) (Tsinghua)
- [ ] [\[2301.02009\] Learning by Sorting: Self-supervised Learning with Group Ordering Constraints](https://arxiv.org/abs/2301.02009) (ICCV)
- [ ] [\[2301.02064\] Single-round Self-supervised Distributed Learning using Vision Transformer](https://arxiv.org/abs/2301.02064) (KAIST)
- [ ] [\[2301.02074\] Test of Time: Instilling Video-Language Models with a Sense of Time](https://arxiv.org/abs/2301.02074) (CVPR)
- [ ] [\[2301.02184\] Chat2Map: Efficient Scene Mapping from Multi-Ego Conversations](https://arxiv.org/abs/2301.02184) (CVPR)
- [ ] [\[2301.02229\] All in Tokens: Unifying Output Space of Visual Tasks via Soft Token](https://arxiv.org/abs/2301.02229) (HUST)
- [ ] [\[2301.02239\] Robust Dynamic Radiance Fields](https://arxiv.org/abs/2301.02239) (CVPR)
- [ ] [\[2301.02240\] Skip-Attention: Improving Vision Transformers by Paying Less Attention](https://arxiv.org/abs/2301.02240) (Inria)
- [ ] [\[2301.02280\] Filtering, Distillation, and Hard Negatives for Vision-Language Pre-Training](https://arxiv.org/abs/2301.02280) (CVPR)
- [ ] [\[2301.02311\] HierVL: Learning Hierarchical Video-Language Embeddings](https://arxiv.org/abs/2301.02311) (CVPR)
- [ ] [\[2301.02315\] TempSAL -- Uncovering Temporal Information for Deep Saliency Prediction](https://arxiv.org/abs/2301.02315) (CVPR)
- [ ] [\[2301.02364\] Object as Query: Lifting any 2D Object Detector to 3D Detection](https://arxiv.org/abs/2301.02364) (ICCV)
- [ ] [\[2301.02371\] Anchor3DLane: Learning to Regress 3D Anchors for Monocular 3D Lane Detection](https://arxiv.org/abs/2301.02371) (CVPR)
- [ ] [\[2301.02379\] CodeTalker: Speech-Driven 3D Facial Animation with Discrete Motion Prior](https://arxiv.org/abs/2301.02379) (CVPR)
- [ ] [\[2301.02403\] CyberLoc: Towards Accurate Long-term Visual Localization](https://arxiv.org/abs/2301.02403) (ECCV)
- [ ] [\[2301.02419\] Exploring Efficient Few-shot Adaptation for Vision Transformers](https://arxiv.org/abs/2301.02419) (Fudan)
- [ ] [\[2301.02524\] Tackling Data Bias in Painting Classification with Style Transfer](https://arxiv.org/abs/2301.02524) (ICCV)
- [ ] [\[2301.02650\] Hierarchical Point Attention for Indoor 3D Object Detection](https://arxiv.org/abs/2301.02650) (UT Austin)
- [ ] [\[2301.02657\] TarViS: A Unified Approach for Target-based Video Segmentation](https://arxiv.org/abs/2301.02657) (CMU, CVPR)
- [ ] [\[2301.02667\] Locomotion-Action-Manipulation: Synthesizing Human-Scene Interactions in Complex 3D Environments](https://arxiv.org/abs/2301.02667) (ICCV)
- [ ] [\[2301.02778\] Lightweight Salient Object Detection in Optical Remote-Sensing Images via Semantic Matching and Edge Alignment](https://arxiv.org/abs/2301.02778) (NTU)
- [ ] [\[2301.02869\] Deep Learning-Based UAV Aerial Triangulation without Image Control Points](https://arxiv.org/abs/2301.02869) (WHU)
- [ ] [\[2301.02911\] Towards early prediction of neurodevelopmental disorders: Computational model for Face Touch and Self-adaptors in Infants](https://arxiv.org/abs/2301.02911) (Cambridge)
- [ ] [\[2301.02969\] Multi-scale multi-modal micro-expression recognition algorithm based on transformer](https://arxiv.org/abs/2301.02969) (XJTU)
- [ ] [\[2301.02993\] DeepMatcher: A Deep Transformer-based Network for Robust and Accurate Local Feature Matching](https://arxiv.org/abs/2301.02993) (HIT)
- [ ] [\[2301.03041\] Learning the Relation between Similarity Loss and Clustering Loss in Self-Supervised Learning](https://arxiv.org/abs/2301.03041) (NJU, TIP)
- [ ] [\[2301.03160\] Towards Real-Time Panoptic Narrative Grounding by an End-to-End Grounding Network](https://arxiv.org/abs/2301.03160) (Xiamen)
- [ ] [\[2301.03169\] A Study on the Generality of Neural Network Structures for Monocular Depth Estimation](https://arxiv.org/abs/2301.03169) (TPAMI)
- [ ] [\[2301.03182\] Structure-Informed Shadow Removal Networks](https://arxiv.org/abs/2301.03182) (A*STAR,, TIP)
- [ ] [\[2301.03194\] Few-shot Semantic Segmentation with Support-induced Graph Convolutional Network](https://arxiv.org/abs/2301.03194) (UVA.NL)
- [ ] [\[2301.03330\] HyRSM++: Hybrid Relation Guided Temporal Set Matching for Few-shot Action Recognition](https://arxiv.org/abs/2301.03330) (Alibaba, CVPR)
- [ ] [\[2301.03331\] A Specific Task-oriented Semantic Image Communication System for substation patrol inspection](https://arxiv.org/abs/2301.03331) (BUPT)
- [ ] [\[2301.03396\] Diffused Heads: Diffusion Models Beat GANs on Talking-Face Generation](https://arxiv.org/abs/2301.03396) (Imperial)
- [ ] [\[2301.03432\] High-Resolution Cloud Removal with Multi-Modal and Multi-Resolution Data Fusion: A New Baseline and Benchmark](https://arxiv.org/abs/2301.03432) (WHU)
- [ ] [\[2301.03461\] DeMT: Deformable Mixer Transformer for Multi-Task Learning of Dense Prediction](https://arxiv.org/abs/2301.03461) (Peking)
- [ ] [\[2301.03510\] Parallel Reasoning Network for Human-Object Interaction Detection](https://arxiv.org/abs/2301.03510) (SenseTime)
- [ ] [\[2301.03580\] Designing BERT for Convolutional Networks: Sparse and Hierarchical Masked Modeling](https://arxiv.org/abs/2301.03580) (Peking)
- [ ] [\[2301.03831\] Dynamic Grained Encoder for Vision Transformers](https://arxiv.org/abs/2301.03831) (XJTU, NIPS)
- [ ] [\[2301.03832\] Video Semantic Segmentation with Inter-Frame Feature Fusion and Inner-Frame Feature Refinement](https://arxiv.org/abs/2301.03832) (USTC)
- [ ] [\[2301.03949\] Modiff: Action-Conditioned 3D Motion Generation with Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2301.03949) (SYSU)
- [ ] [\[2301.03976\] Semi-Supervised Learning with Pseudo-Negative Labels for Image Classification](https://arxiv.org/abs/2301.03976) (BU)
- [ ] [\[2301.04011\] Learning Support and Trivial Prototypes for Interpretable Image Classification](https://arxiv.org/abs/2301.04011) (ICCV)
- [ ] [\[2301.04221\] Explaining Deep Models through Forgettable Learning Dynamics](https://arxiv.org/abs/2301.04221) (GIT)
- [ ] [\[2301.04224\] Pix2Map: Cross-modal Retrieval for Inferring Street Maps from Images](https://arxiv.org/abs/2301.04224) (Princeton)
- [ ] [\[2301.04233\] Adapting to Skew: Imputing Spatiotemporal Urban Data with 3D Partial Convolutions and Biased Masking](https://arxiv.org/abs/2301.04233) (UW)
- [ ] [\[2301.04258\] CARD: Semantic Segmentation with Efficient Class-Aware Regularized Decoder](https://arxiv.org/abs/2301.04258) (UTS)
- [ ] [\[2301.04265\] Adversarial Alignment for Source Free Object Detection](https://arxiv.org/abs/2301.04265) (Tsinghua)
- [ ] [\[2301.04352\] Graph based Environment Representation for Vision-and-Language Navigation in Continuous Environments](https://arxiv.org/abs/2301.04352) (Columbia University)
- [ ] [\[2301.04410\] GraVIS: Grouping Augmented Views from Independent Sources for Dermatology Analysis](https://arxiv.org/abs/2301.04410) (Xiamen)
- [ ] [\[2301.04414\] How Does Traffic Environment Quantitatively Affect the Autonomous Driving Prediction?](https://arxiv.org/abs/2301.04414) (Tsinghua)
- [ ] [\[2301.04454\] Allo-centric Occupancy Grid Prediction for Urban Traffic Scene Using Video Prediction Networks](https://arxiv.org/abs/2301.04454) (Inria)
- [ ] [\[2301.04467\] FrustumFormer: Adaptive Instance-aware Resampling for Multi-view 3D Detection](https://arxiv.org/abs/2301.04467) (CVPR)
- [ ] [\[2301.04502\] Pruning Compact ConvNets for Efficient Inference](https://arxiv.org/abs/2301.04502) (Meta)
- [ ] [\[2301.04545\] AdaPoinTr: Diverse Point Cloud Completion with Adaptive Geometry-Aware Transformers](https://arxiv.org/abs/2301.04545) (Tsinghua, ICCV)
- [ ] [\[2301.04558\] Learning to Exploit Temporal Structure for Biomedical Vision-Language Processing](https://arxiv.org/abs/2301.04558) (Microsoft, CVPR)
- [ ] [\[2301.04581\] Elevation Estimation-Driven Building 3D Reconstruction from Single-View Remote Sensing Imagery](https://arxiv.org/abs/2301.04581) (UCAS)
- [ ] [\[2301.04634\] Street-View Image Generation from a Bird's-Eye View Layout](https://arxiv.org/abs/2301.04634) (UCLA)
- [ ] [\[2301.04644\] Does progress on ImageNet transfer to real-world datasets?](https://arxiv.org/abs/2301.04644) (Google)
- [ ] [\[2301.04647\] EXIF as Language: Learning Cross-Modal Associations Between Images and Camera Metadata](https://arxiv.org/abs/2301.04647) (CVPR)
- [ ] [\[2301.04648\] Head-Free Lightweight Semantic Segmentation with Linear Transformer](https://arxiv.org/abs/2301.04648) (Alibaba)
- [ ] [\[2301.04795\] 1st Place Solution for ECCV 2022 OOD-CV Challenge Image Classification Track](https://arxiv.org/abs/2301.04795) (Peking)
- [ ] [\[2301.04799\] Adaptive Context Selection for Polyp Segmentation](https://arxiv.org/abs/2301.04799) (SYSU)
- [ ] [\[2301.04805\] DEA-Net: Single image dehazing based on detail-enhanced convolution and content-guided attention](https://arxiv.org/abs/2301.04805) (ZJU)
- [ ] [\[2301.04842\] Towards High Performance One-Stage Human Pose Estimation](https://arxiv.org/abs/2301.04842) (ACMMM)
- [ ] [\[2301.04866\] Self-Supervised Correction Learning for Semi-Supervised Biomedical Image Segmentation](https://arxiv.org/abs/2301.04866) (SYSU)
- [ ] [\[2301.04882\] ZScribbleSeg: Zen and the Art of Scribble Supervised Medical Image Segmentation](https://arxiv.org/abs/2301.04882) (Fudan)
- [ ] [\[2301.04926\] CLIP2Scene: Towards Label-efficient 3D Scene Understanding by CLIP](https://arxiv.org/abs/2301.04926) (CVPR)
- [ ] [\[2301.05158\] SemPPL: Predicting pseudo-labels for better contrastive representations](https://arxiv.org/abs/2301.05158) (ICLR)
- [ ] [\[2301.05211\] Accidental Light Probes](https://arxiv.org/abs/2301.05211) (CVPR)
- [ ] [\[2301.05213\] Learning to Summarize Videos by Contrasting Clips](https://arxiv.org/abs/2301.05213) (UVA.NL)
- [ ] [\[2301.05225\] Domain Expansion of Image Generators](https://arxiv.org/abs/2301.05225) (CVPR)
- [ ] [\[2301.05315\] GH-Feat: Learning Versatile Generative Hierarchical Features from GANs](https://arxiv.org/abs/2301.05315) (TPAMI)
- [ ] [\[2301.05323\] Salient Object Detection for Images Taken by People With Vision Impairments](https://arxiv.org/abs/2301.05323) (CVPR)
- [ ] [\[2301.05372\] Text to Point Cloud Localization with Relation-Enhanced Transformer](https://arxiv.org/abs/2301.05372) (NUS)
- [ ] [\[2301.05421\] Anti-aliasing Predictive Coding Network for Future Video Frame Prediction](https://arxiv.org/abs/2301.05421) (PolyU)
- [ ] [\[2301.05434\] LVRNet: Lightweight Image Restoration for Aerial Images under Low Visibility](https://arxiv.org/abs/2301.05434) (CMU)
- [ ] [\[2301.05465\] Explicit Temporal Embedding in Deep Generative Latent Models for Longitudinal Medical Image Synthesis](https://arxiv.org/abs/2301.05465) (University of Copenhagen)
- [ ] [\[2301.05496\] Learning Transformations To Reduce the Geometric Shift in Object Detection](https://arxiv.org/abs/2301.05496) (EPFL)
- [ ] [\[2301.05499\] CLIP the Gap: A Single Domain Generalization Approach for Object Detection](https://arxiv.org/abs/2301.05499) (EPFL)
- [ ] [\[2301.05500\] RCPS: Rectified Contrastive Pseudo Supervision for Semi-Supervised Medical Image Segmentation](https://arxiv.org/abs/2301.05500) (Fudan)
- [ ] [\[2301.05623\] Reworking geometric morphometrics into a methodology of transformation grids](https://arxiv.org/abs/2301.05623) (UW)
- [ ] [\[2301.05709\] Self-Supervised Image-to-Point Distillation via Semantically Tolerant Contrastive Loss](https://arxiv.org/abs/2301.05709) (CVPR)
- [ ] [\[2301.05747\] Laser: Latent Set Representations for 3D Generative Modeling](https://arxiv.org/abs/2301.05747) (DeepMind)
- [ ] [\[2301.05792\] RMM: Reinforced Memory Management for Class-Incremental Learning](https://arxiv.org/abs/2301.05792) (NIPS)
- [ ] [\[2301.05796\] Learning Trajectory-Conditioned Relations to Predict Pedestrian Crossing Behavior](https://arxiv.org/abs/2301.05796) (GIT)
- [ ] [\[2301.05839\] NCP: Neural Correspondence Prior for Effective Unsupervised Shape Matching](https://arxiv.org/abs/2301.05839) (NIPS)
- [ ] [\[2301.05845\] ${S}^{2}$Net: Accurate Panorama Depth Estimation on Spherical Surface](https://arxiv.org/abs/2301.05845) (Alibaba)
- [ ] [\[2301.05858\] Robust Remote Sensing Scene Classification with Multi-View Voting and Entropy Ranking](https://arxiv.org/abs/2301.05858) (ICML)
- [ ] [\[2301.05897\] Model-based Transfer Learning for Automatic Optical Inspection based on domain discrepancy](https://arxiv.org/abs/2301.05897) (Tsinghua)
- [ ] [\[2301.05994\] Min-Max-Jump distance and its applications](https://arxiv.org/abs/2301.05994) (Tsinghua)
- [ ] [\[2301.06002\] ACTIVE: A Deep Model for Sperm and Impurity Detection in Microscopic Videos](https://arxiv.org/abs/2301.06002) (CUHK)
- [ ] [\[2301.06015\] Diffusion-based Generation, Optimization, and Planning in 3D Scenes](https://arxiv.org/abs/2301.06015) (BIT)
- [ ] [\[2301.06020\] Delving Deep into Pixel Alignment Feature for Accurate Multi-view Human Mesh Recovery](https://arxiv.org/abs/2301.06020) (University of Michigan)
- [ ] [\[2301.06051\] DSVT: Dynamic Sparse Voxel Transformer with Rotated Sets](https://arxiv.org/abs/2301.06051) (CVPR)
- [ ] [\[2301.06052\] T2M-GPT: Generating Human Motion from Textual Descriptions with Discrete Representations](https://arxiv.org/abs/2301.06052) (CVPR)
- [ ] [\[2301.06082\] A Survey on Human Action Recognition](https://arxiv.org/abs/2301.06082) (UESTC)
- [ ] [\[2301.06083\] Discrete Point-wise Attack Is Not Enough: Generalized Manifold Adversarial Attack for Face Recognition](https://arxiv.org/abs/2301.06083) (CVPR)
- [ ] [\[2301.06084\] Scattering-induced entropy boost for highly-compressed optical sensing and encryption](https://arxiv.org/abs/2301.06084) (BIT)
- [ ] [\[2301.06116\] Maximally Compact and Separated Features with Regular Polytope Networks](https://arxiv.org/abs/2301.06116) (CVPR)
- [ ] [\[2301.06122\] CORE: Learning Consistent Ordinal REpresentations for Image Ordinal Estimation](https://arxiv.org/abs/2301.06122) (Fudan)
- [ ] [\[2301.06132\] Deep Diversity-Enhanced Feature Representation of Hyperspectral Images](https://arxiv.org/abs/2301.06132) (XJTU, TPAMI)
- [ ] [\[2301.06143\] Multi-Camera Lighting Estimation for Photorealistic Front-Facing Mobile Augmented Reality](https://arxiv.org/abs/2301.06143) (Google)
- [ ] [\[2301.06267\] Multimodality Helps Unimodality: Cross-Modal Few-Shot Learning with Multimodal Models](https://arxiv.org/abs/2301.06267) (CVPR)
- [ ] [\[2301.06269\] DarkVision: A Benchmark for Low-light Image/Video Perception](https://arxiv.org/abs/2301.06269) (Tsinghua)
- [ ] [\[2301.06309\] UATVR: Uncertainty-Adaptive Text-Video Retrieval](https://arxiv.org/abs/2301.06309) (USyd, ICCV)
- [ ] [\[2301.06442\] Modeling Uncertain Feature Representation for Domain Generalization](https://arxiv.org/abs/2301.06442) (Peking, ICLR)
- [ ] [\[2301.06648\] Neuromorphic High-Frequency 3D Dancing Pose Estimation in Dynamic Environment](https://arxiv.org/abs/2301.06648) (UCSD)
- [ ] [\[2301.06719\] FemtoDet: An Object Detection Baseline for Energy Versus Performance Tradeoffs](https://arxiv.org/abs/2301.06719) (ICCV)
- [ ] [\[2301.06733\] Face Inverse Rendering via Hierarchical Decoupling](https://arxiv.org/abs/2301.06733) (Tianjin)
- [ ] [\[2301.06844\] USER: Unified Semantic Enhancement with Momentum Contrast for Image-Text Retrieval](https://arxiv.org/abs/2301.06844) (Tianjin)
- [ ] [\[2301.06855\] Event-based Shape from Polarization](https://arxiv.org/abs/2301.06855) (CVPR)
- [ ] [\[2301.06892\] Cooperation Learning Enhanced Colonic Polyp Segmentation Based on Transformer-CNN Fusion](https://arxiv.org/abs/2301.06892) (PolyU)
- [ ] [\[2301.06944\] DR-WLC: Dimensionality Reduction cognition for object detection and pose estimation by Watching, Learning and Checking](https://arxiv.org/abs/2301.06944) (BIT)
- [ ] [\[2301.06958\] RILS: Masked Visual Reconstruction in Language Semantic Space](https://arxiv.org/abs/2301.06958) (HUST)
- [ ] [\[2301.06962\] Long Range Pooling for 3D Large-Scale Scene Understanding](https://arxiv.org/abs/2301.06962) (Tsinghua)
- [ ] [\[2301.07037\] Explain What You See: Open-Ended Segmentation and Recognition of Occluded 3D Objects](https://arxiv.org/abs/2301.07037) (Imperial)
- [ ] [\[2301.07074\] SegViz: A federated-learning based framework for multi-organ segmentation on heterogeneous data sets with partial annotations](https://arxiv.org/abs/2301.07074) (JHU)
- [ ] [\[2301.07178\] Using Large Text-to-Image Models with Structured Prompts for Skin Disease Identification: A Case Study](https://arxiv.org/abs/2301.07178) (University of Toronto)
- [ ] [\[2301.07236\] Effective End-to-End Vision Language Pretraining with Semantic Visual Loss](https://arxiv.org/abs/2301.07236) (NTU)
- [ ] [\[2301.07301\] PTA-Det: Point Transformer Associating Point cloud and Image for 3D Object Detection](https://arxiv.org/abs/2301.07301) (NWPU)
- [ ] [\[2301.07315\] Face Recognition in the age of CLIP & Billion image datasets](https://arxiv.org/abs/2301.07315) (NYU)
- [ ] [\[2301.07316\] Adaptively Integrated Knowledge Distillation and Prediction Uncertainty for Continual Learning](https://arxiv.org/abs/2301.07316) (SYSU)
- [ ] [\[2301.07320\] Robust Knowledge Adaptation for Federated Unsupervised Person ReID](https://arxiv.org/abs/2301.07320) (USyd)
- [ ] [\[2301.07340\] Semi-Supervised Semantic Segmentation via Gentle Teaching Assistant](https://arxiv.org/abs/2301.07340) (NIPS)
- [ ] [\[2301.07354\] MADAv2: Advanced Multi-Anchor Based Active Domain Adaptation Segmentation](https://arxiv.org/abs/2301.07354) (TPAMI)
- [ ] [\[2301.07382\] ViT-AE++: Improving Vision Transformer Autoencoder for Self-supervised Medical Image Representations](https://arxiv.org/abs/2301.07382) (TUM)
- [ ] [\[2301.07389\] Towards Models that Can See and Read](https://arxiv.org/abs/2301.07389) (AWS)
- [ ] [\[2301.07405\] HiDAnet: RGB-D Salient Object Detection via Hierarchical Depth Awareness](https://arxiv.org/abs/2301.07405) (SJTU)
- [ ] [\[2301.07409\] Representing Noisy Image Without Denoising](https://arxiv.org/abs/2301.07409) (Chongqing, TPAMI)
- [ ] [\[2301.07464\] CLIPTER: Looking at the Bigger Picture in Scene Text Recognition](https://arxiv.org/abs/2301.07464) (AWS, ICCV)
- [ ] [\[2301.07499\] A Comprehensive Review of Modern Object Segmentation Approaches](https://arxiv.org/abs/2301.07499) (AWS)
- [ ] [\[2301.07525\] OmniObject3D: Large-Vocabulary 3D Object Dataset for Realistic Perception, Reconstruction and Generation](https://arxiv.org/abs/2301.07525) (HKUST)
- [ ] [\[2301.07533\] A Multi-Scale Framework for Out-of-Distribution Detection in Dermoscopic Images](https://arxiv.org/abs/2301.07533) (ICML)
- [ ] [\[2301.07668\] Behind the Scenes: Density Fields for Single View Reconstruction](https://arxiv.org/abs/2301.07668) (Oxford)
- [ ] [\[2301.07673\] OnePose++: Keypoint-Free One-Shot Object Pose Estimation without CAD Models](https://arxiv.org/abs/2301.07673) (NIPS)
- [ ] [\[2301.07702\] Learning 3D-aware Image Synthesis with Unknown Pose Distribution](https://arxiv.org/abs/2301.07702) (CVPR)
- [ ] [\[2301.07805\] Multi-target multi-camera vehicle tracking using transformer-based camera link model and spatial-temporal information](https://arxiv.org/abs/2301.07805) (UW)
- [ ] [\[2301.07836\] Masked Autoencoding Does Not Help Natural Language Supervision at Scale](https://arxiv.org/abs/2301.07836) (CVPR)
- [ ] [\[2301.07870\] Fast-BEV: Towards Real-time On-vehicle Bird's-Eye View Perception](https://arxiv.org/abs/2301.07870) (BUPT, NIPS)
- [ ] [\[2301.07879\] Unposed: Unsupervised Pose Estimation based Product Image Recommendations](https://arxiv.org/abs/2301.07879) (AWS)
- [ ] [\[2301.07921\] Spatio-Temporal Context Modeling for Road Obstacle Detection](https://arxiv.org/abs/2301.07921) (ICML)
- [ ] [\[2301.07944\] Revisiting the Spatial and Temporal Modeling for Few-shot Action Recognition](https://arxiv.org/abs/2301.07944) (ZJU)
- [ ] [\[2301.07958\] RecolorNeRF: Layer Decomposed Radiance Fields for Efficient Color Editing of 3D Scenes](https://arxiv.org/abs/2301.07958) (CUHK, ACMMM)
- [ ] [\[2301.08072\] Dif-Fusion: Towards High Color Fidelity in Infrared and Visible Image Fusion with Diffusion Models](https://arxiv.org/abs/2301.08072) (Peking)
- [ ] [\[2301.08125\] Diagnose Like a Pathologist: Transformer-Enabled Hierarchical Attention-Guided Multiple Instance Learning for Whole Slide Image Classification](https://arxiv.org/abs/2301.08125) (HKUST)
- [ ] [\[2301.08140\] Regularising disparity estimation via multi task learning with structured light reconstruction](https://arxiv.org/abs/2301.08140) (Imperial)
- [ ] [\[2301.08237\] LoCoNet: Long-Short Context Network for Active Speaker Detection](https://arxiv.org/abs/2301.08237) (CVPR)
- [ ] [\[2301.08243\] Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture](https://arxiv.org/abs/2301.08243) (Meta, ICCV)
- [ ] [\[2301.08245\] Booster: a Benchmark for Depth from Images of Specular and Transparent Surfaces](https://arxiv.org/abs/2301.08245) (CVPR)
- [ ] [\[2301.08317\] Ultrasound Plane Pose Regression: Assessing Generalized Pose Coordinates in the Fetal Brain](https://arxiv.org/abs/2301.08317) (UCL)
- [ ] [\[2301.08390\] Open-Set Likelihood Maximization for Few-Shot Learning](https://arxiv.org/abs/2301.08390) (CVPR)
- [ ] [\[2301.08413\] Chaos to Order: A Label Propagation Perspective on Source-Free Domain Adaptation](https://arxiv.org/abs/2301.08413) (ACMMM)
- [ ] [\[2301.08414\] FG-Depth: Flow-Guided Unsupervised Monocular Depth Estimation](https://arxiv.org/abs/2301.08414) (ZJU)
- [ ] [\[2301.08433\] Unsupervised Light Field Depth Estimation via Multi-view Feature Matching with Occlusion Prediction](https://arxiv.org/abs/2301.08433) (HKU)
- [ ] [\[2301.08455\] Spatial Steerability of GANs via Self-Supervision from Discriminator](https://arxiv.org/abs/2301.08455) (TPAMI)
- [ ] [\[2301.08555\] Hybrid Open-set Segmentation with Synthetic Negative Data](https://arxiv.org/abs/2301.08555) (TPAMI)
- [ ] [\[2301.08664\] AccDecoder: Accelerated Decoding for Neural-enhanced Video Analytics](https://arxiv.org/abs/2301.08664) (NJU)
- [ ] [\[2301.08730\] Novel-View Acoustic Synthesis](https://arxiv.org/abs/2301.08730) (CVPR)
- [ ] [\[2301.08739\] FlatFormer: Flattened Window Attention for Efficient Point Cloud Transformer](https://arxiv.org/abs/2301.08739) (CVPR)
- [ ] [\[2301.08915\] Improving Deep Regression with Ordinal Entropy](https://arxiv.org/abs/2301.08915) (ICLR)
- [ ] [\[2301.08930\] Dense RGB SLAM with Neural Implicit Maps](https://arxiv.org/abs/2301.08930) (HKUST, ICLR)
- [ ] [\[2301.08951\] Time-Conditioned Generative Modeling of Object-Centric Representations for Video Decomposition and Prediction](https://arxiv.org/abs/2301.08951) (Fudan)
- [ ] [\[2301.09063\] DASTSiam: Spatio-Temporal Fusion and Discriminative Augmentation for Improved Siamese Tracking](https://arxiv.org/abs/2301.09063) (Tsinghua)
- [ ] [\[2301.09077\] Unleash the Potential of Image Branch for Cross-modal 3D Object Detection](https://arxiv.org/abs/2301.09077) (CUHK, NIPS)
- [ ] [\[2301.09091\] BallGAN: 3D-aware Image Synthesis with a Spherical Background](https://arxiv.org/abs/2301.09091) (ICCV)
- [ ] [\[2301.09121\] Learning Open-vocabulary Semantic Segmentation Models From Natural Language Supervision](https://arxiv.org/abs/2301.09121) (CVPR)
- [ ] [\[2301.09249\] Exploring Active 3D Object Detection from a Generalization Perspective](https://arxiv.org/abs/2301.09249) (Queensland, ICLR)
- [ ] [\[2301.09253\] CircNet: Meshing 3D Point Clouds with Circumcenter Detection](https://arxiv.org/abs/2301.09253) (ICLR)
- [ ] [\[2301.09254\] Learning to Linearize Deep Neural Networks for Secure and Efficient Private Inference](https://arxiv.org/abs/2301.09254) (ICLR)
- [ ] [\[2301.09299\] Self-Supervised Image Representation Learning: Transcending Masking with Paired Image Overlay](https://arxiv.org/abs/2301.09299) (Columbia University)
- [ ] [\[2301.09376\] Crowd3D: Towards Hundreds of People Reconstruction from a Single Image](https://arxiv.org/abs/2301.09376) (CVPR)
- [ ] [\[2301.09451\] A Simple Recipe for Competitive Low-compute Self supervised Vision Models](https://arxiv.org/abs/2301.09451) (Meta)
- [ ] [\[2301.09595\] Zorro: the masked multimodal transformer](https://arxiv.org/abs/2301.09595) (Google)
- [ ] [\[2301.09620\] Tracking the industrial growth of modern China with high-resolution panchromatic imagery: A sequential convolutional approach](https://arxiv.org/abs/2301.09620) (NYU)
- [ ] [\[2301.09632\] HexPlane: A Fast Representation for Dynamic Scenes](https://arxiv.org/abs/2301.09632) (CVPR)
- [ ] [\[2301.09724\] Long-tail Detection with Effective Class-Margins](https://arxiv.org/abs/2301.09724) (UT Austin, ECCV)
- [ ] [\[2301.09879\] Data Augmentation Alone Can Improve Adversarial Training](https://arxiv.org/abs/2301.09879) (ICLR)
- [ ] [\[2301.09964\] Uncertainty-Aware Distillation for Semi-Supervised Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2301.09964) (NUDT)
- [ ] [\[2301.10018\] GyroFlow+: Gyroscope-Guided Unsupervised Deep Homography and Optical Flow Learning](https://arxiv.org/abs/2301.10018) (UESTC)
- [ ] [\[2301.10048\] Exploiting Optical Flow Guidance for Transformer-Based Video Inpainting](https://arxiv.org/abs/2301.10048) (USTC, ECCV)
- [ ] [\[2301.10100\] Using a Waffle Iron for Automotive Point Cloud Semantic Segmentation](https://arxiv.org/abs/2301.10100) (ICCV)
- [ ] [\[2301.10208\] A Simple Adaptive Unfolding Network for Hyperspectral Image Reconstruction](https://arxiv.org/abs/2301.10208) (HUST)
- [ ] [\[2301.10222\] RangeViT: Towards Vision Transformers for 3D Semantic Segmentation in Autonomous Driving](https://arxiv.org/abs/2301.10222) (CVPR)
- [ ] [\[2301.10241\] K-Planes: Explicit Radiance Fields in Space, Time, and Appearance](https://arxiv.org/abs/2301.10241) (Berkeley)
- [ ] [\[2301.10293\] A Fast Feature Point Matching Algorithm Based on IMU Sensor](https://arxiv.org/abs/2301.10293) (Peking)
- [ ] [\[2301.10295\] Object Segmentation with Audio Context](https://arxiv.org/abs/2301.10295) (CMU)
- [ ] [\[2301.10460\] HAL3D: Hierarchical Active Learning for Fine-Grained 3D Part Labeling](https://arxiv.org/abs/2301.10460) (ICCV)
- [ ] [\[2301.10540\] Modelling Long Range Dependencies in $N$D: From Task-Specific to a General Purpose CNN](https://arxiv.org/abs/2301.10540) (UVA.NL)
- [ ] [\[2301.10625\] Navigating the Pitfalls of Active Learning Evaluation: A Systematic Framework for Meaningful Performance Assessment](https://arxiv.org/abs/2301.10625) (NIPS)
- [ ] [\[2301.10750\] Out of Distribution Performance of State of Art Vision Model](https://arxiv.org/abs/2301.10750) (NYU)
- [ ] [\[2301.10900\] Graph Contrastive Learning for Skeleton-based Action Recognition](https://arxiv.org/abs/2301.10900) (ICLR)
- [ ] [\[2301.10922\] Detecting Building Changes with Off-Nadir Aerial Images](https://arxiv.org/abs/2301.10922) (WHU)
- [ ] [\[2301.10941\] GeCoNeRF: Few-shot Neural Radiance Fields via Geometric Consistency](https://arxiv.org/abs/2301.10941) (ICML)
- [ ] [\[2301.10972\] On the Importance of Noise Scheduling for Diffusion Models](https://arxiv.org/abs/2301.10972) (Google)
- [ ] [\[2301.11093\] Simple diffusion: End-to-end diffusion for high resolution images](https://arxiv.org/abs/2301.11093) (Google)
- [ ] [\[2301.11100\] Vision-Language Models Performing Zero-Shot Tasks Exhibit Gender-based Disparities](https://arxiv.org/abs/2301.11100) (Meta)
- [ ] [\[2301.11174\] Semi-Supervised Image Captioning by Adversarially Propagating Labeled Data](https://arxiv.org/abs/2301.11174) (POSTECH)
- [ ] [\[2301.11180\] Low-Rank Winograd Transformation for 3D Convolutional Neural Networks](https://arxiv.org/abs/2301.11180) (SJTU)
- [ ] [\[2301.11274\] Self-Supervised RGB-T Tracking with Cross-Input Consistency](https://arxiv.org/abs/2301.11274) (Imperial)
- [ ] [\[2301.11310\] Learning Good Features to Transfer Across Tasks and Domains](https://arxiv.org/abs/2301.11310) (Google, ICCV)
- [ ] [\[2301.11357\] Multimodal Event Transformer for Image-guided Story Ending Generation](https://arxiv.org/abs/2301.11357) (UTS)
- [ ] [\[2301.11362\] Improving Cross-modal Alignment for Text-Guided Image Inpainting](https://arxiv.org/abs/2301.11362) (UTS)
- [ ] [\[2301.11367\] Style-Aware Contrastive Learning for Multi-Style Image Captioning](https://arxiv.org/abs/2301.11367) (UTS)
- [ ] [\[2301.11387\] Universal Domain Adaptation for Remote Sensing Image Scene Classification](https://arxiv.org/abs/2301.11387) (TUM)
- [ ] [\[2301.11431\] Semidefinite Relaxations for Robust Multiview Triangulation](https://arxiv.org/abs/2301.11431) (TUM)
- [ ] [\[2301.11445\] 3DShape2VecSet: A 3D Shape Representation for Neural Fields and Generative Diffusion Models](https://arxiv.org/abs/2301.11445) (TUM, SIGGRAPH)
- [ ] [\[2301.11457\] Attacking Important Pixels for Anchor-free Detectors](https://arxiv.org/abs/2301.11457) (CMU)
- [ ] [\[2301.11507\] Semi-Parametric Video-Grounded Text Generation](https://arxiv.org/abs/2301.11507) (KAIST)
- [ ] [\[2301.11513\] CellMix: A General Instance Relationship based Method for Data Augmentation Towards Pathology Image Classification](https://arxiv.org/abs/2301.11513) (NJU)
- [ ] [\[2301.11650\] Fast Region of Interest Proposals on Maritime UAVs](https://arxiv.org/abs/2301.11650) (University of TÃ¼bingen)
- [ ] [\[2301.11915\] Understanding Self-Supervised Pretraining with Part-Aware Representation Learning](https://arxiv.org/abs/2301.11915) (Peking)
- [ ] [\[2301.12025\] Cross-Architectural Positive Pairs improve the effectiveness of Self-Supervised Learning](https://arxiv.org/abs/2301.12025) (NYU)
- [ ] [\[2301.12046\] Semantic Adversarial Attacks on Face Recognition through Significant Attributes](https://arxiv.org/abs/2301.12046) (HUST)
- [ ] [\[2301.12073\] Towards Equitable Representation in Text-to-Image Synthesis Models with the Cross-Cultural Understanding Benchmark (CCUB) Dataset](https://arxiv.org/abs/2301.12073) (CMU)
- [ ] [\[2301.12082\] Pushing the Limits of Fewshot Anomaly Detection in Industry Vision: Graphcore](https://arxiv.org/abs/2301.12082) (SUSTech)
- [ ] [\[2301.12159\] ClusterFuG: Clustering Fully connected Graphs by Multicut](https://arxiv.org/abs/2301.12159) (MPI, ICML)
- [ ] [\[2301.12247\] SEGA: Instructing Text-to-Image Models using Semantic Guidance](https://arxiv.org/abs/2301.12247) (NIPS)
- [ ] [\[2301.12257\] Few-shot Face Image Translation via GAN Prior Distillation](https://arxiv.org/abs/2301.12257) (Xidian)
- [ ] [\[2301.12332\] Towards Vision Transformer Unrolling Fixed-Point Algorithm: a Case Study on Image Restoration](https://arxiv.org/abs/2301.12332) (NUDT)
- [ ] [\[2301.12416\] Deep Learning for Human Parsing: A Survey](https://arxiv.org/abs/2301.12416) (IA CAS)
- [ ] [\[2301.12429\] Debiased Fine-Tuning for Vision-language Models by Prompt Regularization](https://arxiv.org/abs/2301.12429) (NTU)
- [ ] [\[2301.12439\] Unsupervised Domain Adaptation on Person Re-Identification via Dual-level Asymmetric Mutual Learning](https://arxiv.org/abs/2301.12439) (Xiamen)
- [ ] [\[2301.12470\] Gesture Control of Micro-drone: A Lightweight-Net with Domain Randomization and Trajectory Generators](https://arxiv.org/abs/2301.12470) (UESTC)
- [ ] [\[2301.12643\] Adversarial Style Augmentation for Domain Generalization](https://arxiv.org/abs/2301.12643) (PolyU)
- [ ] [\[2301.12644\] Tagging before Alignment: Integrating Multi-Modal Tags for Video-Text Retrieval](https://arxiv.org/abs/2301.12644) (Xiamen)
- [ ] [\[2301.12739\] FractalAD: A simple industrial anomaly detection method using fractal anomaly generation and backbone knowledge distillation](https://arxiv.org/abs/2301.12739) (SJTU)
- [ ] [\[2301.12798\] Reliable Federated Disentangling Network for Non-IID Domain Feature](https://arxiv.org/abs/2301.12798) (A*STAR,)
- [ ] [\[2301.13007\] EuclidNet: Deep Visual Reasoning for Constructible Problems in Geometry](https://arxiv.org/abs/2301.13007) (Columbia University)
- [ ] [\[2301.13012\] Key Feature Replacement of In-Distribution Samples for Out-of-Distribution Detection](https://arxiv.org/abs/2301.13012) (Illinois)
- [ ] [\[2301.13013\] RFPose-OT: RF-Based 3D Human Pose Estimation via Optimal Transport Theory](https://arxiv.org/abs/2301.13013) (USTC)
- [ ] [\[2301.13014\] Attribute-Guided Multi-Level Attention Network for Fine-Grained Fashion Retrieval](https://arxiv.org/abs/2301.13014) (University of Tokyo)
- [ ] [\[2301.13082\] PaCaNet: A Study on CycleGAN with Transfer Learning for Diversifying Fused Chinese Painting and Calligraphy](https://arxiv.org/abs/2301.13082) (NTU)
- [ ] [\[2301.13096\] Language-Driven Anchors for Zero-Shot Adversarial Robustness](https://arxiv.org/abs/2301.13096) (HIT, CVPR)
- [ ] [\[2301.13155\] Advancing Radiograph Representation Learning with Masked Record Modeling](https://arxiv.org/abs/2301.13155) (Xiamen, ICLR)
- [ ] [\[2301.13156\] SeaFormer++: Squeeze-enhanced Axial Transformer for Mobile Visual Recognition](https://arxiv.org/abs/2301.13156) (Fudan, ICLR)
- [ ] [\[2301.13190\] Audio-Visual Segmentation with Semantics](https://arxiv.org/abs/2301.13190) (ECCV)
- [ ] [\[2301.13335\] Multi-modal Large Language Model Enhanced Pseudo 3D Perception Framework for Visual Commonsense Reasoning](https://arxiv.org/abs/2301.13335) (Tongji)
- [ ] [\[2301.13359\] IM-IAD: Industrial Image Anomaly Detection Benchmark in Manufacturing](https://arxiv.org/abs/2301.13359) (SUSTech)
- [ ] [\[2301.13384\] GaitSADA: Self-Aligned Domain Adaptation for mmWave Gait Recognition](https://arxiv.org/abs/2301.13384) (Tsinghua)
- [ ] [\[2301.13430\] GeneFace: Generalized and High-Fidelity Audio-Driven 3D Talking Face Synthesis](https://arxiv.org/abs/2301.13430) (ICLR)
- [ ] [\[2301.13487\] Adversarial Training of Self-supervised Monocular Depth Estimation against Physical-World Attacks](https://arxiv.org/abs/2301.13487) (Rochester Institute of Technology, ICLR)
- [ ] [\[2301.13510\] 3D Former: Monocular Scene Reconstruction with 3D SDF Transformers](https://arxiv.org/abs/2301.13510) (ICLR)
- [ ] [\[2301.13514\] Fourier Sensitivity and Regularization of Computer Vision Models](https://arxiv.org/abs/2301.13514) (NUS)
- [ ] [\[2301.13558\] Lidar Upsampling with Sliced Wasserstein Distance](https://arxiv.org/abs/2301.13558) (TUM)
- [ ] [\[2301.13569\] NP-Match: Towards a New Probabilistic Model for Semi-Supervised Learning](https://arxiv.org/abs/2301.13569) (Oxford, ICML)
- [ ] [\[2301.13670\] What Makes Good Examples for Visual In-Context Learning?](https://arxiv.org/abs/2301.13670) (NTU)
- [ ] [\[2301.13721\] DisDiff: Unsupervised Disentanglement of Diffusion Probabilistic Models](https://arxiv.org/abs/2301.13721) (XJTU, NIPS)
- [ ] [\[2301.13741\] UPop: Unified and Progressive Pruning for Compressing Vision-Language Transformers](https://arxiv.org/abs/2301.13741) (Tsinghua, ICML)
- [ ] [\[2301.13743\] Zero-shot-Learning Cross-Modality Data Translation Through Mutual Information Guided Stochastic Diffusion](https://arxiv.org/abs/2301.13743) (Harvard)
- [ ] [\[2301.13826\] Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image Diffusion Models](https://arxiv.org/abs/2301.13826) (SIGGRAPH)
- [ ] [\[2301.13865\] From Semi-supervised to Omni-supervised Room Layout Estimation Using Point Clouds](https://arxiv.org/abs/2301.13865) (Tsinghua)
- [ ] [\[2302.00162\] Continual Segment: Towards a Single, Unified and Accessible Continual Segmentation Model of 143 Whole-body Organs in CT Scans](https://arxiv.org/abs/2302.00162) (ZJU)
- [ ] [\[2302.00179\] Stable Attribute Group Editing for Reliable Few-shot Image Generation](https://arxiv.org/abs/2302.00179) (UCAS)
- [ ] [\[2302.00224\] Human Fall Detection- Multimodality Approach](https://arxiv.org/abs/2302.00224) (University of Alberta)
- [ ] [\[2302.00268\] Compositional Prompt Tuning with Motion Cues for Open-vocabulary Video Relation Detection](https://arxiv.org/abs/2302.00268) (NTU, ICLR)
- [ ] [\[2302.00275\] Learning Generalized Zero-Shot Learners for Open-Domain Image Geolocalization](https://arxiv.org/abs/2302.00275) (Stanford)
- [ ] [\[2302.00290\] MS-DETR: Multispectral Pedestrian Detection Transformer with Loosely Coupled Fusion and Modality-Balanced Optimization](https://arxiv.org/abs/2302.00290) (NWPU)
- [ ] [\[2302.00368\] Test-Time Amendment with a Coarse Classifier for Fine-Grained Classification](https://arxiv.org/abs/2302.00368) (NIPS)
- [ ] [\[2302.00402\] mPLUG-2: A Modularized Multi-modal Foundation Model Across Text, Image and Video](https://arxiv.org/abs/2302.00402) (Alibaba)
- [ ] [\[2302.00491\] Learning Prototype Classifiers for Long-Tailed Recognition](https://arxiv.org/abs/2302.00491) (Google)
- [ ] [\[2302.00503\] Tracking People in Highly Dynamic Industrial Environments](https://arxiv.org/abs/2302.00503) (Oxford)
- [ ] [\[2302.00556\] Correspondence-free online human motion retargeting](https://arxiv.org/abs/2302.00556) (Inria)
- [ ] [\[2302.00624\] Open-VCLIP: Transforming CLIP to an Open-vocabulary Video Model via Interpolated Weight Optimization](https://arxiv.org/abs/2302.00624) (Fudan, ICML)
- [ ] [\[2302.00673\] ADAPT: Action-aware Driving Caption Transformer](https://arxiv.org/abs/2302.00673) (Tsinghua)
- [ ] [\[2302.00785\] SkinCon: A skin disease dataset densely annotated by domain experts for fine-grained model debugging and analysis](https://arxiv.org/abs/2302.00785) (NIPS)
- [ ] [\[2302.00884\] Exploring Invariant Representation for Visible-Infrared Person Re-Identification](https://arxiv.org/abs/2302.00884) (Xiamen)
- [ ] [\[2302.00901\] Longformer: Longitudinal Transformer for Alzheimer's Disease Classification with Structural MRIs](https://arxiv.org/abs/2302.00901) (SJTU)
- [ ] [\[2302.00903\] No One Left Behind: Real-World Federated Class-Incremental Learning](https://arxiv.org/abs/2302.00903) (ETH, TPAMI)
- [ ] [\[2302.00918\] Visual Realism Assessment for Face-swap Videos](https://arxiv.org/abs/2302.00918) (IA CAS)
- [ ] [\[2302.00930\] Adaptive Siamese Tracking with a Compact Latent Network](https://arxiv.org/abs/2302.00930) (TPAMI)
- [ ] [\[2302.00988\] HaMuCo: Hand Pose Estimation via Multiview Collaborative Self-Supervised Learning](https://arxiv.org/abs/2302.00988) (ICCV)
- [ ] [\[2302.01034\] An Efficient Convex Hull-based Vehicle Pose Estimation Method for 3D LiDAR](https://arxiv.org/abs/2302.01034) (USTC)
- [ ] [\[2302.01056\] Beyond Pretrained Features: Noisy Image Modeling Provides Adversarial Defense](https://arxiv.org/abs/2302.01056) (USyd, NIPS)
- [ ] [\[2302.01110\] DirectMHP: Direct 2D Multi-Person Head Pose Estimation with Full-range Angles](https://arxiv.org/abs/2302.01110) (SJTU)
- [ ] [\[2302.01133\] SceneScape: Text-Driven Consistent Scene Generation](https://arxiv.org/abs/2302.01133) (NVIDIA)
- [ ] [\[2302.01162\] Get3DHuman: Lifting StyleGAN-Human into a 3D Generative Model using Pixel-aligned Reconstruction Priors](https://arxiv.org/abs/2302.01162) (ICCV)
- [ ] [\[2302.01316\] Are Diffusion Models Vulnerable to Membership Inference Attacks?](https://arxiv.org/abs/2302.01316) (ICML)
- [ ] [\[2302.01327\] Dual PatchNorm](https://arxiv.org/abs/2302.01327) (Google)
- [ ] [\[2302.01330\] SceneDreamer: Unbounded 3D Scene Generation from 2D Image Collections](https://arxiv.org/abs/2302.01330) (TPAMI)
- [ ] [\[2302.01512\] Spectral Aware Softmax for Visible-Infrared Person Re-Identification](https://arxiv.org/abs/2302.01512) (Xiamen)
- [ ] [\[2302.01579\] Semantic 3D-aware Portrait Synthesis and Manipulation Based on Compositional Neural Radiance Field](https://arxiv.org/abs/2302.01579) (IA CAS)
- [ ] [\[2302.01593\] Explicit Box Detection Unifies End-to-End Multi-Person Pose Estimation](https://arxiv.org/abs/2302.01593) (ICLR)
- [ ] [\[2302.01608\] CFFT-GAN: Cross-domain Feature Fusion Transformer for Exemplar-based Image Translation](https://arxiv.org/abs/2302.01608) (IA CAS)
- [ ] [\[2302.01642\] Cluster-CAM: Cluster-Weighted Visual Interpretation of CNNs' Decision in Image Classification](https://arxiv.org/abs/2302.01642) (Xidian)
- [ ] [\[2302.01647\] Blockwise Self-Supervised Learning at Scale](https://arxiv.org/abs/2302.01647) (Cambridge)
- [ ] [\[2302.01650\] ShadowFormer: Global Context Helps Image Shadow Removal](https://arxiv.org/abs/2302.01650) (Harvard)
- [ ] [\[2302.01665\] CVTNet: A Cross-View Transformer Network for Place Recognition Using LiDAR Data](https://arxiv.org/abs/2302.01665) (NUDT)
- [ ] [\[2302.01735\] Rethinking Semi-Supervised Medical Image Segmentation: A Variance-Reduction Perspective](https://arxiv.org/abs/2302.01735) (NIPS)
- [ ] [\[2302.01825\] HDFormer: High-order Directed Transformer for 3D Human Pose Estimation](https://arxiv.org/abs/2302.01825) (CMU)
- [ ] [\[2302.01838\] vMAP: Vectorised Object Mapping for Neural Field SLAM](https://arxiv.org/abs/2302.01838) (CVPR)
- [ ] [\[2302.01881\] IKEA-Manual: Seeing Shape Assembly Step by Step](https://arxiv.org/abs/2302.01881) (NIPS)
- [ ] [\[2302.01891\] Egocentric Video Task Translation @ Ego4D Challenge 2022](https://arxiv.org/abs/2302.01891) (UT Austin, ECCV)
- [ ] [\[2302.02057\] Semantic Diffusion Network for Semantic Segmentation](https://arxiv.org/abs/2302.02057) (HKUST, NIPS)
- [ ] [\[2302.02075\] X-ReID: Cross-Instance Transformer for Identity-Level Person Re-Identification](https://arxiv.org/abs/2302.02075) (Tsinghua)
- [ ] [\[2302.02088\] AV-NeRF: Learning Neural Fields for Real-World Audio-Visual Scene Synthesis](https://arxiv.org/abs/2302.02088) (NIPS)
- [ ] [\[2302.02117\] Learning to Agree on Vision Attention for Visual Commonsense Reasoning](https://arxiv.org/abs/2302.02117) (NUS)
- [ ] [\[2302.02184\] Real-Time Image Demoireing on Mobile Devices](https://arxiv.org/abs/2302.02184) (Xiamen, ICLR)
- [ ] [\[2302.02210\] Oscillation-free Quantization for Low-bit Vision Transformers](https://arxiv.org/abs/2302.02210) (HKUST, ICML)
- [ ] [\[2302.02213\] CosPGD: an efficient white-box adversarial attack for pixel-wise prediction tasks](https://arxiv.org/abs/2302.02213) (ICML)
- [ ] [\[2302.02216\] A Minimax Approach Against Multi-Armed Adversarial Attacks Detection](https://arxiv.org/abs/2302.02216) (Inria)
- [ ] [\[2302.02249\] Self-supervised Multi-view Disentanglement for Expansion of Visual Collections](https://arxiv.org/abs/2302.02249) (CMU)
- [ ] [\[2302.02285\] ReDi: Efficient Learning-Free Diffusion Inference via Trajectory Retrieval](https://arxiv.org/abs/2302.02285) (ICML)
- [ ] [\[2302.02294\] A Disparity Refinement Framework for Learning-based Stereo Matching Methods in Cross-domain Setting for Laparoscopic Images](https://arxiv.org/abs/2302.02294) (Rochester Institute of Technology)
- [ ] [\[2302.02318\] Contrast with Reconstruct: Contrastive 3D Representation Learning Guided by Generative Pretraining](https://arxiv.org/abs/2302.02318) (Tsinghua, ICML)
- [ ] [\[2302.02335\] Semi-Supervised Domain Adaptation with Source Label Adaptation](https://arxiv.org/abs/2302.02335) (CVPR)
- [ ] [\[2302.02373\] ShiftDDPMs: Exploring Conditional Diffusion Models by Shifting Diffusion Trajectories](https://arxiv.org/abs/2302.02373) (ZJU)
- [ ] [\[2302.02410\] Decoupled Iterative Refinement Framework for Interacting Hands Reconstruction from a Single RGB Image](https://arxiv.org/abs/2302.02410) (BUPT, ICCV)
- [ ] [\[2302.02503\] Leaving Reality to Imagination: Robust Classification via Generated Datasets](https://arxiv.org/abs/2302.02503) (UCLA)
- [ ] [\[2302.02535\] PaRot: Patch-Wise Rotation-Invariant Network via Feature Disentanglement and Pose Restoration](https://arxiv.org/abs/2302.02535) (USyd)
- [ ] [\[2302.02550\] Domain Re-Modulation for Few-Shot Generative Domain Adaptation](https://arxiv.org/abs/2302.02550) (NIPS)
- [ ] [\[2302.02551\] CHiLS: Zero-Shot Image Classification with Hierarchical Label Sets](https://arxiv.org/abs/2302.02551) (UCSD, ICML)
- [ ] [\[2302.02598\] Cluster-aware Contrastive Learning for Unsupervised Out-of-distribution Detection](https://arxiv.org/abs/2302.02598) (UESTC)
- [ ] [\[2302.02615\] Rethinking Out-of-distribution (OOD) Detection: Masked Image Modeling is All You Need](https://arxiv.org/abs/2302.02615) (CUHK, CVPR)
- [ ] [\[2302.02688\] HyperSLICE: HyperBand optimized Spiral for Low-latency Interactive Cardiac Examination](https://arxiv.org/abs/2302.02688) (UCL)
- [ ] [\[2302.02693\] PatchDCT: Patch Refinement for High Quality Instance Segmentation](https://arxiv.org/abs/2302.02693) (Alibaba, ICLR)
- [ ] [\[2302.02752\] Baseline Method for the Sport Task of MediaEval 2022 with 3D CNNs using Attention Mechanisms](https://arxiv.org/abs/2302.02752) (MPI)
- [ ] [\[2302.02755\] Fine-Grained Action Detection with RGB and Pose Information using Two Stream Convolutional Networks](https://arxiv.org/abs/2302.02755) (MPI)
- [ ] [\[2302.02814\] MixFormer: End-to-End Tracking with Iterative Mixed Attention](https://arxiv.org/abs/2302.02814) (NJU, CVPR)
- [ ] [\[2302.02887\] UVDoc: Neural Grid-based Document Unwarping](https://arxiv.org/abs/2302.02887) (ETH, SIGGRAPH)
- [ ] [\[2302.02908\] LexLIP: Lexicon-Bottlenecked Language-Image Pre-Training for Large-Scale Image-Text Retrieval](https://arxiv.org/abs/2302.02908) (BU)
- [ ] [\[2302.03004\] Neural Collapse Inspired Feature-Classifier Alignment for Few-Shot Class Incremental Learning](https://arxiv.org/abs/2302.03004) (ICLR)
- [ ] [\[2302.03023\] V1T: large-scale mouse V1 response prediction using a Vision Transformer](https://arxiv.org/abs/2302.03023) (University of Edinburgh)
- [ ] [\[2302.03024\] AIM: Adapting Image Models for Efficient Video Action Recognition](https://arxiv.org/abs/2302.03024) (ICLR)
- [ ] [\[2302.03084\] Pic2Word: Mapping Pictures to Words for Zero-shot Composed Image Retrieval](https://arxiv.org/abs/2302.03084) (CVPR)
- [ ] [\[2302.03156\] Novel Building Detection and Location Intelligence Collection in Aerial Satellite Imagery](https://arxiv.org/abs/2302.03156) (GIT)
- [ ] [\[2302.03242\] Combating Online Misinformation Videos: Characterization, Detection, and Future Directions](https://arxiv.org/abs/2302.03242) (ICT CAS, ACMMM)
- [ ] [\[2302.03318\] PAMI: partition input and aggregate outputs for model interpretation](https://arxiv.org/abs/2302.03318) (SYSU)
- [ ] [\[2302.03397\] AniPixel: Towards Animatable Pixel-Aligned Human Avatar](https://arxiv.org/abs/2302.03397) (USyd)
- [ ] [\[2302.03531\] Structured Generative Models for Scene Understanding](https://arxiv.org/abs/2302.03531) (University of Edinburgh)
- [ ] [\[2302.03566\] Look Around and Learn: Self-Training Object Detection by Exploration](https://arxiv.org/abs/2302.03566) (ECCV)
- [ ] [\[2302.03629\] Ethical Considerations for Responsible Data Curation](https://arxiv.org/abs/2302.03629) (NIPS)
- [ ] [\[2302.03648\] Class-Incremental Learning: A Survey](https://arxiv.org/abs/2302.03648) (NTU, TPAMI)
- [ ] [\[2302.03665\] HumanMAC: Masked Motion Completion for Human Motion Prediction](https://arxiv.org/abs/2302.03665) (ICCV)
- [ ] [\[2302.03675\] Auditing Gender Presentation Differences in Text-to-Image Models](https://arxiv.org/abs/2302.03675) (GIT)
- [ ] [\[2302.03744\] 3D Neural Embedding Likelihood: Probabilistic Inverse Graphics for Robust 6D Pose Estimation](https://arxiv.org/abs/2302.03744) (Google, ICCV)
- [ ] [\[2302.03750\] Linking convolutional kernel size to generalization bias in face analysis CNNs](https://arxiv.org/abs/2302.03750) (Yale)
- [ ] [\[2302.03751\] Understanding Why ViT Trains Badly on Small Datasets: An Intuitive Perspective](https://arxiv.org/abs/2302.03751) (NYU)
- [ ] [\[2302.03802\] Standing Between Past and Future: Spatio-Temporal Modeling for Multi-Camera 3D Multi-Object Tracking](https://arxiv.org/abs/2302.03802) (Illinois, CVPR)
- [ ] [\[2302.03819\] The XPRESS Challenge: Xray Projectomic Reconstruction -- Extracting Segmentation with Skeletons](https://arxiv.org/abs/2302.03819) (Harvard)
- [ ] [\[2302.03840\] MMPD: Multi-Domain Mobile Video Physiology Dataset](https://arxiv.org/abs/2302.03840) (Tsinghua)
- [ ] [\[2302.03860\] EVEN: An Event-Based Framework for Monocular Depth Estimation at Adverse Night Conditions](https://arxiv.org/abs/2302.03860) (Imperial)
- [ ] [\[2302.03900\] Zero-shot Generation of Coherent Storybook from Plain Text Story using Diffusion Models](https://arxiv.org/abs/2302.03900) (Sungkyunkwan University)
- [ ] [\[2302.03911\] Multi-site Organ Segmentation with Federated Partial Supervision and Site Adaptation](https://arxiv.org/abs/2302.03911) (USTC)
- [ ] [\[2302.03914\] Generalized Few-Shot 3D Object Detection of LiDAR Point Cloud for Autonomous Driving](https://arxiv.org/abs/2302.03914) (BIT)
- [ ] [\[2302.03985\] Cross-Layer Retrospective Retrieving via Layer Attention](https://arxiv.org/abs/2302.03985) (ZJU, ICLR)
- [ ] [\[2302.04002\] The Devil is in the Wrongly-classified Samples: Towards Unified Open-set Recognition](https://arxiv.org/abs/2302.04002) (XJTU, ICLR)
- [ ] [\[2302.04060\] A Systematic Evaluation and Benchmark for Embedding-Aware Generative Models: Features, Models, and Any-shot Scenarios](https://arxiv.org/abs/2302.04060) (ZJU)
- [ ] [\[2302.04075\] Best Practices in Active Learning for Semantic Segmentation](https://arxiv.org/abs/2302.04075) (DLR)
- [ ] [\[2302.04149\] Domain Adaptation of Synthetic Driving Datasets for Real-World Autonomous Driving](https://arxiv.org/abs/2302.04149) (Bosch)
- [ ] [\[2302.04303\] Adapting Pre-trained Vision Transformers from 2D to 3D through Weight Inflation Improves Medical Image Segmentation](https://arxiv.org/abs/2302.04303) (Stanford)
- [ ] [\[2302.04308\] Enhancing Modality-Agnostic Representations via Meta-Learning for Brain Tumor Segmentation](https://arxiv.org/abs/2302.04308) (ICCV)
- [ ] [\[2302.04358\] Mitigating Bias in Visual Transformers via Targeted Alignment](https://arxiv.org/abs/2302.04358) (GIT)
- [ ] [\[2302.04427\] Zero-Knowledge Zero-Shot Learning for Novel Visual Category Discovery](https://arxiv.org/abs/2302.04427) (Columbia University)
- [ ] [\[2302.04447\] Contour Completion using Deep Structural Priors](https://arxiv.org/abs/2302.04447) (University of Toronto)
- [ ] [\[2302.04476\] Towards Geospatial Foundation Models via Continual Pretraining](https://arxiv.org/abs/2302.04476) (AWS, ICCV)
- [ ] [\[2302.04521\] IH-ViT: Vision Transformer-based Integrated Circuit Appear-ance Defect Detection](https://arxiv.org/abs/2302.04521) (HUST)
- [ ] [\[2302.04544\] GMConv: Modulating Effective Receptive Fields for Convolutional Kernels](https://arxiv.org/abs/2302.04544) (Microsoft)
- [ ] [\[2302.04578\] Adversarial Example Does Good: Preventing Painting Imitation from Diffusion Models via Adversarial Examples](https://arxiv.org/abs/2302.04578) (SJTU, ICML)
- [ ] [\[2302.04589\] MAPS: A Noise-Robust Progressive Learning Approach for Source-Free Domain Adaptive Keypoint Detection](https://arxiv.org/abs/2302.04589) (IA CAS)
- [ ] [\[2302.04607\] Deep Intra-Image Contrastive Learning for Weakly Supervised One-Step Person Search](https://arxiv.org/abs/2302.04607) (NWPU)
- [ ] [\[2302.04638\] Better Diffusion Models Further Improve Adversarial Training](https://arxiv.org/abs/2302.04638) (ICML)
- [ ] [\[2302.04824\] Lithium Metal Battery Quality Control via Transformer-CNN Segmentation](https://arxiv.org/abs/2302.04824) (Berkeley)
- [ ] [\[2302.04832\] Bridging the Sim2Real gap with CARE: Supervised Detection Adaptation with Conditional Alignment and Reweighting](https://arxiv.org/abs/2302.04832) (GIT)
- [ ] [\[2302.04841\] Is This Loss Informative? Faster Text-to-Image Customization by Tracking Objective Dynamics](https://arxiv.org/abs/2302.04841) (NIPS)
- [ ] [\[2302.04858\] Re-ViLM: Retrieval-Augmented Visual Language Model for Zero and Few-Shot Image Captioning](https://arxiv.org/abs/2302.04858) (Illinois)
- [ ] [\[2302.04860\] Diverse Human Motion Prediction Guided by Multi-Level Spatial-Temporal Anchors](https://arxiv.org/abs/2302.04860) (ECCV)
- [ ] [\[2302.04862\] Polynomial Neural Fields for Subband Decomposition and Manipulation](https://arxiv.org/abs/2302.04862) (NIPS)
- [ ] [\[2302.04869\] Reversible Vision Transformers](https://arxiv.org/abs/2302.04869) (CVPR)
- [ ] [\[2302.04936\] Unsupervised ore/waste classification on open-cut mine faces using close-range hyperspectral data](https://arxiv.org/abs/2302.04936) (USyd)
- [ ] [\[2302.04973\] Invariant Slot Attention: Object Discovery with Slot-Centric Reference Frames](https://arxiv.org/abs/2302.04973) (ICML)
- [ ] [\[2302.05017\] A survey on facial image deblurring](https://arxiv.org/abs/2302.05017) (IS CAS)
- [ ] [\[2302.05043\] A Review of Predictive and Contrastive Self-supervised Learning for Medical Images](https://arxiv.org/abs/2302.05043) (USyd)
- [ ] [\[2302.05087\] Generalized Video Anomaly Event Detection: Systematic Taxonomy and Comparison of Deep Models](https://arxiv.org/abs/2302.05087) (Fudan)
- [ ] [\[2302.05098\] Confidence-based Reliable Learning under Dual Noises](https://arxiv.org/abs/2302.05098) (Tsinghua, NIPS)
- [ ] [\[2302.05155\] TTN: A Domain-Shift Aware Batch Normalization in Test-Time Adaptation](https://arxiv.org/abs/2302.05155) (ICLR)
- [ ] [\[2302.05293\] A Novel Improved Mask RCNN for Multiple Targets Detection in the Indoor Complex Scenes](https://arxiv.org/abs/2302.05293) (BU)
- [ ] [\[2302.05294\] MoreauGrad: Sparse and Robust Interpretation of Neural Networks via Moreau Envelope](https://arxiv.org/abs/2302.05294) (CUHK)
- [ ] [\[2302.05297\] Objective Evaluation-based High-efficiency Learning Framework for Hyperspectral Image Classification](https://arxiv.org/abs/2302.05297) (NJU)
- [ ] [\[2302.05330\] Action Dynamics Task Graphs for Learning Plannable Representations of Procedural Tasks](https://arxiv.org/abs/2302.05330) (Illinois)
- [ ] [\[2302.05438\] Deep Learning on Implicit Neural Representations of Shapes](https://arxiv.org/abs/2302.05438) (ICLR)
- [ ] [\[2302.05442\] Scaling Vision Transformers to 22 Billion Parameters](https://arxiv.org/abs/2302.05442) (Google)
- [ ] [\[2302.05499\] CUDA: Curriculum of Data Augmentation for Long-Tailed Recognition](https://arxiv.org/abs/2302.05499) (ICLR)
- [ ] [\[2302.05615\] Anatomical Invariance Modeling and Semantic Alignment for Self-supervised Learning in 3D Medical Image Analysis](https://arxiv.org/abs/2302.05615) (Alibaba, ICCV)
- [ ] [\[2302.05666\] Jaccard Metric Losses: Optimizing the Jaccard Index with Soft Labels](https://arxiv.org/abs/2302.05666) (KU Leuven, NIPS)
- [ ] [\[2302.05746\] Removing Image Artifacts From Scratched Lens Protectors](https://arxiv.org/abs/2302.05746) (BU)
- [ ] [\[2302.05757\] Multispectral Contrastive Learning with Viewmaker Networks](https://arxiv.org/abs/2302.05757) (CVPR)
- [ ] [\[2302.05844\] Graph Matching Optimization Network for Point Cloud Registration](https://arxiv.org/abs/2302.05844) (UTS)
- [ ] [\[2302.05846\] OAMatcher: An Overlapping Areas-based Network for Accurate Local Feature Matching](https://arxiv.org/abs/2302.05846) (HIT)
- [ ] [\[2302.05872\] I$^2$SB: Image-to-Image Schr\"odinger Bridge](https://arxiv.org/abs/2302.05872) (GIT, ICML)
- [ ] [\[2302.05905\] Single Motion Diffusion](https://arxiv.org/abs/2302.05905) (Tel Aviv)
- [ ] [\[2302.05916\] Video Waterdrop Removal via Spatio-Temporal Fusion in Driving Scenes](https://arxiv.org/abs/2302.05916) (HKUST)
- [ ] [\[2302.05936\] Generalized Few-Shot Continual Learning with Contrastive Mixture of Adapters](https://arxiv.org/abs/2302.05936) (NTU)
- [ ] [\[2302.06052\] CEDNet: A Cascade Encoder-Decoder Network for Dense Prediction](https://arxiv.org/abs/2302.06052) (HUST)
- [ ] [\[2302.06058\] Bi-directional Masks for Efficient N:M Sparse Training](https://arxiv.org/abs/2302.06058) (Xiamen)
- [ ] [\[2302.06060\] Threatening Patch Attacks on Object Detection in Optical Remote Sensing Images](https://arxiv.org/abs/2302.06060) (NWPU)
- [ ] [\[2302.06072\] Actional Atomic-Concept Learning for Demystifying Vision-Language Navigation](https://arxiv.org/abs/2302.06072) (SYSU)
- [ ] [\[2302.06130\] Learning to Scale Temperature in Masked Self-Attention for Image Inpainting](https://arxiv.org/abs/2302.06130) (SUSTech)
- [ ] [\[2302.06185\] PUPS: Point Cloud Unified Panoptic Segmentation](https://arxiv.org/abs/2302.06185) (ZJU)
- [ ] [\[2302.06494\] Explicit3D: Graph Network with Spatial Inference for Single Image 3D Object Detection](https://arxiv.org/abs/2302.06494) (Tsinghua)
- [ ] [\[2302.06504\] Preconditioned Score-based Generative Models](https://arxiv.org/abs/2302.06504) (Fudan)
- [ ] [\[2302.06514\] Multiple Appropriate Facial Reaction Generation in Dyadic Interaction Settings: What, Why and How?](https://arxiv.org/abs/2302.06514) (Cambridge)
- [ ] [\[2302.06556\] VA-DepthNet: A Variational Approach to Single Image Depth Prediction](https://arxiv.org/abs/2302.06556) (UESTC, ICLR)
- [ ] [\[2302.06605\] UniAdapter: Unified Parameter-Efficient Transfer Learning for Cross-modal Modeling](https://arxiv.org/abs/2302.06605) (Berkeley)
- [ ] [\[2302.06608\] 3D-aware Blending with Generative NeRFs](https://arxiv.org/abs/2302.06608) (ICCV)
- [ ] [\[2302.06733\] Robust Unsupervised StyleGAN Image Restoration](https://arxiv.org/abs/2302.06733) (CVPR)
- [ ] [\[2302.06793\] HR-NeuS: Recovering High-Frequency Surface Geometry via Neural Implicit Surfaces](https://arxiv.org/abs/2302.06793) (Berkeley)
- [ ] [\[2302.06826\] DiffFashion: Reference-based Fashion Design with Structure-aware Transfer by Diffusion Models](https://arxiv.org/abs/2302.06826) (ZJU)
- [ ] [\[2302.06845\] SEAM: Searching Transferable Mixed-Precision Quantization Policy through Large Margin Regularization](https://arxiv.org/abs/2302.06845) (Tsinghua)
- [ ] [\[2302.06857\] Make Your Brief Stroke Real and Stereoscopic: 3D-Aware Simplified Sketch to Portrait Generation](https://arxiv.org/abs/2302.06857) (USyd)
- [ ] [\[2302.06961\] DualStreamFoveaNet: A Dual Stream Fusion Architecture with Anatomical Awareness for Robust Fovea Localization](https://arxiv.org/abs/2302.06961) (SJTU)
- [ ] [\[2302.06992\] Hard-aware Instance Adaptive Self-training for Unsupervised Cross-domain Semantic Segmentation](https://arxiv.org/abs/2302.06992) (BUPT)
- [ ] [\[2302.07106\] Normalizing Flow based Feature Synthesis for Outlier-Aware Object Detection](https://arxiv.org/abs/2302.07106) (CVPR)
- [ ] [\[2302.07121\] Universal Guidance for Diffusion Models](https://arxiv.org/abs/2302.07121) (UMD)
- [ ] [\[2302.07344\] Semi-Supervised Visual Tracking of Marine Animals using Autonomous Underwater Vehicles](https://arxiv.org/abs/2302.07344) (MIT)
- [ ] [\[2302.07387\] PolyFormer: Referring Image Segmentation as Sequential Polygon Generation](https://arxiv.org/abs/2302.07387) (CVPR)
- [ ] [\[2302.07440\] Road Redesign Technique Achieving Enhanced Road Safety by Inpainting with a Diffusion Model](https://arxiv.org/abs/2302.07440) (KAIST)
- [ ] [\[2302.07483\] EdgeYOLO: An Edge-Real-Time Object Detector](https://arxiv.org/abs/2302.07483) (BIT)
- [ ] [\[2302.07579\] Semi-Supervised Deep Regression with Uncertainty Consistency and Variational Model Ensembling via Bayesian Neural Networks](https://arxiv.org/abs/2302.07579) (HKUST)
- [ ] [\[2302.07669\] Unsupervised Hashing with Similarity Distribution Calibration](https://arxiv.org/abs/2302.07669) (NTU)
- [ ] [\[2302.07676\] DIVOTrack: A Novel Dataset and Baseline Method for Cross-View Multi-Object Tracking in DIVerse Open Scenes](https://arxiv.org/abs/2302.07676) (ZJU)
- [ ] [\[2302.07685\] Video Probabilistic Diffusion Models in Projected Latent Space](https://arxiv.org/abs/2302.07685) (Google, CVPR)
- [ ] [\[2302.07734\] TFormer: A Transmission-Friendly ViT Model for IoT Devices](https://arxiv.org/abs/2302.07734) (Meta)
- [ ] [\[2302.07817\] Tri-Perspective View for Vision-Based 3D Semantic Occupancy Prediction](https://arxiv.org/abs/2302.07817) (CVPR)
- [ ] [\[2302.07864\] Denoising Diffusion Probabilistic Models for Robust Image Super-Resolution in the Wild](https://arxiv.org/abs/2302.07864) (University of Toronto)
- [ ] [\[2302.07944\] Effective Data Augmentation With Diffusion Models](https://arxiv.org/abs/2302.07944) (CMU)
- [ ] [\[2302.08023\] Object-centric Learning with Cyclic Walks between Parts and Whole](https://arxiv.org/abs/2302.08023) (A*STAR,, NIPS)
- [ ] [\[2302.08050\] Positive-unlabeled learning for binary and multi-class cell detection in histopathology images with incomplete annotations](https://arxiv.org/abs/2302.08050) (BIT)
- [ ] [\[2302.08058\] Learning Non-Local Spatial-Angular Correlation for Light Field Image Super-Resolution](https://arxiv.org/abs/2302.08058) (ICCV)
- [ ] [\[2302.08062\] Fossil Image Identification using Deep Learning Ensembles of Data Augmented Multiviews](https://arxiv.org/abs/2302.08062) (NJU)
- [ ] [\[2302.08207\] Parallax-Tolerant Unsupervised Deep Image Stitching](https://arxiv.org/abs/2302.08207) (ICCV)
- [ ] [\[2302.08242\] Tuning computer vision models with task rewards](https://arxiv.org/abs/2302.08242) (Google)
- [ ] [\[2302.08243\] New Insights on Relieving Task-Recency Bias for Online Class Incremental Learning](https://arxiv.org/abs/2302.08243) (NWPU)
- [ ] [\[2302.08357\] Boundary Guided Learning-Free Semantic Control with Diffusion Models](https://arxiv.org/abs/2302.08357) (Princeton, NIPS)
- [ ] [\[2302.08366\] Defect Transfer GAN: Diverse Defect Synthesis for Data Augmentation](https://arxiv.org/abs/2302.08366) (Bosch)
- [ ] [\[2302.08474\] Efficient 3D Object Reconstruction using Visual Transformers](https://arxiv.org/abs/2302.08474) (GIT)
- [ ] [\[2302.08503\] Unpaired Image-to-Image Translation with Limited Data to Reveal Subtle Phenotypes](https://arxiv.org/abs/2302.08503) (PSL University)
- [ ] [\[2302.08674\] EnfoMax: Domain Entropy and Mutual Information Maximization for Domain Generalized Face Anti-spoofing](https://arxiv.org/abs/2302.08674) (SJTU)
- [ ] [\[2302.08741\] New Insights for the Stability-Plasticity Dilemma in Online Continual Learning](https://arxiv.org/abs/2302.08741) (ICLR)
- [ ] [\[2302.08760\] 3D Human Pose Lifting with Grid Convolution](https://arxiv.org/abs/2302.08760) (Tsinghua)
- [ ] [\[2302.08769\] Collaborative Discrepancy Optimization for Reliable Image Anomaly Localization](https://arxiv.org/abs/2302.08769) (HUST)
- [ ] [\[2302.08788\] MixNeRF: Modeling a Ray with Mixture Density for Novel View Synthesis from Sparse Inputs](https://arxiv.org/abs/2302.08788) (CVPR)
- [ ] [\[2302.08908\] LayoutDiffuse: Adapting Foundational Diffusion Models for Layout-to-Image Generation](https://arxiv.org/abs/2302.08908) (SJTU)
- [ ] [\[2302.08958\] Towards Unifying Medical Vision-and-Language Pre-training via Soft Prompts](https://arxiv.org/abs/2302.08958) (HKUST)
- [ ] [\[2302.09018\] Self-supervised Action Representation Learning from Partial Spatio-Temporal Skeleton Sequences](https://arxiv.org/abs/2302.09018) (CUHK)
- [ ] [\[2302.09027\] CK-Transformer: Commonsense Knowledge Enhanced Transformers for Referring Expression Comprehension](https://arxiv.org/abs/2302.09027) (UVA.NL)
- [ ] [\[2302.09208\] Bridge Damage Cause Estimation Using Multiple Images Based on Visual Question Answering](https://arxiv.org/abs/2302.09208) (University of Tokyo)
- [ ] [\[2302.09260\] Attribute-Specific Manipulation Based on Layer-Wise Channels](https://arxiv.org/abs/2302.09260) (NJU)
- [ ] [\[2302.09309\] StyleAdv: Meta Style Adversarial Training for Cross-Domain Few-Shot Learning](https://arxiv.org/abs/2302.09309) (CVPR)
- [ ] [\[2302.09311\] Temporal Interpolation Is All You Need for Dynamic Neural Radiance Fields](https://arxiv.org/abs/2302.09311) (CVPR)
- [ ] [\[2302.09323\] Heterogeneous Graph Convolutional Neural Network via Hodge-Laplacian for Brain Functional Data](https://arxiv.org/abs/2302.09323) (NUS)
- [ ] [\[2302.09352\] MaxGNR: A Dynamic Weight Strategy via Maximizing Gradient-to-Noise Ratio for Multi-Task Learning](https://arxiv.org/abs/2302.09352) (SYSU)
- [ ] [\[2302.09461\] Liveness score-based regression neural networks for face anti-spoofing](https://arxiv.org/abs/2302.09461) (KAIST)
- [ ] [\[2302.09467\] Designing a 3D-Aware StyleNeRF Encoder for Face Editing](https://arxiv.org/abs/2302.09467) (IA CAS)
- [ ] [\[2302.09498\] Mutual Exclusive Modulator for Long-Tailed Recognition](https://arxiv.org/abs/2302.09498) (USTC)
- [ ] [\[2302.09522\] Interactive Video Corpus Moment Retrieval using Reinforcement Learning](https://arxiv.org/abs/2302.09522) (ACMMM)
- [ ] [\[2302.09528\] A Comprehensive Evaluation Study on Risk Level Classification of Melanoma by Computer Vision on ISIC 2016-2020 Datasets](https://arxiv.org/abs/2302.09528) (UTS)
- [ ] [\[2302.09585\] StreamingFlow: Streaming Occupancy Forecasting with Asynchronous Multi-modal Data Streams via Neural Ordinary Differential Equation](https://arxiv.org/abs/2302.09585) (CVPR)
- [ ] [\[2302.09598\] Guided Depth Map Super-resolution: A Survey](https://arxiv.org/abs/2302.09598) (HIT)
- [ ] [\[2302.09765\] ENInst: Enhancing Weakly-supervised Low-shot Instance Segmentation](https://arxiv.org/abs/2302.09765) (POSTECH)
- [ ] [\[2302.09779\] Incremental Few-Shot Object Detection via Simple Fine-Tuning Approach](https://arxiv.org/abs/2302.09779) (KAIST)
- [ ] [\[2302.09790\] HTNet: Human Topology Aware Network for 3D Human Pose Estimation](https://arxiv.org/abs/2302.09790) (Peking)
- [ ] [\[2302.09814\] Pseudo Label-Guided Model Inversion Attack via Conditional Generative Adversarial Network](https://arxiv.org/abs/2302.09814) (USTC)
- [ ] [\[2302.09884\] GlocalFuse-Depth: Fusing Transformers and CNNs for All-day Self-supervised Monocular Depth Estimation](https://arxiv.org/abs/2302.09884) (HKU)
- [ ] [\[2302.09886\] InOR-Net: Incremental 3D Object Recognition Network for Point Cloud Representation](https://arxiv.org/abs/2302.09886) (ETH)
- [ ] [\[2302.09919\] Interactive Face Video Coding: A Generative Compression Framework](https://arxiv.org/abs/2302.09919) (Alibaba)
- [ ] [\[2302.10279\] Image Reconstruction via Deep Image Prior Subspaces](https://arxiv.org/abs/2302.10279) (UCL)
- [ ] [\[2302.10281\] LiT Tuned Models for Efficient Species Detection](https://arxiv.org/abs/2302.10281) (NYU)
- [ ] [\[2302.10283\] Self-supervised learning of Split Invariant Equivariant representations](https://arxiv.org/abs/2302.10283) (Meta)
- [ ] [\[2302.10307\] ViewCo: Discovering Text-Supervised Segmentation Masks via Multi-View Semantic Consistency](https://arxiv.org/abs/2302.10307) (UTS)
- [ ] [\[2302.10326\] Unsupervised Out-of-Distribution Detection with Diffusion Inpainting](https://arxiv.org/abs/2302.10326) (Cornell, ICML)
- [ ] [\[2302.10383\] On Interpretable Approaches to Cluster, Classify and Represent Multi-Subspace Data via Minimum Lossy Coding Length based on Rate-Distortion Theory](https://arxiv.org/abs/2302.10383) (ZJU)
- [ ] [\[2302.10390\] DrasCLR: A Self-supervised Framework of Learning Disease-related and Anatomy-specific Representation for 3D Medical Images](https://arxiv.org/abs/2302.10390) (BU)
- [ ] [\[2302.10425\] Instance-incremental Scene Graph Generation from Real-world Point Clouds via Normalizing Flows](https://arxiv.org/abs/2302.10425) (BUPT)
- [ ] [\[2302.10450\] Automotive RADAR sub-sampling via object detection networks: Leveraging prior signal information](https://arxiv.org/abs/2302.10450) (UT Austin)
- [ ] [\[2302.10473\] Oriented Object Detection in Optical Remote Sensing Images using Deep Learning: A Survey](https://arxiv.org/abs/2302.10473) (NUDT)
- [ ] [\[2302.10501\] Few-Shot Point Cloud Semantic Segmentation via Contrastive Self-Supervision and Multi-Resolution Attention](https://arxiv.org/abs/2302.10501) (A*STAR,)
- [ ] [\[2302.10518\] USR: Unsupervised Separated 3D Garment and Human Reconstruction via Geometry and Semantic Consistency](https://arxiv.org/abs/2302.10518) (SJTU)
- [ ] [\[2302.10544\] EC-SfM: Efficient Covisibility-based Structure-from-Motion for Both Sequential and Unordered Images](https://arxiv.org/abs/2302.10544) (ZJU)
- [ ] [\[2302.10574\] MulGT: Multi-task Graph-Transformer with Task-aware Knowledge Injection and Domain Knowledge-driven Pooling for Whole Slide Image Analysis](https://arxiv.org/abs/2302.10574) (HKU)
- [ ] [\[2302.10586\] Diffusion Models and Semi-Supervised Learners Benefit Mutually with Few Labels](https://arxiv.org/abs/2302.10586) (Tsinghua, NIPS)
- [ ] [\[2302.10635\] Semantic Segmentation of Urban Textured Meshes Through Point Sampling](https://arxiv.org/abs/2302.10635) (ISPRS)
- [ ] [\[2302.10756\] Unsupervised Seismic Footprint Removal With Physical Prior Augmented Deep Autoencoder](https://arxiv.org/abs/2302.10756) (UESTC)
- [ ] [\[2302.10808\] Bokeh Rendering Based on Adaptive Depth Calibration Network](https://arxiv.org/abs/2302.10808) (Tsinghua)
- [ ] [\[2302.10813\] Tracking Objects and Activities with Attention for Temporal Sentence Grounding](https://arxiv.org/abs/2302.10813) (HUST)
- [ ] [\[2302.11217\] Connecting Vision and Language with Video Localized Narratives](https://arxiv.org/abs/2302.11217) (CVPR)
- [ ] [\[2302.11299\] Towards End-to-end Semi-supervised Learning for One-stage Object Detection](https://arxiv.org/abs/2302.11299) (Xiamen)
- [ ] [\[2302.11301\] View Consistency Aware Holistic Triangulation for 3D Human Pose Estimation](https://arxiv.org/abs/2302.11301) (SJTU)
- [ ] [\[2302.11306\] Human MotionFormer: Transferring Human Motions with Vision Transformers](https://arxiv.org/abs/2302.11306) (HKUST, ICLR)
- [ ] [\[2302.11349\] Steerable Equivariant Representation Learning](https://arxiv.org/abs/2302.11349) (Google)
- [ ] [\[2302.11356\] Poisson Conjugate Prior for PHD Filtering based Track-Before-Detect Strategies in Radar Systems](https://arxiv.org/abs/2302.11356) (UESTC)
- [ ] [\[2302.11383\] Entity-Level Text-Guided Image Manipulation](https://arxiv.org/abs/2302.11383) (CVPR)
- [ ] [\[2302.11416\] Structure Embedded Nucleus Classification for Histopathology Images](https://arxiv.org/abs/2302.11416) (SYSU)
- [ ] [\[2302.11461\] Saliency Guided Contrastive Learning on Scene Images](https://arxiv.org/abs/2302.11461) (USyd)
- [ ] [\[2302.11544\] One-Pot Multi-Frame Denoising](https://arxiv.org/abs/2302.11544) (Peking)
- [ ] [\[2302.11797\] Region-Aware Diffusion for Zero-shot Text-driven Image Editing](https://arxiv.org/abs/2302.11797) (IA CAS)
- [ ] [\[2302.11867\] Transformers in Single Object Tracking: An Experimental Survey](https://arxiv.org/abs/2302.11867) (CVPR)
- [ ] [\[2302.11984\] Unsupervised Domain Adaptation via Distilled Discriminative Clustering](https://arxiv.org/abs/2302.11984) (Peking)
- [ ] [\[2302.12052\] Attention Mechanism for Contrastive Learning in GAN-based Image-to-Image Translation](https://arxiv.org/abs/2302.12052) (TUM)
- [ ] [\[2302.12231\] DiffusioNeRF: Regularizing Neural Radiance Fields with Denoising Diffusion Models](https://arxiv.org/abs/2302.12231) (CVPR)
- [ ] [\[2302.12242\] Side Adapter Network for Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2302.12242) (CVPR)
- [ ] [\[2302.12248\] Learning Visual Representations via Language-Guided Sampling](https://arxiv.org/abs/2302.12248) (CVPR)
- [ ] [\[2302.12251\] VoxFormer: Sparse Voxel Transformer for Camera-based 3D Semantic Scene Completion](https://arxiv.org/abs/2302.12251) (NVIDIA, CVPR)
- [ ] [\[2302.12252\] Boosting Adversarial Transferability using Dynamic Cues](https://arxiv.org/abs/2302.12252) (ICLR)
- [ ] [\[2302.12464\] RGI: robust GAN-inversion for mask-free image inpainting and unsupervised pixel-wise anomaly detection](https://arxiv.org/abs/2302.12464) (GIT)
- [ ] [\[2302.12552\] Deep Learning for Video-Text Retrieval: a Review](https://arxiv.org/abs/2302.12552) (NUDT)
- [ ] [\[2302.12712\] Amortised Invariance Learning for Contrastive Self-Supervision](https://arxiv.org/abs/2302.12712) (University of Edinburgh, ICLR)
- [ ] [\[2302.12764\] Modulating Pretrained Diffusion Models for Multimodal Image Synthesis](https://arxiv.org/abs/2302.12764) (GIT, SIGGRAPH)
- [ ] [\[2302.12827\] Decoupling Human and Camera Motion from Videos in the Wild](https://arxiv.org/abs/2302.12827) (CVPR)
- [ ] [\[2302.12967\] Temporal-Channel Topology Enhanced Network for Skeleton-Based Action Recognition](https://arxiv.org/abs/2302.12967) (IA CAS)
- [ ] [\[2302.12971\] BrainCLIP: Bridging Brain and Visual-Linguistic Representation Via CLIP for Generic Natural Visual Stimulus Decoding](https://arxiv.org/abs/2302.12971) (XJTU)
- [ ] [\[2302.12986\] Self-similarity Driven Scale-invariant Learning for Weakly Supervised Person Search](https://arxiv.org/abs/2302.12986) (IA CAS)
- [ ] [\[2302.12995\] Raw Image Reconstruction with Learned Compact Metadata](https://arxiv.org/abs/2302.12995) (PolyU, CVPR)
- [ ] [\[2302.13094\] Knowledge-infused Contrastive Learning for Urban Imagery-based Socioeconomic Prediction](https://arxiv.org/abs/2302.13094) (Tsinghua)
- [ ] [\[2302.13130\] Point Cloud Forecasting as a Proxy for 4D Occupancy Forecasting](https://arxiv.org/abs/2302.13130) (CVPR)
- [ ] [\[2302.13153\] Directed Diffusion: Direct Control of Object Placement through Attention Guidance](https://arxiv.org/abs/2302.13153) (Google)
- [ ] [\[2302.13263\] PaRK-Detect: Towards Efficient Multi-Task Satellite Imagery Road Extraction via Patch-Wise Keypoints Detection](https://arxiv.org/abs/2302.13263) (BUPT)
- [ ] [\[2302.13275\] Learning cross space mapping via DNN using large scale click-through logs](https://arxiv.org/abs/2302.13275) (HIT)
- [ ] [\[2302.13301\] Pillar R-CNN for Point Cloud 3D Object Detection](https://arxiv.org/abs/2302.13301) (HIT)
- [ ] [\[2302.13331\] Learning Input-agnostic Manipulation Directions in StyleGAN with Text Guidance](https://arxiv.org/abs/2302.13331) (KAIST, ICLR)
- [ ] [\[2302.13408\] Generative Models for 3D Point Clouds](https://arxiv.org/abs/2302.13408) (Stanford)
- [ ] [\[2302.13487\] Contextual adversarial attack against aerial detection in the physical world](https://arxiv.org/abs/2302.13487) (NWPU)
- [ ] [\[2302.13495\] LMSeg: Language-guided Multi-dataset Segmentation](https://arxiv.org/abs/2302.13495) (UCAS)
- [ ] [\[2302.13519\] CBA: Contextual Background Attack against Optical Aerial Detection in the Physical World](https://arxiv.org/abs/2302.13519) (NWPU)
- [ ] [\[2302.13577\] DuEqNet: Dual-Equivariance Network in Outdoor 3D Object Detection for Autonomous Driving](https://arxiv.org/abs/2302.13577) (TUM)
- [ ] [\[2302.13598\] Spatial-Frequency Attention for Image Denoising](https://arxiv.org/abs/2302.13598) (PolyU)
- [ ] [\[2302.13748\] Unsupervised Video Anomaly Detection for Stereotypical Behaviours in Autism](https://arxiv.org/abs/2302.13748) (Microsoft)
- [ ] [\[2302.13765\] Self Correspondence Distillation for End-to-End Weakly-Supervised Semantic Segmentation](https://arxiv.org/abs/2302.13765) (BUPT)
- [ ] [\[2302.13766\] Learning to Super-Resolve Blurry Images with Events](https://arxiv.org/abs/2302.13766) (WHU, TPAMI)
- [ ] [\[2302.13824\] Dirichlet-based Uncertainty Calibration for Active Domain Adaptation](https://arxiv.org/abs/2302.13824) (ICLR)
- [ ] [\[2302.13848\] ELITE: Encoding Visual Concepts into Textual Embeddings for Customized Text-to-Image Generation](https://arxiv.org/abs/2302.13848) (ICCV)
- [ ] [\[2302.13987\] UMIFormer: Mining the Correlations between Similar Tokens for Multi-View 3D Reconstruction](https://arxiv.org/abs/2302.13987) (ICCV)
- [ ] [\[2302.14007\] Joint-MAE: 2D-3D Joint Masked Autoencoders for 3D Point Cloud Pre-training](https://arxiv.org/abs/2302.14007) (HUST)
- [ ] [\[2302.14052\] LODE: Locally Conditioned Eikonal Implicit Scene Completion from Sparse LiDAR](https://arxiv.org/abs/2302.14052) (Tsinghua)
- [ ] [\[2302.14115\] Vid2Seq: Large-Scale Pretraining of a Visual Language Model for Dense Video Captioning](https://arxiv.org/abs/2302.14115) (CVPR)
- [ ] [\[2302.14138\] Layer Grafted Pre-training: Bridging Contrastive Learning And Masked Image Modeling For Label-Efficient Representations](https://arxiv.org/abs/2302.14138) (UT Austin, ICLR)
- [ ] [\[2302.14166\] GLOW: Global Layout Aware Attacks on Object Detection](https://arxiv.org/abs/2302.14166) (ZJU, ICCV)
- [ ] [\[2302.14239\] Nonlinear Intensity, Scale and Rotation Invariant Matching for Multimodal Images](https://arxiv.org/abs/2302.14239) (WHU)
- [ ] [\[2302.14250\] Foundation Model Drives Weakly Incremental Learning for Semantic Segmentation](https://arxiv.org/abs/2302.14250) (UCAS, CVPR)
- [ ] [\[2302.14267\] Adversarial Attack with Raindrops](https://arxiv.org/abs/2302.14267) (CVPR)
- [ ] [\[2302.14268\] Self-Supervised Category-Level Articulated Object Pose Estimation with Part-Level SE(3) Equivariance](https://arxiv.org/abs/2302.14268) (ICLR)
- [ ] [\[2302.14301\] A Comprehensive Study on Robustness of Image Classification Models: Benchmarking and Rethinking](https://arxiv.org/abs/2302.14301) (Tsinghua)
- [ ] [\[2302.14302\] Improving Model Generalization by On-manifold Adversarial Augmentation in the Frequency Domain](https://arxiv.org/abs/2302.14302) (Tsinghua)
- [ ] [\[2302.14323\] Read Pointer Meters in complex environments based on a Human-like Alignment and Recognition Algorithm](https://arxiv.org/abs/2302.14323) (HIT)
- [ ] [\[2302.14325\] BEVPlace: Learning LiDAR-based Place Recognition using Bird's Eye View Images](https://arxiv.org/abs/2302.14325) (ICCV)
- [ ] [\[2302.14332\] Markerless Camera-to-Robot Pose Estimation via Self-supervised Sim-to-Real Transfer](https://arxiv.org/abs/2302.14332) (CVPR)
- [ ] [\[2302.14335\] DC-Former: Diverse and Compact Transformer for Person Re-Identification](https://arxiv.org/abs/2302.14335) (Fudan)
- [ ] [\[2302.14338\] Turning a CLIP Model into a Scene Text Detector](https://arxiv.org/abs/2302.14338) (CVPR)
- [ ] [\[2302.14348\] Im2Hands: Learning Attentive Implicit Representation of Interacting Two-Hand Shapes](https://arxiv.org/abs/2302.14348) (CVPR)
- [ ] [\[2302.14365\] RemoteTouch: Enhancing Immersive 3D Video Communication with Hand Touch](https://arxiv.org/abs/2302.14365) (Microsoft)
- [ ] [\[2302.14368\] Enhanced Controllability of Diffusion Models via Feature Disentanglement and Realism-Enhanced Sampling Methods](https://arxiv.org/abs/2302.14368) (ECCV)
- [ ] [\[2302.14418\] PCR-CG: Point Cloud Registration via Deep Explicit Color and Geometry](https://arxiv.org/abs/2302.14418) (ECCV)
- [ ] [\[2302.14431\] Efficient Masked Autoencoders with Self-Consistency](https://arxiv.org/abs/2302.14431) (TPAMI)
- [ ] [\[2302.14434\] A Hierarchical Representation Network for Accurate and Detailed Face Reconstruction from In-The-Wild Images](https://arxiv.org/abs/2302.14434) (CVPR)
- [ ] [\[2302.14435\] ProxyFormer: Proxy Alignment Assisted Point Cloud Completion with Missing Part Sensitive Transformer](https://arxiv.org/abs/2302.14435) (CVPR)
- [ ] [\[2302.14470\] Learning to Estimate Single-View Volumetric Flow Motions without 3D Supervision](https://arxiv.org/abs/2302.14470) (TUM, ICLR)
- [ ] [\[2302.14475\] Benchmarking Deepart Detection](https://arxiv.org/abs/2302.14475) (XJTU)
- [ ] [\[2302.14511\] A Unified BEV Model for Joint Learning of 3D Local Features and Overlap Estimation](https://arxiv.org/abs/2302.14511) (ZJU)
- [ ] [\[2302.14557\] GRAN: Ghost Residual Attention Network for Single Image Super Resolution](https://arxiv.org/abs/2302.14557) (NWPU)
- [ ] [\[2302.14578\] Interactive Segmentation as Gaussian Process Classification](https://arxiv.org/abs/2302.14578) (XJTU, CVPR)
- [ ] [\[2302.14581\] HopFIR: Hop-wise GraphFormer with Intragroup Joint Refinement for 3D Human Pose Estimation](https://arxiv.org/abs/2302.14581) (ICCV)
- [ ] [\[2302.14589\] Focus On Details: Online Multi-object Tracking with Diverse Fine-grained Representation](https://arxiv.org/abs/2302.14589) (CVPR)
- [ ] [\[2302.14677\] Backdoor Attacks Against Deep Image Compression via Adaptive Frequency Trigger](https://arxiv.org/abs/2302.14677) (CVPR)
- [ ] [\[2302.14746\] Mask3D: Pre-training 2D Vision Transformers by Learning Masked 3D Priors](https://arxiv.org/abs/2302.14746) (CVPR)
- [ ] [\[2302.14771\] Generic-to-Specific Distillation of Masked Autoencoders](https://arxiv.org/abs/2302.14771) (CVPR)
- [ ] [\[2302.14772\] PA&DA: Jointly Sampling PAth and DAta for Consistent NAS](https://arxiv.org/abs/2302.14772) (CVPR)
- [ ] [\[2302.14794\] Meta Learning to Bridge Vision and Language Models for Multimodal Few-Shot Learning](https://arxiv.org/abs/2302.14794) (ICLR)
- [ ] [\[2302.14816\] Monocular Depth Estimation using Diffusion Models](https://arxiv.org/abs/2302.14816) (Google)
- [ ] [\[2302.14831\] FacEDiM: A Face Embedding Distribution Model for Few-Shot Biometric Authentication of Cattle](https://arxiv.org/abs/2302.14831) (NIPS)
- [ ] [\[2303.00040\] Towards Generalisable Video Moment Retrieval: Visual-Dynamic Injection to Image-Text Pre-Training](https://arxiv.org/abs/2303.00040) (Peking, CVPR)
- [ ] [\[2303.00157\] Semi-supervised Parametric Real-world Image Harmonization](https://arxiv.org/abs/2303.00157) (Berkeley)
- [ ] [\[2303.00165\] Diffusion Probabilistic Fields](https://arxiv.org/abs/2303.00165) (Stanford, ICLR)
- [ ] [\[2303.00180\] MMA-MRNNet: Harnessing Multiple Models of Affect and Dynamic Masked RNN for Precise Facial Expression Intensity Estimation](https://arxiv.org/abs/2303.00180) (QMUL)
- [ ] [\[2303.00193\] CLIPER: A Unified Vision-Language Framework for In-the-Wild Facial Expression Recognition](https://arxiv.org/abs/2303.00193) (USTC)
- [ ] [\[2303.00198\] Convolutional Visual Prompt for Robust Visual Perception](https://arxiv.org/abs/2303.00198) (Columbia University)
- [ ] [\[2303.00205\] RECIST Weakly Supervised Lesion Segmentation via Label-Space Co-Training](https://arxiv.org/abs/2303.00205) (Xiamen)
- [ ] [\[2303.00215\] Single Image Backdoor Inversion via Robust Smoothed Classifiers](https://arxiv.org/abs/2303.00215) (CVPR)
- [ ] [\[2303.00236\] P$^2$SDF for Neural Indoor Scene Reconstruction](https://arxiv.org/abs/2303.00236) (ShanghaiTech)
- [ ] [\[2303.00246\] ISBNet: a 3D Point Cloud Instance Segmentation Network with Instance-aware Sampling and Box-aware Dynamic Convolution](https://arxiv.org/abs/2303.00246) (CVPR)
- [ ] [\[2303.00284\] To Make Yourself Invisible with Adversarial Semantic Contours](https://arxiv.org/abs/2303.00284) (Tsinghua)
- [ ] [\[2303.00289\] StrucTexTv2: Masked Visual-Textual Prediction for Document Image Pre-training](https://arxiv.org/abs/2303.00289) (ICLR)
- [ ] [\[2303.00298\] Capturing the motion of every joint: 3D human pose and shape estimation with independent tokens](https://arxiv.org/abs/2303.00298) (ICLR)
- [ ] [\[2303.00304\] Renderable Neural Radiance Map for Visual Navigation](https://arxiv.org/abs/2303.00304) (CVPR)
- [ ] [\[2303.00326\] Empowering Networks With Scale and Rotation Equivariance Using A Similarity Convolution](https://arxiv.org/abs/2303.00326) (CUHK, ICLR)
- [ ] [\[2303.00369\] Indescribable Multi-modal Spatial Evaluator](https://arxiv.org/abs/2303.00369) (UCLA, CVPR)
- [ ] [\[2303.00396\] Controlling Class Layout for Deep Ordinal Classification via Constrained Proxies Learning](https://arxiv.org/abs/2303.00396) (NJU)
- [ ] [\[2303.00404\] Distilled Reverse Attention Network for Open-world Compositional Zero-Shot Learning](https://arxiv.org/abs/2303.00404) (UTS)
- [ ] [\[2303.00440\] Extracting Motion and Appearance via Inter-Frame Attention for Efficient Video Frame Interpolation](https://arxiv.org/abs/2303.00440) (NJU, CVPR)
- [ ] [\[2303.00448\] The style transformer with common knowledge optimization for image-text retrieval](https://arxiv.org/abs/2303.00448) (HIT)
- [ ] [\[2303.00462\] Hidden Gems: 4D Radar Scene Flow Learning Using Cross-Modal Supervision](https://arxiv.org/abs/2303.00462) (University of Edinburgh, CVPR)
- [ ] [\[2303.00500\] Inherently Interpretable Multi-Label Classification Using Class-Specific Counterfactuals](https://arxiv.org/abs/2303.00500) (University of TÃ¼bingen)
- [ ] [\[2303.00521\] Quality-aware Pre-trained Models for Blind Image Quality Assessment](https://arxiv.org/abs/2303.00521) (CVPR)
- [ ] [\[2303.00566\] Structured Pruning for Deep Convolutional Neural Networks: A survey](https://arxiv.org/abs/2303.00566) (TPAMI)
- [ ] [\[2303.00575\] IPCC-TP: Utilizing Incremental Pearson Correlation Coefficient for Joint Multi-Agent Trajectory Prediction](https://arxiv.org/abs/2303.00575) (CVPR)
- [ ] [\[2303.00601\] Multimodal Industrial Anomaly Detection via Hybrid Fusion](https://arxiv.org/abs/2303.00601) (CVPR)
- [ ] [\[2303.00609\] Unsupervised Pathology Detection: A Deep Dive Into the State of the Art](https://arxiv.org/abs/2303.00609) (TUM)
- [ ] [\[2303.00690\] Rethinking Efficient Tuning Methods from a Unified Perspective](https://arxiv.org/abs/2303.00690) (Alibaba)
- [ ] [\[2303.00714\] A Complementarity-Based Switch-Fuse System for Improved Visual Place Recognition](https://arxiv.org/abs/2303.00714) (KAIST)
- [ ] [\[2303.00748\] Efficient and Explicit Modelling of Image Hierarchies for Image Restoration](https://arxiv.org/abs/2303.00748) (CVPR)
- [ ] [\[2303.00749\] S-NeRF: Neural Radiance Fields for Street Views](https://arxiv.org/abs/2303.00749) (Fudan, ICLR)
- [ ] [\[2303.00750\] StraIT: Non-autoregressive Generation with Stratified Image Transformer](https://arxiv.org/abs/2303.00750) (Google)
- [ ] [\[2303.00865\] AMIGO: Sparse Multi-Modal Graph Transformer with Shared-Context Processing for Representation Learning of Giga-pixel Images](https://arxiv.org/abs/2303.00865) (CVPR)
- [ ] [\[2303.00874\] Geometric Visual Similarity Learning in 3D Medical Image Self-supervised Pre-training](https://arxiv.org/abs/2303.00874) (CVPR)
- [ ] [\[2303.00885\] Towards Trustable Skin Cancer Diagnosis via Rewriting Model's Decision](https://arxiv.org/abs/2303.00885) (CVPR)
- [ ] [\[2303.00914\] Neuro-Modulated Hebbian Learning for Fully Test-Time Adaptation](https://arxiv.org/abs/2303.00914) (SUSTech, CVPR)
- [ ] [\[2303.00915\] BiomedCLIP: a multimodal biomedical foundation model pretrained from fifteen million scientific image-text pairs](https://arxiv.org/abs/2303.00915) (Microsoft)
- [ ] [\[2303.00952\] Towards Activated Muscle Group Estimation in the Wild](https://arxiv.org/abs/2303.00952) (ACMMM)
- [ ] [\[2303.00971\] Disentangling Orthogonal Planes for Indoor Panoramic Room Layout Estimation with Cross-Scale Distortion Awareness](https://arxiv.org/abs/2303.00971) (CVPR)
- [ ] [\[2303.00972\] Practical Network Acceleration with Tiny Sets: Hypothesis, Theory, and Algorithm](https://arxiv.org/abs/2303.00972) (NJU, TPAMI)
- [ ] [\[2303.00983\] Using simulation to quantify the performance of automotive perception systems](https://arxiv.org/abs/2303.00983) (Stanford)
- [ ] [\[2303.01000\] X&Fuse: Fusing Visual Information in Text-to-Image Generation](https://arxiv.org/abs/2303.01000) (Tel Aviv)
- [ ] [\[2303.01038\] Neural Intrinsic Embedding for Non-rigid Point Cloud Matching](https://arxiv.org/abs/2303.01038) (Tsinghua, CVPR)
- [ ] [\[2303.01043\] I2P-Rec: Recognizing Images on Large-scale Point Cloud Maps through Bird's Eye View Projections](https://arxiv.org/abs/2303.01043) (ZJU)
- [ ] [\[2303.01047\] Task-Specific Context Decoupling for Object Detection](https://arxiv.org/abs/2303.01047) (NUDT)
- [ ] [\[2303.01091\] OPE-SR: Orthogonal Position Encoding for Designing a Parameter-free Upsampling Module in Arbitrary-scale Image Super-Resolution](https://arxiv.org/abs/2303.01091) (CVPR)
- [ ] [\[2303.01112\] Visual Atoms: Pre-training Vision Transformers with Sinusoidal Waves](https://arxiv.org/abs/2303.01112) (CVPR)
- [ ] [\[2303.01219\] A Coarse to Fine Framework for Object Detection in High Resolution Image](https://arxiv.org/abs/2303.01219) (NWPU)
- [ ] [\[2303.01233\] Domain-aware Triplet loss in Domain Generalization](https://arxiv.org/abs/2303.01233) (Queensland)
- [ ] [\[2303.01239\] MixPHM: Redundancy-Aware Parameter-Efficient Tuning for Low-Resource Visual Question Answering](https://arxiv.org/abs/2303.01239) (XJTU, CVPR)
- [ ] [\[2303.01255\] Combining Generative Artificial Intelligence (AI) and the Internet: Heading towards Evolution or Degradation?](https://arxiv.org/abs/2303.01255) (University of Edinburgh)
- [ ] [\[2303.01267\] Token Contrast for Weakly-Supervised Semantic Segmentation](https://arxiv.org/abs/2303.01267) (CVPR)
- [ ] [\[2303.01274\] Measuring axiomatic soundness of counterfactual image models](https://arxiv.org/abs/2303.01274) (ICLR)
- [ ] [\[2303.01276\] Conflict-Based Cross-View Consistency for Semi-Supervised Semantic Segmentation](https://arxiv.org/abs/2303.01276) (USyd, CVPR)
- [ ] [\[2303.01311\] Zero-Shot Text-to-Parameter Translation for Game Character Auto-Creation](https://arxiv.org/abs/2303.01311) (CVPR)
- [ ] [\[2303.01313\] Weakly-supervised HOI Detection via Prior-guided Bi-level Representation Learning](https://arxiv.org/abs/2303.01313) (ICLR)
- [ ] [\[2303.01338\] AdvRain: Adversarial Raindrops to Attack Camera-based Smart Vision Systems](https://arxiv.org/abs/2303.01338) (NYU)
- [ ] [\[2303.01416\] 3D generation on ImageNet](https://arxiv.org/abs/2303.01416) (ICLR)
- [ ] [\[2303.01480\] Delivering Arbitrary-Modal Semantic Segmentation](https://arxiv.org/abs/2303.01480) (CVPR)
- [ ] [\[2303.01494\] Image as Set of Points](https://arxiv.org/abs/2303.01494) (ICLR)
- [ ] [\[2303.01526\] Semantic Attention Flow Fields for Monocular Dynamic Scene Decomposition](https://arxiv.org/abs/2303.01526) (ICCV)
- [ ] [\[2303.01559\] Improving GAN Training via Feature Space Shrinkage](https://arxiv.org/abs/2303.01559) (CVPR)
- [ ] [\[2303.01573\] DejaVu: Conditional Regenerative Learning to Enhance Dense Prediction](https://arxiv.org/abs/2303.01573) (CVPR)
- [ ] [\[2303.01589\] AZTR: Aerial Video Action Recognition with Auto Zoom and Temporal Reasoning](https://arxiv.org/abs/2303.01589) (UMD)
- [ ] [\[2303.01598\] A Meta-Learning Approach to Predicting Performance and Data Requirements](https://arxiv.org/abs/2303.01598) (CVPR)
- [ ] [\[2303.01605\] Hierarchical discriminative learning improves visual representations of biomedical microscopy](https://arxiv.org/abs/2303.01605) (CVPR)
- [ ] [\[2303.01656\] Feature Completion Transformer for Occluded Person Re-identification](https://arxiv.org/abs/2303.01656) (Peking)
- [ ] [\[2303.01669\] Learning Common Rationale to Improve Self-Supervised Representation for Fine-Grained Visual Recognition Problems](https://arxiv.org/abs/2303.01669) (CVPR)
- [ ] [\[2303.01685\] Multi-Scale Control Signal-Aware Transformer for Motion Synthesis without Phase](https://arxiv.org/abs/2303.01685) (USyd)
- [ ] [\[2303.01686\] Towards Domain Generalization for Multi-view 3D Object Detection in Bird-Eye-View](https://arxiv.org/abs/2303.01686) (CVPR)
- [ ] [\[2303.01736\] Multi-Plane Neural Radiance Fields for Novel View Synthesis](https://arxiv.org/abs/2303.01736) (MBZUAI)
- [ ] [\[2303.01743\] A Laplace-inspired Distribution on SO(3) for Probabilistic Rotation Estimation](https://arxiv.org/abs/2303.01743) (ICLR)
- [ ] [\[2303.01765\] Diverse 3D Hand Gesture Prediction from Body Dynamics by Bilateral Hand Disentanglement](https://arxiv.org/abs/2303.01765) (IA CAS, CVPR)
- [ ] [\[2303.01786\] 3D Multi-Object Tracking Based on Uncertainty-Guided Data Association](https://arxiv.org/abs/2303.01786) (Chongqing)
- [ ] [\[2303.01788\] Visual Exemplar Driven Task-Prompting for Unified Perception in Autonomous Driving](https://arxiv.org/abs/2303.01788) (CVPR)
- [ ] [\[2303.01869\] Intrinsic Physical Concepts Discovery with Object-Centric Predictive Models](https://arxiv.org/abs/2303.01869) (CVPR)
- [ ] [\[2303.01870\] Revisiting Adversarial Training for ImageNet: Architectures, Training and Generalization across Threat Models](https://arxiv.org/abs/2303.01870) (University of TÃ¼bingen, NIPS)
- [ ] [\[2303.01899\] Quantifying the LiDAR Sim-to-Real Domain Shift: A Detailed Investigation Using Object Detectors and Analyzing Point Clouds at Target-Level](https://arxiv.org/abs/2303.01899) (TUM)
- [ ] [\[2303.01903\] Prophet: Prompting Large Language Models with Complementary Answer Heuristics for Knowledge-based Visual Question Answering](https://arxiv.org/abs/2303.01903) (CVPR)
- [ ] [\[2303.01904\] EcoTTA: Memory-Efficient Continual Test-time Adaptation via Self-distilled Regularization](https://arxiv.org/abs/2303.01904) (CVPR)
- [ ] [\[2303.01906\] Generalized Semantic Segmentation by Self-Supervised Source Domain Projection and Multi-Level Contrastive Learning](https://arxiv.org/abs/2303.01906) (XJTU)
- [ ] [\[2303.01917\] Pyramid Pixel Context Adaption Network for Medical Image Classification with Supervised Contrastive Learning](https://arxiv.org/abs/2303.01917) (SUSTech)
- [ ] [\[2303.01920\] Robust Detection Outcome: A Metric for Pathology Detection in Medical Images](https://arxiv.org/abs/2303.01920) (TUM)
- [ ] [\[2303.01932\] MobileBrick: Building LEGO for 3D Reconstruction on Mobile Devices](https://arxiv.org/abs/2303.01932) (CVPR)
- [ ] [\[2303.01943\] Spring: A High-Resolution High-Detail Dataset and Benchmark for Scene Flow, Optical Flow and Stereo](https://arxiv.org/abs/2303.01943) (CVPR)
- [ ] [\[2303.01979\] ACL-SPC: Adaptive Closed-Loop system for Self-Supervised Point Cloud Completion](https://arxiv.org/abs/2303.01979) (CVPR)
- [ ] [\[2303.01999\] Unsupervised 3D Shape Reconstruction by Part Retrieval and Assembly](https://arxiv.org/abs/2303.01999) (CVPR)
- [ ] [\[2303.02001\] Zero-shot Object Counting](https://arxiv.org/abs/2303.02001) (CVPR)
- [ ] [\[2303.02091\] Delicate Textured Mesh Recovery from NeRF via Adaptive Surface Refinement](https://arxiv.org/abs/2303.02091) (ICCV)
- [ ] [\[2303.02151\] Prompt, Generate, then Cache: Cascade of Foundation Models makes Strong Few-shot Learners](https://arxiv.org/abs/2303.02151) (SJTU, CVPR)
- [ ] [\[2303.02165\] DeepMAD: Mathematical Architecture Design for Deep Convolutional Neural Network](https://arxiv.org/abs/2303.02165) (AWS, CVPR)
- [ ] [\[2303.02203\] X$^3$KD: Knowledge Distillation Across Modalities, Tasks and Stages for Multi-Camera 3D Object Detection](https://arxiv.org/abs/2303.02203) (CVPR)
- [ ] [\[2303.02241\] Domain adaptation using optimal transport for invariant learning using histopathology datasets](https://arxiv.org/abs/2303.02241) (Illinois)
- [ ] [\[2303.02260\] Learning to reason over visual objects](https://arxiv.org/abs/2303.02260) (Princeton, ICLR)
- [ ] [\[2303.02287\] OASIS: Automated Assessment of Urban Pedestrian Paths at Scale](https://arxiv.org/abs/2303.02287) (UW)
- [ ] [\[2303.02314\] Virtual Sparse Convolution for Multimodal 3D Object Detection](https://arxiv.org/abs/2303.02314) (CVPR)
- [ ] [\[2303.02323\] APE: An Open and Shared Annotated Dataset for Learning Urban Pedestrian Path Networks](https://arxiv.org/abs/2303.02323) (UW)
- [ ] [\[2303.02328\] Decompose, Adjust, Compose: Effective Normalization by Playing with Frequency for Domain Generalization](https://arxiv.org/abs/2303.02328) (CVPR)
- [ ] [\[2303.02375\] NeuDA: Neural Deformable Anchor for High-Fidelity Implicit Surface Reconstruction](https://arxiv.org/abs/2303.02375) (CVPR)
- [ ] [\[2303.02389\] Few-Shot Defect Image Generation via Defect-Aware Feature Manipulation](https://arxiv.org/abs/2303.02389) (SJTU)
- [ ] [\[2303.02404\] Fine-Grained Classification with Noisy Labels](https://arxiv.org/abs/2303.02404) (NTU, CVPR)
- [ ] [\[2303.02437\] ConZIC: Controllable Zero-shot Image Captioning by Sampling-Based Polishing](https://arxiv.org/abs/2303.02437) (Xidian, CVPR)
- [ ] [\[2303.02449\] Exploit CAM by itself: Complementary Learning System for Weakly Supervised Semantic Segmentation](https://arxiv.org/abs/2303.02449) (SJTU)
- [ ] [\[2303.02452\] Understanding weight-magnitude hyperparameters in training binary networks](https://arxiv.org/abs/2303.02452) (ICLR)
- [ ] [\[2303.02454\] Exploiting Implicit Rigidity Constraints via Weight-Sharing Aggregation for Scene Flow Estimation from Point Clouds](https://arxiv.org/abs/2303.02454) (HUST)
- [ ] [\[2303.02455\] DistilPose: Tokenized Pose Regression with Heatmap Distillation](https://arxiv.org/abs/2303.02455) (Xiamen, CVPR)
- [ ] [\[2303.02460\] Extended Agriculture-Vision: An Extension of a Large Aerial Image Dataset for Agricultural Pattern Analysis](https://arxiv.org/abs/2303.02460) (Illinois)
- [ ] [\[2303.02483\] FAME-ViL: Multi-Tasking Vision-Language Model for Heterogeneous Fashion Tasks](https://arxiv.org/abs/2303.02483) (Fudan, CVPR)
- [ ] [\[2303.02489\] CapDet: Unifying Dense Captioning and Open-World Detection Pretraining](https://arxiv.org/abs/2303.02489) (SYSU, CVPR)
