- [ ] [\[2310.07449\] PoRF: Pose Residual Field for Accurate Neural Surface Reconstruction](https://arxiv.org/abs/2310.07449) (ICLR)
- [ ] [\[2310.07473\] FGPrompt: Fine-grained Goal Prompting for Image-goal Navigation](https://arxiv.org/abs/2310.07473) (NIPS)
- [ ] [\[2310.07492\] Boosting Black-box Attack to Deep Neural Networks with Conditional Diffusion Models](https://arxiv.org/abs/2310.07492) (NTU)
- [ ] [\[2310.07511\] Learning a Cross-modality Anomaly Detector for Remote Sensing Imagery](https://arxiv.org/abs/2310.07511) (WHU)
- [ ] [\[2310.07522\] S4C: Self-Supervised Semantic Scene Completion with Neural Fields](https://arxiv.org/abs/2310.07522) (Oxford)
- [ ] [\[2310.07555\] Does resistance to style-transfer equal Global Shape Bias? Measuring network sensitivity to global shape configuration](https://arxiv.org/abs/2310.07555) (CMU)
- [ ] [\[2310.07585\] A Discrepancy Aware Framework for Robust Anomaly Detection](https://arxiv.org/abs/2310.07585) (HUST)
- [ ] [\[2310.07591\] PeP: a Point enhanced Painting method for unified point cloud tasks](https://arxiv.org/abs/2310.07591) (ZJU)
- [ ] [\[2310.07602\] Dual Radar: A Multi-modal Dataset with Dual 4D Radar for Autonomous Driving](https://arxiv.org/abs/2310.07602) (Tsinghua)
- [ ] [\[2310.07669\] HaarNet: Large-scale Linear-Morphological Hybrid Network for RGB-D Semantic Segmentation](https://arxiv.org/abs/2310.07669) (UVA.NL)
- [ ] [\[2310.07704\] Ferret: Refer and Ground Anything Anywhere at Any Granularity](https://arxiv.org/abs/2310.07704) (Columbia University)
- [ ] [\[2310.07716\] PAD: A Dataset and Benchmark for Pose-agnostic Anomaly Detection](https://arxiv.org/abs/2310.07716) (Tsinghua, NIPS)
- [ ] [\[2310.07726\] Warfare:Breaking the Watermark Protection of AI-Generated Content](https://arxiv.org/abs/2310.07726) (NTU)
- [ ] [\[2310.07781\] 3D TransUNet: Advancing Medical Image Segmentation through Vision Transformers](https://arxiv.org/abs/2310.07781) (JHU)
- [ ] [\[2310.07801\] Trajectory-aware Principal Manifold Framework for Data Augmentation and Image Generation](https://arxiv.org/abs/2310.07801) (UCLA)
- [ ] [\[2310.07855\] CrIBo: Self-Supervised Learning via Cross-Image Object-Level Bootstrapping](https://arxiv.org/abs/2310.07855) (ICLR)
- [ ] [\[2310.07995\] HeightFormer: A Multilevel Interaction and Image-adaptive Classification-regression Network for Monocular Height Estimation with Aerial Images](https://arxiv.org/abs/2310.07995) (UCAS)
- [ ] [\[2310.08009\] Dual-Stream Knowledge-Preserving Hashing for Unsupervised Video Retrieval](https://arxiv.org/abs/2310.08009) (ECCV)
- [ ] [\[2310.08026\] Beyond Sharing Weights in Decoupling Feature Learning Network for UAV RGB-Infrared Vehicle Re-Identification](https://arxiv.org/abs/2310.08026) (NUDT)
- [ ] [\[2310.08064\] Age Estimation Based on Graph Convolutional Networks and Multi-head Attention Mechanisms](https://arxiv.org/abs/2310.08064) (SUSTech)
- [ ] [\[2310.08082\] Jointly Optimized Global-Local Visual Localization of UAVs](https://arxiv.org/abs/2310.08082) (BUPT)
- [ ] [\[2310.08084\] Volumetric Medical Image Segmentation via Scribble Annotations and Shape Priors](https://arxiv.org/abs/2310.08084) (SJTU)
- [ ] [\[2310.08094\] SingleInsert: Inserting New Concepts from a Single Image into Text-to-Image Models for Flexible Editing](https://arxiv.org/abs/2310.08094) (Illinois)
- [ ] [\[2310.08106\] Generalized Logit Adjustment: Calibrating Fine-tuned Models by Removing Label Bias in Foundation Models](https://arxiv.org/abs/2310.08106) (NTU, NIPS)
- [ ] [\[2310.08117\] DUSA: Decoupled Unsupervised Sim2Real Adaptation for Vehicle-to-Everything Collaborative Perception](https://arxiv.org/abs/2310.08117) (UCLA, ACMMM)
- [ ] [\[2310.08129\] Tailored Visions: Enhancing Text-to-Image Generation with Personalized Prompt Rewriting](https://arxiv.org/abs/2310.08129) (UESTC, CVPR)
- [ ] [\[2310.08139\] DualAug: Exploiting Additional Heavy Augmentation with OOD Data Rejection](https://arxiv.org/abs/2310.08139) (HIT)
- [ ] [\[2310.08182\] XIMAGENET-12: An Explainable AI Benchmark Dataset for Model Robustness Evaluation](https://arxiv.org/abs/2310.08182) (UVA.NL)
- [ ] [\[2310.08204\] STELLA: Continual Audio-Video Pre-training with Spatio-Temporal Localized Alignment](https://arxiv.org/abs/2310.08204) (KAIST, ICML)
- [ ] [\[2310.08261\] GraphAlign: Enhancing Accurate Feature Alignment by Graph matching for Multi-Modal 3D Object Detection](https://arxiv.org/abs/2310.08261) (Tsinghua)
- [ ] [\[2310.08303\] Multimodal Variational Auto-encoder based Audio-Visual Segmentation](https://arxiv.org/abs/2310.08303) (ICCV)
- [ ] [\[2310.08312\] GePSAn: Generative Procedure Step Anticipation in Cooking Videos](https://arxiv.org/abs/2310.08312) (ICCV)
- [ ] [\[2310.08370\] UniPAD: A Universal Pre-training Paradigm for Autonomous Driving](https://arxiv.org/abs/2310.08370) (CVPR)
- [ ] [\[2310.08381\] AutoVP: An Automated Visual Prompting Framework and Benchmark](https://arxiv.org/abs/2310.08381) (ICLR)
- [ ] [\[2310.08420\] Visual Attention Prompted Prediction and Learning](https://arxiv.org/abs/2310.08420) (Stanford)
- [ ] [\[2310.08442\] Unmasking Bias in Diffusion Model Training](https://arxiv.org/abs/2310.08442) (USTC, ECCV)
- [ ] [\[2310.08471\] WinSyn: A High Resolution Testbed for Synthetic Data](https://arxiv.org/abs/2310.08471) (CVPR)
- [ ] [\[2310.08528\] 4D Gaussian Splatting for Real-Time Dynamic Scene Rendering](https://arxiv.org/abs/2310.08528) (CVPR)
- [ ] [\[2310.08529\] GaussianDreamer: Fast Generation from Text to 3D Gaussians by Bridging 2D and 3D Diffusion Models](https://arxiv.org/abs/2310.08529) (CVPR)
- [ ] [\[2310.08530\] X-Pose: Detecting Any Keypoints](https://arxiv.org/abs/2310.08530) (ECCV)
- [ ] [\[2310.08534\] Animating Street View](https://arxiv.org/abs/2310.08534) (SIGGRAPH)
- [ ] [\[2310.08541\] Idea2Img: Iterative Self-Refinement with GPT-4V(ision) for Automatic Image Design and Generation](https://arxiv.org/abs/2310.08541) (ECCV)
- [ ] [\[2310.08577\] Visual Data-Type Understanding does not emerge from Scaling Vision-Language Models](https://arxiv.org/abs/2310.08577) (Cambridge)
- [ ] [\[2310.08579\] HyperHuman: Hyper-Realistic Human Generation with Latent Structural Diffusion](https://arxiv.org/abs/2310.08579) (CUHK, ICLR)
- [ ] [\[2310.08580\] OmniControl: Control Any Joint at Any Time for Human Motion Generation](https://arxiv.org/abs/2310.08580) (ICLR)
- [ ] [\[2310.08584\] Is ImageNet worth 1 video? Learning strong image encoders from 1 long unlabelled video](https://arxiv.org/abs/2310.08584) (ICLR)
- [ ] [\[2310.08585\] Im4D: High-Fidelity and Real-Time Novel View Synthesis for Dynamic Scenes](https://arxiv.org/abs/2310.08585) (ZJU, SIGGRAPH)
- [ ] [\[2310.08586\] PonderV2: Pave the Way for 3D Foundation Model with A Universal Pre-training Paradigm](https://arxiv.org/abs/2310.08586) (Shanghai AI Lab)
- [ ] [\[2310.08587\] Pseudo-Generalized Dynamic View Synthesis from a Video](https://arxiv.org/abs/2310.08587) (Illinois, ICLR)
- [ ] [\[2310.08755\] PU-Ray: Domain-Independent Point Cloud Upsampling via Ray Marching on Neural Implicit Surface](https://arxiv.org/abs/2310.08755) (University of Alberta)
- [ ] [\[2310.08785\] DeltaSpace: A Semantic-aligned Feature Space for Flexible Text-guided Image Editing](https://arxiv.org/abs/2310.08785) (IA CAS)
- [ ] [\[2310.08826\] Revisiting Multi-modal 3D Semantic Segmentation in Real-world Autonomous Driving](https://arxiv.org/abs/2310.08826) (Fudan)
- [ ] [\[2310.08854\] Rank-DETR for High Quality Object Detection](https://arxiv.org/abs/2310.08854) (Tsinghua, NIPS)
- [ ] [\[2310.08861\] Re-initialization-free Level Set Method via Molecular Beam Epitaxy Equation Regularization for Image Segmentation](https://arxiv.org/abs/2310.08861) (HIT)
- [ ] [\[2310.08872\] R&B: Region and Boundary Aware Zero-shot Grounded Text-to-image Generation](https://arxiv.org/abs/2310.08872) (ICT CAS)
- [ ] [\[2310.08892\] Image Cropping under Design Constraints](https://arxiv.org/abs/2310.08892) (University of Tokyo, ACMMM)
- [ ] [\[2310.08904\] 3D Understanding of Deformable Linear Objects: Datasets and Transferability Benchmark](https://arxiv.org/abs/2310.08904) (TUM)
- [ ] [\[2310.08921\] Feature Proliferation -- the "Cancer" in StyleGAN and its Treatments](https://arxiv.org/abs/2310.08921) (ICCV)
- [ ] [\[2310.08932\] TIDE: Temporally Incremental Disparity Estimation via Pattern Flow in Structured Light System](https://arxiv.org/abs/2310.08932) (Peking)
- [ ] [\[2310.08934\] Online Adaptive Disparity Estimation for Dynamic Scenes in Structured Light Systems](https://arxiv.org/abs/2310.08934) (Peking)
- [ ] [\[2310.08956\] LRRU: Long-short Range Recurrent Updating Networks for Depth Completion](https://arxiv.org/abs/2310.08956) (ICCV)
- [ ] [\[2310.08984\] UniParser: Multi-Human Parsing with Unified Correlation Representation Learning](https://arxiv.org/abs/2310.08984) (BUPT)
- [ ] [\[2310.09092\] iPUNet:Iterative Cross Field Guided Point Cloud Upsampling](https://arxiv.org/abs/2310.09092) (Microsoft)
- [ ] [\[2310.09114\] Timestamp-supervised Wearable-based Activity Segmentation and Recognition with Contrastive Learning and Order-Preserving Optimal Transport](https://arxiv.org/abs/2310.09114) (SJTU)
- [ ] [\[2310.09276\] Transformer-based Multimodal Change Detection with Multitask Consistency Constraints](https://arxiv.org/abs/2310.09276) (UESTC)
- [ ] [\[2310.09291\] Vision-by-Language for Training-Free Compositional Image Retrieval](https://arxiv.org/abs/2310.09291) (ICLR)
- [ ] [\[2310.09444\] Tackling Heterogeneity in Medical Federated learning via Vision Transformers](https://arxiv.org/abs/2310.09444) (Harvard)
- [ ] [\[2310.09449\] Pairwise Similarity Learning is SimPLE](https://arxiv.org/abs/2310.09449) (ICCV)
- [ ] [\[2310.09458\] PaintHuman: Towards High-fidelity Text-to-3D Human Texturing via Denoised Score Distillation](https://arxiv.org/abs/2310.09458) (USyd)
- [ ] [\[2310.09461\] MAC: ModAlity Calibration for Object Detection](https://arxiv.org/abs/2310.09461) (CMU)
- [ ] [\[2310.09471\] Plug-and-Play Feature Generation for Few-Shot Medical Image Classification](https://arxiv.org/abs/2310.09471) (Fudan)
- [ ] [\[2310.09492\] Perception Reinforcement Using Auxiliary Learning Feature Fusion: A Modified Yolov8 for Head Detection](https://arxiv.org/abs/2310.09492) (CUHK)
- [ ] [\[2310.09533\] Towards End-to-End Unsupervised Saliency Detection with Self-Supervised Top-Down Context](https://arxiv.org/abs/2310.09533) (Fudan, ACMMM)
- [ ] [\[2310.09562\] Does CLIP's Generalization Performance Mainly Stem from High Train-Test Similarity?](https://arxiv.org/abs/2310.09562) (University of Tübingen, ICLR)
- [ ] [\[2310.09563\] Learning Unified Representations for Multi-Resolution Face Recognition](https://arxiv.org/abs/2310.09563) (BIT)
- [ ] [\[2310.09600\] Hawkeye: A PyTorch-based Library for Fine-Grained Image Recognition with Deep Learning](https://arxiv.org/abs/2310.09600) (ACM Multimedia)
- [ ] [\[2310.09612\] Deep Neural Networks Can Learn Generalizable Same-Different Visual Relations](https://arxiv.org/abs/2310.09612) (NYU)
- [ ] [\[2310.09679\] What Do Deep Saliency Models Learn about Visual Attention?](https://arxiv.org/abs/2310.09679) (NIPS)
- [ ] [\[2310.09755\] Beyond Segmentation: Road Network Generation with Multi-Modal LLMs](https://arxiv.org/abs/2310.09755) (GIT)
- [ ] [\[2310.09756\] New Benchmarks for Asian Facial Recognition Tasks: Face Classification with Large Foundation Models](https://arxiv.org/abs/2310.09756) (POSTECH)
- [ ] [\[2310.09757\] MoEmo Vision Transformer: Integrating Cross-Attention and Movement Vectors in 3D Pose Estimation for HRI Emotion Detection](https://arxiv.org/abs/2310.09757) (ShanghaiTech)
- [ ] [\[2310.09761\] CAPro: Webly Supervised Learning with Cross-Modality Aligned Prototypes](https://arxiv.org/abs/2310.09761) (NIPS)
- [ ] [\[2310.09776\] CBARF: Cascaded Bundle-Adjusting Neural Radiance Fields from Imperfect Camera Poses](https://arxiv.org/abs/2310.09776) (Tsinghua)
- [ ] [\[2310.09821\] LICO: Explainable Models with Language-Image Consistency](https://arxiv.org/abs/2310.09821) (Fudan, NIPS)
- [ ] [\[2310.09876\] Bounding and Filling: A Fast and Flexible Framework for Image Captioning](https://arxiv.org/abs/2310.09876) (NJU)
- [ ] [\[2310.09912\] Unsupervised Discovery of Interpretable Directions in h-space of Pre-trained Diffusion Models](https://arxiv.org/abs/2310.09912) (ZJU)
- [ ] [\[2310.09929\] Prompting Scientific Names for Zero-Shot Species Recognition](https://arxiv.org/abs/2310.09929) (CMU)
- [ ] [\[2310.09965\] ProteusNeRF: Fast Lightweight NeRF Editing using 3D-Aware Image Context](https://arxiv.org/abs/2310.09965) (SIGGRAPH)
- [ ] [\[2310.09982\] AEP$n$P: A Less-constrained EP$n$P Solver for Pose Estimation with Anisotropic Scaling](https://arxiv.org/abs/2310.09982) (ShanghaiTech)
- [ ] [\[2310.09994\] A Survey of Graph and Attention Based Hyperspectral Image Classification Methods for Remote Sensing Data](https://arxiv.org/abs/2310.09994) (GIT)
- [ ] [\[2310.10008\] Towards Unified and Effective Domain Generalization](https://arxiv.org/abs/2310.10008) (CUHK)
- [ ] [\[2310.10027\] RoomDesigner: Encoding Anchor-latents for Style-consistent and Shape-compatible Indoor Scene Generation](https://arxiv.org/abs/2310.10027) (ShanghaiTech)
- [ ] [\[2310.10033\] Deep Unfolding Network for Image Compressed Sensing by Content-adaptive Gradient Updating and Deformation-invariant Non-local Modeling](https://arxiv.org/abs/2310.10033) (HIT)
- [ ] [\[2310.10050\] EfficientOCR: An Extensible, Open-Source Package for Efficiently Digitizing World Knowledge](https://arxiv.org/abs/2310.10050) (Harvard)
- [ ] [\[2310.10051\] EAR-Net: Pursuing End-to-End Absolute Rotations from Multi-View Images](https://arxiv.org/abs/2310.10051) (IA CAS)
- [ ] [\[2310.10068\] Generalizable Person Search on Open-world User-Generated Video Content](https://arxiv.org/abs/2310.10068) (SJTU)
- [ ] [\[2310.10071\] ZoomTrack: Target-aware Non-uniform Resizing for Efficient Visual Tracking](https://arxiv.org/abs/2310.10071) (IA CAS, NIPS)
- [ ] [\[2310.10125\] Few-shot Action Recognition with Captioning Foundation Models](https://arxiv.org/abs/2310.10125) (ZJU)
- [ ] [\[2310.10198\] MoConVQ: Unified Physics-Based Motion Control via Scalable Discrete Representations](https://arxiv.org/abs/2310.10198) (Peking)
- [ ] [\[2310.10372\] Learning Object Permanence from Videos via Latent Imaginations](https://arxiv.org/abs/2310.10372) (University of Tübingen)
- [ ] [\[2310.10375\] GTA: A Geometry-Aware Attention Mechanism for Multi-View Transformers](https://arxiv.org/abs/2310.10375) (ICLR)
- [ ] [\[2310.10404\] LLM4SGG: Large Language Models for Weakly Supervised Scene Graph Generation](https://arxiv.org/abs/2310.10404) (CVPR)
- [ ] [\[2310.10417\] Prior-Free Continual Learning with Unlabeled Data in the Wild](https://arxiv.org/abs/2310.10417) (NUS)
- [ ] [\[2310.10427\] DANAA: Towards transferable attacks with double adversarial neuron attribution](https://arxiv.org/abs/2310.10427) (USyd)
- [ ] [\[2310.10463\] Combating Label Noise With A General Surrogate Model For Sample Selection](https://arxiv.org/abs/2310.10463) (ZJU)
- [ ] [\[2310.10533\] Label-efficient Segmentation via Affinity Propagation](https://arxiv.org/abs/2310.10533) (NIPS)
- [ ] [\[2310.10541\] AST: Effective Dataset Distillation through Alignment with Smooth and High-Quality Expert Trajectories](https://arxiv.org/abs/2310.10541) (NTU)
- [ ] [\[2310.10547\] InfoGCN++: Learning Representation by Predicting the Future for Online Human Skeleton-based Action Recognition](https://arxiv.org/abs/2310.10547) (UT Austin)
- [ ] [\[2310.10563\] RefConv: Re-parameterized Refocusing Convolution for Powerful ConvNets](https://arxiv.org/abs/2310.10563) (NJU)
- [ ] [\[2310.10591\] Interpreting and Controlling Vision Foundation Models via Text Explanations](https://arxiv.org/abs/2310.10591) (Columbia University)
- [ ] [\[2310.10640\] LLM Blueprint: Enabling Text-to-Image Generation with Complex and Detailed Prompts](https://arxiv.org/abs/2310.10640) (ICLR)
- [ ] [\[2310.10642\] Real-time Photorealistic Dynamic Scene Representation and Rendering with 4D Gaussian Splatting](https://arxiv.org/abs/2310.10642) (Fudan, ICLR)
- [ ] [\[2310.10647\] A Survey on Video Diffusion Models](https://arxiv.org/abs/2310.10647) (Fudan)
- [ ] [\[2310.10651\] HairCLIPv2: Unifying Hair Editing via Proxy Feature Blending](https://arxiv.org/abs/2310.10651) (ICCV)
- [ ] [\[2310.10755\] IDRNet: Intervention-Driven Relation Network for Semantic Segmentation](https://arxiv.org/abs/2310.10755) (Shanghai AI Lab, NIPS)
- [ ] [\[2310.10769\] LAMP: Learn A Motion Pattern for Few-Shot-Based Video Generation](https://arxiv.org/abs/2310.10769) (Nankai)
- [ ] [\[2310.10861\] SoybeanNet: Transformer-Based Convolutional Neural Network for Soybean Pod Counting from Unmanned Aerial Vehicle (UAV) Images](https://arxiv.org/abs/2310.10861) (Michigan State University)
- [ ] [\[2310.10942\] UNK-VQA: A Dataset and a Probe into the Abstention Ability of Multi-modal Large Models](https://arxiv.org/abs/2310.10942) (NUS, TPAMI)
- [ ] [\[2310.10975\] NICE: Improving Panoptic Narrative Detection and Segmentation with Cascading Collaborative Learning](https://arxiv.org/abs/2310.10975) (Xiamen)
- [ ] [\[2310.11092\] DORec: Decomposed Object Reconstruction and Segmentation Utilizing 2D Self-Supervised Features](https://arxiv.org/abs/2310.11092) (ZJU)
- [ ] [\[2310.11106\] 3D Structure-guided Network for Tooth Alignment in 2D Photograph](https://arxiv.org/abs/2310.11106) (ShanghaiTech)
- [ ] [\[2310.11142\] BayesDiff: Estimating Pixel-wise Uncertainty in Diffusion via Bayesian Inference](https://arxiv.org/abs/2310.11142) (SJTU, ICLR)
- [ ] [\[2310.11153\] Unsupervised Pre-Training Using Masked Autoencoders for ECG Analysis](https://arxiv.org/abs/2310.11153) (NUS)
- [ ] [\[2310.11173\] Knowledge Extraction and Distillation from Large-Scale Image-Text Colonoscopy Records Leveraging Large Language and Vision Models](https://arxiv.org/abs/2310.11173) (Fudan)
- [ ] [\[2310.11178\] FocDepthFormer: Transformer with LSTM for Depth Estimation from Focus](https://arxiv.org/abs/2310.11178) (KU Leuven)
- [ ] [\[2310.11184\] Sparse Multi-Object Render-and-Compare](https://arxiv.org/abs/2310.11184) (Cambridge)
- [ ] [\[2310.11210\] Learning Comprehensive Representations with Richer Self for Text-to-Image Person Re-Identification](https://arxiv.org/abs/2310.11210) (ACMMM)
- [ ] [\[2310.11239\] LiDAR-based 4D Occupancy Completion and Forecasting](https://arxiv.org/abs/2310.11239) (NYU)
- [ ] [\[2310.11284\] Self-Supervised 3D Scene Flow Estimation and Motion Prediction using Local Rigidity Prior](https://arxiv.org/abs/2310.11284) (NTU, CVPR)
- [ ] [\[2310.11307\] Multi Self-supervised Pre-fine-tuned Transformer Fusion for Better Intelligent Transportation Detection](https://arxiv.org/abs/2310.11307) (SYSU)
- [ ] [\[2310.11346\] Towards Generalizable Multi-Camera 3D Object Detection via Perspective Debiasing](https://arxiv.org/abs/2310.11346) (HKUST)
- [ ] [\[2310.11598\] Learning Neural Implicit through Volume Rendering with Attentive Depth Fusion Priors](https://arxiv.org/abs/2310.11598) (NIPS)
- [ ] [\[2310.11622\] High-Resolution Building and Road Detection from Sentinel-2](https://arxiv.org/abs/2310.11622) (Google)
- [ ] [\[2310.11657\] ChatGPT-guided Semantics for Zero-shot Learning](https://arxiv.org/abs/2310.11657) (UTS)
- [ ] [\[2310.11696\] MOHO: Learning Single-view Hand-held Object Reconstruction with Multi-view Occlusion-Aware Supervision](https://arxiv.org/abs/2310.11696) (CVPR)
- [ ] [\[2310.11702\] DPF-Nutrition: Food Nutrition Estimation via Depth Prediction and Fusion](https://arxiv.org/abs/2310.11702) (HUST)
- [ ] [\[2310.11713\] Separating Invisible Sounds Toward Universal Audiovisual Scene-Aware Sound Separation](https://arxiv.org/abs/2310.11713) (Michigan State University, ICCV)
- [ ] [\[2310.11733\] DBDNet:Partial-to-Partial Point Cloud Registration with Dual Branches Decoupling](https://arxiv.org/abs/2310.11733) (XJTU)
- [ ] [\[2310.11766\] Multi Task Consistency Guided Source-Free Test-Time Domain Adaptation Medical Image Segmentation](https://arxiv.org/abs/2310.11766) (NWPU)
- [ ] [\[2310.11784\] Progressive3D: Progressively Local Editing for Text-to-3D Content Creation with Complex Semantic Prompts](https://arxiv.org/abs/2310.11784) (ICLR)
- [ ] [\[2310.11834\] HB-net: Holistic bursting cell cluster integrated network for occluded multi-objects recognition](https://arxiv.org/abs/2310.11834) (Chongqing)
- [ ] [\[2310.11862\] Learning to Generate Parameters of ConvNets for Unseen Image Data](https://arxiv.org/abs/2310.11862) (BIT, TIP)
- [ ] [\[2310.11868\] To Generate or Not? Safety-Driven Unlearned Diffusion Models Are Still Easy To Generate Unsafe Images ... For Now](https://arxiv.org/abs/2310.11868) (ECCV)
- [ ] [\[2310.11881\] A Comparative Study of Image Restoration Networks for General Backbone Network Design](https://arxiv.org/abs/2310.11881) (ECCV)
- [ ] [\[2310.12017\] Exploring Decision-based Black-box Attacks on Face Forgery Detection](https://arxiv.org/abs/2310.12017) (Fudan)
- [ ] [\[2310.12085\] On the Benefit of Generative Foundation Models for Human Activity Recognition](https://arxiv.org/abs/2310.12085) (GIT)
- [ ] [\[2310.12152\] Learning from Rich Semantics and Coarse Locations for Long-tailed Object Detection](https://arxiv.org/abs/2310.12152) (NIPS)
- [ ] [\[2310.12274\] An Image is Worth Multiple Words: Discovering Object Level Concepts using Multi-Concept Prompt Learning](https://arxiv.org/abs/2310.12274) (ICML)
- [ ] [\[2310.12334\] Improving Representation Learning for Histopathologic Images with Cluster Constraints](https://arxiv.org/abs/2310.12334) (ICCV)
- [ ] [\[2310.12452\] Not Just Learning from Others but Relying on Yourself: A New Perspective on Few-Shot Segmentation in Remote Sensing](https://arxiv.org/abs/2310.12452) (UCAS)
- [ ] [\[2310.12470\] RecolorCloud: A Point Cloud Tool for Recoloring, Segmentation, and Conversion](https://arxiv.org/abs/2310.12470) (ACMMM)
- [ ] [\[2310.12474\] Enhancing High-Resolution 3D Generation through Pixel-wise Gradient Clipping](https://arxiv.org/abs/2310.12474) (Fudan, ICLR)
- [ ] [\[2310.12600\] FUSC: Fetal Ultrasound Semantic Clustering of Second Trimester Scans Using Deep Self-supervised Learning](https://arxiv.org/abs/2310.12600) (MBZUAI)
- [ ] [\[2310.12616\] Cross-attention Spatio-temporal Context Transformer for Semantic Segmentation of Historical Maps](https://arxiv.org/abs/2310.12616) (ETH)
- [ ] [\[2310.12692\] Representation Learning via Consistent Assignment of Views over Random Partitions](https://arxiv.org/abs/2310.12692) (NIPS)
- [ ] [\[2310.12705\] Exploiting Low-confidence Pseudo-labels for Source-free Object Detection](https://arxiv.org/abs/2310.12705) (USTC)
- [ ] [\[2310.12707\] Recoverable Privacy-Preserving Image Classification through Noise-like Adversarial Examples](https://arxiv.org/abs/2310.12707) (Alibaba)
- [ ] [\[2310.12724\] Query-aware Long Video Localization and Relation Discrimination for Deep Video Understanding](https://arxiv.org/abs/2310.12724) (BUPT, ACMMM)
- [ ] [\[2310.12755\] Minimalist and High-Performance Semantic Segmentation with Plain Vision Transformers](https://arxiv.org/abs/2310.12755) (HIT)
- [ ] [\[2310.12790\] Anomaly Heterogeneity Learning for Open-set Supervised Anomaly Detection](https://arxiv.org/abs/2310.12790) (CVPR)
- [ ] [\[2310.12817\] 2D-3D Interlaced Transformer for Point Cloud Segmentation with Scene-Level Supervision](https://arxiv.org/abs/2310.12817) (ICCV)
- [ ] [\[2310.12848\] Neural Degradation Representation Learning for All-In-One Image Restoration](https://arxiv.org/abs/2310.12848) (USTC)
- [ ] [\[2310.12970\] Real-Time Motion Prediction via Heterogeneous Polyline Transformer with Relative Pose Encoding](https://arxiv.org/abs/2310.12970) (ETH, NIPS)
- [ ] [\[2310.12973\] Frozen Transformers in Language Models Are Effective Visual Encoder Layers](https://arxiv.org/abs/2310.12973) (ICLR)
- [ ] [\[2310.12982\] Putting the Object Back into Video Object Segmentation](https://arxiv.org/abs/2310.12982) (CVPR)
- [ ] [\[2310.12985\] Enabling energy-Efficient object detection with surrogate gradient descent in spiking neural networks](https://arxiv.org/abs/2310.12985) (SYSU)
- [ ] [\[2310.12990\] Wave-informed dictionary learning for high-resolution imaging in complex media](https://arxiv.org/abs/2310.12990) (Stanford)
- [ ] [\[2310.12995\] Comprehensive Multimodal Segmentation in Medical Imaging: Combining YOLOv8 with SAM and HQ-SAM Models](https://arxiv.org/abs/2310.12995) (University of Copenhagen)
- [ ] [\[2310.13165\] CycleNet: Rethinking Cycle Consistency in Text-Guided Diffusion for Image Manipulation](https://arxiv.org/abs/2310.13165) (NIPS)
- [ ] [\[2310.13183\] Breaking through Deterministic Barriers: Randomized Pruning Mask Generation and Selection](https://arxiv.org/abs/2310.13183) (NYU)
- [ ] [\[2310.13215\] Zone Evaluation: Revealing Spatial Bias in Object Detection](https://arxiv.org/abs/2310.13215) (TPAMI)
- [ ] [\[2310.13255\] Steve-Eye: Equipping LLM-based Embodied Agents with Visual Perception in Open Worlds](https://arxiv.org/abs/2310.13255) (Peking)
- [ ] [\[2310.13263\] UE4-NeRF:Neural Radiance Field for Real-Time Rendering of Large-Scale Scene](https://arxiv.org/abs/2310.13263) (NIPS)
- [ ] [\[2310.13268\] DPM-Solver-v3: Improved Diffusion ODE Solver with Empirical Model Statistics](https://arxiv.org/abs/2310.13268) (NIPS)
- [ ] [\[2310.13320\] CylinderTag: An Accurate and Flexible Marker for Cylinder-Shape Objects Pose Estimation Based on Projective Invariants](https://arxiv.org/abs/2310.13320) (Peking)
- [ ] [\[2310.13336\] FLAIR: a Country-Scale Land Cover Semantic Segmentation Dataset From Multi-Source Optical Imagery](https://arxiv.org/abs/2310.13336) (NIPS)
- [ ] [\[2310.13347\] NurViD: A Large Expert-Level Video Database for Nursing Procedure Activity Understanding](https://arxiv.org/abs/2310.13347) (NIPS)
- [ ] [\[2310.13350\] EarlyBird: Early-Fusion for Multi-View Tracking in the Bird's Eye View](https://arxiv.org/abs/2310.13350) (TUM)
- [ ] [\[2310.13378\] ScalableMap: Scalable Map Learning for Online Long-Range Vectorized HD Map Construction](https://arxiv.org/abs/2310.13378) (WHU)
- [ ] [\[2310.13398\] OpenAnnotate3D: Open-Vocabulary Auto-Labeling System for Multi-modal 3D Data](https://arxiv.org/abs/2310.13398) (Fudan)
- [ ] [\[2310.13479\] Segment, Select, Correct: A Framework for Weakly-Supervised Referring Segmentation](https://arxiv.org/abs/2310.13479) (Oxford)
- [ ] [\[2310.13481\] A review of individual tree crown detection and delineation from optical remote sensing images](https://arxiv.org/abs/2310.13481) (Tsinghua)
- [ ] [\[2310.13545\] ScaleLong: Towards More Stable Training of Diffusion Model via Scaling Network Long Skip Connection](https://arxiv.org/abs/2310.13545) (SYSU, NIPS)
- [ ] [\[2310.13593\] Learning with Unmasked Tokens Drives Stronger Vision Learners](https://arxiv.org/abs/2310.13593) (ECCV)
- [ ] [\[2310.13605\] FMRT: Learning Accurate Feature Matching with Reconciliatory Transformer](https://arxiv.org/abs/2310.13605) (Tsinghua)
- [ ] [\[2310.13622\] What you see is what you get: Experience ranking with deep neural dataset-to-dataset similarity for topological localisation](https://arxiv.org/abs/2310.13622) (Oxford)
- [ ] [\[2310.13730\] Localizing and Editing Knowledge in Text-to-Image Generative Models](https://arxiv.org/abs/2310.13730) (UMD)
- [ ] [\[2310.13766\] U-BEV: Height-aware Bird's-Eye-View Segmentation and Neural Map-based Relocalization](https://arxiv.org/abs/2310.13766) (MPI)
- [ ] [\[2310.13912\] Learning Motion Refinement for Unsupervised Face Animation](https://arxiv.org/abs/2310.13912) (NIPS)
- [ ] [\[2310.13951\] Fuzzy-NMS: Improving 3D Object Detection with Fuzzy Classification in NMS](https://arxiv.org/abs/2310.13951) (Tsinghua)
- [ ] [\[2310.14019\] You Only Condense Once: Two Rules for Pruning Condensed Datasets](https://arxiv.org/abs/2310.14019) (NIPS)
- [ ] [\[2310.14154\] Affine-Consistent Transformer for Multi-Class Cell Nuclei Detection](https://arxiv.org/abs/2310.14154) (SYSU, ICCV)
- [ ] [\[2310.14176\] Prompt-based Grouping Transformer for Nucleus Detection and Classification](https://arxiv.org/abs/2310.14176) (SYSU)
- [ ] [\[2310.14184\] Partition Speeds Up Learning Implicit Neural Representations Based on Exponential-Increase Hypothesis](https://arxiv.org/abs/2310.14184) (BU, ICCV)
- [ ] [\[2310.14214\] TransY-Net:Learning Fully Transformer Networks for Change Detection of Remote Sensing Images](https://arxiv.org/abs/2310.14214) (NWPU)
- [ ] [\[2310.14226\] Multi-stream Cell Segmentation with Low-level Cues for Multi-modality Images](https://arxiv.org/abs/2310.14226) (NIPS)
- [ ] [\[2310.14294\] Deep MDP: A Modular Framework for Multi-Object Tracking](https://arxiv.org/abs/2310.14294) (University of Alberta)
- [ ] [\[2310.14344\] What's in a Prior? Learned Proximal Networks for Inverse Problems](https://arxiv.org/abs/2310.14344) (JHU)
- [ ] [\[2310.14364\] A Quantitative Evaluation of Dense 3D Reconstruction of Sinus Anatomy from Monocular Endoscopic Video](https://arxiv.org/abs/2310.14364) (JHU)
- [ ] [\[2310.14374\] OV-VG: A Benchmark for Open-Vocabulary Visual Grounding](https://arxiv.org/abs/2310.14374) (NTU)
- [ ] [\[2310.14390\] Cross-Domain HAR: Few Shot Transfer Learning for Human Activity Recognition](https://arxiv.org/abs/2310.14390) (GIT)
- [ ] [\[2310.14414\] Vision Language Models in Autonomous Driving: A Survey and Outlook](https://arxiv.org/abs/2310.14414) (TUM)
- [ ] [\[2310.14437\] Mobile AR Depth Estimation: Challenges & Prospects -- Extended Version](https://arxiv.org/abs/2310.14437) (NVIDIA)
- [ ] [\[2310.14453\] Skipped Feature Pyramid Network with Grid Anchor for Object Detection](https://arxiv.org/abs/2310.14453) (WHU)
- [ ] [\[2310.14489\] MSFormer: A Skeleton-multiview Fusion Method For Tooth Instance Segmentation](https://arxiv.org/abs/2310.14489) (ZJU)
- [ ] [\[2310.14504\] ADoPT: LiDAR Spoofing Attack Detection Based on Point-Level Temporal Consistency](https://arxiv.org/abs/2310.14504) (NVIDIA)
- [ ] [\[2310.14532\] Practical Deep Dispersed Watermarking with Synchronization and Fusion](https://arxiv.org/abs/2310.14532) (ACMMM)
- [ ] [\[2310.14566\] HallusionBench: An Advanced Diagnostic Suite for Entangled Language Hallucination and Visual Illusion in Large Vision-Language Models](https://arxiv.org/abs/2310.14566) (CVPR)
- [ ] [\[2310.14570\] DICE: Diverse Diffusion Model with Scoring for Trajectory Prediction](https://arxiv.org/abs/2310.14570) (University of Toronto)
- [ ] [\[2310.14592\] Pre-Training LiDAR-Based 3D Object Detectors Through Colorization](https://arxiv.org/abs/2310.14592) (ICLR)
- [ ] [\[2310.14652\] Invariant Feature Regularization for Fair Face Recognition](https://arxiv.org/abs/2310.14652) (NTU, ICCV)
- [ ] [\[2310.14670\] Dataset Bias Mitigation in Multiple-Choice Visual Question Answering and Beyond](https://arxiv.org/abs/2310.14670) (HKUST)
- [ ] [\[2310.14700\] Interaction-Driven Active 3D Reconstruction with Object Interiors](https://arxiv.org/abs/2310.14700) (SIGGRAPH)
- [ ] [\[2310.14702\] BM2CP: Efficient Collaborative Perception with LiDAR-Camera Modalities](https://arxiv.org/abs/2310.14702) (HIT)
- [ ] [\[2310.14718\] Rethinking Scale Imbalance in Semi-supervised Object Detection for Aerial Images](https://arxiv.org/abs/2310.14718) (WHU)
- [ ] [\[2310.14729\] MAS: Multi-view Ancestral Sampling for 3D motion generation using 2D diffusion](https://arxiv.org/abs/2310.14729) (Tel Aviv)
- [ ] [\[2310.14785\] Vision-Enhanced Semantic Entity Recognition in Document Images via Visually-Asymmetric Consistency Learning](https://arxiv.org/abs/2310.14785) (SJTU)
- [ ] [\[2310.14839\] ESVAE: An Efficient Spiking Variational Autoencoder with Reparameterizable Poisson Spiking Sampling](https://arxiv.org/abs/2310.14839) (UESTC)
- [ ] [\[2310.14942\] Domain Watermark: Effective and Harmless Dataset Copyright Protection is Closed at Hand](https://arxiv.org/abs/2310.14942) (ZJU, NIPS)
- [ ] [\[2310.14958\] Learning Real-World Image De-Weathering with Imperfect Supervision](https://arxiv.org/abs/2310.14958) (HIT)
- [ ] [\[2310.15023\] SONIC: Sonar Image Correspondence using Pose Supervised Learning for Imaging Sonars](https://arxiv.org/abs/2310.15023) (CMU)
- [ ] [\[2310.15052\] DREAM+: Efficient Dataset Distillation by Bidirectional Representative Matching](https://arxiv.org/abs/2310.15052) (NUS, ICCV)
- [ ] [\[2310.15066\] Localizing Active Objects from Egocentric Vision with Symbolic World Knowledge](https://arxiv.org/abs/2310.15066) (UCLA)
- [ ] [\[2310.15105\] FD-Align: Feature Discrimination Alignment for Fine-tuning Pre-Trained Models in Few-Shot Learning](https://arxiv.org/abs/2310.15105) (Microsoft, NIPS)
- [ ] [\[2310.15111\] Matryoshka Diffusion Models](https://arxiv.org/abs/2310.15111) (ICLR)
- [ ] [\[2310.15115\] SpVOS: Efficient Video Object Segmentation with Triple Sparse Convolution](https://arxiv.org/abs/2310.15115) (Fudan)
- [ ] [\[2310.15160\] FreeMask: Synthetic Images with Dense Annotations Make Stronger Segmentation Models](https://arxiv.org/abs/2310.15160) (NIPS)
- [ ] [\[2310.15161\] SAM-Med3D: Towards General-purpose Segmentation Models for Volumetric Medical Images](https://arxiv.org/abs/2310.15161) (Shanghai AI Lab)
- [ ] [\[2310.15165\] Handling Data Heterogeneity via Architectural Design for Federated Visual Recognition](https://arxiv.org/abs/2310.15165) (NIPS)
- [ ] [\[2310.15166\] Large Language Models are Visual Reasoning Coordinators](https://arxiv.org/abs/2310.15166) (NIPS)
- [ ] [\[2310.15168\] Ghost on the Shell: An Expressive Representation of General 3D Shapes](https://arxiv.org/abs/2310.15168) (ICLR)
- [ ] [\[2310.15169\] FreeNoise: Tuning-Free Longer Video Diffusion via Noise Rescheduling](https://arxiv.org/abs/2310.15169) (ICLR)
- [ ] [\[2310.15171\] RoboDepth: Robust Out-of-Distribution Depth Estimation under Corruptions](https://arxiv.org/abs/2310.15171) (NIPS)
- [ ] [\[2310.15308\] SAM-CLIP: Merging Vision Foundation Models towards Semantic and Spatial Understanding](https://arxiv.org/abs/2310.15308) (Illinois)
- [ ] [\[2310.15422\] G2-MonoDepth: A General Framework of Generalized Depth Inference from Monocular RGB+X Data](https://arxiv.org/abs/2310.15422) (XJTU)
- [ ] [\[2310.15444\] Fast Propagation is Better: Accelerating Single-Step Adversarial Training via Sampling Subnetworks](https://arxiv.org/abs/2310.15444) (SYSU)
- [ ] [\[2310.15482\] Salient Object Detection in RGB-D Videos](https://arxiv.org/abs/2310.15482) (TIP)
- [ ] [\[2310.15568\] I$^2$MD: 3D Action Representation Learning with Inter- and Intra-modal Mutual Distillation](https://arxiv.org/abs/2310.15568) (USTC)
- [ ] [\[2310.15624\] GUPNet++: Geometry Uncertainty Propagation Network for Monocular 3D Object Detection](https://arxiv.org/abs/2310.15624) (USyd)
- [ ] [\[2310.15646\] Mean Teacher DETR with Masked Feature Alignment: A Robust Domain Adaptive Detection Transformer Framework](https://arxiv.org/abs/2310.15646) (Tsinghua)
- [ ] [\[2310.15670\] Leveraging Vision-Centric Multi-Modal Expertise for 3D Object Detection](https://arxiv.org/abs/2310.15670) (NIPS)
- [ ] [\[2310.15676\] Recent Advances in Multi-modal 3D Scene Understanding: A Comprehensive Survey and Evaluation](https://arxiv.org/abs/2310.15676) (UESTC)
- [ ] [\[2310.15688\] Nighttime Thermal Infrared Image Colorization with Feedback-based Object Appearance Learning](https://arxiv.org/abs/2310.15688) (UESTC)
- [ ] [\[2310.15712\] GNeSF: Generalizable Neural Semantic Fields](https://arxiv.org/abs/2310.15712) (NIPS)
- [ ] [\[2310.15948\] Language-driven Scene Synthesis using Multi-conditional Diffusion Model](https://arxiv.org/abs/2310.15948) (NIPS)
- [ ] [\[2310.15955\] Decoupled DETR: Spatially Disentangling Localization and Classification for Improved End-to-End Object Detection](https://arxiv.org/abs/2310.15955) (CUHK, ICCV)
- [ ] [\[2310.15984\] Geometry-Aware Video Quality Assessment for Dynamic Digital Human](https://arxiv.org/abs/2310.15984) (SJTU)
- [ ] [\[2310.15999\] Transitivity Recovering Decompositions: Interpretable and Robust Fine-Grained Relationships](https://arxiv.org/abs/2310.15999) (NIPS)
- [ ] [\[2310.16002\] Integrating View Conditions for Image Synthesis](https://arxiv.org/abs/2310.16002) (Berkeley)
- [ ] [\[2310.16035\] What's Left? Concept Grounding with Logic-Enhanced Foundation Models](https://arxiv.org/abs/2310.16035) (Stanford, NIPS)
- [ ] [\[2310.16044\] Stanford-ORB: A Real-World 3D Object Inverse Rendering Benchmark](https://arxiv.org/abs/2310.16044) (NIPS)
- [ ] [\[2310.16047\] From Posterior Sampling to Meaningful Diversity in Image Restoration](https://arxiv.org/abs/2310.16047) (ICLR)
- [ ] [\[2310.16052\] Synthetic Data as Validation](https://arxiv.org/abs/2310.16052) (CUHK)
- [ ] [\[2310.16069\] CPSeg: Finer-grained Image Semantic Segmentation via Chain-of-Thought Language Prompting](https://arxiv.org/abs/2310.16069) (University of Copenhagen)
- [ ] [\[2310.16073\] FloCoDe: Unbiased Dynamic Scene Graph Generation with Temporal Consistency and Correlation Debiasing](https://arxiv.org/abs/2310.16073) (CVPR)
- [ ] [\[2310.16112\] Towards long-tailed, multi-label disease classification from chest X-ray: Overview of the CXR-LT challenge](https://arxiv.org/abs/2310.16112) (Cornell)
- [ ] [\[2310.16167\] iNVS: Repurposing Diffusion Inpainters for Novel View Synthesis](https://arxiv.org/abs/2310.16167) (SIGGRAPH)
- [ ] [\[2310.16226\] TiC-CLIP: Continual Training of CLIP Models](https://arxiv.org/abs/2310.16226) (CMU, ICLR)
- [ ] [\[2310.16255\] UAV-Sim: NeRF-based Synthetic Data Generation for UAV-based Perception](https://arxiv.org/abs/2310.16255) (UMD)
- [ ] [\[2310.16279\] TransPose: 6D Object Pose Estimation with Geometry-Aware Transformer](https://arxiv.org/abs/2310.16279) (Tongji)
- [ ] [\[2310.16364\] Towards Large-scale Masked Face Recognition](https://arxiv.org/abs/2310.16364) (CUHK, ICCV)
- [ ] [\[2310.16402\] Video Referring Expression Comprehension via Transformer with Content-conditioned Query](https://arxiv.org/abs/2310.16402) (Peking)
- [ ] [\[2310.16430\] An Integrative Paradigm for Enhanced Stroke Prediction: Synergizing XGBoost and xDeepFM Algorithms](https://arxiv.org/abs/2310.16430) (BU)
- [ ] [\[2310.16436\] DDCoT: Duty-Distinct Chain-of-Thought Prompting for Multimodal Reasoning in Language Models](https://arxiv.org/abs/2310.16436) (ShanghaiTech, NIPS)
- [ ] [\[2310.16447\] ChimpACT: A Longitudinal Dataset for Understanding Chimpanzee Behaviors](https://arxiv.org/abs/2310.16447) (Peking, NIPS)
- [ ] [\[2310.16459\] DualMatch: Robust Semi-Supervised Learning with Dual-Level Interaction](https://arxiv.org/abs/2310.16459) (NJU)
- [ ] [\[2310.16492\] On the Powerfulness of Textual Outlier Exposure for Visual OoD Detection](https://arxiv.org/abs/2310.16492) (NIPS)
- [ ] [\[2310.16542\] ParisLuco3D: A high-quality target dataset for domain generalization of LiDAR perception](https://arxiv.org/abs/2310.16542) (PSL University)
- [ ] [\[2310.16569\] Flow-Attention-based Spatio-Temporal Aggregation Network for 3D Mask Detection](https://arxiv.org/abs/2310.16569) (NIPS)
- [ ] [\[2310.16573\] Adapt Anything: Tailor Any Image Classifiers across Domains And Categories Using Text-to-Image Diffusion Models](https://arxiv.org/abs/2310.16573) (NWPU)
- [ ] [\[2310.16629\] EdgeCalib: Multi-Frame Weighted Edge Features for Automatic Targetless LiDAR-Camera Calibration](https://arxiv.org/abs/2310.16629) (USTC)
- [ ] [\[2310.16656\] A Picture is Worth a Thousand Words: Principled Recaptioning Improves Image Generation](https://arxiv.org/abs/2310.16656) (Google)
- [ ] [\[2310.16667\] CoDet: Co-Occurrence Guided Region-Word Alignment for Open-Vocabulary Object Detection](https://arxiv.org/abs/2310.16667) (NIPS)
- [ ] [\[2310.16717\] Prompt-Driven Building Footprint Extraction in Aerial Images with Offset-Building Model](https://arxiv.org/abs/2310.16717) (UCAS)
- [ ] [\[2310.16750\] Metrically Scaled Monocular Depth Estimation through Sparse Priors for Underwater Robots](https://arxiv.org/abs/2310.16750) (ETH)
- [ ] [\[2310.16764\] ConvNets Match Vision Transformers at Scale](https://arxiv.org/abs/2310.16764) (Google)
- [ ] [\[2310.16781\] Kiki or Bouba? Sound Symbolism in Vision-and-Language Models](https://arxiv.org/abs/2310.16781) (NIPS)
- [ ] [\[2310.16835\] Proposal-Contrastive Pretraining for Object Detection from Fewer Data](https://arxiv.org/abs/2310.16835) (ICLR)
- [ ] [\[2310.16870\] MACP: Efficient Model Adaptation for Cooperative Perception](https://arxiv.org/abs/2310.16870) (Tsinghua)
- [ ] [\[2310.16898\] MCUFormer: Deploying Vision Transformers on Microcontrollers with Limited Memory](https://arxiv.org/abs/2310.16898) (NIPS)
- [ ] [\[2310.17050\] Exploring Question Decomposition for Zero-Shot VQA](https://arxiv.org/abs/2310.17050) (NIPS)
- [ ] [\[2310.17075\] HyperFields: Towards Zero-Shot Generation of NeRFs from Text](https://arxiv.org/abs/2310.17075) (ICML)
- [ ] [\[2310.17078\] HCT: Hybrid Convnet-Transformer for Parkinson's disease detection and severity prediction from gait](https://arxiv.org/abs/2310.17078) (ICML)
- [ ] [\[2310.17080\] Automating lichen monitoring in ecological studies using instance segmentation of time-lapse images](https://arxiv.org/abs/2310.17080) (ICML)
- [ ] [\[2310.17097\] Navigating Data Heterogeneity in Federated Learning A Semi-Supervised Federated Object Detection](https://arxiv.org/abs/2310.17097) (KAIST, NIPS)
- [ ] [\[2310.17131\] Virtual Accessory Try-On via Keypoint Hallucination](https://arxiv.org/abs/2310.17131) (SJTU)
- [ ] [\[2310.17177\] Bridging The Gaps Between Token Pruning and Full Pre-training via Masked Fine-tuning](https://arxiv.org/abs/2310.17177) (NJU, TIP)
- [ ] [\[2310.17188\] Blind Image Super-resolution with Rich Texture-Aware Codebooks](https://arxiv.org/abs/2310.17188) (Tsinghua)
- [ ] [\[2310.17189\] Exploring Iterative Refinement with Diffusion Models for Video Grounding](https://arxiv.org/abs/2310.17189) (Tsinghua)
- [ ] [\[2310.17190\] Lookup Table meets Local Laplacian Filter: Pyramid Reconstruction Network for Tone Mapping](https://arxiv.org/abs/2310.17190) (HUST)
- [ ] [\[2310.17212\] Affective Video Content Analysis: Decade Review and New Perspectives](https://arxiv.org/abs/2310.17212) (XJTU)
- [ ] [\[2310.17218\] Prototypical Contrastive Learning-based CLIP Fine-tuning for Object Re-identification](https://arxiv.org/abs/2310.17218) (ZJU)
- [ ] [\[2310.17261\] Attribute Based Interpretable Evaluation Metrics for Generative Models](https://arxiv.org/abs/2310.17261) (ICML)
- [ ] [\[2310.17290\] RIO: A Benchmark for Reasoning Intention-Oriented Objects in Open Environments](https://arxiv.org/abs/2310.17290) (WHU, NIPS)
- [ ] [\[2310.17294\] Scale-Adaptive Feature Aggregation for Efficient Space-Time Video Super-Resolution](https://arxiv.org/abs/2310.17294) (Peking)
- [ ] [\[2310.17316\] Defect Spectrum: A Granular Look of Large-Scale Defect Datasets with Rich Semantics](https://arxiv.org/abs/2310.17316) (ECCV)
- [ ] [\[2310.17347\] CADS: Unleashing the Diversity of Diffusion Models through Condition-Annealed Sampling](https://arxiv.org/abs/2310.17347) (ICLR)
- [ ] [\[2310.17359\] SE(3) Diffusion Model-based Point Cloud Registration for Robust 6D Object Pose Estimation](https://arxiv.org/abs/2310.17359) (NIPS)
- [ ] [\[2310.17379\] YOLO-BEV: Generating Bird's-Eye View in the Same Way as 2D Object Detection](https://arxiv.org/abs/2310.17379) (TUM)
- [ ] [\[2310.17455\] OTMatch: Improving Semi-Supervised Learning with Optimal Transport](https://arxiv.org/abs/2310.17455) (ICML)
- [ ] [\[2310.17468\] Cross-modal Active Complementary Learning with Self-refining Correspondence](https://arxiv.org/abs/2310.17468) (NIPS)
- [ ] [\[2310.17519\] FLARE: Fast Learning of Animatable and Relightable Mesh Avatars](https://arxiv.org/abs/2310.17519) (MPI, SIGGRAPH)
- [ ] [\[2310.17527\] Masked Space-Time Hash Encoding for Efficient Dynamic Scene Reconstruction](https://arxiv.org/abs/2310.17527) (Tsinghua, NIPS)
- [ ] [\[2310.17569\] SD4Match: Learning to Prompt Stable Diffusion Model for Semantic Matching](https://arxiv.org/abs/2310.17569) (Oxford, CVPR)
- [ ] [\[2310.17577\] Global Structure-Aware Diffusion Process for Low-Light Image Enhancement](https://arxiv.org/abs/2310.17577) (NIPS)
- [ ] [\[2310.17594\] SPA: A Graph Spectral Alignment Perspective for Domain Adaptation](https://arxiv.org/abs/2310.17594) (NIPS)
- [ ] [\[2310.17768\] A Dataset of Relighted 3D Interacting Hands](https://arxiv.org/abs/2310.17768) (Meta, NIPS)
- [ ] [\[2310.17796\] ControlLLM: Augment Language Models with Tools by Searching on Graphs](https://arxiv.org/abs/2310.17796) (Shanghai AI Lab)
- [ ] [\[2310.17835\] One Style is All you Need to Generate a Video](https://arxiv.org/abs/2310.17835) (PSL University)
  
  - [x] [\[2310.17874\] SmooSeg: Smoothness Prior for Unsupervised Semantic Segmentation](https://arxiv.org/abs/2310.17874) (NTU, NIPS)

- [ ] [\[2310.17887\] Impressions: Understanding Visual Semiotics and Aesthetic Impact](https://arxiv.org/abs/2310.17887) (GIT)
- [ ] [\[2310.17914\] 3D-Aware Visual Question Answering about Parts, Poses and Occlusions](https://arxiv.org/abs/2310.17914) (MPI, NIPS)
- [ ] [\[2310.17942\] Diversifying Spatial-Temporal Perception for Video Domain Generalization](https://arxiv.org/abs/2310.17942) (NIPS)
- [ ] [\[2310.17951\] Understanding Parameter Saliency via Extreme Value Theory](https://arxiv.org/abs/2310.17951) (University of Tokyo)
- [ ] [\[2310.17956\] Qilin-Med-VL: Towards Chinese Large Vision-Language Model for General Healthcare](https://arxiv.org/abs/2310.17956) (Peking)
- [ ] [\[2310.17994\] ZeroNVS: Zero-Shot 360-Degree View Synthesis from a Single Image](https://arxiv.org/abs/2310.17994) (CVPR)
- [ ] [\[2310.18087\] A Chebyshev Confidence Guided Source-Free Domain Adaptation Framework for Medical Image Segmentation](https://arxiv.org/abs/2310.18087) (HIT)
- [ ] [\[2310.18131\] End-to-end Video Gaze Estimation via Capturing Head-face-eye Spatial-temporal Interaction Context](https://arxiv.org/abs/2310.18131) (HUST)
  
  - [ ] [\[2310.18142\] Semi-Supervised Panoptic Narrative Grounding](https://arxiv.org/abs/2310.18142) (Xiamen, ACMMM)

- [ ] [\[2310.18235\] Davidsonian Scene Graph: Improving Reliability in Fine-grained Evaluation for Text-to-Image Generation](https://arxiv.org/abs/2310.18235) (ICLR)
- [ ] [\[2310.18236\] How Re-sampling Helps for Long-Tail Learning?](https://arxiv.org/abs/2310.18236) (NIPS)
- [ ] [\[2310.18274\] LipSim: A Provably Robust Perceptual Similarity Metric](https://arxiv.org/abs/2310.18274) (NYU)
- [ ] [\[2311.02782\] Towards Generic Anomaly Detection and Understanding: Large-scale Visual-linguistic Model (GPT-4V) Takes the Lead](https://arxiv.org/abs/2311.02782) (HUST)
- [ ] [\[2311.02803\] Fast and Interpretable Face Identification for Out-Of-Distribution Data Using Vision Transformers](https://arxiv.org/abs/2311.02803) (Columbia University)
- [ ] [\[2311.02815\] Efficient, Self-Supervised Human Pose Estimation with Inductive Prior Tuning](https://arxiv.org/abs/2311.02815) (Princeton)
- [ ] [\[2311.02820\] Mesh Neural Cellular Automata](https://arxiv.org/abs/2311.02820) (EPFL, SIGGRAPH)
- [ ] [\[2311.02826\] InstructPix2NeRF: Instructed 3D Portrait Editing from a Single Image](https://arxiv.org/abs/2311.02826) (Tsinghua)
