- [ ] [\[2311.12815\] Proposing an intelligent mesh smoothing method with graph neural networks](https://arxiv.org/abs/2311.12815) (ZJU)
- [ ] [\[2311.12817\] Semantic Face Compression for Metaverse: A Compact 3D Descriptor Based Approach](https://arxiv.org/abs/2311.12817) (Peking)
- [ ] [\[2311.12818\] Manifold Path Guiding for Importance Sampling Specular Chains](https://arxiv.org/abs/2311.12818) (NJU)
- [ ] [\[2311.12829\] Intelligent Knee Sleeves: A Real-time Multimodal Dataset for 3D Lower Body Motion Estimation Using Smart Textile](https://arxiv.org/abs/2311.12829) (NIPS)
- [ ] [\[2311.12832\] Toward effective protection against diffusion based mimicry through score distillation](https://arxiv.org/abs/2311.12832) (GIT, ICLR)
- [ ] [\[2311.12847\] CopyScope: Model-level Copyright Infringement Quantification in the Diffusion Workflow](https://arxiv.org/abs/2311.12847) (SUSTech)
- [ ] [\[2311.12850\] PrivImage: Differentially Private Synthetic Image Generation using Diffusion Models with Semantic-Aware Pretraining](https://arxiv.org/abs/2311.12850) (UCAS)
- [ ] [\[2311.12871\] An Embodied Generalist Agent in 3D World](https://arxiv.org/abs/2311.12871) (ICML)
- [ ] [\[2311.12885\] Long-MIL: Scaling Long Contextual Multiple Instance Learning for Histopathology Whole Slide Image Analysis](https://arxiv.org/abs/2311.12885) (ZJU)
- [ ] [\[2311.12890\] De-fine: Decomposing and Refining Visual Programs with Auto-Feedback](https://arxiv.org/abs/2311.12890) (ZJU)
- [ ] [\[2311.12967\] Robustifying Generalizable Implicit Shape Networks with a Tunable Non-Parametric Model](https://arxiv.org/abs/2311.12967) (NIPS)
- [ ] [\[2311.12981\] SD-NAE: Generating Natural Adversarial Examples with Stable Diffusion](https://arxiv.org/abs/2311.12981) (ICLR)
- [ ] [\[2311.12993\] AI for Agriculture: the Comparison of Semantic Segmentation Methods for Crop Mapping with Sentinel-2 Imagery](https://arxiv.org/abs/2311.12993) (QMUL)
- [ ] [\[2311.13009\] 3D Compression Using Neural Fields](https://arxiv.org/abs/2311.13009) (TUM)
- [ ] [\[2311.13099\] PIE-NeRF: Physics-based Interactive Elastodynamics with NeRF](https://arxiv.org/abs/2311.13099) (UCLA)
- [ ] [\[2311.13120\] Multi-modal In-Context Learning Makes an Ego-evolving Scene Text Recognizer](https://arxiv.org/abs/2311.13120) (CVPR)
- [ ] [\[2311.13125\] DAE-Net: Deforming Auto-Encoder for fine-grained shape co-segmentation](https://arxiv.org/abs/2311.13125) (SIGGRAPH)
- [ ] [\[2311.13127\] MetaCloak: Preventing Unauthorized Subject-driven Text-to-image Diffusion-based Synthesis via Meta-learning](https://arxiv.org/abs/2311.13127) (CVPR)
- [ ] [\[2311.13128\] P2RBox: Point Prompt Oriented Object Detection with SAM](https://arxiv.org/abs/2311.13128) (UCAS)
- [ ] [\[2311.13134\] Lightweight High-Speed Photography Built on Coded Exposure and Implicit Neural Representation of Videos](https://arxiv.org/abs/2311.13134) (Tsinghua)
- [ ] [\[2311.13168\] 3D Face Style Transfer with a Hybrid Solution of NeRF and Mesh Rasterization](https://arxiv.org/abs/2311.13168) (AWS)
- [ ] [\[2311.13199\] Two-stage Synthetic Supervising and Multi-view Consistency Self-supervising based Animal 3D Reconstruction by Single Image](https://arxiv.org/abs/2311.13199) (University of Alberta)
- [ ] [\[2311.13209\] Fast-Slow Test-Time Adaptation for Online Vision-and-Language Navigation](https://arxiv.org/abs/2311.13209) (ICML)
- [ ] [\[2311.13234\] TSegFormer: 3D Tooth Segmentation in Intraoral Scans with Geometry Guided Transformer](https://arxiv.org/abs/2311.13234) (ZJU)
- [ ] [\[2311.13250\] FedHCA$^2$: Towards Hetero-Client Federated Multi-Task Learning](https://arxiv.org/abs/2311.13250) (CVPR)
- [ ] [\[2311.13254\] Unified Domain Adaptive Semantic Segmentation](https://arxiv.org/abs/2311.13254) (USyd, Transactions on Pattern Analysis and Machine Intelligence)
- [ ] [\[2311.13263\] CMFDFormer: Transformer-based Copy-Move Forgery Detection with Continual Learning](https://arxiv.org/abs/2311.13263) (Xidian)
- [ ] [\[2311.13297\] Retargeting Visual Data with Deformation Fields](https://arxiv.org/abs/2311.13297) (ECCV)
- [ ] [\[2311.13307\] Rethinking Radiology Report Generation via Causal Inspired Counterfactual Augmentation](https://arxiv.org/abs/2311.13307) (Nankai)
- [ ] [\[2311.13372\] MRGazer: Decoding Eye Gaze Points from Functional Magnetic Resonance Imaging in Individual Space](https://arxiv.org/abs/2311.13372) (USTC)
- [ ] [\[2311.13385\] SegVol: Universal and Interactive Volumetric Medical Image Segmentation](https://arxiv.org/abs/2311.13385) (SJTU)
- [ ] [\[2311.13444\] SkeletonGait: Gait Recognition Using Skeleton Maps](https://arxiv.org/abs/2311.13444) (SUSTech)
- [ ] [\[2311.13574\] XAGen: 3D Expressive Human Avatars Generation](https://arxiv.org/abs/2311.13574) (NIPS)
- [ ] [\[2311.13596\] T-Rex: Counting by Visual Prompting](https://arxiv.org/abs/2311.13596) (HKUST)
- [ ] [\[2311.13602\] Retrieval-Augmented Layout Transformer for Content-Aware Layout Generation](https://arxiv.org/abs/2311.13602) (CVPR)
- [ ] [\[2311.13612\] Descriptor and Word Soups: Overcoming the Parameter Efficiency Accuracy Tradeoff for Out-of-Distribution Few-shot Learning](https://arxiv.org/abs/2311.13612) (BU)
- [ ] [\[2311.13613\] Spanning Training Progress: Temporal Dual-Depth Scoring (TDDS) for Enhanced Dataset Pruning](https://arxiv.org/abs/2311.13613) (Xidian, CVPR)
- [ ] [\[2311.13614\] HalluciDoctor: Mitigating Hallucinatory Toxicity in Visual Instruction Data](https://arxiv.org/abs/2311.13614) (ICT CAS, CVPR)
- [ ] [\[2311.13627\] Vamos: Versatile Action Models for Video Understanding](https://arxiv.org/abs/2311.13627) (ECCV)
- [ ] [\[2311.13661\] BenthIQ: a Transformer-Based Benthic Classification Model for Coral Restoration](https://arxiv.org/abs/2311.13661) (Caltech)
- [ ] [\[2311.13750\] Towards Transferable Multi-modal Perception Representation Learning for Autonomy: NeRF-Supervised Masked AutoEncoder](https://arxiv.org/abs/2311.13750) (University of Michigan)
- [ ] [\[2311.13752\] 3D-MIR: A Benchmark and Empirical Study on 3D Medical Image Retrieval in Radiology](https://arxiv.org/abs/2311.13752) (Microsoft)
- [ ] [\[2311.13777\] GS-Pose: Category-Level Object Pose Estimation via Geometric and Semantic Correspondence](https://arxiv.org/abs/2311.13777) (TUM)
- [ ] [\[2311.13833\] Lego: Learning to Disentangle and Invert Concepts Beyond Object Appearance in Text-to-Image Diffusion Models](https://arxiv.org/abs/2311.13833) (ETH)
- [ ] [\[2311.13846\] Progressive Learning with Visual Prompt Tuning for Variable-Rate Image Compression](https://arxiv.org/abs/2311.13846) (Tsinghua)
- [ ] [\[2311.13847\] Perceptual Image Compression with Cooperative Cross-Modal Side Information](https://arxiv.org/abs/2311.13847) (HIT)
- [ ] [\[2311.13928\] Parameter Exchange for Robust Dynamic Domain Generalization](https://arxiv.org/abs/2311.13928) (Chongqing, ACMMM)
- [ ] [\[2311.13929\] MetaFBP: Learning to Learn High-Order Predictor for Personalized Facial Beauty Prediction](https://arxiv.org/abs/2311.13929) (ZJU, ACMMM)
- [ ] [\[2311.13930\] Periodically Exchange Teacher-Student for Source-Free Object Detection](https://arxiv.org/abs/2311.13930) (ICCV)
- [ ] [\[2311.13993\] EIGEN: Expert-Informed Joint Learning Aggregation for High-Fidelity Information Extraction from Document Images](https://arxiv.org/abs/2311.13993) (NIPS)
- [ ] [\[2311.14062\] Hardware Resilience Properties of Text-Guided Image Classifiers](https://arxiv.org/abs/2311.14062) (NIPS)
- [ ] [\[2311.14097\] ACT-Diffusion: Efficient Adversarial Consistency Training for One-step Diffusion Models](https://arxiv.org/abs/2311.14097) (CVPR)
- [ ] [\[2311.14155\] GigaPose: Fast and Robust Novel Object Pose Estimation via One Correspondence](https://arxiv.org/abs/2311.14155) (CVPR)
- [ ] [\[2311.14189\] D-SCo: Dual-Stream Conditional Diffusion for Monocular Hand-Held Object Reconstruction](https://arxiv.org/abs/2311.14189) (Google, ECCV)
- [ ] [\[2311.14199\] A Systematic Review of Deep Learning-based Research on Radiology Report Generation](https://arxiv.org/abs/2311.14199) (UW)
- [ ] [\[2311.14242\] RSB-Pose: Robust Short-Baseline Binocular 3D Human Pose Estimation with Occlusion Handling](https://arxiv.org/abs/2311.14242) (SJTU, Transactions on Image Processing)
- [ ] [\[2311.14271\] Segmentation-Based Parametric Painting](https://arxiv.org/abs/2311.14271) (University of Toronto)
- [ ] [\[2311.14275\] Cooperative Dual Attention for Audio-Visual Speech Enhancement with Facial Cues](https://arxiv.org/abs/2311.14275) (UCAS)
- [ ] [\[2311.14310\] Stable Cluster Discrimination for Deep Clustering](https://arxiv.org/abs/2311.14310) (Alibaba, ICCV)
- [ ] [\[2311.14334\] Maximizing Discrimination Capability of Knowledge Distillation with Energy Function](https://arxiv.org/abs/2311.14334) (KAIST)
- [ ] [\[2311.14485\] Towards Interpretable Classification of Leukocytes based on Deep Learning](https://arxiv.org/abs/2311.14485) (TUM)
- [ ] [\[2311.14633\] One Strike, You're Out: Detecting Markush Structures in Low Signal-to-Noise Ratio Images](https://arxiv.org/abs/2311.14633) (UVA.NL)
- [ ] [\[2311.14656\] Charting New Territories: Exploring the Geographic and Geospatial Capabilities of Multimodal LLMs](https://arxiv.org/abs/2311.14656) (Cambridge)
- [ ] [\[2311.14671\] SEGIC: Unleashing the Emergent Correspondence for In-Context Segmentation](https://arxiv.org/abs/2311.14671) (ECCV)
- [ ] [\[2311.14749\] Compositional Zero-shot Learning via Progressive Language-based Observations](https://arxiv.org/abs/2311.14749) (HKUST)
- [ ] [\[2311.14750\] Attribute-Aware Representation Rectification for Generalized Zero-Shot Learning](https://arxiv.org/abs/2311.14750) (CUHK)
- [ ] [\[2311.14757\] PointOBB: Learning Oriented Object Detection via Single Point Supervision](https://arxiv.org/abs/2311.14757) (WHU)
- [ ] [\[2311.14758\] Point2RBox: Combine Knowledge from Synthetic Visual Patterns for End-to-end Oriented Object Detection with Single Point Supervision](https://arxiv.org/abs/2311.14758) (HIT)
- [ ] [\[2311.14775\] VSViG: Real-time Video-based Seizure Detection via Skeleton-based Spatiotemporal ViG](https://arxiv.org/abs/2311.14775) (ECCV)
- [ ] [\[2311.14822\] Text and Click inputs for unambiguous open vocabulary instance segmentation](https://arxiv.org/abs/2311.14822) (GIT)
- [ ] [\[2311.14837\] Benchmarking Robustness of Text-Image Composed Retrieval](https://arxiv.org/abs/2311.14837) (QMUL)
- [ ] [\[2311.14851\] Unified Medical Image Pre-training in Language-Guided Common Semantic Space](https://arxiv.org/abs/2311.14851) (Microsoft)
- [ ] [\[2311.14899\] HyperDID: Hyperspectral Intrinsic Image Decomposition with Deep Feature Embedding](https://arxiv.org/abs/2311.14899) (NUDT)
- [ ] [\[2311.14900\] Resfusion: Denoising Diffusion Probabilistic Models for Image Restoration Based on Prior Residual Noise](https://arxiv.org/abs/2311.14900) (Nankai)
- [ ] [\[2311.14905\] Class Gradient Projection For Continual Learning](https://arxiv.org/abs/2311.14905) (UESTC, ACMMM)
- [ ] [\[2311.14906\] AutoEval-Video: An Automatic Benchmark for Assessing Large Vision Language Models in Open-Ended Video Question Answering](https://arxiv.org/abs/2311.14906) (ECCV)
- [ ] [\[2311.14909\] Continual Referring Expression Comprehension via Dual Modular Memorization](https://arxiv.org/abs/2311.14909) (Transactions on Image Processing)
- [ ] [\[2311.14911\] CUCL: Codebook for Unsupervised Continual Learning](https://arxiv.org/abs/2311.14911) (UESTC, ACMMM)
- [ ] [\[2311.14920\] DECap: Towards Generalized Explicit Caption Editing via Diffusion Mechanism](https://arxiv.org/abs/2311.14920) (ZJU)
- [ ] [\[2311.14922\] GDTS: Goal-Guided Diffusion Model with Tree Sampling for Multi-Modal Pedestrian Trajectory Prediction](https://arxiv.org/abs/2311.14922) (HKUST)
- [ ] [\[2311.14926\] FreePIH: Training-Free Painterly Image Harmonization with Diffusion Model](https://arxiv.org/abs/2311.14926) (HKUST)
- [ ] [\[2311.14927\] View-Based Luminance Mapping in Open Workplace](https://arxiv.org/abs/2311.14927) (CMU)
- [ ] [\[2311.15011\] VSCode: General Visual Salient and Camouflaged Object Detection with 2D Prompt Learning](https://arxiv.org/abs/2311.15011) (CVPR)
- [ ] [\[2311.15040\] InstaStyle: Inversion Noise of a Stylized Image is Secretly a Style Adviser](https://arxiv.org/abs/2311.15040) (IA CAS, ECCV)
- [ ] [\[2311.15100\] Unbalancedness in Neural Monge Maps Improves Unpaired Domain Translation](https://arxiv.org/abs/2311.15100) (University of Tübingen, ICLR)
- [ ] [\[2311.15111\] UAE: Universal Anatomical Embedding on Multi-modality Medical Images](https://arxiv.org/abs/2311.15111) (NWPU)
- [ ] [\[2311.15145\] Choosing Wisely and Learning Deeply: Selective Cross-Modality Distillation via CLIP for Domain Generalization](https://arxiv.org/abs/2311.15145) (JHU)
- [ ] [\[2311.15153\] Predicting Gradient is Better: Exploring Self-Supervised Learning for SAR ATR with a Joint-Embedding Predictive Architecture](https://arxiv.org/abs/2311.15153) (Shanghai AI Lab)
- [ ] [\[2311.15193\] IA-LSTM: Interaction-Aware LSTM for Pedestrian Trajectory Prediction](https://arxiv.org/abs/2311.15193) (XJTU)
- [ ] [\[2311.15225\] One-bit Supervision for Image Classification: Problem, Solution, and Beyond](https://arxiv.org/abs/2311.15225) (USTC)
- [ ] [\[2311.15230\] GAIA: Zero-shot Talking Avatar Generation](https://arxiv.org/abs/2311.15230) (Microsoft, ICLR)
- [ ] [\[2311.15241\] CalibFormer: A Transformer-based Automatic LiDAR-Camera Calibration Network](https://arxiv.org/abs/2311.15241) (USTC)
- [ ] [\[2311.15264\] ChAda-ViT : Channel Adaptive Attention for Joint Representation Learning of Heterogeneous Microscopy Images](https://arxiv.org/abs/2311.15264) (PSL University)
- [ ] [\[2311.15273\] An Intelligent-Detection Network for Handwritten Mathematical Expression Recognition](https://arxiv.org/abs/2311.15273) (Fudan)
- [ ] [\[2311.15291\] Obj-NeRF: Extract Object NeRFs from Multi-view Images](https://arxiv.org/abs/2311.15291) (Tsinghua)
- [ ] [\[2311.15308\] AV-Deepfake1M: A Large-Scale LLM-Driven Audio-Visual Deepfake Dataset](https://arxiv.org/abs/2311.15308) (ACMMM)
- [ ] [\[2311.15367\] BatchNorm-based Weakly Supervised Video Anomaly Detection](https://arxiv.org/abs/2311.15367) (UESTC)
- [ ] [\[2311.15368\] Flow-Guided Diffusion for Video Inpainting](https://arxiv.org/abs/2311.15368) (IS CAS)
- [ ] [\[2311.15383\] Visual Programming for Zero-shot Open-Vocabulary 3D Visual Grounding](https://arxiv.org/abs/2311.15383) (CVPR)
- [ ] [\[2311.15421\] Wired Perspectives: Multi-View Wire Art Embraces Generative AI](https://arxiv.org/abs/2311.15421) (CVPR)
- [ ] [\[2311.15438\] ProtoArgNet: Interpretable Image Classification with Super-Prototypes and Argumentation [Technical Report]](https://arxiv.org/abs/2311.15438) (Imperial)
- [ ] [\[2311.15463\] Where to Begin? From Random to Foundation Model Instructed Initialization in Federated Learning for Medical Image Segmentation](https://arxiv.org/abs/2311.15463) (Imperial)
- [ ] [\[2311.15510\] CaesarNeRF: Calibrated Semantic Representation for Few-shot Generalizable Neural Rendering](https://arxiv.org/abs/2311.15510) (ECCV)
- [ ] [\[2311.15512\] Sparse Pedestrian Character Learning for Trajectory Prediction](https://arxiv.org/abs/2311.15512) (XJTU)
- [ ] [\[2311.15529\] Efficient Dataset Distillation via Minimax Diffusion](https://arxiv.org/abs/2311.15529) (CVPR)
- [ ] [\[2311.15537\] SED: A Simple Encoder-Decoder for Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2311.15537) (Chongqing, CVPR)
- [ ] [\[2311.15540\] EAFP-Med: An Efficient Adaptive Feature Processing Module Based on Prompts for Medical Image Detection](https://arxiv.org/abs/2311.15540) (NUDT)
- [ ] [\[2311.15543\] Beyond Pixels: Exploring Human-Readable SVG Generation for Simple Images with Vision Language Models](https://arxiv.org/abs/2311.15543) (Illinois)
- [ ] [\[2311.15547\] Dataset Distillation in Latent Space](https://arxiv.org/abs/2311.15547) (SJTU)
- [ ] [\[2311.15556\] PKU-I2IQA: An Image-to-Image Quality Assessment Database for AI Generated Images](https://arxiv.org/abs/2311.15556) (Peking)
- [ ] [\[2311.15573\] EucliDreamer: Fast and High-Quality Texturing for 3D Models with Stable Diffusion Depth](https://arxiv.org/abs/2311.15573) (Columbia University)
- [ ] [\[2311.15596\] EgoThink: Evaluating First-Person Perspective Thinking Capability of Vision-Language Models](https://arxiv.org/abs/2311.15596) (Tsinghua)
- [ ] [\[2311.15599\] UniRepLKNet: A Universal Perception Large-Kernel ConvNet for Audio, Video, Point Cloud, Time-Series and Image Recognition](https://arxiv.org/abs/2311.15599) (CVPR)
- [ ] [\[2311.15619\] Align before Adapt: Leveraging Entity-to-Region Alignments for Generalizable Video Action Recognition](https://arxiv.org/abs/2311.15619) (CVPR)
- [ ] [\[2311.15637\] Neural 3D Strokes: Creating Stylized 3D Scenes with Vectorized 3D Strokes](https://arxiv.org/abs/2311.15637) (CVPR)
- [ ] [\[2311.15648\] Reinforcement Learning from Diffusion Feedback: Q* for Image Search](https://arxiv.org/abs/2311.15648) (CMU)
- [ ] [\[2311.15657\] Enhancing Diffusion Models with Text-Encoder Reinforcement Learning](https://arxiv.org/abs/2311.15657) (NTU, ECCV)
- [ ] [\[2311.15668\] Deformation-Guided Unsupervised Non-Rigid Shape Matching](https://arxiv.org/abs/2311.15668) (Inria)
- [ ] [\[2311.15707\] SAM-6D: Segment Anything Model Meets Zero-Shot 6D Object Pose Estimation](https://arxiv.org/abs/2311.15707) (CVPR)
- [ ] [\[2311.15727\] RISAM: Referring Image Segmentation via Mutual-Aware Attention Features](https://arxiv.org/abs/2311.15727) (Tianjin)
- [ ] [\[2311.15744\] One More Step: A Versatile Plug-and-Play Module for Rectifying Diffusion Schedule Flaws and Enhancing Low-Frequency Controls](https://arxiv.org/abs/2311.15744) (Oxford)
- [ ] [\[2311.15773\] Check, Locate, Rectify: A Training-Free Layout Calibration System for Text-to-Image Generation](https://arxiv.org/abs/2311.15773) (ZJU)
- [ ] [\[2311.15803\] SOAC: Spatio-Temporal Overlap-Aware Multi-Sensor Calibration using Neural Radiance Fields](https://arxiv.org/abs/2311.15803) (CVPR)
- [ ] [\[2311.15826\] GeoChat: Grounded Large Vision-Language Model for Remote Sensing](https://arxiv.org/abs/2311.15826) (MBZUAI)
- [ ] [\[2311.15841\] Learning Disentangled Identifiers for Action-Customized Text-to-Image Generation](https://arxiv.org/abs/2311.15841) (CVPR)
- [ ] [\[2311.15851\] Single-Model and Any-Modality for Video Object Tracking](https://arxiv.org/abs/2311.15851) (CVPR)
- [ ] [\[2311.15855\] SiTH: Single-view Textured Human Reconstruction with Image-Conditioned Diffusion](https://arxiv.org/abs/2311.15855) (CVPR)
- [ ] [\[2311.15864\] InterControl: Zero-shot Human Interaction Generation by Controlling Every Joint](https://arxiv.org/abs/2311.15864) (Shanghai AI Lab)
- [ ] [\[2311.15876\] End-to-End Breast Cancer Radiotherapy Planning via LMMs with Consistency Embedding](https://arxiv.org/abs/2311.15876) (KAIST)
- [ ] [\[2311.15879\] EVCap: Retrieval-Augmented Image Captioning with External Visual-Name Memory for Open-World Comprehension](https://arxiv.org/abs/2311.15879) (University of Tokyo, CVPR)
- [ ] [\[2311.15908\] Enhancing Perceptual Quality in Video Super-Resolution through Temporally-Consistent Detail Synthesis using Diffusion Models](https://arxiv.org/abs/2311.15908) (ECCV)
- [ ] [\[2311.15964\] Efficient Pre-training for Localized Instruction Generation of Videos](https://arxiv.org/abs/2311.15964) (University of Edinburgh, ECCV)
- [ ] [\[2311.15965\] FALCON: Fairness Learning via Contrastive Attention Approach to Continual Semantic Scene Understanding](https://arxiv.org/abs/2311.15965) (CMU)
- [ ] [\[2311.15977\] Text2Loc: 3D Point Cloud Localization from Natural Language](https://arxiv.org/abs/2311.15977) (Oxford, CVPR)
- [ ] [\[2311.15980\] Direct2.5: Diverse Text-to-3D Generation via Multi-view 2.5D Diffusion](https://arxiv.org/abs/2311.15980) (NJU, CVPR)
- [ ] [\[2311.15993\] Unified Batch Normalization: Identifying and Alleviating the Feature Condensation in Batch Normalization and a Unified Framework](https://arxiv.org/abs/2311.15993) (SJTU)
- [ ] [\[2311.16037\] GaussianEditor: Editing 3D Gaussians Delicately with Text Instructions](https://arxiv.org/abs/2311.16037) (CVPR)
- [ ] [\[2311.16042\] Weakly-Supervised 3D Reconstruction of Clothed Humans via Normal Maps](https://arxiv.org/abs/2311.16042) (Stanford)
- [ ] [\[2311.16060\] DiffSLVA: Harnessing Diffusion Models for Sign Language Video Anonymization](https://arxiv.org/abs/2311.16060) (BU)
- [ ] [\[2311.16081\] ViT-Lens: Towards Omni-modal Representations](https://arxiv.org/abs/2311.16081) (CVPR)
- [ ] [\[2311.16097\] CG-HOI: Contact-Guided 3D Human-Object Interaction Generation](https://arxiv.org/abs/2311.16097) (TUM)
- [ ] [\[2311.16099\] GART: Gaussian Articulated Template Models](https://arxiv.org/abs/2311.16099) (Berkeley)
- [ ] [\[2311.16102\] Diffusion-TTA: Test-time Adaptation of Discriminative Models via Generative Feedback](https://arxiv.org/abs/2311.16102) (NIPS)
- [ ] [\[2311.16114\] Learning Noise-Robust Joint Representation for Multimodal Emotion Recognition under Incomplete Data Scenarios](https://arxiv.org/abs/2311.16114) (IA CAS, ACM Multimedia)
- [ ] [\[2311.16127\] SeamlessNeRF: Stitching Part NeRFs with Gradient Propagation](https://arxiv.org/abs/2311.16127) (CUHK, SIGGRAPH)
- [ ] [\[2311.16194\] BadCLIP: Trigger-Aware Prompt Learning for Backdoor Attacks on CLIP](https://arxiv.org/abs/2311.16194) (Tsinghua)
- [ ] [\[2311.16201\] Pre-trained Language Models Do Not Help Auto-regressive Text-to-Image Generation](https://arxiv.org/abs/2311.16201) (Stanford)
- [ ] [\[2311.16254\] Safe-CLIP: Removing NSFW Concepts from Vision-and-Language Models](https://arxiv.org/abs/2311.16254) (ECCV)
- [ ] [\[2311.16261\] RelVAE: Generative Pretraining for few-shot Visual Relationship Detection](https://arxiv.org/abs/2311.16261) (MPI)
- [ ] [\[2311.16344\] Spatially Adaptive Cloth Regression with Implicit Neural Representations](https://arxiv.org/abs/2311.16344) (ETH)
- [ ] [\[2311.16432\] Text-Driven Image Editing via Learnable Regions](https://arxiv.org/abs/2311.16432) (CVPR)
- [ ] [\[2311.16445\] CLAP: Isolating Content from Style through Contrastive Learning with Augmented Prompts](https://arxiv.org/abs/2311.16445) (ECCV)
- [ ] [\[2311.16462\] Viewport Prediction for Volumetric Video Streaming by Exploring Video Saliency and Trajectory Information](https://arxiv.org/abs/2311.16462) (USTC)
- [ ] [\[2311.16465\] TextDiffuser-2: Unleashing the Power of Language Models for Text Rendering](https://arxiv.org/abs/2311.16465) (HKUST)
- [ ] [\[2311.16474\] Progressive Classifier and Feature Extractor Adaptation for Unsupervised Domain Adaptation on Point Clouds](https://arxiv.org/abs/2311.16474) (ECCV)
- [ ] [\[2311.16477\] UniHPE: Towards Unified Human Pose Estimation via Contrastive Learning](https://arxiv.org/abs/2311.16477) (University of Copenhagen)
- [ ] [\[2311.16478\] RetouchUAA: Unconstrained Adversarial Attack via Image Retouching](https://arxiv.org/abs/2311.16478) (ZJU)
- [ ] [\[2311.16479\] Mitigating Hallucination in Visual Language Models with Visual Supervision](https://arxiv.org/abs/2311.16479) (IA CAS)
- [ ] [\[2311.16482\] Animatable 3D Gaussian: Fast and High-Quality Reconstruction of Multiple Human Avatars](https://arxiv.org/abs/2311.16482) (Tsinghua)
- [ ] [\[2311.16491\] $Z^*$: Zero-shot Style Transfer via Attention Rearrangement](https://arxiv.org/abs/2311.16491) (IA CAS)
- [ ] [\[2311.16494\] ArGue: Attribute-Guided Prompt Tuning for Vision-Language Models](https://arxiv.org/abs/2311.16494) (CVPR)
- [ ] [\[2311.16499\] InceptionHuman: Controllable Prompt-to-NeRF for Photorealistic 3D Human Generation](https://arxiv.org/abs/2311.16499) (HKUST)
- [ ] [\[2311.16500\] LLMGA: Multimodal Large Language Model based Generation Assistant](https://arxiv.org/abs/2311.16500) (ECCV)
- [ ] [\[2311.16501\] Context-Aware Indoor Point Cloud Object Generation through User Instructions](https://arxiv.org/abs/2311.16501) (USTC, ACMMM)
- [ ] [\[2311.16503\] TFMQ-DM: Temporal Feature Maintenance Quantization for Diffusion Models](https://arxiv.org/abs/2311.16503) (UT Austin)
- [ ] [\[2311.16510\] Source-Free Domain Adaptation with Frozen Multimodal Foundation Model](https://arxiv.org/abs/2311.16510) (CVPR)
- [ ] [\[2311.16512\] CoSeR: Bridging Image and Language for Cognitive Super-Resolution](https://arxiv.org/abs/2311.16512) (Tsinghua)
- [ ] [\[2311.16515\] Word4Per: Zero-shot Composed Person Retrieval](https://arxiv.org/abs/2311.16515) (BUPT)
- [ ] [\[2311.16516\] Segment Every Out-of-Distribution Object](https://arxiv.org/abs/2311.16516) (Harvard)
- [ ] [\[2311.16518\] SeeSR: Towards Semantics-Aware Real-World Image Super-Resolution](https://arxiv.org/abs/2311.16518) (PolyU, CVPR)
- [ ] [\[2311.16555\] Enhancing Scene Text Detectors with Realistic Text Image Synthesis Using Diffusion Models](https://arxiv.org/abs/2311.16555) (HUST)
- [ ] [\[2311.16565\] DiffusionTalker: Personalization and Acceleration for Speech-Driven 3D Face Diffuser](https://arxiv.org/abs/2311.16565) (UCAS)
- [ ] [\[2311.16567\] MobileDiffusion: Instant Text-to-Image Generation on Mobile Devices](https://arxiv.org/abs/2311.16567) (BU)
- [ ] [\[2311.16652\] Augmenting x-ray single particle imaging reconstruction with self-supervised machine learning](https://arxiv.org/abs/2311.16652) (Stanford)
- [ ] [\[2311.16657\] SCALAR-NeRF: SCAlable LARge-scale Neural Radiance Fields for Scene Reconstruction](https://arxiv.org/abs/2311.16657) (NUS)
- [ ] [\[2311.16668\] LiveNVS: Neural View Synthesis on Live RGB-D Streams](https://arxiv.org/abs/2311.16668) (SIGGRAPH)
- [ ] [\[2311.16711\] LEDITS++: Limitless Image Editing using Text-to-Image Models](https://arxiv.org/abs/2311.16711) (CVPR)
- [ ] [\[2311.16714\] Embodied Multi-Modal Agent trained by an LLM from a Parallel TextWorld](https://arxiv.org/abs/2311.16714) (CVPR)
- [ ] [\[2311.16728\] Photo-SLAM: Real-time Simultaneous Localization and Photorealistic Mapping for Monocular, Stereo, and RGB-D Cameras](https://arxiv.org/abs/2311.16728) (HKUST, CVPR)
- [ ] [\[2311.16754\] Towards Full-scene Domain Generalization in Multi-agent Collaborative Bird's Eye View Segmentation for Connected and Autonomous Driving](https://arxiv.org/abs/2311.16754) (HKU)
- [ ] [\[2311.16818\] DI-Net : Decomposed Implicit Garment Transfer Network for Digital Clothed 3D Human](https://arxiv.org/abs/2311.16818) (NTU)
- [ ] [\[2311.16843\] Self-training solutions for the ICCV 2023 GeoNet Challenge](https://arxiv.org/abs/2311.16843) (ICCV)
- [ ] [\[2311.16917\] UGG: Unified Generative Grasping](https://arxiv.org/abs/2311.16917) (UT Austin, ECCV)
- [ ] [\[2311.16922\] Mitigating Object Hallucinations in Large Vision-Language Models through Visual Contrastive Decoding](https://arxiv.org/abs/2311.16922) (Alibaba)
- [ ] [\[2311.16923\] Super-Resolution through StyleGAN Regularized Latent Search: A Realism-Fidelity Trade-off](https://arxiv.org/abs/2311.16923) (PSL University)
- [ ] [\[2311.16926\] LLaFS: When Large Language Models Meet Few-Shot Segmentation](https://arxiv.org/abs/2311.16926) (CVPR)
- [ ] [\[2311.16937\] The Sky's the Limit: Re-lightable Outdoor Scenes via a Sky-pixel Constrained Illumination Prior and Outside-In Visibility](https://arxiv.org/abs/2311.16937) (ECCV)
- [ ] [\[2311.16945\] UC-NeRF: Neural Radiance Field for Under-Calibrated Multi-view Cameras in Autonomous Driving](https://arxiv.org/abs/2311.16945) (USTC)
- [ ] [\[2311.16973\] DemoFusion: Democratising High-Resolution Image Generation With No $$$](https://arxiv.org/abs/2311.16973) (University of Edinburgh)
- [ ] [\[2311.17005\] MVBench: A Comprehensive Multi-modal Video Understanding Benchmark](https://arxiv.org/abs/2311.17005) (CVPR)
- [ ] [\[2311.17024\] Diffusion 3D Features (Diff3F): Decorating Untextured Shapes with Distilled Semantic Features](https://arxiv.org/abs/2311.17024) (CVPR)
- [ ] [\[2311.17034\] Telling Left from Right: Identifying Geometry-Aware Semantic Correspondence](https://arxiv.org/abs/2311.17034) (CVPR)
- [ ] [\[2311.17048\] Zero-shot Referring Expression Comprehension via Structural Similarity Between Images and Captions](https://arxiv.org/abs/2311.17048) (CVPR)
- [ ] [\[2311.17049\] MobileCLIP: Fast Image-Text Models through Multi-Modal Reinforced Training](https://arxiv.org/abs/2311.17049) (CVPR)
- [ ] [\[2311.17050\] Surf-D: Generating High-Quality Surfaces of Arbitrary Topologies Using Diffusion Models](https://arxiv.org/abs/2311.17050) (ECCV)
- [ ] [\[2311.17055\] No Representation Rules Them All in Category Discovery](https://arxiv.org/abs/2311.17055) (NIPS)
- [ ] [\[2311.17058\] Panoptic Video Scene Graph Generation](https://arxiv.org/abs/2311.17058) (CVPR)
- [ ] [\[2311.17061\] HumanGaussian: Text-Driven 3D Human Generation with Gaussian Splatting](https://arxiv.org/abs/2311.17061) (CVPR)
- [ ] [\[2311.17072\] IG Captioner: Information Gain Captioners are Strong Zero-shot Classifiers](https://arxiv.org/abs/2311.17072) (ECCV)
- [ ] [\[2311.17081\] I-MedSAM: Implicit Medical Image Segmentation with Segment Anything](https://arxiv.org/abs/2311.17081) (ECCV)
- [ ] [\[2311.17084\] DepthSSC: Depth-Spatial Alignment and Dynamic Voxel Resolution for Monocular 3D Semantic Scene Completion](https://arxiv.org/abs/2311.17084) (UW)
- [ ] [\[2311.17086\] PEA-Diffusion: Parameter-Efficient Adapter with Knowledge Distillation in non-English Text-to-Image Generation](https://arxiv.org/abs/2311.17086) (ECCV)
- [ ] [\[2311.17087\] Rethinking Mixup for Improving the Adversarial Transferability](https://arxiv.org/abs/2311.17087) (HUST)
- [ ] [\[2311.17089\] Multi-Scale 3D Gaussian Splatting for Anti-Aliased Rendering](https://arxiv.org/abs/2311.17089) (NUS, CVPR)
- [ ] [\[2311.17091\] Beyond Sole Strength: Customized Ensembles for Generalized Vision-Language Models](https://arxiv.org/abs/2311.17091) (NUS, ICML)
- [ ] [\[2311.17095\] Emergent Open-Vocabulary Semantic Segmentation from Off-the-shelf Vision-Language Models](https://arxiv.org/abs/2311.17095) (CVPR)
- [ ] [\[2311.17101\] A High-Quality Robust Diffusion Framework for Corrupted Dataset](https://arxiv.org/abs/2311.17101) (ECCV)
- [ ] [\[2311.17112\] Parameter Efficient Fine-tuning via Cross Block Orchestration for Segment Anything Model](https://arxiv.org/abs/2311.17112) (SJTU, CVPR)
- [ ] [\[2311.17113\] Human Gaussian Splatting: Real-time Rendering of Animatable Avatars](https://arxiv.org/abs/2311.17113) (CVPR)
- [ ] [\[2311.17118\] Towards Weakly Supervised End-to-end Learning for Long-video Action Recognition](https://arxiv.org/abs/2311.17118) (HKUST(GZ))
- [ ] [\[2311.17122\] Large Model Based Referring Camouflaged Object Detection](https://arxiv.org/abs/2311.17122) (Tsinghua)
- [ ] [\[2311.17132\] TransNeXt: Robust Foveal Visual Perception for Vision Transformers](https://arxiv.org/abs/2311.17132) (CVPR)
- [ ] [\[2311.17216\] Self-Discovering Interpretable Diffusion Latent Directions for Responsible Text-to-Image Generation](https://arxiv.org/abs/2311.17216) (CVPR)
- [ ] [\[2311.17241\] End-to-End Temporal Action Detection with 1B Parameters Across 1000 Frames](https://arxiv.org/abs/2311.17241) (CVPR)
- [ ] [\[2311.17267\] E-ViLM: Efficient Video-Language Model via Masked Video Modeling with Semantic Vector-Quantized Tokenizer](https://arxiv.org/abs/2311.17267) (Meta)
- [ ] [\[2311.17286\] LEOD: Label-Efficient Object Detection for Event Cameras](https://arxiv.org/abs/2311.17286) (CVPR)
- [ ] [\[2311.17315\] Explaining CLIP's performance disparities on data from blind/low vision users](https://arxiv.org/abs/2311.17315) (CVPR)
- [ ] [\[2311.17320\] Revisiting Single Image Reflection Removal In the Wild](https://arxiv.org/abs/2311.17320) (USTC)
- [ ] [\[2311.17325\] Alternate Diverse Teaching for Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2311.17325) (ECCV)
- [ ] [\[2311.17331\] Towards Top-Down Reasoning: An Explainable Multi-Agent Approach for Visual Question Answering](https://arxiv.org/abs/2311.17331) (SYSU)
- [ ] [\[2311.17332\] NeRFTAP: Enhancing Transferability of Adversarial Patches on Face Recognition using Neural Radiance Fields](https://arxiv.org/abs/2311.17332) (NJU)
- [ ] [\[2311.17335\] eMotions: A Large-Scale Dataset for Emotion Recognition in Short Videos](https://arxiv.org/abs/2311.17335) (XJTU)
- [ ] [\[2311.17339\] RADAP: A Robust and Adaptive Defense Against Diverse Adversarial Patches on Face Recognition](https://arxiv.org/abs/2311.17339) (NJU)
- [ ] [\[2311.17350\] Implicit-explicit Integrated Representations for Multi-view Video Compression](https://arxiv.org/abs/2311.17350) (SJTU)
- [ ] [\[2311.17365\] Symbol-LLM: Leverage Language Models for Symbolic System in Visual Human Activity Reasoning](https://arxiv.org/abs/2311.17365) (NIPS)
- [ ] [\[2311.17368\] Two Scalable Approaches for Burned-Area Mapping Using U-Net and Landsat Imagery](https://arxiv.org/abs/2311.17368) (Berkeley)
- [ ] [\[2311.17389\] 360Loc: A Dataset and Benchmark for Omnidirectional Visual Localization with Cross-device Queries](https://arxiv.org/abs/2311.17389) (SYSU, CVPR)
- [ ] [\[2311.17428\] SigFormer: Sparse Signal-Guided Transformer for Multi-Modal Human Action Segmentation](https://arxiv.org/abs/2311.17428) (USTC)
- [ ] [\[2311.17449\] Weakly-semi-supervised object detection in remotely sensed imagery](https://arxiv.org/abs/2311.17449) (NIPS)
- [ ] [\[2311.17450\] Continual Learning for Image Segmentation with Dynamic Query](https://arxiv.org/abs/2311.17450) (ZJU)
- [ ] [\[2311.17456\] DifFlow3D: Toward Robust Uncertainty-Aware Scene Flow Estimation with Diffusion Model](https://arxiv.org/abs/2311.17456) (CVPR)
- [ ] [\[2311.17460\] W-HMR: Monocular Human Mesh Recovery in World Space with Weak-Supervised Calibration](https://arxiv.org/abs/2311.17460) (Tsinghua)
- [ ] [\[2311.17461\] When StyleGAN Meets Stable Diffusion: a $\mathscr{W}_+$ Adapter for Personalized Image Generation](https://arxiv.org/abs/2311.17461) (NTU)
- [ ] [\[2311.17491\] Spherical Frustum Sparse Convolution Network for LiDAR Point Cloud Semantic Segmentation](https://arxiv.org/abs/2311.17491) (ETH)
- [ ] [\[2311.17493\] Towards Higher Ranks via Adversarial Weight Pruning](https://arxiv.org/abs/2311.17493) (Peking, NIPS)
- [ ] [\[2311.17510\] StructRe: Rewriting for Structured Shape Modeling](https://arxiv.org/abs/2311.17510) (Microsoft)
- [ ] [\[2311.17518\] The devil is in the fine-grained details: Evaluating open-vocabulary object detectors for fine-grained understanding](https://arxiv.org/abs/2311.17518) (CVPR)
- [ ] [\[2311.17524\] Improving Feature Stability during Upsampling -- Spectral Artifacts and the Importance of Spatial Context](https://arxiv.org/abs/2311.17524) (ECCV)
- [ ] [\[2311.17532\] Weakly-Supervised Emotion Transition Learning for Diverse 3D Co-speech Gesture Generation](https://arxiv.org/abs/2311.17532) (HKUST, CVPR)
- [ ] [\[2311.17536\] SmoothVideo: Smooth Video Synthesis with Noise Constraints on Diffusion Models for One-shot Video Tuning](https://arxiv.org/abs/2311.17536) (ZJU)
- [ ] [\[2311.17583\] CLIPC8: Face liveness detection algorithm based on image-text pairs and contrastive learning](https://arxiv.org/abs/2311.17583) (NJU)
- [ ] [\[2311.17590\] SyncTalk: The Devil is in the Synchronization for Talking Head Synthesis](https://arxiv.org/abs/2311.17590) (CVPR)
- [ ] [\[2311.17597\] Continual Self-supervised Learning: Towards Universal Multi-modal Medical Data Representation Learning](https://arxiv.org/abs/2311.17597) (NWPU)
- [ ] [\[2311.17607\] Topology-preserving Adversarial Training for Alleviating Natural Accuracy Degradation](https://arxiv.org/abs/2311.17607) (ICT CAS)
- [ ] [\[2311.17608\] Adversarial Robust Memory-Based Continual Learner](https://arxiv.org/abs/2311.17608) (Tsinghua)
- [ ] [\[2311.17626\] Focus on Query: Adversarial Mining Transformer for Few-Shot Segmentation](https://arxiv.org/abs/2311.17626) (USTC, NIPS)
- [ ] [\[2311.17634\] Erasing the Ephemeral: Joint Camera Refinement and Transient Object Removal for Street View Synthesis](https://arxiv.org/abs/2311.17634) (TUM)
- [ ] [\[2311.17643\] Neural Fields with Thermal Activations for Arbitrary-Scale Super-Resolution](https://arxiv.org/abs/2311.17643) (ETH)
- [ ] [\[2311.17657\] Volumetric Cloud Field Reconstruction](https://arxiv.org/abs/2311.17657) (Imperial)
- [ ] [\[2311.17663\] Cam4DOcc: Benchmark for Camera-Only 4D Occupancy Forecasting in Autonomous Driving Applications](https://arxiv.org/abs/2311.17663) (SJTU)
- [ ] [\[2311.17717\] Receler: Reliable Concept Erasing of Text-to-Image Diffusion Models via Lightweight Erasers](https://arxiv.org/abs/2311.17717) (NVIDIA, ECCV)
- [ ] [\[2311.17752\] BAND-2k: Banding Artifact Noticeable Database for Banding Detection and Quality Assessment](https://arxiv.org/abs/2311.17752) (Tianjin)
- [ ] [\[2311.17754\] Cinematic Behavior Transfer via NeRF-based Differentiable Filming](https://arxiv.org/abs/2311.17754) (Stanford)
- [ ] [\[2311.17810\] Coloring the Past: Neural Historical Buildings Reconstruction from Archival Photography](https://arxiv.org/abs/2311.17810) (TUM)
- [ ] [\[2311.17833\] DiG-IN: Diffusion Guidance for Investigating Networks -- Uncovering Classifier Differences Neuron Visualisations and Visual Counterfactual Explanations](https://arxiv.org/abs/2311.17833) (CVPR)
- [ ] [\[2311.17834\] Spice-E : Structural Priors in 3D Diffusion using Cross-Entity Attention](https://arxiv.org/abs/2311.17834) (SIGGRAPH)
- [ ] [\[2311.17851\] Leveraging VLM-Based Pipelines to Annotate 3D Objects](https://arxiv.org/abs/2311.17851) (Google)
- [ ] [\[2311.17891\] A Graph-Based Approach for Category-Agnostic Pose Estimation](https://arxiv.org/abs/2311.17891) (Tel Aviv)
- [ ] [\[2311.17893\] Betrayed by Attention: A Simple yet Effective Approach for Self-supervised Video Object Segmentation](https://arxiv.org/abs/2311.17893) (CUHK, ECCV)
- [ ] [\[2311.17901\] SODA: Bottleneck Diffusion Models for Representation Learning](https://arxiv.org/abs/2311.17901) (Google)
- [ ] [\[2311.17902\] Language-conditioned Detection Transformer](https://arxiv.org/abs/2311.17902) (UT Austin)
- [ ] [\[2311.17907\] CG3D: Compositional Generation for Text-to-3D via Gaussian Splatting](https://arxiv.org/abs/2311.17907) (UCLA)
- [ ] [\[2311.17911\] OPERA: Alleviating Hallucination in Multi-Modal Large Language Models via Over-Trust Penalty and Retrospection-Allocation](https://arxiv.org/abs/2311.17911) (CVPR)
- [ ] [\[2311.17919\] Visual Anagrams: Generating Multi-View Optical Illusions with Diffusion Models](https://arxiv.org/abs/2311.17919) (CVPR)
- [ ] [\[2311.17922\] A Simple Recipe for Language-guided Domain Generalized Segmentation](https://arxiv.org/abs/2311.17922) (CVPR)
- [ ] [\[2311.17940\] Scene Summarization: Clustering Scene Videos into Spatially Diverse Frames](https://arxiv.org/abs/2311.17940) (NYU)
- [ ] [\[2311.17948\] Action-slot: Visual Action-centric Representations for Multi-label Atomic Activity Recognition in Traffic Scenes](https://arxiv.org/abs/2311.17948) (Google)
- [ ] [\[2311.17950\] Generalized Large-Scale Data Condensation via Various Backbone and Statistical Matching](https://arxiv.org/abs/2311.17950) (CVPR)
- [ ] [\[2311.17955\] PEAN: A Diffusion-Based Prior-Enhanced Attention Network for Scene Text Image Super-Resolution](https://arxiv.org/abs/2311.17955) (ACMMM)
- [ ] [\[2311.17957\] HandRefiner: Refining Malformed Hands in Generated Images by Diffusion-based Conditional Inpainting](https://arxiv.org/abs/2311.17957) (USyd)
- [ ] [\[2311.17963\] M$^{2}$Chat: Empowering VLM for Multimodal LLM Interleaved Text-Image Generation](https://arxiv.org/abs/2311.17963) (HKUST)
- [ ] [\[2311.17975\] GeoDeformer: Geometric Deformable Transformer for Action Recognition](https://arxiv.org/abs/2311.17975) (HKUST)
- [ ] [\[2311.17983\] Improving Interpretation Faithfulness for Vision Transformers](https://arxiv.org/abs/2311.17983) (ICML)
- [ ] [\[2311.17984\] 4D-fy: Text-to-4D Generation Using Hybrid Score Distillation Sampling](https://arxiv.org/abs/2311.17984) (CVPR)
- [ ] [\[2311.18021\] Understanding and Improving In-Context Learning on Vision-language Models](https://arxiv.org/abs/2311.18021) (Oxford)
- [ ] [\[2311.18064\] GELDA: A generative language annotation framework to reveal visual biases in datasets](https://arxiv.org/abs/2311.18064) (MIT)
- [ ] [\[2311.18071\] Turn Down the Noise: Leveraging Diffusion Models for Test-time Adaptation via Pseudo-label Ensembling](https://arxiv.org/abs/2311.18071) (CMU)
- [ ] [\[2311.18113\] Back to 3D: Few-Shot 3D Keypoint Detection with Back-Projected 2D Features](https://arxiv.org/abs/2311.18113) (TUM, CVPR)
- [ ] [\[2311.18158\] HiPA: Enabling One-Step Text-to-Image Diffusion Models via High-Frequency-Promoting Adaptation](https://arxiv.org/abs/2311.18158) (NUS)
- [ ] [\[2311.18166\] A-Scan2BIM: Assistive Scan to Building Information Modeling](https://arxiv.org/abs/2311.18166) (Google)
- [ ] [\[2311.18169\] Few-shot Image Generation via Style Adaptation and Content Preservation](https://arxiv.org/abs/2311.18169) (NTU)
- [ ] [\[2311.18193\] Persistent Test-time Adaptation in Episodic Testing Scenarios](https://arxiv.org/abs/2311.18193) (University of Tokyo)
- [ ] [\[2311.18198\] S-T CRF: Spatial-Temporal Conditional Random Field for Human Trajectory Prediction](https://arxiv.org/abs/2311.18198) (Chongqing)
- [ ] [\[2311.18231\] TCP:Textual-based Class-aware Prompt tuning for Visual-Language Model](https://arxiv.org/abs/2311.18231) (IA CAS, CVPR)
- [ ] [\[2311.18237\] Knowledge Transfer from Vision Foundation Models for Efficient Training of Small Task-specific Models](https://arxiv.org/abs/2311.18237) (International Conference on Machine Learning)
- [ ] [\[2311.18254\] Sketch Input Method Editor: A Comprehensive Dataset and Methodology for Systematic Input Recognition](https://arxiv.org/abs/2311.18254) (Xidian, ACM Multimedia)
- [ ] [\[2311.18286\] SimulFlow: Simultaneously Extracting Feature and Identifying Target for Unsupervised Video Object Segmentation](https://arxiv.org/abs/2311.18286) (ACMMM)
- [ ] [\[2311.18296\] Perceptual Group Tokenizer: Building Perception with Iterative Grouping](https://arxiv.org/abs/2311.18296) (ICLR)
- [ ] [\[2311.18328\] Advances in 3D Neural Stylization: A Survey](https://arxiv.org/abs/2311.18328) (HKUST)
- [ ] [\[2311.18331\] MRFP: Learning Generalizable Semantic Segmentation from Sim-2-Real with Multi-Resolution Feature Perturbation](https://arxiv.org/abs/2311.18331) (CVPR)
- [ ] [\[2311.18361\] Automating lookahead planning using site appearance and space utilization](https://arxiv.org/abs/2311.18361) (NYU)
- [ ] [\[2311.18363\] Each Test Image Deserves A Specific Prompt: Continual Test-Time Adaptation for 2D Medical Image Segmentation](https://arxiv.org/abs/2311.18363) (NWPU)
- [ ] [\[2311.18405\] CAT-DM: Controllable Accelerated Virtual Try-on with Diffusion Model](https://arxiv.org/abs/2311.18405) (Tianjin)
- [ ] [\[2311.18420\] TeG-DG: Textually Guided Domain Generalization for Face Anti-Spoofing](https://arxiv.org/abs/2311.18420) (ZJU)
- [ ] [\[2311.18433\] E2PNet: Event to Point Cloud Registration with Spatio-Temporal Representation Learning](https://arxiv.org/abs/2311.18433) (NIPS)
- [ ] [\[2311.18531\] Dataset Distillation via the Wasserstein Metric](https://arxiv.org/abs/2311.18531) (JHU)
- [ ] [\[2311.18537\] A Simple Video Segmenter by Tracking Objects Along Axial Trajectories](https://arxiv.org/abs/2311.18537) (JHU)
- [ ] [\[2311.18561\] Periodic Vibration Gaussian: Dynamic Urban Scene Reconstruction and Real-time Rendering](https://arxiv.org/abs/2311.18561) (Fudan)
- [ ] [\[2311.18572\] Overcoming Label Noise for Source-free Unsupervised Video Domain Adaptation](https://arxiv.org/abs/2311.18572) (Inria)
- [ ] [\[2311.18576\] Fixed-length Dense Descriptor for Efficient Fingerprint Matching](https://arxiv.org/abs/2311.18576) (Tsinghua)
- [ ] [\[2311.18605\] Learning Triangular Distribution in Visual World](https://arxiv.org/abs/2311.18605) (CVPR)
- [ ] [\[2311.18608\] Contrastive Denoising Score for Text-guided Latent Diffusion Image Editing](https://arxiv.org/abs/2311.18608) (CVPR)
- [ ] [\[2311.18610\] DiffCAD: Weakly-Supervised Probabilistic CAD Model Retrieval and Alignment from an RGB Image](https://arxiv.org/abs/2311.18610) (TUM, SIGGRAPH)
- [ ] [\[2311.18649\] Simple Semantic-Aided Few-Shot Learning](https://arxiv.org/abs/2311.18649) (Alibaba, CVPR)
- [ ] [\[2311.18729\] Portrait4D: Learning One-Shot 4D Head Avatar Synthesis using Synthetic Data](https://arxiv.org/abs/2311.18729) (CVPR)
- [ ] [\[2311.18763\] Continual Diffusion with STAMINA: STack-And-Mask INcremental Adapters](https://arxiv.org/abs/2311.18763) (CVPR)
- [ ] [\[2311.18775\] CoDi-2: In-Context, Interleaved, and Interactive Any-to-Any Generation](https://arxiv.org/abs/2311.18775) (Microsoft)
- [ ] [\[2311.18803\] BioCLIP: A Vision Foundation Model for the Tree of Life](https://arxiv.org/abs/2311.18803) (CVPR)
- [ ] [\[2311.18814\] Is Underwater Image Enhancement All Object Detectors Need?](https://arxiv.org/abs/2311.18814) (Tianjin)
- [ ] [\[2311.18822\] ElasticDiffusion: Training-free Arbitrary Size Image Generation through Global-Local Content Separation](https://arxiv.org/abs/2311.18822) (CVPR)
- [ ] [\[2311.18825\] CAST: Cross-Attention in Space and Time for Video Action Recognition](https://arxiv.org/abs/2311.18825) (NIPS)
- [ ] [\[2311.18832\] Exploiting Diffusion Prior for Generalizable Dense Prediction](https://arxiv.org/abs/2311.18832) (CVPR)
- [ ] [\[2311.18835\] InstructSeq: Unifying Vision Tasks with Instruction-conditioned Multi-modal Sequence Generation](https://arxiv.org/abs/2311.18835) (CUHK)
- [ ] [\[2312.00055\] LEAP: LLM-Generation of Egocentric Action Programs](https://arxiv.org/abs/2312.00055) (UMD)
- [ ] [\[2312.00081\] Synthesize, Diagnose, and Optimize: Towards Fine-Grained Vision-Language Understanding](https://arxiv.org/abs/2312.00081) (CVPR)
- [ ] [\[2312.00083\] BAM-DETR: Boundary-Aligned Moment Detection Transformer for Temporal Sentence Grounding in Videos](https://arxiv.org/abs/2312.00083) (ECCV)
- [ ] [\[2312.00084\] Can Protective Perturbation Safeguard Personal Data from Being Exploited by Stable Diffusion?](https://arxiv.org/abs/2312.00084) (UCAS)
- [ ] [\[2312.00085\] X-Dreamer: Creating High-quality 3D Content by Bridging the Domain Gap Between Text-to-2D and Text-to-3D Generation](https://arxiv.org/abs/2312.00085) (Xiamen)
- [ ] [\[2312.00093\] GraphDreamer: Compositional 3D Scene Synthesis from Scene Graphs](https://arxiv.org/abs/2312.00093) (CVPR)
- [ ] [\[2312.00094\] Fast ODE-based Sampling for Diffusion Models in Around 5 Steps](https://arxiv.org/abs/2312.00094) (CVPR)
- [ ] [\[2312.00097\] SparseDC: Depth Completion from sparse and non-uniform inputs](https://arxiv.org/abs/2312.00097) (HKU)
- [ ] [\[2312.00151\] Which way is `right'?: Uncovering limitations of Vision-and-Language Navigation model](https://arxiv.org/abs/2312.00151) (Google)
- [ ] [\[2312.00206\] SparseGS: Real-Time 360{\deg} Sparse View Synthesis using Gaussian Splatting](https://arxiv.org/abs/2312.00206) (UCLA, TIP)
- [ ] [\[2312.00236\] Brainformer: Mimic Human Visual Brain Functions to Machine Vision Models via fMRI](https://arxiv.org/abs/2312.00236) (MIT)
- [ ] [\[2312.00252\] PyNeRF: Pyramidal Neural Radiance Fields](https://arxiv.org/abs/2312.00252) (CMU, NIPS)
- [ ] [\[2312.00269\] Adaptability of Computer Vision at the Tactical Edge: Addressing Environmental Uncertainty](https://arxiv.org/abs/2312.00269) (CMU)
- [ ] [\[2312.00311\] 3D Face Reconstruction with the Geometric Guidance of Facial Part Segmentation](https://arxiv.org/abs/2312.00311) (CVPR)
- [ ] [\[2312.00330\] StyleCrafter: Enhancing Stylized Text-to-Video Generation with Style Adapter](https://arxiv.org/abs/2312.00330) (Tsinghua, SIGGRAPH)
- [ ] [\[2312.00335\] Learning Anatomically Consistent Embedding for Chest Radiography](https://arxiv.org/abs/2312.00335) (SJTU)
- [ ] [\[2312.00343\] OpenStereo: A Comprehensive Benchmark for Stereo Matching and Strong Baseline](https://arxiv.org/abs/2312.00343) (IA CAS)
- [ ] [\[2312.00347\] RTQ: Rethinking Video-language Understanding Based on Image-text Model](https://arxiv.org/abs/2312.00347) (ACMMM)
- [ ] [\[2312.00362\] Dancing with Still Images: Video Distillation via Static-Dynamic Disentanglement](https://arxiv.org/abs/2312.00362) (CVPR)
- [ ] [\[2312.00412\] SCHEME: Scalable Channel Mixer for Vision Transformers](https://arxiv.org/abs/2312.00412) (UCSD)
- [ ] [\[2312.00589\] Merlin:Empowering Multimodal LLMs with Foresight Minds](https://arxiv.org/abs/2312.00589) (ECCV)
- [ ] [\[2312.00596\] BCN: Batch Channel Normalization for Image Classification](https://arxiv.org/abs/2312.00596) (Tianjin)
- [ ] [\[2312.00598\] Learning from One Continuous Video Stream](https://arxiv.org/abs/2312.00598) (Google, CVPR)
- [ ] [\[2312.00633\] Towards Efficient 3D Object Detection in Bird's-Eye-View Space for Autonomous Driving: A Convolutional-Only Approach](https://arxiv.org/abs/2312.00633) (NTU)
- [ ] [\[2312.00648\] SPOT: Self-Training with Patch-Order Permutation for Object-Centric Learning with Autoregressive Transformers](https://arxiv.org/abs/2312.00648) (CVPR)
- [ ] [\[2312.00663\] Generalized Label-Efficient 3D Scene Parsing via Hierarchical Feature Aligned Pre-Training and Region-Aware Fine-tuning](https://arxiv.org/abs/2312.00663) (Transactions on Pattern Analysis and Machine Intelligence)
- [ ] [\[2312.00671\] CellMixer: Annotation-free Semantic Cell Segmentation of Heterogeneous Cell Populations](https://arxiv.org/abs/2312.00671) (NIPS)
- [ ] [\[2312.00690\] Open-vocabulary object 6D pose estimation](https://arxiv.org/abs/2312.00690) (QMUL, CVPR)
- [ ] [\[2312.00692\] VisionaryVR: An Optical Simulation Tool for Evaluating and Optimizing Vision Correction Solutions in Virtual Reality](https://arxiv.org/abs/2312.00692) (University of Tübingen)
- [ ] [\[2312.00732\] Gaussian Grouping: Segment and Edit Anything in 3D Scenes](https://arxiv.org/abs/2312.00732) (ECCV)
- [ ] [\[2312.00739\] Adversarial Score Distillation: When score distillation meets GAN](https://arxiv.org/abs/2312.00739) (CVPR)
- [ ] [\[2312.00778\] MorpheuS: Neural Dynamic 360{\deg} Surface Reconstruction from Monocular RGB-D Video](https://arxiv.org/abs/2312.00778) (CVPR)
- [ ] [\[2312.00784\] ViP-LLaVA: Making Large Multimodal Models Understand Arbitrary Visual Prompts](https://arxiv.org/abs/2312.00784) (CVPR)
- [ ] [\[2312.00786\] Dense Optical Tracking: Connecting the Dots](https://arxiv.org/abs/2312.00786) (Inria, CVPR)
- [ ] [\[2312.00794\] Informative Priors Improve the Reliability of Multimodal Clinical Data Classification](https://arxiv.org/abs/2312.00794) (NYU)
- [ ] [\[2312.00825\] SocialCounterfactuals: Probing and Mitigating Intersectional Social Biases in Vision-Language Models with Counterfactual Examples](https://arxiv.org/abs/2312.00825) (CVPR)
- [ ] [\[2312.00826\] DEVIAS: Learning Disentangled Video Representations of Action and Scene](https://arxiv.org/abs/2312.00826) (KAIST, ECCV)
- [ ] [\[2312.00833\] Lasagna: Layered Score Distillation for Disentangled Object Relighting](https://arxiv.org/abs/2312.00833) (BU)
- [ ] [\[2312.00844\] Sparse Beats Dense: Rethinking Supervision in Radar-Camera Depth Completion](https://arxiv.org/abs/2312.00844) (ECCV)
- [ ] [\[2312.00853\] Motion-Guided Latent Diffusion for Temporally Consistent Real-world Video Super-resolution](https://arxiv.org/abs/2312.00853) (PolyU)
- [ ] [\[2312.00858\] DeepCache: Accelerating Diffusion Models for Free](https://arxiv.org/abs/2312.00858) (NUS)
- [ ] [\[2312.00860\] Segment Any 3D Gaussians](https://arxiv.org/abs/2312.00860) (SJTU)
- [ ] [\[2312.00869\] Segment and Caption Anything](https://arxiv.org/abs/2312.00869) (CVPR)
- [ ] [\[2312.00937\] Zero-Shot Video Question Answering with Procedural Programs](https://arxiv.org/abs/2312.00937) (CMU)
- [ ] [\[2312.00944\] Enhancing Diffusion Models with 3D Perspective Geometry Constraints](https://arxiv.org/abs/2312.00944) (UCLA)
- [ ] [\[2312.00950\] Improve Supervised Representation Learning with Masked Image Modeling](https://arxiv.org/abs/2312.00950) (Google)
- [ ] [\[2312.01026\] Token Fusion: Bridging the Gap between Token Pruning and Token Merging](https://arxiv.org/abs/2312.01026) (Michigan State University)
- [ ] [\[2312.01068\] DPHMs: Diffusion Parametric Head Models for Depth-based Tracking](https://arxiv.org/abs/2312.01068) (CVPR)
- [ ] [\[2312.01083\] Consistency Prototype Module and Motion Compensation for Few-Shot Action Recognition (CLIP-CP$\mathbf{M^2}$C)](https://arxiv.org/abs/2312.01083) (XJTU)
- [ ] [\[2312.01099\] Rethinking Multiple Instance Learning for Whole Slide Image Classification: A Bag-Level Classifier is a Good Instance-Level Teacher](https://arxiv.org/abs/2312.01099) (ZJU)
- [ ] [\[2312.01105\] S2P3: Self-Supervised Polarimetric Pose Prediction](https://arxiv.org/abs/2312.01105) (TUM)
- [ ] [\[2312.01163\] A New Learning Paradigm for Foundation Model-based Remote Sensing Change Detection](https://arxiv.org/abs/2312.01163) (XJTU)
- [ ] [\[2312.01196\] Neural Parametric Gaussians for Monocular Non-Rigid Object Reconstruction](https://arxiv.org/abs/2312.01196) (CVPR)
- [ ] [\[2312.01215\] RNb-NeuS: Reflectance and Normal-based Multi-View 3D Reconstruction](https://arxiv.org/abs/2312.01215) (University of Copenhagen, CVPR)
- [ ] [\[2312.01220\] Boosting Object Detection with Zero-Shot Day-Night Domain Adaptation](https://arxiv.org/abs/2312.01220) (Tongji, CVPR)
- [ ] [\[2312.01255\] Meta ControlNet: Enhancing Task Adaptation via Meta Learning](https://arxiv.org/abs/2312.01255) (UT Austin)
- [ ] [\[2312.01261\] TIBET: Identifying and Evaluating Biases in Text-to-Image Generative Models](https://arxiv.org/abs/2312.01261) (ECCV)
- [ ] [\[2312.01274\] Learning to Compose SuperWeights for Neural Parameter Allocation Search](https://arxiv.org/abs/2312.01274) (BU)
- [ ] [\[2312.01283\] Deeper into Self-Supervised Monocular Indoor Depth Estimation](https://arxiv.org/abs/2312.01283) (UCAS)
- [ ] [\[2312.01324\] MABViT -- Modified Attention Block Enhances Vision Transformers](https://arxiv.org/abs/2312.01324) (NVIDIA)
- [ ] [\[2312.01361\] MoEC: Mixture of Experts Implicit Neural Compression](https://arxiv.org/abs/2312.01361) (Peking)
- [ ] [\[2312.01397\] Visual Prompting Upgrades Neural Network Sparsification: A Data-Model Perspective](https://arxiv.org/abs/2312.01397) (USTC)
- [ ] [\[2312.01407\] VideoRF: Rendering Dynamic Radiance Fields as 2D Feature Video Streams](https://arxiv.org/abs/2312.01407) (KU Leuven)
- [ ] [\[2312.01408\] Improving In-Context Learning in Diffusion Models with Visual Context-Modulated Prompts](https://arxiv.org/abs/2312.01408) (UT Austin)
- [ ] [\[2312.01431\] D$^2$ST-Adapter: Disentangled-and-Deformable Spatio-Temporal Adapter for Few-shot Action Recognition](https://arxiv.org/abs/2312.01431) (HIT)
- [ ] [\[2312.01504\] Effectively Fine-tune to Improve Large Multimodal Models for Radiology Report Generation](https://arxiv.org/abs/2312.01504) (CMU)
- [ ] [\[2312.01531\] SANeRF-HQ: Segment Anything for NeRF in High Quality](https://arxiv.org/abs/2312.01531) (CVPR)
- [ ] [\[2312.01561\] Multi-View Person Matching and 3D Pose Estimation with Arbitrary Uncalibrated Camera Networks](https://arxiv.org/abs/2312.01561) (CMU)
- [ ] [\[2312.01576\] Learning Efficient Unsupervised Satellite Image-based Building Damage Detection](https://arxiv.org/abs/2312.01576) (Queensland)
- [ ] [\[2312.01597\] SCLIP: Rethinking Self-Attention for Dense Vision-Language Inference](https://arxiv.org/abs/2312.01597) (JHU)
- [ ] [\[2312.01616\] SchurVINS: Schur Complement-Based Lightweight Visual Inertial Navigation System](https://arxiv.org/abs/2312.01616) (CVPR)
- [ ] [\[2312.01623\] Universal Segmentation at Arbitrary Granularity with Language Instruction](https://arxiv.org/abs/2312.01623) (Tsinghua)
- [ ] [\[2312.01629\] CLAMP: Contrastive LAnguage Model Prompt-tuning](https://arxiv.org/abs/2312.01629) (BU)
- [ ] [\[2312.01663\] Customize your NeRF: Adaptive Source Driven 3D Scene Editing via Local-Global Iterative Training](https://arxiv.org/abs/2312.01663) (SYSU)
- [ ] [\[2312.01671\] Multimodality-guided Image Style Transfer using Cross-modal GAN Inversion](https://arxiv.org/abs/2312.01671) (UMD)
- [ ] [\[2312.01682\] ResEnsemble-DDPM: Residual Denoising Diffusion Probabilistic Models for Ensemble Learning](https://arxiv.org/abs/2312.01682) (Nankai)
- [ ] [\[2312.01711\] Regressor-Segmenter Mutual Prompt Learning for Crowd Counting](https://arxiv.org/abs/2312.01711) (UCAS)
- [ ] [\[2312.01713\] Disentangled Interaction Representation for One-Stage Human-Object Interaction Detection](https://arxiv.org/abs/2312.01713) (USyd)
- [ ] [\[2312.01745\] Cross-Modal Adaptive Dual Association for Text-to-Image Person Retrieval](https://arxiv.org/abs/2312.01745) (SYSU)
- [ ] [\[2312.01746\] Open-DDVM: A Reproduction and Extension of Diffusion Model for Optical Flow Estimation](https://arxiv.org/abs/2312.01746) (Fudan)
- [ ] [\[2312.01758\] CILF-CIAE: CLIP-driven Image-Language Fusion for Correcting Inverse Age Estimation](https://arxiv.org/abs/2312.01758) (XJTU)
- [ ] [\[2312.01764\] Dynamic Erasing Network Based on Multi-Scale Temporal Features for Weakly Supervised Video Anomaly Detection](https://arxiv.org/abs/2312.01764) (UCAS)
- [ ] [\[2312.01850\] Generalization by Adaptation: Diffusion-Based Domain Extension for Domain-Generalized Semantic Segmentation](https://arxiv.org/abs/2312.01850) (DLR)
- [ ] [\[2312.01871\] FeaInfNet: Diagnosis in Medical Image with Feature-Driven Inference and Visual Explanations](https://arxiv.org/abs/2312.01871) (Fudan)
- [ ] [\[2312.01897\] Adapting Short-Term Transformers for Action Detection in Untrimmed Videos](https://arxiv.org/abs/2312.01897) (NJU, CVPR)
- [ ] [\[2312.01915\] A Reliable Representation with Bidirectional Transition Model for Visual Reinforcement Learning Generalization](https://arxiv.org/abs/2312.01915) (ZJU)
- [ ] [\[2312.01919\] COTR: Compact Occupancy TRansformer for Vision-based 3D Occupancy Prediction](https://arxiv.org/abs/2312.01919) (SJTU, CVPR)
- [ ] [\[2312.01964\] Semantics-aware Motion Retargeting with Vision-Language Models](https://arxiv.org/abs/2312.01964) (ZJU, CVPR)
- [ ] [\[2312.01987\] Bootstrapping SparseFormers from Vision Foundation Models](https://arxiv.org/abs/2312.01987) (CVPR)
- [ ] [\[2312.01998\] Language-only Efficient Training of Zero-shot Composed Image Retrieval](https://arxiv.org/abs/2312.01998) (CVPR)
- [ ] [\[2312.02010\] Towards Learning a Generalist Model for Embodied Navigation](https://arxiv.org/abs/2312.02010) (CVPR)
- [ ] [\[2312.02051\] TimeChat: A Time-sensitive Multimodal Large Language Model for Long Video Understanding](https://arxiv.org/abs/2312.02051) (CVPR)
- [ ] [\[2312.02103\] Learning Pseudo-Labeler beyond Noun Concepts for Open-Vocabulary Object Detection](https://arxiv.org/abs/2312.02103) (KAIST)
- [ ] [\[2312.02116\] GIVT: Generative Infinite-Vocabulary Transformers](https://arxiv.org/abs/2312.02116) (ECCV)
- [ ] [\[2312.02126\] SplaTAM: Splat, Track & Map 3D Gaussians for Dense RGB-D SLAM](https://arxiv.org/abs/2312.02126) (CVPR)
- [ ] [\[2312.02134\] GaussianAvatar: Towards Realistic Human Avatar Modeling from a Single Video via Animatable 3D Gaussians](https://arxiv.org/abs/2312.02134) (Tsinghua)
- [ ] [\[2312.02135\] Fast View Synthesis of Casual Videos with Soup-of-Planes](https://arxiv.org/abs/2312.02135) (ECCV)
- [ ] [\[2312.02137\] MANUS: Markerless Grasp Capture using Articulated 3D Gaussians](https://arxiv.org/abs/2312.02137) (CVPR)
- [ ] [\[2312.02139\] DiffiT: Diffusion Vision Transformers for Image Generation](https://arxiv.org/abs/2312.02139) (ECCV)
- [ ] [\[2312.02141\] iMatching: Imperative Correspondence Learning](https://arxiv.org/abs/2312.02141) (MIT, ECCV)
- [ ] [\[2312.02142\] Object Recognition as Next Token Prediction](https://arxiv.org/abs/2312.02142) (UMD, CVPR)
- [ ] [\[2312.02145\] Repurposing Diffusion-Based Image Generators for Monocular Depth Estimation](https://arxiv.org/abs/2312.02145) (CVPR)
- [ ] [\[2312.02147\] Rejuvenating image-GPT as Strong Visual Representation Learners](https://arxiv.org/abs/2312.02147) (ICML)
- [ ] [\[2312.02150\] Readout Guidance: Learning Control from Diffusion Features](https://arxiv.org/abs/2312.02150) (CVPR)
- [ ] [\[2312.02152\] Steerers: A framework for rotation equivariant keypoint descriptors](https://arxiv.org/abs/2312.02152) (CVPR)
- [ ] [\[2312.02153\] Aligning and Prompting Everything All at Once for Universal Visual Perception](https://arxiv.org/abs/2312.02153) (Xiamen)
- [ ] [\[2312.02155\] GPS-Gaussian: Generalizable Pixel-wise 3D Gaussian Splatting for Real-time Human Novel View Synthesis](https://arxiv.org/abs/2312.02155) (Tsinghua, CVPR)
- [ ] [\[2312.02158\] PaSCo: Urban 3D Panoptic Scene Completion with Uncertainty Awareness](https://arxiv.org/abs/2312.02158) (CVPR)
- [ ] [\[2312.02167\] Uncertainty Quantification in Machine Learning Based Segmentation: A Post-Hoc Approach for Left Ventricle Volume Estimation in MRI](https://arxiv.org/abs/2312.02167) (DLR)
- [ ] [\[2312.02188\] Video Summarization: Towards Entity-Aware Captions](https://arxiv.org/abs/2312.02188) (Columbia University)
- [ ] [\[2312.02190\] Diffusion Handles: Enabling 3D Edits for Diffusion Models by Lifting Activations to 3D](https://arxiv.org/abs/2312.02190) (University of Toronto)
- [ ] [\[2312.02192\] DiverseDream: Diverse Text-to-3D Synthesis with Augmented Text Embedding](https://arxiv.org/abs/2312.02192) (ECCV)
- [ ] [\[2312.02196\] Dynamic Inertial Poser (DynaIP): Part-Based Motion Dynamics Learning for Enhanced Human Pose Estimation with Sparse Inertial Sensors](https://arxiv.org/abs/2312.02196) (CVPR)
- [ ] [\[2312.02205\] Disentangling the Effects of Data Augmentation and Format Transform in Self-Supervised Learning of Image Representations](https://arxiv.org/abs/2312.02205) (UMD)
- [ ] [\[2312.02207\] TranSegPGD: Improving Transferability of Adversarial Examples on Semantic Segmentation](https://arxiv.org/abs/2312.02207) (NTU)
- [ ] [\[2312.02208\] A Data-efficient Framework for Robotics Large-scale LiDAR Scene Parsing](https://arxiv.org/abs/2312.02208) (CUHK)
- [ ] [\[2312.02209\] AttriHuman-3D: Editable 3D Human Avatar Generation with Attribute Decomposition and Indexing](https://arxiv.org/abs/2312.02209) (NTU, CVPR)
- [ ] [\[2312.02212\] Portrait Diffusion: Training-free Face Stylization with Chain-of-Painting](https://arxiv.org/abs/2312.02212) (ShanghaiTech)
- [ ] [\[2312.02226\] Generating Action-conditioned Prompts for Open-vocabulary Video Action Recognition](https://arxiv.org/abs/2312.02226) (XJTU)
- [ ] [\[2312.02228\] PixelLM: Pixel Reasoning with Large Multimodal Model](https://arxiv.org/abs/2312.02228) (CVPR)
- [ ] [\[2312.02237\] Singular Regularization with Information Bottleneck Improves Model's Adversarial Robustness](https://arxiv.org/abs/2312.02237) (NTU)
- [ ] [\[2312.02244\] Geometrically-driven Aggregation for Zero-shot 3D Point Cloud Understanding](https://arxiv.org/abs/2312.02244) (CVPR)
- [ ] [\[2312.02255\] Re-Nerfing: Improving Novel View Synthesis through Novel View Synthesis](https://arxiv.org/abs/2312.02255) (TUM)
- [ ] [\[2312.02338\] A Contrastive Compositional Benchmark for Text-to-Image Synthesis: A Study with Unified Text-to-Image Fidelity Metrics](https://arxiv.org/abs/2312.02338) (HKUST(GZ))
- [ ] [\[2312.02428\] FreestyleRet: Retrieving Images from Style-Diversified Queries](https://arxiv.org/abs/2312.02428) (Tsinghua)
- [ ] [\[2312.02434\] FINER: Flexible spectral-bias tuning in Implicit NEural Representation by Variable-periodic Activation Functions](https://arxiv.org/abs/2312.02434) (NJU)
- [ ] [\[2312.02437\] GDN: A Stacking Network Used for Skin Cancer Diagnosis](https://arxiv.org/abs/2312.02437) (HUST)
- [ ] [\[2312.02481\] Learning to Holistically Detect Bridges from Large-Size VHR Remote Sensing Imagery](https://arxiv.org/abs/2312.02481) (WHU)
- [ ] [\[2312.02512\] AV2AV: Direct Audio-Visual Speech to Audio-Visual Speech Translation with Unified Audio-Visual Speech Representation](https://arxiv.org/abs/2312.02512) (CVPR)
- [ ] [\[2312.02520\] Towards More Unified In-context Visual Understanding](https://arxiv.org/abs/2312.02520) (CVPR)
- [ ] [\[2312.02528\] Towards Automatic Power Battery Detection: New Challenge, Benchmark Dataset and Baseline](https://arxiv.org/abs/2312.02528) (CVPR)
- [ ] [\[2312.02535\] Towards Open-set Gesture Recognition via Feature Activation Enhancement and Orthogonal Prototype Learning](https://arxiv.org/abs/2312.02535) (SJTU)
- [ ] [\[2312.02545\] Graph Information Bottleneck for Remote Sensing Segmentation](https://arxiv.org/abs/2312.02545) (XJTU)
- [ ] [\[2312.02546\] Machine Vision Therapy: Multimodal Large Language Models Can Enhance Visual Robustness via Denoising In-Context Learning](https://arxiv.org/abs/2312.02546) (USyd, ICML)
- [ ] [\[2312.02549\] DemaFormer: Damped Exponential Moving Average Transformer with Energy-Based Modeling for Temporal Language Grounding](https://arxiv.org/abs/2312.02549) (NTU)
- [ ] [\[2312.02567\] Think Twice Before Selection: Federated Evidential Active Learning for Medical Image Analysis with Domain Shifts](https://arxiv.org/abs/2312.02567) (NWPU, CVPR)
- [ ] [\[2312.02568\] Prompt2NeRF-PIL: Fast NeRF Generation via Pretrained Implicit Latent](https://arxiv.org/abs/2312.02568) (HKUST)
- [ ] [\[2312.02625\] Diffusion Noise Feature: Accurate and Fast Generated Image Detection](https://arxiv.org/abs/2312.02625) (ZJU)
- [ ] [\[2312.02647\] TPA3D: Triplane Attention for Fast Text-to-3D Generation](https://arxiv.org/abs/2312.02647) (NVIDIA, ECCV)
- [ ] [\[2312.02700\] Revisit Human-Scene Interaction via Space Occupancy](https://arxiv.org/abs/2312.02700) (HKU, ECCV)
- [ ] [\[2312.02702\] Neural Sign Actors: A diffusion model for 3D sign language production from text](https://arxiv.org/abs/2312.02702) (CVPR)
- [ ] [\[2312.02813\] BIVDiff: A Training-Free Framework for General-Purpose Video Synthesis via Bridging Image and Video Diffusion Models](https://arxiv.org/abs/2312.02813) (NJU, CVPR)
- [ ] [\[2312.02843\] Are Vision Transformers More Data Hungry Than Newborn Visual Systems?](https://arxiv.org/abs/2312.02843) (NIPS)
- [ ] [\[2312.02878\] Towards More Practical Group Activity Detection: A New Benchmark and Model](https://arxiv.org/abs/2312.02878) (ECCV)
- [ ] [\[2312.02902\] HeadGaS: Real-Time Animatable Head Avatars via 3D Gaussian Splatting](https://arxiv.org/abs/2312.02902) (ECCV)
- [ ] [\[2312.02914\] Unsupervised Video Domain Adaptation with Masked Pre-Training and Collaborative Self-Training](https://arxiv.org/abs/2312.02914) (CVPR)
- [ ] [\[2312.02918\] Multimodal Prompt Perceiver: Empower Adaptiveness, Generalizability and Fidelity for All-in-One Image Restoration](https://arxiv.org/abs/2312.02918) (IA CAS)
- [ ] [\[2312.02934\] WoVoGen: World Volume-aware Diffusion for Controllable Multi-camera Driving Scene Generation](https://arxiv.org/abs/2312.02934) (Fudan, ECCV)
- [ ] [\[2312.02957\] Classification for everyone : Building geography agnostic models for fairer recognition](https://arxiv.org/abs/2312.02957) (Stanford)
- [ ] [\[2312.02966\] Diffusion-SS3D: Diffusion Model for Semi-supervised 3D Object Detection](https://arxiv.org/abs/2312.02966) (NIPS)
- [ ] [\[2312.02974\] Describing Differences in Image Sets with Natural Language](https://arxiv.org/abs/2312.02974) (Berkeley, CVPR)
- [ ] [\[2312.02980\] GPT4Point: A Unified Framework for Point-Language Understanding and Generation](https://arxiv.org/abs/2312.02980) (Shanghai AI Lab)
- [ ] [\[2312.02985\] FocalPose++: Focal Length and Object Pose Estimation via Render and Compare](https://arxiv.org/abs/2312.02985) (Meta)
- [ ] [\[2312.03011\] InstructBooth: Instruction-following Personalized Text-to-Image Generation](https://arxiv.org/abs/2312.03011) (KAIST)
- [ ] [\[2312.03015\] PartSLIP++: Enhancing Low-Shot 3D Part Segmentation via Multi-View Instance Segmentation and Maximum Likelihood Estimation](https://arxiv.org/abs/2312.03015) (UCSD)
- [ ] [\[2312.03030\] Generating Visually Realistic Adversarial Patch](https://arxiv.org/abs/2312.03030) (HUST)
- [ ] [\[2312.03031\] Is Ego Status All You Need for Open-Loop End-to-End Autonomous Driving?](https://arxiv.org/abs/2312.03031) (NVIDIA, CVPR)
- [ ] [\[2312.03033\] LiDAR-based Person Re-identification](https://arxiv.org/abs/2312.03033) (BIT)
- [ ] [\[2312.03035\] SEVA: Leveraging sketches to evaluate alignment between human and machine visual abstraction](https://arxiv.org/abs/2312.03035) (NIPS)
- [ ] [\[2312.03045\] Customization Assistant for Text-to-image Generation](https://arxiv.org/abs/2312.03045) (CVPR)
- [ ] [\[2312.03048\] DGInStyle: Domain-Generalizable Semantic Segmentation with Image Diffusion Models and Stylized Semantic Control](https://arxiv.org/abs/2312.03048) (ECCV)
- [ ] [\[2312.03050\] HIG: Hierarchical Interlacement Graph Approach to Scene Graph Generation in Video Understanding](https://arxiv.org/abs/2312.03050) (CVPR)
- [ ] [\[2312.03052\] Visual Program Distillation: Distilling Tools and Programmatic Reasoning into Vision-Language Models](https://arxiv.org/abs/2312.03052) (CVPR)
- [ ] [\[2312.03160\] HybridNeRF: Efficient Neural Rendering via Adaptive Volumetric Surfaces](https://arxiv.org/abs/2312.03160) (CVPR)
- [ ] [\[2312.03207\] Satellite Imagery and AI: A New Era in Ocean Conservation, from Research to Deployment and Impact](https://arxiv.org/abs/2312.03207) (NIPS)
- [ ] [\[2312.03209\] Cache Me if You Can: Accelerating Diffusion Models through Block Caching](https://arxiv.org/abs/2312.03209) (TUM)
- [ ] [\[2312.03222\] Predicting Scores of Various Aesthetic Attribute Sets by Learning from Overall Score Labels](https://arxiv.org/abs/2312.03222) (USTC)
- [ ] [\[2312.03226\] Rethinking Object Saliency Ranking: A Novel Whole-flow Processing Paradigm](https://arxiv.org/abs/2312.03226) (Transactions on Image Processing)
- [ ] [\[2312.03266\] SO-NeRF: Active View Planning for NeRF using Surrogate Objectives](https://arxiv.org/abs/2312.03266) (NYU)
- [ ] [\[2312.03298\] DiffPMAE: Diffusion Masked Autoencoders for Point Cloud Reconstruction](https://arxiv.org/abs/2312.03298) (USyd)
- [ ] [\[2312.03341\] Online Vectorized HD Map Construction using Geometry](https://arxiv.org/abs/2312.03341) (BIT, ECCV)
- [ ] [\[2312.03357\] RING-NeRF : Rethinking Inductive Biases for Versatile and Efficient Neural Fields](https://arxiv.org/abs/2312.03357) (ECCV)
- [ ] [\[2312.03406\] SVQ: Sparse Vector Quantization for Spatiotemporal Forecasting](https://arxiv.org/abs/2312.03406) (Alibaba)
- [ ] [\[2312.03408\] Open-sourced Data Ecosystem in Autonomous Driving: the Present and Future](https://arxiv.org/abs/2312.03408) (Shanghai AI Lab)
- [ ] [\[2312.03441\] UFineBench: Towards Text-based Person Retrieval with Ultra-fine Granularity](https://arxiv.org/abs/2312.03441) (HUST)
- [ ] [\[2312.03517\] FRDiff : Feature Reuse for Universal Training-free Acceleration of Diffusion Models](https://arxiv.org/abs/2312.03517) (ECCV)
- [ ] [\[2312.03533\] Low-shot Object Learning with Mutual Exclusivity Bias](https://arxiv.org/abs/2312.03533) (NIPS)
- [ ] [\[2312.03543\] GPT-4 Enhanced Multimodal Grounding for Autonomous Driving: Leveraging Cross-Modal Attention with Large Language Models](https://arxiv.org/abs/2312.03543) (Chongqing)
- [ ] [\[2312.03568\] DocBinFormer: A Two-Level Transformer Network for Effective Document Image Binarization](https://arxiv.org/abs/2312.03568) (NTU)
- [ ] [\[2312.03585\] Foundation Model Assisted Weakly Supervised Semantic Segmentation](https://arxiv.org/abs/2312.03585) (ZJU)
- [ ] [\[2312.03587\] Language-Informed Visual Concept Learning](https://arxiv.org/abs/2312.03587) (ICLR)
- [ ] [\[2312.03596\] MMM: Generative Masked Motion Model](https://arxiv.org/abs/2312.03596) (CVPR)
- [ ] [\[2312.03606\] DiffusionSat: A Generative Foundation Model for Satellite Imagery](https://arxiv.org/abs/2312.03606) (ICLR)
- [ ] [\[2312.03626\] TokenCompose: Text-to-Image Diffusion with Token-level Supervision](https://arxiv.org/abs/2312.03626) (Princeton, CVPR)
- [ ] [\[2312.03628\] Boosting Segment Anything Model Towards Open-Vocabulary Learning](https://arxiv.org/abs/2312.03628) (UCAS)
- [ ] [\[2312.03641\] MotionCtrl: A Unified and Flexible Motion Controller for Video Generation](https://arxiv.org/abs/2312.03641) (HKU, SIGGRAPH)
- [ ] [\[2312.03661\] Reason2Drive: Towards Interpretable and Chain-based Reasoning for Autonomous Driving](https://arxiv.org/abs/2312.03661) (Fudan, ECCV)
- [ ] [\[2312.03667\] WarpDiffusion: Efficient Diffusion Model for High-Fidelity Virtual Try-on](https://arxiv.org/abs/2312.03667) (HKU)
- [ ] [\[2312.03678\] Hybrid Functional Maps for Crease-Aware Non-Isometric Shape Matching](https://arxiv.org/abs/2312.03678) (CVPR)
- [ ] [\[2312.03698\] Intrinsic Harmonization for Illumination-Aware Compositing](https://arxiv.org/abs/2312.03698) (SIGGRAPH)
- [ ] [\[2312.03703\] Skeleton-in-Context: Unified Skeleton Sequence Modeling with In-Context Learning](https://arxiv.org/abs/2312.03703) (ETH)
- [ ] [\[2312.03767\] Unknown Sample Discovery for Source Free Open Set Domain Adaptation](https://arxiv.org/abs/2312.03767) (Rochester Institute of Technology)
- [ ] [\[2312.03781\] Lite-Mind: Towards Efficient and Robust Brain Representation Network](https://arxiv.org/abs/2312.03781) (Tongji, ACMMM)
- [ ] [\[2312.03804\] How Low Can You Go? Surfacing Prototypical In-Distribution Samples for Unsupervised Anomaly Detection](https://arxiv.org/abs/2312.03804) (TUM)
- [ ] [\[2312.03805\] SYNC-CLIP: Synthetic Data Make CLIP Generalize Better in Data-Limited Scenarios](https://arxiv.org/abs/2312.03805) (ZJU)
- [ ] [\[2312.03806\] XCube: Large-Scale 3D Generative Modeling using Sparse Voxel Hierarchies](https://arxiv.org/abs/2312.03806) (CVPR)
- [ ] [\[2312.03808\] SurfaceAug: Closing the Gap in Multimodal Ground Truth Sampling](https://arxiv.org/abs/2312.03808) (CVPR)
- [ ] [\[2312.03818\] Alpha-CLIP: A CLIP Model Focusing on Wherever You Want](https://arxiv.org/abs/2312.03818) (SJTU)
- [ ] [\[2312.03849\] LEGO: Learning EGOcentric Action Frame Generation via Visual Instruction Tuning](https://arxiv.org/abs/2312.03849) (GIT)
- [ ] [\[2312.03913\] Controllable Human-Object Interaction Synthesis](https://arxiv.org/abs/2312.03913) (ECCV)
- [ ] [\[2312.03936\] The Potential of Vision-Language Models for Content Moderation of Children's Videos](https://arxiv.org/abs/2312.03936) (ICML)
- [ ] [\[2312.03996\] Stable Diffusion for Data Augmentation in COCO and Weed Datasets](https://arxiv.org/abs/2312.03996) (Michigan State University)
- [ ] [\[2312.04016\] PartDistill: 3D Shape Part Segmentation by Vision-Language Model Distillation](https://arxiv.org/abs/2312.04016) (CVPR)
- [ ] [\[2312.04043\] Doodle Your 3D: From Abstract Freehand Sketches to Precise 3D Shapes](https://arxiv.org/abs/2312.04043) (CVPR)
- [ ] [\[2312.04060\] Differentiable Registration of Images and LiDAR Point Clouds with VoxelPoint-to-Pixel Matching](https://arxiv.org/abs/2312.04060) (Tsinghua, NIPS)
- [ ] [\[2312.04076\] Large Language Models are Good Prompt Learners for Low-Shot Image Classification](https://arxiv.org/abs/2312.04076) (CVPR)
- [ ] [\[2312.04086\] MEVG: Multi-event Video Generation with Text-to-Video Models](https://arxiv.org/abs/2312.04086) (ECCV)
- [ ] [\[2312.04087\] VRPTEST: Evaluating Visual Referring Prompting in Large Multimodal Models](https://arxiv.org/abs/2312.04087) (NTU)
- [ ] [\[2312.04089\] Open-Vocabulary Segmentation with Semantic-Assisted Calibration](https://arxiv.org/abs/2312.04089) (Tsinghua)
- [ ] [\[2312.04106\] Identity-Obscured Neural Radiance Fields: Privacy-Preserving 3D Facial Reconstruction](https://arxiv.org/abs/2312.04106) (NTU)
- [ ] [\[2312.04113\] Multi-strategy Collaborative Optimized YOLOv5s and its Application in Distance Estimation](https://arxiv.org/abs/2312.04113) (HKUST)
- [ ] [\[2312.04145\] Diffusing Colors: Image Colorization with Text Guided Diffusion](https://arxiv.org/abs/2312.04145) (SIGGRAPH)
- [ ] [\[2312.04168\] Augmentation-Free Dense Contrastive Knowledge Distillation for Efficient Semantic Segmentation](https://arxiv.org/abs/2312.04168) (BUPT, NIPS)
- [ ] [\[2312.04197\] SAMBA: A Trainable Segmentation Web-App with Smart Labelling](https://arxiv.org/abs/2312.04197) (Imperial)
- [ ] [\[2312.04233\] Fine-tuning vision foundation model for crack segmentation in civil infrastructures](https://arxiv.org/abs/2312.04233) (Tsinghua)
- [ ] [\[2312.04266\] Activity Grammars for Temporal Action Segmentation](https://arxiv.org/abs/2312.04266) (NIPS)
- [ ] [\[2312.04302\] Prompt Highlighter: Interactive Control for Multi-Modal LLMs](https://arxiv.org/abs/2312.04302) (CVPR)
- [ ] [\[2312.04314\] GPT4SGG: Synthesizing Scene Graphs from Holistic and Region-specific Narratives](https://arxiv.org/abs/2312.04314) (IA CAS)
- [ ] [\[2312.04326\] iDesigner: A High-Resolution and Complex-Prompt Following Text-to-Image Diffusion Model for Interior Design](https://arxiv.org/abs/2312.04326) (UW)
- [ ] [\[2312.04328\] A Multi-scale Information Integration Framework for Infrared and Visible Image Fusion](https://arxiv.org/abs/2312.04328) (Xidian)
- [ ] [\[2312.04403\] OT-Attack: Enhancing Adversarial Transferability of Vision-Language Models via Optimal Transport Optimization](https://arxiv.org/abs/2312.04403) (SYSU)
- [ ] [\[2312.04424\] Cascade-Zero123: One Image to Highly Consistent 3D with Self-Prompted Nearby Views](https://arxiv.org/abs/2312.04424) (ECCV)
- [ ] [\[2312.04433\] DreamVideo: Composing Your Dream Videos with Customized Subject and Motion](https://arxiv.org/abs/2312.04433) (Fudan)
- [ ] [\[2312.04466\] Emotional Speech-driven 3D Body Animation via Disentangled Latent Diffusion](https://arxiv.org/abs/2312.04466) (CVPR)
- [ ] [\[2312.04483\] Hierarchical Spatio-temporal Decoupling for Text-to-Video Generation](https://arxiv.org/abs/2312.04483) (Fudan)
- [ ] [\[2312.04519\] Bootstrapping Autonomous Driving Radars with Self-Supervised Learning](https://arxiv.org/abs/2312.04519) (Computer Vision and Pattern Recognition)
- [ ] [\[2312.04521\] Multimodal Industrial Anomaly Detection by Crossmodal Feature Mapping](https://arxiv.org/abs/2312.04521) (CVPR)
- [ ] [\[2312.04524\] RAVE: Randomized Noise Shuffling for Fast and Consistent Video Editing with Diffusion Models](https://arxiv.org/abs/2312.04524) (GIT)
- [ ] [\[2312.04529\] Diffusion Reflectance Map: Single-Image Stochastic Inverse Rendering of Illumination and Reflectance](https://arxiv.org/abs/2312.04529) (CVPR)
- [ ] [\[2312.04543\] HyperDreamer: Hyper-Realistic 3D Content Generation and Editing from a Single Image](https://arxiv.org/abs/2312.04543) (CUHK, SIGGRAPH)
- [ ] [\[2312.04552\] Generating Illustrated Instructions](https://arxiv.org/abs/2312.04552) (CVPR)
- [ ] [\[2312.04553\] SPIDeRS: Structured Polarization for Invisible Depth and Reflectance Sensing](https://arxiv.org/abs/2312.04553) (CVPR)
- [ ] [\[2312.04557\] GenTron: Diffusion Transformers for Image and Video Generation](https://arxiv.org/abs/2312.04557) (CVPR)
- [ ] [\[2312.04559\] PrimDiffusion: Volumetric Primitives Diffusion for 3D Human Generation](https://arxiv.org/abs/2312.04559) (NIPS)
- [ ] [\[2312.04564\] EAGLES: Efficient Accelerated 3D Gaussians with Lightweight EncodingS](https://arxiv.org/abs/2312.04564) (UMD)
- [ ] [\[2312.04565\] MuRF: Multi-Baseline Radiance Fields](https://arxiv.org/abs/2312.04565) (CVPR)
- [ ] [\[2312.04651\] VOODOO 3D: Volumetric Portrait Disentanglement for One-Shot 3D Head Reenactment](https://arxiv.org/abs/2312.04651) (ETH)
- [ ] [\[2312.04784\] Reality's Canvas, Language's Brush: Crafting 3D Avatars from Monocular Video](https://arxiv.org/abs/2312.04784) (TUM)
- [ ] [\[2312.04793\] User-Aware Prefix-Tuning is a Good Learner for Personalized Image Captioning](https://arxiv.org/abs/2312.04793) (UW)
- [ ] [\[2312.04813\] DARNet: Bridging Domain Gaps in Cross-Domain Few-Shot Segmentation with Dynamic Adaptation](https://arxiv.org/abs/2312.04813) (HKUST)
- [ ] [\[2312.04821\] Unify Change Point Detection and Segment Classification in a Regression Task for Transportation Mode Identification](https://arxiv.org/abs/2312.04821) (Tsinghua)
- [ ] [\[2312.04823\] Assessing Neural Network Representations During Training Using Noise-Resilient Diffusion Spectral Entropy](https://arxiv.org/abs/2312.04823) (Yale)
- [ ] [\[2312.04861\] Exploring Radar Data Representations in Autonomous Driving: A Comprehensive Review](https://arxiv.org/abs/2312.04861) (HKUST(GZ))
- [ ] [\[2312.04891\] Cross-BERT for Point Cloud Pretraining](https://arxiv.org/abs/2312.04891) (PolyU)
- [ ] [\[2312.04913\] SA-Attack: Improving Adversarial Transferability of Vision-Language Pre-training Models via Self-Augmentation](https://arxiv.org/abs/2312.04913) (SYSU)
- [ ] [\[2312.04931\] Retrieval-based Video Language Model for Efficient Long Video Question Answering](https://arxiv.org/abs/2312.04931) (USTC)
- [ ] [\[2312.04947\] Benchmarking and Analysis of Unsupervised Object Segmentation from Real-world Single Images](https://arxiv.org/abs/2312.04947) (PolyU)
- [ ] [\[2312.04964\] ZePT: Zero-Shot Pan-Tumor Segmentation via Query-Disentangling and Self-Prompting](https://arxiv.org/abs/2312.04964) (Shanghai AI Lab, CVPR)
- [ ] [\[2312.05006\] Decoupling Degradation and Content Processing for Adverse Weather Image Restoration](https://arxiv.org/abs/2312.05006) (USTC)
- [ ] [\[2312.05024\] A Unified Framework for Unsupervised Domain Adaptation based on Instance Weighting](https://arxiv.org/abs/2312.05024) (SUSTech)
- [ ] [\[2312.05133\] GIR: 3D Gaussian Inverse Rendering for Relightable Scene Factorization](https://arxiv.org/abs/2312.05133) (Peking)
- [ ] [\[2312.05161\] TriHuman : A Real-time and Controllable Tri-plane Representation for Detailed Human Geometry and Appearance Synthesis](https://arxiv.org/abs/2312.05161) (MPI)
- [ ] [\[2312.05210\] IntrinsicAvatar: Physically Based Inverse Rendering of Dynamic Humans from Monocular Videos via Explicit Ray Tracing](https://arxiv.org/abs/2312.05210) (CVPR)
- [ ] [\[2312.05219\] Enhancing Facial Classification and Recognition using 3D Facial Models and Deep Learning](https://arxiv.org/abs/2312.05219) (CUHK)
- [ ] [\[2312.05229\] Few-Shot Class-Incremental Learning via Training-Free Prototype Calibration](https://arxiv.org/abs/2312.05229) (NIPS)
- [ ] [\[2312.05239\] SwiftBrush: One-Step Text-to-Image Diffusion Model with Variational Score Distillation](https://arxiv.org/abs/2312.05239) (CVPR)
- [ ] [\[2312.05272\] GenQ: Quantization in Low Data Regimes with Generative Synthetic Data](https://arxiv.org/abs/2312.05272) (ECCV)
- [ ] [\[2312.05277\] 3D Copy-Paste: Physically Plausible Object Insertion for Monocular 3D Detection](https://arxiv.org/abs/2312.05277) (NIPS)
- [ ] [\[2312.05284\] SlimSAM: 0.1% Data Makes Segment Anything Slim](https://arxiv.org/abs/2312.05284) (NUS)
- [ ] [\[2312.05286\] Bridging Synthetic and Real Worlds for Pre-training Scene Text Detectors](https://arxiv.org/abs/2312.05286) (Shanghai AI Lab, ECCV)
- [ ] [\[2312.05287\] Human-in-the-Loop Visual Re-ID for Population Size Estimation](https://arxiv.org/abs/2312.05287) (Berkeley)
- [ ] [\[2312.05291\] GlitchBench: Can large multimodal models detect video game glitches?](https://arxiv.org/abs/2312.05291) (CVPR)
- [ ] [\[2312.05447\] From Static to Dynamic: Adapting Landmark-Aware Image Models for Facial Expression Recognition in Videos](https://arxiv.org/abs/2312.05447) (ICT CAS)
- [ ] [\[2312.05464\] Identifying and Mitigating Model Failures through Few-shot CLIP-aided Diffusion Generation](https://arxiv.org/abs/2312.05464) (UMD)
- [ ] [\[2312.05482\] BARET : Balanced Attention based Real image Editing driven by Target-text Inversion](https://arxiv.org/abs/2312.05482) (Tsinghua)
- [ ] [\[2312.05490\] Shapley Values-enabled Progressive Pseudo Bag Augmentation for Whole Slide Image Classification](https://arxiv.org/abs/2312.05490) (HKUST)
- [ ] [\[2312.05525\] You Only Learn One Query: Learning Unified Human Query for Single-Stage Multi-Person Multi-Task Human-Centric Perception](https://arxiv.org/abs/2312.05525) (HKU, ECCV)
- [ ] [\[2312.05538\] CSL: Class-Agnostic Structure-Constrained Learning for Segmentation Including the Unseen](https://arxiv.org/abs/2312.05538) (Illinois)
- [ ] [\[2312.05664\] CoGS: Controllable Gaussian Splatting](https://arxiv.org/abs/2312.05664) (CMU, CVPR)
- [ ] [\[2312.05695\] The Counterattack of CNNs in Self-Supervised Learning: Larger Kernel Size might be All You Need](https://arxiv.org/abs/2312.05695) (MIT)
- [ ] [\[2312.05716\] Initialization Matters for Adversarial Transfer Learning](https://arxiv.org/abs/2312.05716) (CVPR)
- [ ] [\[2312.05752\] Camera-based 3D Semantic Scene Completion with Sparse Guidance Network](https://arxiv.org/abs/2312.05752) (ZJU)
- [ ] [\[2312.05760\] RepViT-SAM: Towards Real-Time Segmenting Anything](https://arxiv.org/abs/2312.05760) (Tsinghua, CVPR)
- [ ] [\[2312.05798\] Disentangled Representation Learning for Controllable Person Image Generation](https://arxiv.org/abs/2312.05798) (AWS)
- [ ] [\[2312.05803\] Transformer-based Selective Super-Resolution for Efficient Image Refinement](https://arxiv.org/abs/2312.05803) (Cornell)
- [ ] [\[2312.05832\] Spatial-wise Dynamic Distillation for MLP-like Efficient Visual Fault Detection of Freight Trains](https://arxiv.org/abs/2312.05832) (CUHK)
- [ ] [\[2312.05849\] InteractDiffusion: Interaction Control in Text-to-Image Diffusion Models](https://arxiv.org/abs/2312.05849) (NTU, CVPR)
- [ ] [\[2312.05856\] A Video is Worth 256 Bases: Spatial-Temporal Expectation-Maximization Inversion for Zero-Shot Video Editing](https://arxiv.org/abs/2312.05856) (HKU)
- [ ] [\[2312.05889\] SuperPrimitive: Scene Reconstruction at a Primitive Level](https://arxiv.org/abs/2312.05889) (CVPR)
- [ ] [\[2312.05897\] PSCR: Patches Sampling-based Contrastive Regression for AIGC Image Quality Assessment](https://arxiv.org/abs/2312.05897) (Peking)
- [ ] [\[2312.05924\] Data-Free Hard-Label Robustness Stealing Attack](https://arxiv.org/abs/2312.05924) (USTC)
- [ ] [\[2312.05984\] Accurate Differential Operators for Hybrid Neural Fields](https://arxiv.org/abs/2312.05984) (Cornell)
- [ ] [\[2312.05995\] From Correspondences to Pose: Non-minimal Certifiably Optimal Relative Pose without Disambiguation](https://arxiv.org/abs/2312.05995) (CVPR)
- [ ] [\[2312.06038\] Correcting Diffusion Generation through Resampling](https://arxiv.org/abs/2312.06038) (MIT)
- [ ] [\[2312.06052\] MaskConver: Revisiting Pure Convolution Model for Panoptic Segmentation](https://arxiv.org/abs/2312.06052) (Google)
- [ ] [\[2312.06063\] PCRDiffusion: Diffusion Probabilistic Models for Point Cloud Registration](https://arxiv.org/abs/2312.06063) (Xidian)
- [ ] [\[2312.06069\] Mining Gaze for Contrastive Learning toward Computer-Assisted Diagnosis](https://arxiv.org/abs/2312.06069) (SJTU)
- [ ] [\[2312.06075\] Oracle Character Recognition using Unsupervised Discriminative Consistency Network](https://arxiv.org/abs/2312.06075) (BUPT)
- [ ] [\[2312.06085\] Robust Geometry and Reflectance Disentanglement for 3D Face Reconstruction from Sparse-view Images](https://arxiv.org/abs/2312.06085) (NTU)
- [ ] [\[2312.06106\] AUGCAL: Improving Sim2Real Adaptation by Uncertainty Calibration on Augmented Synthetic Images](https://arxiv.org/abs/2312.06106) (ICLR)
- [ ] [\[2312.06112\] MAFA: Managing False Negatives for Vision-Language Pre-training](https://arxiv.org/abs/2312.06112) (CVPR)
- [ ] [\[2312.06113\] SimMining-3D: Altitude-Aware 3D Object Detection in Complex Mining Environments: A Novel Dataset and ROS-Based Automatic Annotation Pipeline](https://arxiv.org/abs/2312.06113) (USyd)
- [ ] [\[2312.06117\] M3SOT: Multi-frame, Multi-field, Multi-space 3D Single Object Tracking](https://arxiv.org/abs/2312.06117) (Xidian)
- [ ] [\[2312.06163\] Adversarial Camera Patch: An Effective and Robust Physical-World Attack on Object Detectors](https://arxiv.org/abs/2312.06163) (UESTC)
- [ ] [\[2312.06164\] Implicit Shape Modeling for Anatomical Structure Refinement of Volumetric Medical Images](https://arxiv.org/abs/2312.06164) (SJTU)
- [ ] [\[2312.06171\] Jointly Explicit and Implicit Cross-Modal Interaction Network for Anterior Chamber Inflammation Diagnosis](https://arxiv.org/abs/2312.06171) (ZJU)
- [ ] [\[2312.06221\] CSOT: Curriculum and Structure-Aware Optimal Transport for Learning with Noisy Labels](https://arxiv.org/abs/2312.06221) (NIPS)
- [ ] [\[2312.06226\] Invariant Representation via Decoupling Style and Spurious Features from Images](https://arxiv.org/abs/2312.06226) (USTC)
- [ ] [\[2312.06240\] UIEDP:Underwater Image Enhancement with Diffusion Prior](https://arxiv.org/abs/2312.06240) (Tsinghua)
- [ ] [\[2312.06259\] Adaptive Annotation Distribution for Weakly Supervised Point Cloud Semantic Segmentation](https://arxiv.org/abs/2312.06259) (Peking)
- [ ] [\[2312.06299\] RCA-NOC: Relative Contrastive Alignment for Novel Object Captioning](https://arxiv.org/abs/2312.06299) (ICCV)
- [ ] [\[2312.06323\] Learning Hierarchical Prompt with Structured Linguistic Knowledge for Vision-Language Models](https://arxiv.org/abs/2312.06323) (Tongji)
- [ ] [\[2312.06351\] Evaluation of Large Language Models for Decision Making in Autonomous Driving](https://arxiv.org/abs/2312.06351) (NIPS)
- [ ] [\[2312.06358\] Intraoperative 2D/3D Image Registration via Differentiable X-ray Rendering](https://arxiv.org/abs/2312.06358) (CVPR)
- [ ] [\[2312.06372\] Ternary Spike: Learning Ternary Spikes for Spiking Neural Networks](https://arxiv.org/abs/2312.06372) (Peking)
- [ ] [\[2312.06398\] NVFi: Neural Velocity Fields for 3D Physics Learning from Dynamic Videos](https://arxiv.org/abs/2312.06398) (PolyU, NIPS)
- [ ] [\[2312.06401\] Compound Text-Guided Prompt Tuning via Image-Adaptive Cues](https://arxiv.org/abs/2312.06401) (IA CAS)
- [ ] [\[2312.06428\] VisionTraj: A Noise-Robust Trajectory Recovery Framework based on Large-scale Camera Network](https://arxiv.org/abs/2312.06428) (SenseTime)
- [ ] [\[2312.06439\] DreamControl: Control-Based Text-to-3D Generation with 3D Self-Prior](https://arxiv.org/abs/2312.06439) (CVPR)
- [ ] [\[2312.06462\] Cooperation Does Matter: Exploring Multi-Order Bilateral Relations for Audio-Visual Segmentation](https://arxiv.org/abs/2312.06462) (CVPR)
- [ ] [\[2312.06474\] Relevant Intrinsic Feature Enhancement Network for Few-Shot Semantic Segmentation](https://arxiv.org/abs/2312.06474) (IA CAS)
- [ ] [\[2312.06505\] Grounded Question-Answering in Long Egocentric Videos](https://arxiv.org/abs/2312.06505) (CVPR)
- [ ] [\[2312.06561\] Inferring Hybrid Neural Fluid Fields from Videos](https://arxiv.org/abs/2312.06561) (NIPS)
- [ ] [\[2312.06575\] EasyVolcap: Accelerating Neural Volumetric Video Research](https://arxiv.org/abs/2312.06575) (ZJU, SIGGRAPH)
- [ ] [\[2312.06630\] TMT-VIS: Taxonomy-aware Multi-dataset Joint Training for Video Instance Segmentation](https://arxiv.org/abs/2312.06630) (NIPS)
- [ ] [\[2312.06642\] CorresNeRF: Image Correspondence Priors for Neural Radiance Fields](https://arxiv.org/abs/2312.06642) (HKU)
- [ ] [\[2312.06644\] AnyHome: Open-Vocabulary Generation of Structured and Textured 3D Homes](https://arxiv.org/abs/2312.06644) (ECCV)
- [ ] [\[2312.06645\] Beyond Classification: Definition and Density-based Estimation of Calibration in Object Detection](https://arxiv.org/abs/2312.06645) (KU Leuven)
- [ ] [\[2312.06647\] 4M: Massively Multimodal Masked Modeling](https://arxiv.org/abs/2312.06647) (NIPS)
- [ ] [\[2312.06653\] Adaptive Human Trajectory Prediction via Latent Corridors](https://arxiv.org/abs/2312.06653) (ECCV)
- [ ] [\[2312.06654\] LightSim: Neural Lighting Simulation for Urban Scenes](https://arxiv.org/abs/2312.06654) (NIPS)
- [ ] [\[2312.06704\] SIFU: Side-view Conditioned Implicit Function for Real-world Usable Clothed Human Reconstruction](https://arxiv.org/abs/2312.06704) (CVPR)
- [ ] [\[2312.06709\] AM-RADIO: Agglomerative Vision Foundation Model -- Reduce All Domains Into One](https://arxiv.org/abs/2312.06709) (CVPR)
- [ ] [\[2312.06712\] Separate-and-Enhance: Compositional Finetuning for Text2Image Diffusion Models](https://arxiv.org/abs/2312.06712) (Illinois)
- [ ] [\[2312.06716\] Deciphering 'What' and 'Where' Visual Pathways from Spectral Clustering of Layer-Distributed Neural Representations](https://arxiv.org/abs/2312.06716) (CVPR)
- [ ] [\[2312.06721\] Understanding Physical Dynamics with Counterfactual World Modeling](https://arxiv.org/abs/2312.06721) (ECCV)
- [ ] [\[2312.06726\] Filter & Align: Leveraging Human Knowledge to Curate Image-Text Data](https://arxiv.org/abs/2312.06726) (ZJU)
- [ ] [\[2312.06731\] Genixer: Empowering Multimodal Large Language Models as a Powerful Data Generator](https://arxiv.org/abs/2312.06731) (ECCV)
- [ ] [\[2312.06733\] TULIP: Transformer for Upsampling of LiDAR Point Clouds](https://arxiv.org/abs/2312.06733) (CVPR)
- [ ] [\[2312.06734\] DiffCast: A Unified Framework via Residual Diffusion for Precipitation Nowcasting](https://arxiv.org/abs/2312.06734) (HIT, CVPR)
- [ ] [\[2312.06741\] Gaussian Splatting SLAM](https://arxiv.org/abs/2312.06741) (CVPR)
- [ ] [\[2312.06742\] Honeybee: Locality-enhanced Projector for Multimodal LLM](https://arxiv.org/abs/2312.06742) (CVPR)
- [ ] [\[2312.06797\] Improving the Robustness of 3D Human Pose Estimation: A Benchmark and Learning from Noisy Input](https://arxiv.org/abs/2312.06797) (University of Tokyo)
- [ ] [\[2312.06886\] Relightful Harmonization: Lighting-aware Portrait Background Replacement](https://arxiv.org/abs/2312.06886) (CVPR)
- [ ] [\[2312.06947\] MaTe3D: Mask-guided Text-based 3D-aware Portrait Editing](https://arxiv.org/abs/2312.06947) (Nankai)
- [ ] [\[2312.06960\] Remote Sensing Vision-Language Foundation Models without Annotations via Ground Remote Alignment](https://arxiv.org/abs/2312.06960) (Columbia University)
- [ ] [\[2312.06968\] Hallucination Augmented Contrastive Learning for Multimodal Large Language Model](https://arxiv.org/abs/2312.06968) (Alibaba)
- [ ] [\[2312.06988\] MWSIS: Multimodal Weakly Supervised Instance Segmentation with 2D Box Annotations for Autonomous Driving](https://arxiv.org/abs/2312.06988) (USTC)
- [ ] [\[2312.07006\] Mixed Pseudo Labels for Semi-Supervised Object Detection](https://arxiv.org/abs/2312.07006) (Tsinghua)
- [ ] [\[2312.07051\] Mask as Supervision: Leveraging Unified Mask Information for Unsupervised 3D Pose Estimation](https://arxiv.org/abs/2312.07051) (Fudan, ECCV)
- [ ] [\[2312.07061\] MaxQ: Multi-Axis Query for N:M Sparsity Network](https://arxiv.org/abs/2312.07061) (CVPR)
- [ ] [\[2312.07063\] Template Free Reconstruction of Human-object Interaction with Procedural Interaction Generation](https://arxiv.org/abs/2312.07063) (CVPR)
- [ ] [\[2312.07079\] Spatial-Contextual Discrepancy Information Compensation for GAN Inversion](https://arxiv.org/abs/2312.07079) (Xiamen)
- [ ] [\[2312.07165\] Language-Guided Transformer for Federated Multi-Label Classification](https://arxiv.org/abs/2312.07165) (NVIDIA)
- [ ] [\[2312.07180\] Context-Aware Iteration Policy Network for Efficient Optical Flow Estimation](https://arxiv.org/abs/2312.07180) (Fudan)
- [ ] [\[2312.07246\] Unifying Correspondence, Pose and NeRF for Pose-Free Novel View Synthesis from Stereo Pairs](https://arxiv.org/abs/2312.07246) (CVPR)
- [ ] [\[2312.07264\] Dual Structure-Aware Image Filterings for Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2312.07264) (WHU)
- [ ] [\[2312.07266\] ProxyDet: Synthesizing Proxy Novel Classes via Classwise Mixup for Open-Vocabulary Object Detection](https://arxiv.org/abs/2312.07266) (KAIST)
- [ ] [\[2312.07311\] Scalable Motion Style Transfer with Constrained Diffusion Generation](https://arxiv.org/abs/2312.07311) (University of Copenhagen)
- [ ] [\[2312.07315\] NVS-Adapter: Plug-and-Play Novel View Synthesis from a Single Image](https://arxiv.org/abs/2312.07315) (ECCV)
- [ ] [\[2312.07322\] GenHowTo: Learning to Generate Actions and State Transformations from Instructional Videos](https://arxiv.org/abs/2312.07322) (CVPR)
- [ ] [\[2312.07327\] Adaptive Confidence Multi-View Hashing for Multimedia Retrieval](https://arxiv.org/abs/2312.07327) (USTC)
- [ ] [\[2312.07353\] CLIP in Medical Imaging: A Comprehensive Survey](https://arxiv.org/abs/2312.07353) (ShanghaiTech)
- [ ] [\[2312.07364\] Collapse-Aware Triplet Decoupling for Adversarially Robust Image Retrieval](https://arxiv.org/abs/2312.07364) (XJTU, ICML)
- [ ] [\[2312.07381\] ScribblePrompt: Fast and Flexible Interactive Segmentation for Any Biomedical Image](https://arxiv.org/abs/2312.07381) (ECCV)
- [ ] [\[2312.07385\] GSmoothFace: Generalized Smooth Talking Face Generation via Fine Grained 3D Face Guidance](https://arxiv.org/abs/2312.07385) (SYSU)
- [ ] [\[2312.07423\] Holoported Characters: Real-time Free-viewpoint Rendering of Humans from Sparse RGB Cameras](https://arxiv.org/abs/2312.07423) (CVPR)
- [ ] [\[2312.07472\] MP5: A Multi-modal Open-ended Embodied System in Minecraft via Active Perception](https://arxiv.org/abs/2312.07472) (Shanghai AI Lab, CVPR)
- [ ] [\[2312.07485\] MinD-3D: Reconstruct High-quality 3D objects in Human Brain](https://arxiv.org/abs/2312.07485) (Fudan, ECCV)
- [ ] [\[2312.07495\] Exploring Plain ViT Reconstruction for Multi-class Unsupervised Anomaly Detection](https://arxiv.org/abs/2312.07495) (ZJU)
- [ ] [\[2312.07526\] RTMO: Towards High-Performance One-Stage Real-Time Multi-Person Pose Estimation](https://arxiv.org/abs/2312.07526) (Tsinghua, CVPR)
- [ ] [\[2312.07530\] Weakly Supervised 3D Object Detection via Multi-Level Visual Guidance](https://arxiv.org/abs/2312.07530) (ECCV)
- [ ] [\[2312.07533\] VILA: On Pre-training for Visual Language Models](https://arxiv.org/abs/2312.07533) (CVPR)
- [ ] [\[2312.07539\] HeadArtist: Text-conditioned 3D Head Generation with Self Score Distillation](https://arxiv.org/abs/2312.07539) (HKUST, SIGGRAPH)
- [ ] [\[2312.07571\] Investigating YOLO Models Towards Outdoor Obstacle Detection For Visually Impaired People](https://arxiv.org/abs/2312.07571) (Oxford)
- [ ] [\[2312.07586\] Characteristic Guidance: Non-linear Correction for Diffusion Model at Large Guidance Scale](https://arxiv.org/abs/2312.07586) (HKUST)
- [ ] [\[2312.07623\] Supervised Contrastive Learning for Fine-grained Chromosome Recognition](https://arxiv.org/abs/2312.07623) (SJTU)
- [ ] [\[2312.07661\] CLIP as RNN: Segment Countless Visual Concepts without Training Endeavor](https://arxiv.org/abs/2312.07661) (CVPR)
- [ ] [\[2312.07723\] Automated Behavioral Analysis Using Instance Segmentation](https://arxiv.org/abs/2312.07723) (Cornell)
- [ ] [\[2312.07806\] Contextually Affinitive Neighborhood Refinery for Deep Clustering](https://arxiv.org/abs/2312.07806) (NIPS)
- [ ] [\[2312.07814\] A Foundational Multimodal Vision Language AI Assistant for Human Pathology](https://arxiv.org/abs/2312.07814) (Harvard)
- [ ] [\[2312.07823\] Semantic Lens: Instance-Centric Semantic Alignment for Video Super-Resolution](https://arxiv.org/abs/2312.07823) (NTU)
- [ ] [\[2312.07835\] Video Dynamics Prior: An Internal Learning Approach for Robust Video Enhancements](https://arxiv.org/abs/2312.07835) (UMD, NIPS)
- [ ] [\[2312.07853\] High-Order Structure Based Middle-Feature Learning for Visible-Infrared Person Re-Identification](https://arxiv.org/abs/2312.07853) (Xiamen)
- [ ] [\[2312.07856\] DTL: Disentangled Transfer Learning for Visual Recognition](https://arxiv.org/abs/2312.07856) (NJU)
- [ ] [\[2312.07865\] SimAC: A Simple Anti-Customization Method for Protecting Face Privacy against Text-to-Image Synthesis of Diffusion Models](https://arxiv.org/abs/2312.07865) (Alibaba, CVPR)
- [ ] [\[2312.07875\] Enhance Sketch Recognition's Explainability via Semantic Component-Level Parsing](https://arxiv.org/abs/2312.07875) (Xidian)
- [ ] [\[2312.07884\] Mutual-Learning Knowledge Distillation for Nighttime UAV Tracking](https://arxiv.org/abs/2312.07884) (Tongji)
- [ ] [\[2312.07937\] BOTH2Hands: Inferring 3D Hands from Both Text Prompts and Body Dynamics](https://arxiv.org/abs/2312.07937) (CVPR)
- [ ] [\[2312.07943\] ReFusion: Learning Image Fusion from Reconstruction with Learnable Loss via Meta-Learning](https://arxiv.org/abs/2312.07943) (XJTU)
- [ ] [\[2312.07955\] Erasing Self-Supervised Learning Backdoor by Cluster Activation Masking](https://arxiv.org/abs/2312.07955) (IA CAS)
- [ ] [\[2312.07971\] LMD: Faster Image Reconstruction with Latent Masking Diffusion](https://arxiv.org/abs/2312.07971) (Tsinghua)
- [ ] [\[2312.08007\] Unveiling Parts Beyond Objects:Towards Finer-Granularity Referring Expression Segmentation](https://arxiv.org/abs/2312.08007) (IA CAS, CVPR)
- [ ] [\[2312.08048\] Compositional Inversion for Stable Diffusion Models](https://arxiv.org/abs/2312.08048) (PolyU)
- [ ] [\[2312.08054\] Semantic Complete Scene Forecasting from a 4D Dynamic Point Cloud Sequence](https://arxiv.org/abs/2312.08054) (Tsinghua)
- [ ] [\[2312.08056\] Knowledge-Aware Artifact Image Synthesis with LLM-Enhanced Prompting and Multi-Source Supervision](https://arxiv.org/abs/2312.08056) (Peking)
- [ ] [\[2312.08071\] Novel View Synthesis with View-Dependent Effects from a Single Image](https://arxiv.org/abs/2312.08071) (KAIST)
- [ ] [\[2312.08078\] Fine-Grained Image-Text Alignment in Medical Imaging Enables Explainable Cyclic Image-Report Generation](https://arxiv.org/abs/2312.08078) (CUHK)
- [ ] [\[2312.08220\] EventAid: Benchmarking Event-aided Image/Video Enhancement Algorithms with Real-captured Hybrid Dataset](https://arxiv.org/abs/2312.08220) (Peking)
- [ ] [\[2312.08234\] Beyond the Label Itself: Latent Labels Enhance Semi-supervised Point Cloud Panoptic Segmentation](https://arxiv.org/abs/2312.08234) (Xiamen)
- [ ] [\[2312.08338\] Global Latent Neural Rendering](https://arxiv.org/abs/2312.08338) (CVPR)
- [ ] [\[2312.08371\] PTT: Point-Trajectory Transformer for Efficient Temporal 3D Object Detection](https://arxiv.org/abs/2312.08371) (CVPR)
- [ ] [\[2312.08568\] NViST: In the Wild New View Synthesis from a Single Image with Transformers](https://arxiv.org/abs/2312.08568) (CVPR)
- [ ] [\[2312.08578\] A Picture is Worth More Than 77 Text Tokens: Evaluating CLIP-Style Models on Dense Captions](https://arxiv.org/abs/2312.08578) (Meta)
- [ ] [\[2312.08628\] YOLO-OB: An improved anchor-free real-time multiscale colon polyp detector in colonoscopy](https://arxiv.org/abs/2312.08628) (HUST)
- [ ] [\[2312.08636\] MmAP : Multi-modal Alignment Prompt for Cross-domain Multi-task Learning](https://arxiv.org/abs/2312.08636) (NJU)
- [ ] [\[2312.08644\] Generative Model-based Feature Knowledge Distillation for Action Recognition](https://arxiv.org/abs/2312.08644) (XJTU)
- [ ] [\[2312.08648\] CLIP-guided Federated Learning on Heterogeneous and Long-Tailed Data](https://arxiv.org/abs/2312.08648) (Xiamen)
- [ ] [\[2312.08664\] SPEAL: Skeletal Prior Embedded Attention Learning for Cross-Source Point Cloud Registration](https://arxiv.org/abs/2312.08664) (NTU)
- [ ] [\[2312.08733\] VMT-Adapter: Parameter-Efficient Transfer Learning for Multi-Task Dense Scene Understanding](https://arxiv.org/abs/2312.08733) (NJU)
- [ ] [\[2312.08744\] GOEmbed: Gradient Origin Embeddings for Representation Agnostic 3D Feature Learning](https://arxiv.org/abs/2312.08744) (ECCV)
- [ ] [\[2312.08754\] UniDream: Unifying Diffusion Priors for Relightable Text-to-3D Generation](https://arxiv.org/abs/2312.08754) (ECCV)
- [ ] [\[2312.08760\] CF-NeRF: Camera Parameter Free Neural Radiance Fields with Incremental Learning](https://arxiv.org/abs/2312.08760) (WHU)
- [ ] [\[2312.08822\] Planning and Rendering: Towards Product Poster Generation with Diffusion Models](https://arxiv.org/abs/2312.08822) (Peking)
- [ ] [\[2312.08863\] HeadRecon: High-Fidelity 3D Head Reconstruction from Monocular Video](https://arxiv.org/abs/2312.08863) (USTC)
- [ ] [\[2312.08869\] I'M HOI: Inertia-aware Monocular Capture of 3D Human-Object Interactions](https://arxiv.org/abs/2312.08869) (CVPR)
- [ ] [\[2312.08872\] The Lottery Ticket Hypothesis in Denoising: Towards Semantic-Driven Initialization](https://arxiv.org/abs/2312.08872) (ECCV)
- [ ] [\[2312.08874\] Agent Attention: On the Integration of Softmax and Linear Attention](https://arxiv.org/abs/2312.08874) (ECCV)
- [ ] [\[2312.08881\] AdaptIR: Parameter Efficient Multi-task Adaptation for Pre-trained Image Restoration Models](https://arxiv.org/abs/2312.08881) (HIT)
- [ ] [\[2312.08886\] Diffusion-based Blind Text Image Super-Resolution](https://arxiv.org/abs/2312.08886) (CVPR)
- [ ] [\[2312.08889\] SEEAvatar: Photorealistic Text-to-3D Avatar Generation with Constrained Geometry and Appearance](https://arxiv.org/abs/2312.08889) (ZJU)
- [ ] [\[2312.08892\] VaLID: Variable-Length Input Diffusion for Novel View Synthesis](https://arxiv.org/abs/2312.08892) (UVA.NL)
- [ ] [\[2312.08916\] Progressive Feature Self-reinforcement for Weakly Supervised Semantic Segmentation](https://arxiv.org/abs/2312.08916) (ZJU)
- [ ] [\[2312.08917\] An Incremental Unified Framework for Small Defect Inspection](https://arxiv.org/abs/2312.08917) (HKUST)
- [ ] [\[2312.08951\] Multi-Scene Generalized Trajectory Global Graph Solver with Composite Nodes for Multiple Object Tracking](https://arxiv.org/abs/2312.08951) (Xidian)
- [ ] [\[2312.08962\] Depicting Beyond Scores: Advancing Image Quality Assessment through Multi-modal Language Models](https://arxiv.org/abs/2312.08962) (USyd, ECCV)
- [ ] [\[2312.08963\] LEMON: Learning 3D Human-Object Interaction Relation from 2D Images](https://arxiv.org/abs/2312.08963) (CVPR)
- [ ] [\[2312.08985\] OMG: Towards Open-vocabulary Motion Generation via Mixture of Controllers](https://arxiv.org/abs/2312.08985) (CVPR)
- [ ] [\[2312.09008\] Style Injection in Diffusion: A Training-free Approach for Adapting Large-scale Diffusion Models for Style Transfer](https://arxiv.org/abs/2312.09008) (CVPR)
- [ ] [\[2312.09059\] Auto-Prox: Training-Free Vision Transformer Architecture Search via Automatic Proxy Discovery](https://arxiv.org/abs/2312.09059) (Columbia University)
- [ ] [\[2312.09066\] CMOSE: Comprehensive Multi-Modality Online Student Engagement Dataset with High-Quality Labels](https://arxiv.org/abs/2312.09066) (HKUST)
- [ ] [\[2312.09067\] Holodeck: Language Guided Generation of 3D Embodied AI Environments](https://arxiv.org/abs/2312.09067) (CVPR)
- [ ] [\[2312.09069\] PI3D: Efficient Text-to-3D Generation with Pseudo-Image Diffusion](https://arxiv.org/abs/2312.09069) (CVPR)
- [ ] [\[2312.09138\] Living Scenes: Multi-object Relocalization and Reconstruction in Changing 3D Environments](https://arxiv.org/abs/2312.09138) (CVPR)
- [ ] [\[2312.09154\] CMG-Net: Robust Normal Estimation for Point Clouds via Chamfer Normal Distance and Multi-scale Geometry](https://arxiv.org/abs/2312.09154) (IA CAS)
- [ ] [\[2312.09158\] General Object Foundation Model for Images and Videos at Scale](https://arxiv.org/abs/2312.09158) (HUST)
- [ ] [\[2312.09159\] WIT-UAS: A Wildland-fire Infrared Thermal Dataset to Detect Crew Assets From Aerial Views](https://arxiv.org/abs/2312.09159) (CMU)
- [ ] [\[2312.09168\] DiffusionLight: Light Probes for Free by Painting a Chrome Ball](https://arxiv.org/abs/2312.09168) (CVPR)
- [ ] [\[2312.09181\] Improving Efficiency of Diffusion Models via Multi-Stage Framework and Tailored Multi-Decoder Architectures](https://arxiv.org/abs/2312.09181) (CVPR)
- [ ] [\[2312.09243\] OccNeRF: Advancing 3D Occupancy Prediction in LiDAR-Free Environments](https://arxiv.org/abs/2312.09243) (Tsinghua)
- [ ] [\[2312.09250\] Single Mesh Diffusion Models with Field Latents for Texture Generation](https://arxiv.org/abs/2312.09250) (CVPR)
